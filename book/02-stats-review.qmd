<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7PRVEBE1EF"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-7PRVEBE1EF');
</script>

# Basic Cuisine: A Review on Probability and Frequentist Statistical Inference {#sec-stats-review}

```{r}
#| include: false

colourize <- function(x, color) {
  if (knitr::is_latex_output()) {
    sprintf("\\textcolor{%s}{%s}", color, x)
  } else if (knitr::is_html_output()) {
    sprintf("<span style='color: %s;'>%s</span>", color,
      x)
  } else x
}
```


This chapter will delve into probability and frequentist statistical inference. We can view these sections as a quick review of introductory probability and statistics concepts. Moreover, this review will be important to understanding the philosophy of modelling parameter estimation as outlined in @sec-ds-workflow-estimation. Then, we will pave the way to the rationale behind statistical inference in the *results* stage (as in @sec-ds-workflow-results) in our workflow from @fig-ds-workflow. Note that we aim to explain all these statistical and probabilistic concepts in the most possible practical way via a made-up case study throughout this chapter. Still, we will use an appropriate level of jargon and will follow the colour convention found in @sec-dictionary along with the [**definition callout box**](#Definition-sample).

![Image by [*OpenClipart-Vectors*](https://pixabay.com/users/openclipart-vectors-30363/) via [*Pixabay*](https://pixabay.com/vectors/panda-cute-bear-blue-question-149818/).](img/panda.png){width="400"} 

Imagine you are an undergraduate engineering student. Moreover, last term, you just took and passed your first course in probability and statistics (inference included!) in an industrial engineering context. Moreover, as it could happen while taking an introductory course in probability and statistics, you used to feel quite overwhelmed by the large amount of jargon and formulas one had to grasp and use regularly for primary engineering fields such as quality control in a manufacturing facility. *Population parameters*, *hypothesis testing*, *tests statistics*, *significance level*, *$p$-values*, and *confidence intervals* (**do not worry, our `r colourize("statistical", "blue")`/`r colourize("machine learning", "magenta")` scheme will come in later in this review**) were appearing here and there! And to your frustration, you could never find a statistical connection between all these inferential tools! Instead, you relied on mechanistic procedures when solving assignments or exam problems. 

For instance, when performing hypothesis testing for a two-sample $t$-test, you struggled to reflect what the hypotheses were trying to indicate for the corresponding population parameter(s) or how the test statistic was related to these hypotheses. Moreover, your interpretation of the resulting $p$-value and/or confidence interval was purely mechanical with the inherent claim: 

> *With a significance level $\alpha = 0.05$, we reject (**or fail to reject, if that is the case!**) the null hypothesis given that...* 

Truthfully, this whole mechanical way of doing statistics is not ideal in a teaching, research or industry environment. Along the same lines, the above situation should also not happen when we learn key statistical topics for the very first time as undergraduate students. That is why we will investigate a more intuitive way of viewing probability and its crucial role in statistical inference. This matter will help us deliver more coherent storytelling (as in @sec-ds-workflow-storytelling) when presenting our results in practice during any regression analysis to our peers or stakeholders. Note that the role of probability also extends to model training (as in @sec-ds-workflow-estimation) when it comes to supervised learning and not just regarding statistical inference.

Having said all this, it is time to introduce a statement that is key when teaching hypothesis testing in an introductory statistical inference course:

> **In statistical inference, everything always boils down to randomness and how we can control it!**

That is quite a bold statement! Nonetheless, once one starts teaching statistical topics to audiences not entirely familiar with the usual field jargon, the idea of randomness always persists across many different tools. And, of course, regression analysis is not an exception at all since it also involves inference on population parameters of interest! This is why we have allocated this section in the textbook to explain core probabilistic and inferential concepts to pave the way to its role in regression analysis.

::: {#headsup-mechanical .Heads-up}
::::{.Heads-up-header}
Heads-up on why we mean as a non-ideal mechanical analysis!
::::
::::{.Heads-up-container}
The reader might need clarification on why the mechanical way of performing hypothesis testing is considered **non-ideal**, mainly when the term **cookbook** is used in the book's title. The **cookbook** concept here actually refers to a homogenized recipe for data modelling, as seen in the workflow from @fig-ds-workflow. However, there's a crucial distinction between this and the non-ideal mechanical way of hypothesis testing.

On the one hand, the non-ideal mechanical way refers to **the use of a tool without understanding the rationale of what this tool stands for**, resulting in vacuous and standard statements that we would not be able to explain any way further, such as the statement we previously indicated:\

> *With a significance level $\alpha = 0.05$, we reject (**or fail to reject, if that is the case!**) the null hypothesis given that...*\

What if a stakeholder of our analysis asks us in plain words what a significance level means? Why are we phrasing our conclusion on the null hypothesis and not directly on the alternative one? As a data scientist, one should be able to explain why the whole inference process yields that statement without misleading the stakeholders' understanding. **For sure, this also implicates appropriate communication skills that cater to general audiences rather than just statistical ones.**\

Conversely, the data modelling workflow in @fig-ds-workflow involves stages that necessitate a comprehensive and precise understanding of our analysis. Progressing to the next stage without a complete grasp of the current one risks perpetuating false insights, potentially leading to faulty data storytelling of the entire analysis.
::::
:::

Finally, even though this book has suggested reviews related to the basics of probability via different distributions and the fundamentals of frequentist statistical inference as stated in **Audience and Scope**, we will retake essential concepts as follows:

- The role of *random variables* and *probability distributions* and the governance of *population (or system) parameters* (i.e., the so-called Greek letters we usually see in statistical inference and regression analysis). @sec-basics-prob will explore these topics more in detail while connecting them to the subsequent inferential terrain under a *frequentist context*.
- When delving into supervised learning and regression analysis, we might wonder how randomness is incorporated into *model fitting* (i.e., *parameter estimation*). That is quite a fascinating aspect, implemented via a crucial statistical tool known as *maximum likelihood estimation*. This tool is heavily related to the concept of *loss function* in supervised learning. @sec-mle will explore these matters in more detail and how the idea of a *random sample* is connected to this estimation tool.
- @sec-basics-inf will explore the basics of *hypothesis testing* and its intrinsic components such as *null* and *alternative hypotheses*, *type I* and *type II* errors, *test statistic*, *standard error*, *$p$-value*, and *confidence interval*.
- Finally, @sec-sup-learning-regression will briefly discuss the connections between supervised learning and regression analysis regarding terminology.

Without further ado, let us start with reviewing core concepts in probability via quite a tasty example.

## Basics of Probability {#sec-basics-prob}

In terms of `r colourize("regression analysis", "blue")` and its `r colourize("supervised learning", "magenta")` counterpart (either on an **inferential** or **predictive** framework), `r colourize("probability", "blue")` can be viewed as the solid foundation on which more complex tools, including estimation and `r colourize("hypothesis testing", "blue")`, are built upon. Under this foundation, our data is coming from a given `r colourize("population", "blue")` or system of interest. Moreover, the `r colourize("population", "blue")` or system is assumed to be governed by `r colourize("parameters", "blue")` which, as data scientists or researchers, they are of their best interest to study. That said, the terms `r colourize("population", "blue")` and `r colourize("parameter", "blue")` will pave the way to our first statistical definitions.

::: {#Definition-population .definition}
::::{.definition-header}
Definition of population
::::
::::{.definition-container}
It is a **whole collection of individuals or items** that share **distinctive attributes**. As data scientists or researchers, we are interested in studying these attributes, which we assume are **governed** by `r colourize("parameters", "blue")`. In practice, we must be **as specific as possible** when defining our given `r colourize("population", "blue")` such that we would frame our entire data modelling process since its very early stages. Examples of a `r colourize("population", "blue")` could be the following:

- *Children between the ages of 5 and 10 years old in states of the American West Coast.*
- *Customers of musical vinyl records in the Canadian provinces of British Columbia and Alberta.*
- *Avocado trees grown in the Mexican state of Michoacán.*
- *Adult giant pandas in the Southwestern Chinese province of Sichuan.*
- *Mature açaí palm trees from the Brazilian Amazonian jungle.*

![Image by [*Eak K.*](https://pixabay.com/users/eak_kkk-907811/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=1044891) via [*Pixabay*](https://pixabay.com/photos/lego-toys-figurines-crowd-many-1044891/).](img/lego.jpg){width="550"} 

Note that the term `r colourize("population", "blue")` could be exchanged for the term **system**, given that certain contexts do not particularly refer to individuals or items. Instead, these contexts could refer to **processes** whose attributes are also governed by `r colourize("parameters", "blue")`. Examples of a **system** could be the following:

- *The production of cellular phones from a given model in a set of manufacturing facilities.*
- *The sale process in the Vancouver franchises of a well-known ice cream parlour.*
- *The transit cycle during rush hours on weekdays in the twelve lines of Mexico City's subway.*
::::
:::

::: {#Definition-parameter .definition}
::::{.definition-header}
Definition of parameter
::::
::::{.definition-container}
It is a characteristic (**numerical** or even **non-numerical**, such as a **distinctive category**) that **summarizes** the state of our `r colourize("population", "blue")` or **system** of interest. Examples of a `r colourize("population parameter", "blue")` can be described as follows:

- *The average weight of children between the ages of 5 and 10 years old in states of the American west coast (**numerical**).*
- *The variability in the height of the mature açaí palm trees from the Brazilian Amazonian jungle (**numerical**).*
- *The proportion of defective items in the production of cellular phones in a set of manufacturing facilities (**numerical**).*
- *The average customer waiting time to get their order in the Vancouver franchises of a well-known ice cream parlour (**numerical**).*
- *The most favourite pizza topping of vegetarian adults between the ages of 30 and 40 years old in Edmonton (**non-numerical**).*

![Image by [*meineresterampe*](https://pixabay.com/users/meineresterampe-26089/) via [*Pixabay*](https://pixabay.com/photos/typewriter-old-retro-office-1899760/).](img/typewriter.jpg){width="450"} 

Note the **standard mathematical notation** for `r colourize("population parameters", "blue")` are **Greek letters**. Moreover, in practice, these `r colourize("population parameter(s)", "blue")` of interest will be **unknown** to the data scientist or researcher. Instead, they would use formal statistical inference to **estimate** them.
::::
:::

The `r colourize("parameter", "blue")` [definition](#Definition-parameter) points out a crucial fact in investigating any given `r colourize("population", "blue")` or system: 

> **Our `r colourize("parameter(s)", "blue")` of interest are usually *unknown*!** 

Given this fact, it would be pretty unfortunate and inconvenient if we eventually wanted to discover any significant insights about the `r colourize("population", "blue")` or system. Therefore, let us proceed to our so-called tasty example so we can dive into the need for statistical inference and why `r colourize("probability", "blue")` is our perfect ally in this `r colourize("parameter", "blue")` quest.

Imagine you are the owner of a large fleet of ice cream carts, around 900 to be exact. These ice cream carts operate across different parks in the following Canadian cities: *Vancouver*, *Victoria*, *Edmonton*, *Calgary*, *Winnipeg*, *Ottawa*, *Toronto*, and *Montréal*. In the past, to optimize operational costs, you decided to limit ice cream cones to only two items: *vanilla* and *chocolate* flavours, as in @fig-ice-cream.

::: {#fig-ice-cream}
![](img/ice-cream.jpg){width="390"}

The two flavours of the ice cream cone you sell across all your ice cream carts: *vanilla* and *chocolate*. Image by [*tomekwalecki*](https://pixabay.com/users/tomekwalecki-13027968/) via [*Pixabay*](https://pixabay.com/photos/ice-cream-flavor-chocolate-vanilla-4401300/).
:::

Now, let us direct this whole case onto a more statistical and probabilistic field; suppose you have a well-defined overall `r colourize("population", "blue")` of interest for those above eight Canadian cities: **children between 4 and 11 years old attending these parks during the Summer weekends**. Of course, Summer time is coming this year, and you would like to know **which ice cream cone flavour is the favourite one** for this `r colourize("population", "blue")` (*and by how much!*). As a business owner, investigating ice cream flavour preferences would allow you to plan Summer restocks more carefully with your corresponding suppliers. Therefore, it would be essential to start collecting consumer data so the company can tackle this **demand query**.

Also, suppose there is a second query. For the sake of our case, we will call it a **time query**. As a critical component of demand planning, besides estimating which cone flavour is the most preferred one (*and by how much!*) for the above `r colourize("population", "blue")` of interest, the operations area is currently requiring a realistic estimation of **the `r colourize("average", "blue")` waiting time from one customer to the next one in any given cart during Summer weekends**. This `r colourize("average", "blue")` waiting time would allow the operations team to plan carefully how much stock each cart should have so there will not be any waste or shortage.

![Image by [*Icons8 Team*](https://unsplash.com/@icons8?utm_content=creditCopyText&utm_medium=referral&utm_source=unsplash) via [*Unsplash*](https://unsplash.com/photos/silver-bell-alarm-clock-dhZtNlvNE8M).](img/clock.jpg){width="500"}

Note that the nature of the aforementioned **time query** is more related to a larger `r colourize("population", "blue")`. Therefore, we can define it as **all our ice cream customers during the Summer weekends**. Furthermore, this second definition would expand this query to our corresponding general ice cream customers, given the requirements of our operations team, and **not** all the children between 4 and 11 years old attending the parks during Summer weekends. Consequently, it is crucial to note that the nature of our queries will dictate how we define our `r colourize("population", "blue")` and our subsequent data modelling and statistical inference.

Summer time represents the most profitable season from a business perspective, thus solving these above two queries is a significant priority for your company. Hence, you decide to organize a meeting with your eight general managers (one per Canadian city). Finally, during the meeting with the general managers, it was decided to do the following:

1. For the **demand query**, a comprehensive market study will be run on the `r colourize("population", "blue")` of interest across the eight Canadian cities right before next Summer; suppose we are currently in Spring.
2. For the **time query**, since the operations team has not previously recorded any historical data, **ALL** vendor staff from 900 carts will start collecting data on **the waiting time in seconds** between each customer this upcoming Summer.

Surprisingly, when discussing study requirements for the marketing firm who would be in charge of it for the **demand query**, *Vancouver's general manager* dares to state the following:

> *Since we're already planning to collect consumer data on these cities, let's mimic a census-type study to ensure we can have the **MOST PRECISE** results on their preferences.*

On the other hand, when agreeing on the specific operations protocol to start recording waiting times for all the 900 vending carts this upcoming Summer, *Ottawa's general manager* provides a comment for further statistical food for thought:

> *The operations protocol for recording waiting times in the 900 vending carts looks too cumbersome to implement straightforwardly this upcoming Summer. Why don't we select **A SMALLER GROUP** of ice cream carts across the eight cities to have a more efficient process implementation that would allow us to optimize operational costs?*

Bingo! *Ottawa's general manager* just nailed the probabilistic way of making inference on our `r colourize("population parameter", "blue")` of interest for the **time query**. Indeed, their comment was primarily framed from a business perspective of optimizing operational costs. Still, this fact does not take away a crucial insight on which statistical inference is built: a `r colourize("random sample", "blue")` ( as in its [corresponding definition](#Definition-random-sample)). As for *Vancouver's general manager*, ironically, their statement is **NOT PRECISE** at all! Mimicking a census-type study might not be the most optimal decision for the **demand query** given the time constraint and the potential size of its target `r colourize("population", "blue")`. 

> **Realistically, there is no cheap and efficient way to conduct a census-type study for any of the two queries!**

Moving on to one of the core topics in this chapter, we can state that `r colourize("probability", "blue")` is viewed as the language to decode random phenomena that occur in any given `r colourize("population", "blue")` or system of interest. In our example, we have two random phenomena:

1. For the **demand query**, a phenomenon can be represented by the preferred ice cream cone flavour of **any randomly selected child between 4 and 11 years old attending the parks of the above eight Canadian cities during the Summer weekends**. 
1. Regarding the **time query**, a phenomenon of this kind can be represented by **any randomly recorded waiting time between two customers during a Summer weekend in any of the above eight Canadian cities**. 

Hence, let us finally define what we mean by `r colourize("probability", "blue")` along with the inherent concept of `r colourize("sample space", "blue")`.

::: {#Definition-probability .definition}
::::{.definition-header}
Definition of probability
::::
::::{.definition-container}
Let $A$ be an event of interest in a random phenomenon, in a `r colourize("population", "blue")` or **system** of interest, whose all possible outcomes belong to a given `r colourize("sample space", "blue")` $S$. Generally, the `r colourize("probability", "blue")` for this event $A$ happening can be mathematically depicted as $P(A)$. Moreover, **suppose we observe the random phenomenon $n$ times** such as we were running some class of experiment, then $P(A)$ is defined as the following ratio:

$$
P(A) = \frac{\text{Number of times event $A$ is observed}}{n},
$${#eq-probability}

**as the $n$ times we observe the random phenomenon goes to infinity.**\

@eq-probability will always put $P(A)$ in the following numerical range:

$$
0 \leq P(A) \leq 1.
$$
::::
:::

::: {#Definition-sample-space .definition}
::::{.definition-header}
Definition of sample space
::::
::::{.definition-container}
Let $A$ be an event of interest in a random phenomenon in a `r colourize("population", "blue")` or **system** of interest. The `r colourize("sample space", "blue")` $S$ of event $A$ denotes the set of all the possible **random outcomes** we might encounter every time we randomly observe $A$ such as we were running some class of experiment.\

Note each of these outcomes has a determined probability associated with them. If we add up all these `r colourize("probabilities", "blue")`, the `r colourize("probability", "blue")` of the `r colourize("sample space", "blue")` $S$ will be one, i.e.,

$$
P(S) = 1.
$${#eq-sample-space}
::::
:::

Note the definition of the `r colourize("probability", "blue")` for an event $A$ in the [**definition of probability**](#Definition-probability) specifically highlights the following:

>**... as the $n$ times we observe the random phenomenon goes to infinity.**

The "*infinity*" term is key when it comes to understanding the philosophy behind the `r colourize("frequentist", "blue")` school of statistical thinking in contrast to its `r colourize("Bayesian", "blue")`  counterpart. In general, the `r colourize("frequentist", "blue")` way of practicing statistics in terms of `r colourize("probability", "blue")` and inference is the approach we usually learn in introductory courses, more specifically when it comes to `r colourize("hypothesis testing", "blue")` and `r colourize("confidence intervals", "blue")` which will be explored in @sec-basics-inf. That said, the Bayesian approach is another way of practicing statistical inference. Its philosophy differs in what information is used to infer our `r colourize("population parameters", "blue")` of interest. Below, we briefly define both schools of thinking.

::: {#Definition-frequentist-stats .definition}
::::{.definition-header}
Definition of frequentist statistics
::::
::::{.definition-container}
This statistical school of thinking heavily relies on the **frequency of events** to estimate specific `r colourize("parameters", "blue")` of interest in a `r colourize("population", "blue")` or **system**. This frequency of events is reflected in the repetition of $n$ experiments involving a random phenomenon within this `r colourize("population", "blue")` or **system**.\

Under the umbrella of this approach, we assume that our governing `r colourize("parameters", "blue")` are **fixed**. Note that, within the philosophy of this school of thinking, we can only make **precise** and **accurate** predictions as long as we repeat our $n$ experiments as many times as possible, i.e., 

$$
n \rightarrow \infty.
$$
::::
:::

::: {#Definition-bayesian-stats .definition}
::::{.definition-header}
Definition of Bayesian statistics
::::
::::{.definition-container}
This statistical school of thinking also relies on the **frequency of events** to estimate specific `r colourize("parameters", "blue")` of interest in a `r colourize("population", "blue")` or **system**.  Nevertheless, unlike `r colourize("frequentist", "blue")` statistics, `r colourize("Bayesian", "blue")` statisticians use **prior knowledge** on the `r colourize("population parameters", "blue")` to update their estimations on them along with the **current evidence** they can gather. This evidence is in the form of the repetition of $n$ experiments involving a random phenomenon. All these ingredients allow `r colourize("Bayesian", "blue")` statisticians to make inference by conducting  appropriate `r colourize("hypothesis testings", "blue")`, which are designed differently from their mainstream `r colourize("frequentist", "blue")` counterpart.\

![The unique known portrait of Reverend Thomas Bayes according to @odonnell1936, even though @bellhouse2004 argues it might not be a Bayes' portrait.](img/thomas-bayes.jpg){width="300"}

Under the umbrella of this approach, we assume that our governing `r colourize("parameters", "blue")` are **random**; i.e., they have their own `r colourize("sample space", "blue")` and `r colourize("probabilities", "blue")` associated to their corresponding outcomes. The statistical process of inference is heavily backed up by **probability theory** mostly in the form of the **Bayes theorem** (named after Reverend **Thomas Bayes**, an English statistician from the 18th century). This theorem uses our **current evidence** along with our **prior beliefs** to deliver a **posterior distribution** of our **random** `r colourize("parameter(s)", "blue")` of interest.
::::
:::

Let us put the definitions for the above schools of statistical thinking into a more concrete example. We can use the **demand query** from our ice cream case as a starting point. More concretely, we can dig more into a standalone `r colourize("population parameter", "blue")` such as the `r colourize("probability", "blue")` that a randomly selected child between 4 and 11 years old, attending the parks of the above eight Canadian cities during the Summer weekends, prefers the chocolate-flavoured ice cream cone over the vanilla one. Think about the following two hypothetical questions:

a. From a `r colourize("frequentist", "blue")` point of view, what is the **estimated** `r colourize("probability", "blue")` of **preferring chocolate over vanilla** after **randomly** surveying $n = 100$ children from our `r colourize("population", "blue")` of interest?
b. Using a `r colourize("Bayesian", "blue")` approach, suppose the marketing team has found ten **prior** market studies on similar children `r colourize("populations", "blue")` on their preferred ice cream flavour (between chocolate and vanilla). Therefore, along with our actual **random** survey of $n = 100$ children from our `r colourize("population", "blue")` of interest, what is the **posterior estimation** of the `r colourize("probability", "blue")` of **preferring chocolate over vanilla**?

By comparing the above (a) and (b), we can see one characteristic in common when it comes to the estimation of the `r colourize("probability", "blue")` of **preferring chocolate over vanilla**: both `r colourize("frequentist", "blue")` and `r colourize("Bayesian", "blue")` rely on the gathered **evidence** coming from the **random** survey of $n = 100$ children from our `r colourize("population", "blue")` of interest. On the one hand, the `r colourize("frequentist", "blue")` approach solely relies on **observed data** to **estimate** this single `r colourize("probability", "blue")` of **preferring chocolate over vanilla**. On the other hand, the `r colourize("Bayesian", "blue")` approach uses the **observed data** in conjunction with the **prior** knowledge provided by the ten estimated `r colourize("probabilities", "blue")` to deliver a whole posterior distribution (i.e., the **posterior estimation**) of the probability of **preferring chocolate over vanilla**.

::: {#Headsup-frequentist-vs-bayesian .Heads-up}
::::{.Heads-up-header}
Heads-up on the debate between frequentist and Bayesian statistics!
::::
::::{.Heads-up-container}
Even though most of us began our statistical journey in a `r colourize("frequentist", "blue")` framework, we might be tempted to state that a `r colourize("Bayesian", "blue")` paradigm for `r colourize("parameter", "blue")` estimation and inference is better than a `r colourize("frequentist", "blue")` one since the former only takes into account the **observed evidence** without the **prior knowledge** on our `r colourize("parameters", "blue")` of interest.

![Image by [*Manfred Steger*](https://pixabay.com/users/manfredsteger-1848497/?utm_source=link-attribution&utm_medium=referral&utm_campaign=image&utm_content=3699345) via [*Pixabay*](https://pixabay.com/vectors/pixel-pixel-cells-pedagogy-3699345/).](img/argument.png){width="300"}

In the statistical community, there could be a fascinating debate between the **pros** and **cons** of each school of thinking. That said, **it is crucial to state that no paradigm is considered wrong!** Instead, using a **pragmatic strategy** of performing statistics according to our data science context is more convenient.
::::
:::

Let us check the following two examples to illustrate the above pragmatic way of doing things:

1. Take the production of cellular phones from a given model in a set of manufacturing facilities as the context. Hence, one might find a `r colourize("frequentist", "blue")` estimation of the proportion of defective items as a quicker and more efficient way to correct any given manufacturing process. That is, we will sample products from our finalized batches and check their status (**defective** or **non-defective**, our **observed evidence**) to deliver a proportion estimation of defective items.
2. Now, take a physician's context. It would not make a lot of sense to study the `r colourize("probability", "blue")` that a patient develops a certain disease by only using a `r colourize("frequentist", "blue")` approach, i.e., looking at the current symptoms which account for the **observed evidence**. In lieu, a `r colourize("Bayesian", "blue")` approach would be more suitable to study this `r colourize("probability", "blue")` which uses the **observed evidence** combined with the patient's history (i.e., the **prior knowledge**) to deliver our **posterior belief** on the disease `r colourize("probability", "blue")`.

::: {#Tip-bayesian-resource .Tip}
::::{.Tip-header}
Tip on a further Bayesian resource!
::::
::::{.Tip-container}
It is important to reiterate that the focus of this textbook is purely `r colourize("frequentist", "blue")` in regards to data modelling in `r colourize("regression analysis", "blue")`. If you would like to explore the fundamentals of the `r colourize("Bayesian", "blue")` paradigm; @johnson2022 have developed an amazing textbook on the basic `r colourize("probability", "blue")` theory behind this school of statistical thinking along with a whole variety regression techniques including the `r colourize("parameter", "blue")` estimation rationale. 
::::
:::





::: {#Definition-independence-sample .definition}
::::{.definition-header}
Definition of independence
::::
::::{.definition-container}
We define `r colourize("probabilistic independence", "blue")`
::::
:::

::: {#Definition-random-variable .definition}
::::{.definition-header}
Definition of random variable
::::
::::{.definition-container}
A `r colourize("random variable", "blue")` is a
::::
:::

::: {#Definition-discrete-random-variables .definition}
::::{.definition-header}
Definition of discrete random variable
::::
::::{.definition-container}
A `r colourize("discrete random variable", "blue")` is a
::::
:::

::: {#Definition-continuous-random-variables .definition}
::::{.definition-header}
Definition of continuous random variable
::::
::::{.definition-container}
A `r colourize("continuous random variable", "blue")` is a
::::
:::

::: {#Definition-probability-distribution .definition}
::::{.definition-header}
Definition of probability distribution 
::::
::::{.definition-container}
A `r colourize("probability distribution", "blue")` is a
::::
:::

::: {#Definition-probability-mass-function .definition}
::::{.definition-header}
Definition of probability mass function 
::::
::::{.definition-container}
The `r colourize("probability mass function (PMF)", "blue")` of a `r colourize("discrete random variable", "blue")`
::::
:::

::: {#Definition-probability-density-function .definition}
::::{.definition-header}
Definition of probability density function 
::::
::::{.definition-container}
The `r colourize("probability density function (PDF)", "blue")` of a `r colourize("continuous random variable", "blue")`
::::
:::

::: {#Definition-measure-central-tendency .definition}
::::{.definition-header}
Definition of measure of central tendency
::::
::::{.definition-container}
A `r colourize("measure of central tendency", "blue")` is
::::
:::

::: {#Definition-measure-uncertainty .definition}
::::{.definition-header}
Definition of measure of uncertainty
::::
::::{.definition-container}
A `r colourize("measure of uncertainty", "blue")` is
::::
:::

::: {#Definition-expected-value .definition}
::::{.definition-header}
Definition of expected value 
::::
::::{.definition-container}
The `r colourize("expected  value", "blue")` of a `r colourize("random  variable", "blue")` is
::::
:::

::: {#Definition-variance .definition}
::::{.definition-header}
Definition of variance 
::::
::::{.definition-container}
The `r colourize("variance", "blue")` of a `r colourize("random  variable", "blue")` is
::::
:::

::: {#Definition-LOTUS .definition}
::::{.definition-header}
Definition of the Law of the Unconscious Statistician
::::
::::{.definition-container}
The `r colourize(" Law of the Unconscious Statistician (LOTUS) ", "blue")` is
::::
:::

::: {#Definition-random-sample .definition}
::::{.definition-header}
Definition of random sample
::::
::::{.definition-container}
A `r  colourize("random sample", "blue")` is a collection of `r colourize("random  variables", "blue")`
::::
:::

@joram2023

## What is Maximum Likelihood Estimation? {#sec-mle}

## Basics of Frequentist Statistical Inference {#sec-basics-inf}

::: {#Definition-hypothesis-testing .definition}
::::{.definition-header}
Definition of hypothesis testing 
::::
::::{.definition-container}
A `r colourize("frequentist hypothesis testing", "blue")` is
::::
:::

## Supervised Learning and Regression Analysis {#sec-sup-learning-regression}
