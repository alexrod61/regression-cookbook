<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7PRVEBE1EF"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-7PRVEBE1EF');
</script>

# Ordinal Logistic Regression {#sec-ordinal-logistic}

```{r}
#| include: false

colourize <- function(x, color) {
  if (knitr::is_latex_output()) {
    sprintf("\\textcolor{%s}{%s}", color, x)
  } else if (knitr::is_html_output()) {
    sprintf("<span style='color: %s;'>%s</span>", color,
      x)
  } else x
}
```

::: {#fig-regression-ordinal-logistic-regression}
```{mermaid}
mindmap
  root((Regression 
  Analysis)
    Continuous <br/>Outcome Y
      {{Unbounded <br/>Outcome Y}}
        )Chapter 3: <br/>Ordinary <br/>Least Squares <br/>Regression(
          (Normal <br/>Outcome Y)
      {{Nonnegative <br/>Outcome Y}}
        )Chapter 4: <br/>Gamma Regression(
          (Gamma <br/>Outcome Y)
      {{Bounded <br/>Outcome Y <br/> between 0 and 1}}
        )Chapter 5: Beta <br/>Regression(
          (Beta <br/>Outcome Y)
      {{Nonnegative <br/>Survival <br/>Time Y}}
        )Chapter 6: <br/>Parametric <br/> Survival <br/>Regression(
          (Exponential <br/>Outcome Y)
          (Weibull <br/>Outcome Y)
          (Lognormal <br/>Outcome Y)
        )Chapter 7: <br/>Semiparametric <br/>Survival <br/>Regression(
          (Cox Proportional <br/>Hazards Model)
            (Hazard Function <br/>Outcome Y)
    Discrete <br/>Outcome Y
      {{Binary <br/>Outcome Y}}
        {{Ungrouped <br/>Data}}
          )Chapter 8: <br/>Binary Logistic <br/>Regression(
            (Bernoulli <br/>Outcome Y)
        {{Grouped <br/>Data}}
          )Chapter 9: <br/>Binomial Logistic <br/>Regression(
            (Binomial <br/>Outcome Y)
      {{Count <br/>Outcome Y}}
        {{Equidispersed <br/>Data}}
          )Chapter 10: <br/>Classical Poisson <br/>Regression(
            (Poisson <br/>Outcome Y)
        {{Overdispersed <br/>Data}}
          )Chapter 11: <br/>Negative Binomial <br/>Regression(
            (Negative Binomial <br/>Outcome Y)
        {{Overdispersed or <br/>Underdispersed <br/>Data}}
          )Chapter 13: <br/>Generalized <br/>Poisson <br/>Regression(
            (Generalized <br/>Poisson <br/>Outcome Y)
        {{Zero Inflated <br/>Data}}
          )Chapter 12: <br/>Zero Inflated <br/>Poisson <br/>Regression(
            (Zero Inflated <br/>Poisson <br/>Outcome Y)
      {{Categorical <br/>Outcome Y}}
        {{Nominal <br/>Outcome Y}}
          )Chapter 14: <br/>Multinomial <br/>Logistic <br/>Regression(
            (Multinomial <br/>Outcome Y)
        {{Ordinal <br/>Outcome Y}}
          )Chapter 15: <br/>Ordinal <br/>Logistic <br/>Regression(
            (Logistic <br/>Distributed <br/>Cumulative Outcome <br/>Probability)
```
:::



::: {.LO}
::::{.LO-header}
Learning Objectives
::::
::::{.LO-container}
By the end of this chapter, you will be able to:

- Describe why ordinary **linear models** and **multinomial logistic regression** are inappropriate for **ordered categorical outcomes**.

- Write down the ordinal regression likelihood and the cumulative logit link functions, express cumulative probabilities, and recover category probabilities.

- Understand the **proportional odds assumption** and how it constrains the model (common slope parameters across cutpoints).

- Understand how coefficient estimation via maximum likelihood works in this model.

- Interpret ordinal regression coefficients in real scenarios.

- Use **ordinal logistic regression** for prediction by computing cumulative and category-specific probabilities.

- Assess and diagnose the proportional odds assumption by the **Brantâ€“Wald** test.

- Formulate and interpret **non-proportional odds models** when the proportional odds assumption is violated.

- Evaluate model performance and construct confidence intervals.

::::
:::


## Introduction

**Ordinal logistic regression** is a statistical modeling technique used to analyze relationships between an ordered multi-class categorical response variable and a set of explanatory variables. Unlike **multinomial logistic regression**, which treats categories as unordered, ordinal logistic regression take into account the natural ranking of response levels. Ignoring this ordering may lead to loss of valuable information in both **inference** and **prediction**.

In ordinal outcomes, the information lies **not only** in category membership **but also** in the relative ordering between categories. This structure is modeled through cumulative probabilities, which form the foundation of the cumulative logit (proportional odds) model. Instead of modeling the log-odds of each category relative to a baseline (as we do in multinomial regression), ordinal logistic regression models the **log-odds of being at or below a given category threshold**. That's right! We are looking at a cumulative probabbility now.

A key characteristic of the most commonly used ordinal models is the proportional odds model. It asserts that the effect of predictors is assumed to be constant across all cumulative splits of the response. This assumption plays a central role in the modeling framework and interpretation. To start this chpater let us see some of the assumptions in this model.


### Ordinal Logistic Regression Assumptions

The following are the assumptions that we need to be aware of before fitting this model:

- The response or dependent variable should be measured at the ordinal level with more than two ordered categories. This means there is a natural order between the categories in the response variable. For example likert scale: Strongly agree / Agree / Neutral / Disagree / Strongly Disagree

- There should be one or more independent variables that are continuous, ordinal, or nominal (including dichotomous variables).

- Logit linearity assumption: There must be a linear relationship between any continuous independent variables and the logit of the cumulative probabilities.

- Independent observations: The observations should be independent and the dependent variable should consist of mutually exclusive and exhaustive ordered categories.

- Proportional odds assumption: The relationship between each predictor and the log-odds of being at or below any category is constant across all category thresholds (parallel slopes assumption).

- When the proportional odds assumption is violated, a non-proportional odds model may be considered that allows for some predictors to vary across thresholds.


### Use Cases of Ordinal Logistic Regression

Ordinal logistic regression is particularly useful when the outcome has a meaningful ranking and collapsing categories would discard important structure. Some examples of this are:

1. Likert Scale Survey Responses: A classic example is agreement levels in surveys (Strongly disagree/ Disagree / Neutral / Agree / Strongly Agree). For example, you may study how predictors such as age, education, or exposure to misinformation influence the probability of showing extreme political ideas. 

2. Customer Satisfaction Levels: Marketing analysts may use ordinal regression to understand how service quality, wait time, or pricing influence the likelihood of higher satisfaction ratings.

3. Educational Achievement Levels: Educational researchers may study how study time, attendance in lectures and class activities, or prior preparation affects the probability of achieving higher results in exams.

4. Clinical Severity Scales: Ordinal models help quantify how treatments or patient characteristics influence the likelihood of more severe disease states. These status are often divided into categories such as mild, moderate, or severe.

In all these examples, the ordering is essential. Treating these outcomes as nominal would ignore the structured progression between categories, while treating them as numeric would impose unrealistic equal spacing. Ordinal logistic regression provides a principled framework that respects the ranking while maintaining probabilistic modeling rigor.

## Case Study

- TBD


## Data Collection and Wrangling

- TBD


## Exploratory Data Analysis

- TBD


## Data Modeling

We have been discussing the advantageous of using a different model in the presence of an **ordinal response variable**. In this section, we go over the details of data modeling for an **ordinal response variable** with a set of discrete or continuous explanatory variables using an ordinal logistic regression model. This type of modeling is the most frequent and popular model for ordinal responses. 

To present the details of the modeling framework, we begin with the concept of **cumulative logits**. We have already encountered the logit function in the context of binary logistic regression. Recall that in logistic regression, the logit function is applied to the odds of an event. Specifically, if 

$$
p = P(Y = 1 |X_1, X_2, ..., X_k)
$$

then the odds of the event $Y=1$ given the predictors is:

$$
\frac{P(Y = 1 \quad | \quad X_1, ..., X_k)}{P(Y = 0 \quad | \quad X_1, ..., X_k)} = \frac{p}{1-p}
$$

and the logit is defined as the logarithm of these odds, i.e. $log(\frac{p}{1-p})$. In logistic regression modeling we assume that this log-odds is a linear function of the predictors:

$$
log(\frac{p}{1-p}) = \beta_0 + \beta_1 X_1 + \beta_2X_2 + \ldots + \beta_k X_k
$$

This idea and formulation is the basis for extending logistic regression modeling for an outcome with two categories to ordinal outcomes where there are more than two categories and the order matters as well. In the ordinal case, instead of modeling the **log-odds of a single binary event**, we model **the cumulative logits** which compare the probability of being at or below a given category to the probability of being above that category. 

**Notation:** To avoid lengthy formulas, we introduce compact notation that will be used consistently throughout this chapter of book. In expressions such as $P(Y = 1 \quad | \quad X_1, ..., X_k)$ the conditioning is on all explanatory variables. Instead of repeatedly writing all predictors, we define:  

$$
\underline{X} = (X_1,...,X_k)
$$ 

and write;

$$
P(Y = 1 \quad | \quad \underline{X})
$$

This notation simplifies expressions and improves readability. Let's continue!

Imagine your ordered response variable have $J$ different categories where $J \ge 3$. We start with the category ordering by formally defining the **logits of cumulative probabilities** as follows. Let:

$$
P(Y \leq j \quad | \quad \underline{X}) = p_1(\underline{X}) + p_2(\underline{X}) + \ldots + p_j(\underline{X}) \quad \quad j = 1, 2, \ldots, J-1
$$

be the cumulative probability. The **logits of cumulative probabilities** are defined as:

$$
\begin{aligned}
&\text{logit}(P(Y \leq j \quad | \quad \underline{X})) = \log( \frac{P(Y \leq j \quad | \quad \underline{X})}{ 1 - P(Y \leq j \quad | \quad \underline{X})} ) \\
&= \log( \frac{P(Y = 1 \quad | \quad \underline{X}) + P(Y = 2 \quad | \quad \underline{X}) + \ldots + P(Y = j \quad | \quad \underline{X})}{ P(Y = j+1 \quad | \quad \underline{X}) + P(Y = j+2 \quad | \quad \underline{X}) + \ldots + P(Y = J \quad | \quad \underline{X}) } )
\end{aligned}
$$

Perfect! We have defined our **cumulative logit odds here**! At this point, an important modeling decision must be addressed. When working with cumulative logits in ordinal logistic regression, there are two primary modeling approaches based on different assumptions about the relationship between the predictors and the response categories. These two primary modeling approaches are 1) the proportional odds assumption and 2) the non-proportional odds assumption. 

The proportional odds model assumes that the effect of each explanatory variable is constant across all cumulative logits, meaning that the regression coefficients do not depend on the category $j$. In contrast, the non-proportional odds model allows the effects of the explanatory variables to vary across cumulative splits of the response variable. In the following sections, we introduce these two approaches in detail and discuss their interpretation and practical implications. Later in this chapter we explain how you can verify these assumptions while fitting the model.


### The Proportional Odds Modeling


### The Non-proportional Odds Modeling


### Data Modeling


## Estimation


## Goodness of Fit


## Inference


## Results


## Storytelling



