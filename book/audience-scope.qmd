<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7PRVEBE1EF"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-7PRVEBE1EF');
</script>

# Audience and Scope {.unnumbered}

This book mainly focuses on statistical **regression analysis** with connections to its corresponding **supervised learning** counterpart. Thus, it is not introductory statistics and machine learning material. Also, some coding background on `R` [@r2024] and/or `Python` [@python] is recommended. That said, the following topics are suggested:

- **Mutivariable differential calculus.** Certain sections of each chapter pertain to modelling estimation. Therefore, topics such as *partial derivatives* are a good asset. You can find helpful learning resources on the [Master of Data Science (MDS) webpage](https://ubc-mds.github.io/resources_pages/learning_resources/).
- **Basic `Python` programming.** When necessary, `Python` [{pandas}](https://pypi.org/project/pandas/) [@pandas2024] library will be used to perform *data wrangling*. The MDS course [DSCI 511 (Programming for Data Science)](https://github.com/UBC-MDS/DSCI_511_prog-dsci) is an ideal example of a quick review.

![Image by [*Lubos Houska*](https://pixabay.com/users/luboshouska-198496/) via [*Pixabay*](https://pixabay.com/photos/books-bookstore-book-reading-1204029/).](img/books.jpg){width=500}

- **Basic `R` programming.** Knowledge of *data wrangling* through `R` [{tidyverse}](https://www.tidyverse.org) [@tidyverse] is recommended for hands-on practice via the cases provided in each one of the chapters of this book. The MDS course [DSCI 523 (Programming for Data Manipulation)](https://github.com/UBC-MDS/DSCI_523_r-prog) is an ideal example of a quick review.
- **Foundations of supervised learning.** A fundamental data science paradigm to be covered pertains to *prediction*, which is core in machine learning. The reader should be familiar with basic terminology, such as *training and testing data*, *overfitting*, *underfitting*, etc. The MDS course [DSCI 571 (Machine Learning I)](https://github.com/UBC-MDS/DSCI_571_sup-learn-1) provides these foundations.
- **Foundations of feature and model selection.** This prerequisite also relates to machine learning and its corresponding prediction paradigm. Basic knowledge of *prediction accuracy* and *model selection tools* is recommended. The MDS course [DSCI 573 (Feature and Model Selection)](https://github.com/UBC-MDS/DSCI_573_feat-model-select) is an ideal example of a quick review.

::: {.Warning}
::::{.Warning-header}
A Crucial Remark on Probability and Statistical Inference
::::
::::{.Warning-container}
If you are not fully familiar with introductory statistical concepts, particularly topics related to probability and inference, we suggest two pathways for review. The first pathway involves revisiting the following course materials:

1. **Foundations of probability and basic distributional knowledge:** The MDS course [DSCI 551 (Descriptive Statistics and Probability for Data Science)](https://ubc-mds.github.io/course-descriptions/DSCI_551_eda-dsci/) covers fundamental *discrete and continuous probability distributions*, which are essential components of any regression or supervised learning model.
2. **Foundations of frequentist statistical inference:** The MDS course [DSCI 552 (Statistical Inference and Computation I)](https://github.com/UBC-MDS/DSCI_552_stat-inf-1) addresses *statistical inference*, a key paradigm in this book. This involves identifying relationships between different variables within a *population or system* of interest using a *sampled dataset*. We focus exclusively on a frequentist approach utilizing tools such as *parameter estimation*, *hypothesis testing*, and *confidence intervals*.

The second pathway entails an in-depth review of the refresher material provided in [Chapter 2](https://alexrod61.github.io/regression-cookbook/book/02-stats-review.html), which covers critical points needed to grasp the **statistical concepts** presented in each of the core thirteen regression chapters. This refresher chapter aims to address the same topics outlined in the above bullet points through a practical example, with the necessary theoretical background to understand the foundations of generative modeling and statistical inference.
::::
:::
