[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Regression Cookbook",
    "section": "",
    "text": "Preface\n\nLet the regression cooking begin!\n\nThroughout my journey as a postdoctoral fellow in the Master of Data Science (MDS) at the University of British Columbia, I became aware of the fascinating overlap between Machine Learning and Statistics. Many Data Science students usually come across common Machine Learning/Statistics concepts or ideas that might only differ in names. For instance, simple terms such as weights in supervised learning (and their equivalent statistical counterpart as regression coefficients) might be misleading for students starting their Data Science formation. On the other hand, from an instructor’s perspective in a Data Science program that subsets its courses in Machine Learning in Python and Statistics in R, regression courses in R also demand the inclusion of Python-related packages as alternative tools. In my MDS teaching experience, this is especially critical for students whose career plans lean towards industry where Python is more heavily used.\nAs a Data Science educator, I view this field as a substantial synergy between Machine Learning and Statistics. Nevertheless, many gaps between both disciplines still need to be addressed. Thus, closing these critical gaps is imperative in a domain with accelerated growth, such as Data Science. In this regard, the MDS Stat-ML dictionary inspired me to write this textbook. It basically consists of common ground between foundational supervised learning models from Machine Learning and regression models commonly used in Statistics. I strive to explore linear modelling approaches as a primary step while highlighting different terminology found in both fields. Furthermore, this discussion is more comprehensive than a simple conceptual exploration. Hence, the second step is hands-on practice via the corresponding Python packages for Machine Learning and R for Statistics.\nAs a fun fact, while thinking about possible names for this work, I was planning to name it “Machine Learning and Statistics: A Common Ground.” Nevertheless, it was quite plain and boring! That said, this whole textbook idea sounded analogous to a cookbook, given its heavily applied focus.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "book/audience-scope.html",
    "href": "book/audience-scope.html",
    "title": "Audience and Scope",
    "section": "",
    "text": "This book mainly focuses on regression analysis and its supervised learning counterpart. Thus, it is not introductory Statistics and Machine Learning material. Instead, the following topics are suggested as prerequisites:\n\n\n\nMutivariable Differential Calculus and Linear Algebra. Certain sections of each chapter pertain to modelling estimation. Therefore, topics such as partial derivatives and matrix algebra are a great asset. You can find helpful learning resources on the MDS webpage.\nBasic Python programming. When necessary, Python {pandas} library will be used to perform data wrangling. The MDS course DSCI 511 (Programming for Data Science) is an ideal example of this prerequisite.\n\n\n  \n\n\n\nBasic R programming. Knowledge of data wrangling and plotting through R {tidyverse} is recommended for hands-on practice via the examples provided in each one of the chapters of this book. The MDS courses DSCI 523 (Programming for Data Manipulation) and DSCI 531 (Data Visualization I) are ideal examples of this prerequisite.\nFoundations of probability and basic distributional knowledge. The reader should be familiar with elemental discrete and continuous distributions since they are a vital component of any given regression or supervised learning model. The MDS course DSCI 551 (Descriptive Statistics and Probability for Data Science) is an ideal example of this prerequisite.\nFoundations of frequentist statistical inference. One of the Data Science paradigms to be covered in this book is statistical inference, i.e., identifying relationships between different variables in a given population or system of interest via a sampled dataset. I only aim to cover a frequentist approach using inferential tools such as parameter estimation, hypothesis testing, and confidence intervals. The MDS course DSCI 552 (Statistical Inference and Computation I) is an ideal example of this prerequisite.\nFoundations of supervised learning. The second Data Science paradigm to be covered pertains to prediction, which is core in Machine Learning. The reader should be familiar with basic terminology, such as training and testing data, overfitting, underfitting, cross-validation, etc. The MDS course DSCI 571 (Machine Learning I) provides these foundations.\nFoundations of feature and model selection. This prerequisite also relates to Machine Learning and its corresponding prediction paradigm. Basic knowledge of prediction accuracy and variable selection tools is recommended. The MDS course DSCI 573 (Feature and Model Selection) is an ideal example of this prerequisite.\n\nEven though it is recommended that you check the above general topics, especially the statistical ones, I will initially provide a fair review of probability and frequentist inference so we can explain key concepts in data modelling in the context of regression analysis.",
    "crumbs": [
      "Audience and Scope"
    ]
  },
  {
    "objectID": "book/intro.html",
    "href": "book/intro.html",
    "title": "\n1  Introduction\n",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2\n\n\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "book/summary.html",
    "href": "book/summary.html",
    "title": "\n2  Summary\n",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "book/references.html",
    "href": "book/references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  }
]