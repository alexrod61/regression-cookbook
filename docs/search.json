[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Regression Cookbook",
    "section": "",
    "text": "Preface\nData science is a field in which we become aware of the fascinating overlap between machine learning and statistics. Many data science students usually come across everyday machine learning and statistics concepts or ideas that might only differ in names. For instance, simple terms such as weights in supervised learning (and their statistical counterpart as regression coefficients) might be misleading for students starting their data science formation. On the other hand, from an instructor’s perspective in a data science program that subsets its courses in machine learning in Python and statistics in R, regression courses in R also demand the inclusion of Python-related packages as alternative tools. Furthermore, in a graduate program such as the Master of Data Science (MDS) at the University of British Columbia, this is especially critical for students whose career plan leans towards the industry job market where Python is more heavily used.\nThat said, we can state that data science is a substantial synergy between machine learning and statistics. Nevertheless, many gaps between both disciplines still need to be addressed. Thus, closing these critical gaps is imperative in a domain with accelerated growth, such as data science. In this regard, the MDS Stat-ML dictionary has inspired us to write this textbook. It basically consists of common ground between foundational supervised learning models from machine learning and regression models commonly used in statistics. We strive to explore linear modelling approaches as a primary step while highlighting different terminology found in both fields. Furthermore, this discussion is more comprehensive than a simple conceptual exploration. Hence, the second step is hands-on practice via the corresponding Python packages for machine learning and R for statistics.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#g.-alexi-rodríguez-arelis",
    "href": "index.html#g.-alexi-rodríguez-arelis",
    "title": "The Regression Cookbook",
    "section": "G. Alexi Rodríguez-Arelis",
    "text": "G. Alexi Rodríguez-Arelis\n\n\n\n\n\n\n\n\n\n\n\nI'm an Assistant Professor of Teaching in the Department of Statistics and Master of Data Science at the University of British Columbia. Throughout my academic and professional journey, I've been involved in diverse fields, such as credit risk management, statistical consulting, and data science teaching. My doctoral research in statistics is primarily focused on computer experiments that emulate scientific and engineering systems via Gaussian stochastic processes (i.e., kriging regression). I'm incredibly passionate about teaching regression topics while combining statistical and machine learning contexts.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#andy-tai",
    "href": "index.html#andy-tai",
    "title": "The Regression Cookbook",
    "section": "Andy Tai",
    "text": "Andy Tai\n\n\n\n\n\n\n\n\n\n\n\nI'm a Postdoctoral Teaching and Learning Fellow in the Department of Statistics and Master of Data Science at the University of British Columbia. Throughout my academic and professional journey, I've been involved in diverse fields, such as addiction psychiatry, machine learning, and data science teaching. My doctoral research in neuroscience primarily focused on using machine learning to predict the risk of fatal overdose. I am interested in leveraging data science and machine learning to solve complex problems, and I strive to inspire others to explore the vast potential of these fields.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#ben-chen",
    "href": "index.html#ben-chen",
    "title": "The Regression Cookbook",
    "section": "Ben Chen",
    "text": "Ben Chen\n\n\n\n\n\n\n\n\n\n\n\nI hold a Master's degree in Data Science from the University of British Columbia, and I am passionate about educating others in the fields of statistics and data science. With experience teaching students how to use statistical methods and data science tools, I also enjoy sharing my knowledge through writing. My blog focuses on making complex statistical concepts accessible to everyone. Additionally, I've worked on a variety of data science projects, ranging from developing recommendation systems to building Generative Adversarial Network (GAN) models.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "The Regression Cookbook",
    "section": "",
    "text": "Special thanks to Jonathan Graves, who mentioned the cookbook term when this textbook was conceptualized during very early stages.↩︎",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "book/privacy-policy.html",
    "href": "book/privacy-policy.html",
    "title": "Website Privacy Policy",
    "section": "",
    "text": "Information Collection and Use\nYour privacy is important to us. This policy outlines how this online textbook created for courses at the University of British Columbia (UBC) (“we,” “us,” or “our”) collects, uses, and protects your information.\nWe use Google Analytics, a web analytics service provided by Google, LLC. (“Google”). Google Analytics uses cookies to help analyze how students interact with the textbook, including tracking which sections are accessed most frequently. Information generated by cookies about your use of our website (including IP address) will be transmitted to and stored by Google on servers in the United States.\nGoogle will use this information solely for evaluating textbook usage, compiling usage reports to enhance the educational effectiveness of the textbook, and providing related services.\nYou may refuse the use of cookies by selecting the appropriate settings in your browser; however, please note this may affect your textbook browsing experience.",
    "crumbs": [
      "Website Privacy Policy"
    ]
  },
  {
    "objectID": "book/privacy-policy.html#personal-information",
    "href": "book/privacy-policy.html#personal-information",
    "title": "Website Privacy Policy",
    "section": "Personal Information",
    "text": "Personal Information\nWe do not collect personally identifiable information through Google Analytics. Any personally identifiable information, such as your name and email address, would only be collected if voluntarily submitted for specific educational purposes (e.g., feedback or course-related inquiries). We will never sell or distribute your personal information to third parties.\nFor any questions or concerns, please contact us at alexrod@stat.ubc.ca.",
    "crumbs": [
      "Website Privacy Policy"
    ]
  },
  {
    "objectID": "book/audience-scope.html",
    "href": "book/audience-scope.html",
    "title": "Audience and Scope",
    "section": "",
    "text": "This book mainly focuses on regression analysis and its supervised learning counterpart. Thus, it is not introductory statistics and machine learning material. Also, some coding background on R (R Core Team 2024) and/or Python (Van Rossum and Drake 2009) is recommended. That said, the following topics are suggested as fundamental reviews:\n\nMutivariable differential calculus and linear algebra. Certain sections of each chapter pertain to modelling estimation. Therefore, topics such as partial derivatives and matrix algebra are a great asset. You can find helpful learning resources on the MDS webpage.\nBasic Python programming. When necessary, Python {pandas} (The Pandas Development Team 2024) library will be used to perform data wrangling. The MDS course DSCI 511 (Programming for Data Science) is an ideal example of a quick review.\n\n\n\n\nImage by Lubos Houska via Pixabay.\n\n\n\nBasic R programming. Knowledge of data wrangling and plotting through R {tidyverse} (Wickham et al. 2019) is recommended for hands-on practice via the cases provided in each one of the chapters of this book. The MDS courses DSCI 523 (Programming for Data Manipulation) and DSCI 531 (Data Visualization I) are ideal examples of a quick review.\nFoundations of probability and basic distributional knowledge. The reader should be familiar with elemental discrete and continuous distributions since they are a vital component of any given regression or supervised learning model. The MDS course DSCI 551 (Descriptive Statistics and Probability for Data Science) is an ideal example of a quick review.\nFoundations of frequentist statistical inference. One of the data science paradigms to be covered in this book is statistical inference, i.e., identifying relationships between different variables in a given population or system of interest via a sampled dataset. I only aim to cover a frequentist approach using inferential tools such as parameter estimation, hypothesis testing, and confidence intervals. The MDS course DSCI 552 (Statistical Inference and Computation I) is an ideal example of a quick review.\nFoundations of supervised learning. The second data science paradigm to be covered pertains to prediction, which is core in machine learning. The reader should be familiar with basic terminology, such as training and testing data, overfitting, underfitting, cross-validation, etc. The MDS course DSCI 571 (Machine Learning I) provides these foundations.\nFoundations of feature and model selection. This prerequisite also relates to machine learning and its corresponding prediction paradigm. Basic knowledge of prediction accuracy and variable selection tools is recommended. The MDS course DSCI 573 (Feature and Model Selection) is an ideal example of a quick review.\n\n\n\nA further remark on probability and statistical inference\n\n\nIn case the reader is not 100% familiar with probabilistic and inferential topics, as discussed above, we will provide a fundamental refresher in 2  Basic Cuisine: A Review on Probability and Frequentist Statistical Inference with crucial points that are needed to follow along the statistical way each one of the chapters is delivered (more specifically for modelling estimation/training matters!).\n\nFurthermore, this refresher will be integrated into the three big pillars that will be fully expanded in this book, more concretely in 1  Getting Ready for Regression Cooking!: a data science workflow, the right workflow flavour (inferential or predictive), and a regression toolbox.\n\n\n\n\n\n\nR Core Team. 2024. “R: A Language and Environment for Statistical Computing.” Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nThe Pandas Development Team. 2024. “Pandas-Dev/Pandas: Pandas.” Zenodo. https://doi.org/10.5281/zenodo.3509134.\n\n\nVan Rossum, Guido, and Fred L. Drake. 2009. Python 3 Reference Manual. Scotts Valley, CA: CreateSpace.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.",
    "crumbs": [
      "Audience and Scope"
    ]
  },
  {
    "objectID": "book/01-intro.html",
    "href": "book/01-intro.html",
    "title": "1  Getting Ready for Regression Cooking!",
    "section": "",
    "text": "1.1 The ML-Stats Dictionary\nFirst things first! Let us prepare for all the different regression techniques to be introduced in Chapter 3.\nThat said, we want to highlight one guiding principle for all of our work:\nThe above guiding principle rests on foundational statistical ideas on how data is generated and how it can be modelled through various regression methods. We will explore these underlying concepts in Chapter 2. Before doing so, however, this chapter will build on the three core pillars introduced in Audience and Scope:\nLet us establish a convention for using admonitions throughout this textbook. These admonitions will help distinguish between key concepts, important insights, and supplementary material, ensuring clarity as we explore different regression techniques. We will start using these admonitions in Section 1.1.\nThe core idea of the above admonition arrangement is to allow the reader to discern between ideas or concepts that are key to grasp from those whose understanding might not be highly essential (but still interesting to check out in further literature!). With this structure in place, we can now introduce another foundational resource: a common ground between machine learning and statistics which will be elaborated on in the next section.\nMachine learning and statistics often overlap, especially in regression modelling. Topics covered in a regression-focused course, under a purely statistical framework, can also appear in machine learning-based courses on supervised learning, but the terminology can differ. Recognizing this overlap, the Master of Data Science (MDS) program at the University of British Columbia (UBC) provides the MDS Stat-ML dictionary (Gelbart 2017) under the following premises:\nBoth disciplines have a tremendous amount of jargon and terminology. As mentioned in the Preface, machine learning and statistics construct a substantial synergy reflected in data science. Despite this overlap, misunderstandings can still happen due to differences in terminology. To prevent this, we need clear bridges between these disciplines. Therefore, the above definition callout box will pave the way to a complimentary resource called the ML-Stats dictionary (ML stands for Machine Learning). This ML-Stats dictionary clarifies terminology that differs between statistics and machine learning, specifically in the context of supervised learning and regression analysis.\nNote that Appendix A will be the section in this book where the reader can find all those statistical and machine learning-related terms in alphabetical order. Notable terms (either statistical or machine learning-related) will include an admonition identifying which terms (again, either statistical or machine learning-related) are equivalent or somewhat equivalent (or even NOT equivalent if that is the case!).\nHence, in Appendix A, readers will find all those statistical and machine learning-related terms in alphabetical order as in a regular dictionary. Notable terms will include clear notes on their equivalence or non-equivalence. For instance, consider the statistical term dependent variable:\nThen, the above definition will be followed by this admonition:\nAbove, we have identified four equivalent terms for the term dependent variable. Furthermore, these terms can be statistical or machine learning-related. Finally, it is important to highlight we will start using this colour scheme in Chapter 2.\nNext, we will introduce the three main foundations of this textbook: a data science workflow, choosing the correct workflow flavour (inferential or predictive), and building your regression toolbox.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting Ready for Regression Cooking!</span>"
    ]
  },
  {
    "objectID": "book/01-intro.html#sec-ml-stats-dictionary",
    "href": "book/01-intro.html#sec-ml-stats-dictionary",
    "title": "1  Getting Ready for Regression Cooking!",
    "section": "",
    "text": "This document is intended to help students navigate the large amount of jargon, terminology, and acronyms encountered in the MDS program and beyond.\n\n\nThis section covers terms that have different meanings in different contexts, specifically statistics vs. machine learning (ML).\n\n\n\n\nHeads-up on terminology highlights!\n\n\nThroughout the book, following the ML-Stats dictionary, all statistical terms will be highlighted in blue whereas the machine learning terms will be highlighted in magenta. This color scheme helps readers move easily between disciplines. With practice, readers will comfortably use concepts from either field.\n\n\n\n\n\nIn supervised learning, it is the main variable of interest we are trying to learn or predict, or equivalently, in a statistical inference framework, the variable we are trying explain.\n\n\n\n\nEquivalent to:\n\n\nResponse variable, outcome, output or target.\n\n\n\n\n\nHeads-up on the use of terminology!\n\n\nThroughout this book, we will use specific terms interchangeably while explaining different regression methods. If confusion arises, readers should always check definitions and equivalences (or non-equivalences) in Appendix A.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting Ready for Regression Cooking!</span>"
    ]
  },
  {
    "objectID": "book/01-intro.html#sec-ds-workflow",
    "href": "book/01-intro.html#sec-ds-workflow",
    "title": "1  Getting Ready for Regression Cooking!",
    "section": "\n1.2 The Data Science Workflow",
    "text": "1.2 The Data Science Workflow\nUnderstanding the data science workflow is essential for mastering regression analysis. This workflow serves as a blueprint that guides us through each stage of our analysis, ensuring that we apply a systematic approach to solving our inquiries in a reproducible way. Each of the three pillars of this textbook—data science workflow, the right workflow flavor (inferential or predictive), and a regression toolbox—are deeply interconnected. Regardless of the regression model we explore, this general workflow provides a consistent framework that helps us navigate our data analysis with clarity and purpose. As shown in Figure 1.1, the data science workflow is composed of the following stages (each of which will be discussed in more detail in subsequent subsections):\n\n\nStudy design: Define the research question, objectives, and variables of interest to ensure the analysis is purpose-driven and aligned with the problem at hand.\n\nData collection and wrangling: Gather and clean data, addressing issues such as missing values, outliers, and inconsistencies to transform it into a usable format.\n\nExploratory data analysis: Explore the data through statistical summaries and visualizations to identify patterns, trends, and potential anomalies.\n\nData modelling: Apply statistical or machine learning models to uncover relationships between variables or make predictions based on the data.\n\nEstimation: Calculate model parameters to quantify relationships between variables and assess the accuracy and reliability of the model.\n\nGoodness of fit: Evaluate the model’s performance using metrics and diagnostic checks to determine how well it explains the data.\n\nResults: Interpret the model’s outputs to derive meaningful insights and provide answers to the original research question.\n\nStorytelling Communicate the findings through a clear, engaging narrative that is accessible to a non-technical audience.\n\nBy adhering to this workflow, we ensure that our regression analysis are not only systematic and thorough but also capable of producing results that are meaningful within the context of the problem we aim to solve.\n\n\n\n\n\n\nThe Importance of a Formal Structure in Regression Analysis\n\n\n\nFrom the earliest stages of learning data analysis, understanding the importance of a structured workflow is crucial. If we do not adhere to a predefined workflow, we risk misinterpreting the data, leading to incorrect conclusions that fail to address the core questions of our analysis. Such missteps can result in outcomes that are not only meaningless but potentially misleading when taken out of the problem’s context. Therefore, it is essential for aspiring data scientists to internalize this workflow from the very beginning of their education. A systematic approach ensures that each stage of the analysis is conducted with precision, ultimately producing reliable and contextually relevant results.\n\n\n\n\n\n\n\nFigure 1.1: Data science workflow for inferential and predictive inquiries in regression analysis and supervised learning, respectively. The workflow is structured in eight stages: study design, data collection and wrangling, exploratory data analysis, data modelling, estimation, goodness of fit, results, and storytelling.\n\n\n\n1.2.1 Study Design\nThe first stage of this workflow is centered around defining the main statistical inquiries we aim to address throughout the data analysis process. As a data scientist, your primary task is to translate these inquiries from the stakeholders into one of two categories: inferential or predictive. This classification determines the direction of your analysis and the methods you will use.\n\nInferential: The objective here is to explore and quantify relationships of association or causation between explanatory variables (regressors) and the response variable within the context of the problem at hand. For example, you may seek to determine whether a specific marketing campaign (regressor) significantly impacts sales revenue (response) and, if so, by how much.\nPredictive: In this case, the focus is on making accurate predictions about the response variable based on future observations of the regressors. Unlike inferential inquiries, where understanding the relationship between variables is key, the primary goal here is to maximize prediction accuracy. This approach is fundamental in machine learning. For instance, you might build a model to predict future sales revenue based on past marketing expenditures, without necessarily needing to understand the underlying relationship between the two.\n\nExample: Predicting Housing Prices\nTo illustrate the study design stage, let’s consider a simple example: predicting housing prices in a specific city.\n\nIf our goal is inferential, we might be interested in understanding the relationship between various factors (like square footage, number of bedrooms, and proximity to schools) and housing prices. Specifically, we would ask questions like, “How much does the number of bedrooms affect the price of a house, after accounting for other factors?”\nIf our goal is predictive, we would focus on creating a model that can accurately predict the price of a house based on its features, regardless of whether we fully understand how each factor contributes to the price.\n\nIn both cases, the study design stage involves clearly defining these objectives and determining the appropriate methods to address them. This stage sets the foundation for all subsequent steps in the data science workflow, as illustrated in Figure 1.2. Once the study design is established, the next stage is data collection and wrangling.\n\n\n\n\n\nFigure 1.2: Study design stage from the data science workflow in Figure 1.1. This stage is directly followed by data collection and wrangling.\n\n\n\n1.2.2 Data Collection and Wrangling\nOnce we have clearly defined our statistical questions, the next crucial step is to collect the data that will form the basis of our analysis. The way we collect this data is vital because it directly affects the accuracy and reliability of our results:\n\n\nFor inferential inquiries, we focus on understanding large groups or systems (populations) that we cannot fully observe. These populations are governed by characteristics (parameters) that we want to estimate. Because we can’t study every individual in the population, we collect a smaller, representative subset called a sample. The method we use to collect this sample—known as sampling—is crucial. A proper sampling method ensures that our sample reflects the larger population, allowing us to make accurate generalizations (inferences) about the entire group. After collecting the sample, it’s common practice to randomly split the data into training and test sets. This split allows us to build and validate our models, ensuring that the findings are robust and not overly tailored to the specific data at hand.\n\n\n\n\n\n\n\nA Quick Debrief on Sampling!\n\n\n\nAlthough this book does not cover sampling methods in detail, it’s important to know that the way you collect your sample can greatly influence your results. Depending on the problem, you might use different techniques:\n\n\nSimple Random Sampling: Every individual in the population has an equal chance of being selected.\n\nSystematic Sampling: You select individuals at regular intervals from a list of the population.\n\nStratified Sampling: You divide the population into subgroups (strata) and take a proportional sample from each subgroup.\n\nClustered Sampling: You divide the population into clusters and randomly select whole clusters for your sample.\nEtc.\n\nAs in the case of Regression Analysis, statistical sampling is a vast field, and we could spend a whole course on it. If you’re interested in learning more about these methods, Sampling: design and analysis by Lohr is a great resource.\n\n\n\n\nFor predictive inquiries, our goal is often to use existing data to make predictions about future events or outcomes. In these cases, we usually work with large datasets (databases) that have already been collected. Instead of focusing on whether the data represents a population (as in inferential inquiries), we focus on cleaning and preparing the data so that it can be used to train models that make accurate predictions. After wrangling the data, it is typically split into training, validation, and test sets. The training set is used to build the model, the validation set is used to tune model parameters, and the test set evaluates the model’s final performance on unseen data.\n\nExample: Collecting Data for Housing Price Predictions\nLet’s continue with our housing price prediction example to illustrate these concepts:\n\nInferential Approach: Suppose we want to understand how the number of bedrooms affects housing prices in a city. To do this, we would collect a sample of house sales that accurately represents the city’s entire housing market. For instance, we might use stratified sampling to ensure that we include houses from different neighborhoods in proportion to how common they are. After collecting the data, we would split it into training and test sets. The training set helps us build our model and estimate the relationship between variables, while the test set allows us to evaluate how well our findings generalize to new data.\nPredictive Approach: If our goal is to predict the selling price of a house based on its features (like size, number of bedrooms, and location), we would gather a large dataset of recent house sales. This data might come from a real estate database that tracks the details of each sale. Before we can use this data to train a model, we would clean it by filling in any missing information, converting data to a consistent format, and making sure all variables are ready for analysis. After preprocessing, we would split the data into training, validation, and test sets. The training set would be used to fit the model, the validation set to fine-tune it, and the test set to assess how well the model can predict prices for houses it hasn’t seen before.\n\nAs shown in Figure 1.3, the data collection and wrangling stage is fundamental to the workflow. It directly follows the study design and sets the stage for exploratory data analysis.\n\n\n\n\n\nFigure 1.3: Data collection and wrangling stage from the data science workflow in Figure 1.1. This stage is directly followed by exploratory data analysis and preceded by study design.\n\n\n\n1.2.3 Exploratory Data Analysis\nBefore diving into data modelling, it’s crucial to develop a deep understanding of the relationships between the variables in your training data. This is where the third stage of the data science workflow—Exploratory Data Analysis (EDA)—comes into play. EDA serves as a vital process that allows you to visualize and summarize your data, uncover patterns, detect anomalies, and test key assumptions that will inform your modelling decisions.\nThe first step in EDA is to classify your variables according to their types. This classification is essential because it guides your choice of analysis techniques and models. Specifically, you need to determine whether each variable is discrete or continuous, and whether it has any specific characteristics such as being bounded or unbounded.\n\n\nResponse Variable:\n\nDetermine if your response variable is discrete (e.g., binary, count-based, categorical) or continuous.\nIf it is continuous, consider whether it is bounded (e.g., percentages that range between 0 and 100) or unbounded (e.g., a variable like temperature that can take on a wide range of values).\n\n\n\nRegressors:\n\nFor each regressor, identify whether it is discrete or continuous.\nIf a regressor is discrete, classify it further as binary, count-based, or categorical.\nIf a regressor is continuous, determine whether it is bounded or unbounded.\n\n\n\nThis classification step ensures that you are prepared to choose the correct visualization and statistical methods for your analysis, as different types of variables often require different approaches.\nThis classification step ensures that you are prepared to choose the correct visualization and statistical methods for your analysis, as different types of variables often require different approaches.\nAfter classifying your variables, the next step is to create visualizations and calculate descriptive statistics using your training data. This involves coding plots that can reveal the underlying distribution of each variable and the relationships between them. For instance, you might create histograms to visualize distributions, scatter plots to explore relationships between continuous variables, and box plots to compare categorical variables against the response variable.\nAlongside these visualizations, it is important to calculate key descriptive statistics such as the mean, median, and standard deviation. These statistics provide a numerical summary of your data, offering insights into central tendency and variability. You might also use a correlation matrix to assess the strength of relationships between continuous variables.\nOnce you have generated these plots and statistics, they should be displayed in a clear and logical manner. The goal here is to interpret the data and draw preliminary conclusions about the relationships between variables. Presenting these findings effectively helps to uncover key insights and prepares you for the modelling stage.\nFinally, the insights gained from this exploratory analysis must be clearly articulated. This involves summarizing the key findings and considering their implications for the next stage of the workflow—data modelling. Observing patterns, correlations, and potential outliers in this stage will inform your modelling approach and ensure that it is grounded in a thorough and informed analysis.\nThis structured approach to EDA is visually summarized in Figure 1.4, illustrating the sequential steps from variable classification to the delivery of exploratory insights.\nExample: EDA for Housing Price Predictions\nTo illustrate the EDA process, let’s apply it to the example of predicting housing prices.\nWe start with variable classification:\n\nThe response variable is the sale price of a house, a continuous and unbounded variable.\nThe regressors include:\n\n\nNumber of bedrooms: Discrete, count-based.\n\nSquare footage: Continuous and unbounded.\n\nNeighborhood type: Discrete, categorical (e.g., urban, suburban, rural).\n\nProximity to schools: Continuous, potentially bounded by distance.\n\n\n\nOnce the variables are classified, we move on to coding plots and calculating descriptive statistics. Here are a couple of visualizations that can be helpful in this context:\n\nA histogram of sale prices helps visualize the distribution and spot any outliers.\nA scatter plot of square footage versus sale price shows the relationship, typically revealing a positive correlation.\n\nBox plots compare sale prices across different neighborhood types, highlighting any variations in median prices.\n\nDescriptive statistics like the mean and standard deviation provide a numerical summary, while a correlation matrix helps assess relationships between continuous variables like square footage and sale price.\n\nFinally, in displaying and interpreting results, these plots and statistics guide us in understanding the data:\n\nThe histogram might show most houses fall within a mid-range price.\nThe scatter plot could confirm that larger houses generally sell for more.\nBox plots may reveal that urban homes tend to have higher prices.\n\nThese exploratory insights help identify key predictors like square footage and neighborhood type, and highlight any outliers that may require further attention during modelling.\nBy following these steps, the EDA process in the housing price prediction example lays a solid foundation for effective modelling, ensuring that the key variables and their relationships are well understood.\n\n\n\n\n\nFigure 1.4: Exploratory data analysis stage from the data science workflow in Figure 1.1. This stage is directly followed by data modelling and preceded by data collection and wrangling.\n\n\n\n1.2.4 Data Modelling\n\n\n\n\n\nFigure 1.5: Data modelling stage from the data science workflow in Figure 1.1. This stage is directly preceded by exploratory data analysis. On the other hand, it is directly followed by estimation but indirectly with goodness of fit. If necessary, the goodness of fit stage could retake the process to data modelling.\n\n\n\n1.2.5 Estimation\n\n\n\n\n\nFigure 1.6: Estimation stage from the data science workflow in Figure 1.1. This stage is directly preceded by data modelling and followed by goodness of fit. If necessary, the goodness of fit stage could retake the process to data modelling and then to estimation.\n\n\n\n1.2.6 Goodness of Fit\n\n\n\n\n\nFigure 1.7: Goodness of fit stage from the data science workflow in Figure 1.1. This stage is directly preceded by estimation and followed by results. If necessary, the goodness of fit stage could retake the process to data modelling and then to estimation.\n\n\n\n1.2.7 Results\n\n\n\n\n\nFigure 1.8: Results stage from the data science workflow in Figure 1.1. This stage is directly followed by storytelling and preceded by goodness of fit.\n\n\n\n1.2.8 Storytelling\n\n\n\n\n\nFigure 1.9: Storytelling stage from the data science workflow in Figure 1.1. This stage preceded by results.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting Ready for Regression Cooking!</span>"
    ]
  },
  {
    "objectID": "book/01-intro.html#sec-regression-mindmap",
    "href": "book/01-intro.html#sec-regression-mindmap",
    "title": "1  Getting Ready for Regression Cooking!",
    "section": "\n1.3 Mind Map of Regression Analysis",
    "text": "1.3 Mind Map of Regression Analysis\nHaving defined the necessary statistical aspects to execute a proper supervised learning analysis, either inferential or predictive across its seven sequential phases, we must dig into the different approaches we might encounter in practice as regression models. The nature of our outcome of interest will dictate any given modelling approach to apply, depicted as clouds in Figure 1.10. Note these regression models can be split into two sets depending on whether the outcome of interest is continuous or discrete. Therefore, under a probabilistic view, identifying the nature of a given random variable is crucial in regression analysis.\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}\n        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(\n          (Exponential &lt;br/&gt;Outcome Y)\n          (Weibull &lt;br/&gt;Outcome Y)\n          (Lognormal &lt;br/&gt;Outcome Y)\n        )Chapter 7: &lt;br/&gt;Semiparametric &lt;br/&gt;Survival &lt;br/&gt;Regression(\n          (Cox Proportional &lt;br/&gt;Hazards Model)\n            (Hazard Function &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n      {{Binary &lt;br/&gt;Outcome Y}}\n        {{Ungrouped &lt;br/&gt;Data}}\n          )Chapter 8: &lt;br/&gt;Binary Logistic &lt;br/&gt;Regression(\n            (Bernoulli &lt;br/&gt;Outcome Y)\n        {{Grouped &lt;br/&gt;Data}}\n          )Chapter 9: &lt;br/&gt;Binomial Logistic &lt;br/&gt;Regression(\n            (Binomial &lt;br/&gt;Outcome Y)\n      {{Count &lt;br/&gt;Outcome Y}}\n        {{Equidispersed &lt;br/&gt;Data}}\n          )Chapter 10: &lt;br/&gt;Classical Poisson &lt;br/&gt;Regression(\n            (Poisson &lt;br/&gt;Outcome Y)\n        {{Overdispersed &lt;br/&gt;Data}}\n          )Chapter 11: &lt;br/&gt;Negative Binomial &lt;br/&gt;Regression(\n            (Negative Binomial &lt;br/&gt;Outcome Y)\n        {{Overdispersed or &lt;br/&gt;Underdispersed &lt;br/&gt;Data}}\n          )Chapter 13: &lt;br/&gt;Generalized &lt;br/&gt;Poisson &lt;br/&gt;Regression(\n            (Generalized &lt;br/&gt;Poisson &lt;br/&gt;Outcome Y)\n        {{Zero Inflated &lt;br/&gt;Data}}\n          )Chapter 12: &lt;br/&gt;Zero Inflated &lt;br/&gt;Poisson &lt;br/&gt;Regression(\n            (Zero Inflated &lt;br/&gt;Poisson &lt;br/&gt;Outcome Y)\n      {{Categorical &lt;br/&gt;Outcome Y}}\n        {{Nominal &lt;br/&gt;Outcome Y}}\n          )Chapter 14: &lt;br/&gt;Multinomial &lt;br/&gt;Logistic &lt;br/&gt;Regression(\n            (Multinomial &lt;br/&gt;Outcome Y)\n        {{Ordinal &lt;br/&gt;Outcome Y}}\n          )Chapter 15: &lt;br/&gt;Ordinal &lt;br/&gt;Logistic &lt;br/&gt;Regression(\n            (Logistic &lt;br/&gt;Distributed &lt;br/&gt;Cumulative Outcome &lt;br/&gt;Probability)\n\n\n\n\n\n\n\n\nFigure 1.10: Regression analysis mind map depicting all modelling techniques to be explored in this book. Depending on the type of outcome \\(Y\\), these techniques are split into two large zones: discrete and continuous.\n\n\nThat said, we will go beyond OLS regression and explore further regression techniques. In practice, these techniques have been developed in the statistical literature to address practical cases where the OLS modelling framework and assumptions are not suitable anymore. Thus, throughout this block, we will cover (at least) one new regression model per lecture.\nAs we can see in the clouds of Figure 1.10, there are 13 regression models: 8 belonging to discrete outcomes and 5 to continuous outcomes. Each of these models is contained in a chapter of this book, beginning with the most basic regression tool known as ordinary least-squares in Chapter 3. We must clarify that the current statistical literature is not restricted to these 13 regression models. The field of regression analysis is vast, and one might encounter more complex models to target certain specific inquiries. Nonetheless, I consider these models the fundamental regression approaches that any data scientist must be familiar with in everyday practice.\nEven though this book comprises 13 chapters, each depicting a different regression model, we have split these chapters into two major subsets: those with continuous outcomes and those with discrete outcomes.\n\n\n\n\nGelbart, Michael. 2017. “Data Science Terminology.” UBC MDS. Master of Data Science at the University of British Columbia. https://ubc-mds.github.io/resources_pages/terminology/.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting Ready for Regression Cooking!</span>"
    ]
  },
  {
    "objectID": "book/02-stats-review.html",
    "href": "book/02-stats-review.html",
    "title": "2  Basic Cuisine: A Review on Probability and Frequentist Statistical Inference",
    "section": "",
    "text": "2.1 Basics of Probability\nThis chapter will delve into probability and frequentist statistical inference. We can view these sections as a quick review of introductory probability and statistics concepts. Moreover, this review will be important to understanding the philosophy of modelling parameter estimation as outlined in Section 1.2.5. Then, we will pave the way to the rationale behind statistical inference in the results stage (as in Section 1.2.7) in our workflow from Figure 1.1. Note that we aim to explain all these statistical and probabilistic concepts in the most possible practical way via a made-up case study throughout this chapter. Still, we will use an appropriate level of jargon and will follow the colour convention found in Appendix A along with the definition callout box.\nImagine you are an undergraduate engineering student. Moreover, last term, you just took and passed your first course in probability and statistics (inference included!) in an industrial engineering context. Moreover, as it could happen while taking an introductory course in probability and statistics, you used to feel quite overwhelmed by the large amount of jargon and formulas one had to grasp and use regularly for primary engineering fields such as quality control in a manufacturing facility. Population parameters, hypothesis testing, tests statistics, significance level, \\(p\\)-values, and confidence intervals (do not worry, our statistical/machine learning scheme will come in later in this review) were appearing here and there! And to your frustration, you could never find a statistical connection between all these inferential tools! Instead, you relied on mechanistic procedures when solving assignments or exam problems.\nFor instance, when performing hypothesis testing for a two-sample \\(t\\)-test, you struggled to reflect what the hypotheses were trying to indicate for the corresponding population parameter(s) or how the test statistic was related to these hypotheses. Moreover, your interpretation of the resulting \\(p\\)-value and/or confidence interval was purely mechanical with the inherent claim:\nTruthfully, this whole mechanical way of doing statistics is not ideal in a teaching, research or industry environment. Along the same lines, the above situation should also not happen when we learn key statistical topics for the very first time as undergraduate students. That is why we will investigate a more intuitive way of viewing probability and its crucial role in statistical inference. This matter will help us deliver more coherent storytelling (as in Section 1.2.8) when presenting our results in practice during any regression analysis to our peers or stakeholders. Note that the role of probability also extends to model training (as in Section 1.2.5) when it comes to supervised learning and not just regarding statistical inference.\nHaving said all this, it is time to introduce a statement that is key when teaching hypothesis testing in an introductory statistical inference course:\nThat is quite a bold statement! Nonetheless, once one starts teaching statistical topics to audiences not entirely familiar with the usual field jargon, the idea of randomness always persists across many different tools. And, of course, regression analysis is not an exception at all since it also involves inference on population parameters of interest! This is why we have allocated this section in the textbook to explain core probabilistic and inferential concepts to pave the way to its role in regression analysis.\nFinally, even though this book has suggested reviews related to the basics of probability via different distributions and the fundamentals of frequentist statistical inference as stated in Audience and Scope, we will retake essential concepts as follows:\nWithout further ado, let us start with reviewing core concepts in probability via quite a tasty example.\nIn terms of regression analysis and its supervised learning counterpart (either on an inferential or predictive framework), probability can be viewed as the solid foundation on which more complex tools, including estimation and hypothesis testing, are built upon. Having said that, let us scaffold across all the necessary probabilistic concepts that will allow us to move forward into these more complex tools.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Cuisine: A Review on Probability and Frequentist Statistical Inference</span>"
    ]
  },
  {
    "objectID": "book/02-stats-review.html#sec-basics-prob",
    "href": "book/02-stats-review.html#sec-basics-prob",
    "title": "2  Basic Cuisine: A Review on Probability and Frequentist Statistical Inference",
    "section": "",
    "text": "2.1.1 First Insights\nUnder the above solid foundation, our data is coming from a given population or system of interest. Moreover, the population or system is assumed to be governed by parameters which, as data scientists or researchers, they are of their best interest to study. That said, the terms population and parameter will pave the way to our first statistical definitions.\n\n\nDefinition of population\n\n\nIt is a whole collection of individuals or items that share distinctive attributes. As data scientists or researchers, we are interested in studying these attributes, which we assume are governed by parameters. In practice, we must be as specific as possible when defining our given population such that we would frame our entire data modelling process since its very early stages. Examples of a population could be the following:\n\nChildren between the ages of 5 and 10 years old in states of the American West Coast.\nCustomers of musical vinyl records in the Canadian provinces of British Columbia and Alberta.\nAvocado trees grown in the Mexican state of Michoacán.\nAdult giant pandas in the Southwestern Chinese province of Sichuan.\nMature açaí palm trees from the Brazilian Amazonian jungle.\n\n\n\nImage by Eak K. via Pixabay.\n\nNote that the term population could be exchanged for the term system, given that certain contexts do not particularly refer to individuals or items. Instead, these contexts could refer to processes whose attributes are also governed by parameters. Examples of a system could be the following:\n\nThe production of cellular phones from a given model in a set of manufacturing facilities.\nThe sale process in the Vancouver franchises of a well-known ice cream parlour.\nThe transit cycle during rush hours on weekdays in the twelve lines of Mexico City’s subway.\n\n\n\n\n\nDefinition of parameter\n\n\nIt is a characteristic (numerical or even non-numerical, such as a distinctive category) that summarizes the state of our population or system of interest. Examples of a population parameter can be described as follows:\n\nThe average weight of children between the ages of 5 and 10 years old in states of the American west coast (numerical).\nThe variability in the height of the mature açaí palm trees from the Brazilian Amazonian jungle (numerical).\nThe proportion of defective items in the production of cellular phones in a set of manufacturing facilities (numerical).\nThe average customer waiting time to get their order in the Vancouver franchises of a well-known ice cream parlour (numerical).\nThe most favourite pizza topping of vegetarian adults between the ages of 30 and 40 years old in Edmonton (non-numerical).\n\n\n\nImage by meineresterampe via Pixabay.\n\nNote the standard mathematical notation for population parameters are Greek letters. Moreover, in practice, these population parameter(s) of interest will be unknown to the data scientist or researcher. Instead, they would use formal statistical inference to estimate them.\n\n\nThe parameter definition points out a crucial fact in investigating any given population or system:\n\nOur parameter(s) of interest are usually unknown!\n\nGiven this fact, it would be pretty unfortunate and inconvenient if we eventually wanted to discover any significant insights about the population or system. Therefore, let us proceed to our so-called tasty example so we can dive into the need for statistical inference and why probability is our perfect ally in this parameter quest.\nImagine you are the owner of a large fleet of ice cream carts, around 900 to be exact. These ice cream carts operate across different parks in the following Canadian cities: Vancouver, Victoria, Edmonton, Calgary, Winnipeg, Ottawa, Toronto, and Montréal. In the past, to optimize operational costs, you decided to limit ice cream cones to only two items: vanilla and chocolate flavours, as in Figure 2.1.\n\n\n\n\n\nFigure 2.1: The two flavours of the ice cream cone you sell across all your ice cream carts: vanilla and chocolate. Image by tomekwalecki via Pixabay.\n\n\nNow, let us direct this whole case onto a more statistical and probabilistic field; suppose you have a well-defined overall population of interest for those above eight Canadian cities: children between 4 and 11 years old attending these parks during the Summer weekends. Of course, Summer time is coming this year, and you would like to know which ice cream cone flavour is the favourite one for this population (and by how much!). As a business owner, investigating ice cream flavour preferences would allow you to plan Summer restocks more carefully with your corresponding suppliers. Therefore, it would be essential to start collecting consumer data so the company can tackle this demand query.\nAlso, suppose there is a second query. For the sake of our case, we will call it a time query. As a critical component of demand planning, besides estimating which cone flavour is the most preferred one (and by how much!) for the above population of interest, the operations area is currently requiring a realistic estimation of the average waiting time from one customer to the next one in any given cart during Summer weekends. This average waiting time would allow the operations team to plan carefully how much stock each cart should have so there will not be any waste or shortage.\n\n\nImage by Icons8 Team via Unsplash.\n\nNote that the nature of the aforementioned time query is more related to a larger population. Therefore, we can define it as all our ice cream customers during the Summer weekends. Furthermore, this second definition would expand this query to our corresponding general ice cream customers, given the requirements of our operations team, and not all the children between 4 and 11 years old attending the parks during Summer weekends. Consequently, it is crucial to note that the nature of our queries will dictate how we define our population and our subsequent data modelling and statistical inference.\nSummer time represents the most profitable season from a business perspective, thus solving these above two queries is a significant priority for your company. Hence, you decide to organize a meeting with your eight general managers (one per Canadian city). Finally, during the meeting with the general managers, it was decided to do the following:\n\nFor the demand query, a comprehensive market study will be run on the population of interest across the eight Canadian cities right before next Summer; suppose we are currently in Spring.\nFor the time query, since the operations team has not previously recorded any historical data, ALL vendor staff from 900 carts will start collecting data on the waiting time in seconds between each customer this upcoming Summer.\n\nSurprisingly, when discussing study requirements for the marketing firm who would be in charge of it for the demand query, Vancouver’s general manager dares to state the following:\n\nSince we’re already planning to collect consumer data on these cities, let’s mimic a census-type study to ensure we can have the MOST PRECISE results on their preferences.\n\nOn the other hand, when agreeing on the specific operations protocol to start recording waiting times for all the 900 vending carts this upcoming Summer, Ottawa’s general manager provides a comment for further statistical food for thought:\n\nThe operations protocol for recording waiting times in the 900 vending carts looks too cumbersome to implement straightforwardly this upcoming Summer. Why don’t we select A SMALLER GROUP of ice cream carts across the eight cities to have a more efficient process implementation that would allow us to optimize operational costs?\n\nBingo! Ottawa’s general manager just nailed the probabilistic way of making inference on our population parameter of interest for the time query. Indeed, their comment was primarily framed from a business perspective of optimizing operational costs. Still, this fact does not take away a crucial insight on which statistical inference is built: a random sample ( as in its corresponding definition). As for Vancouver’s general manager, ironically, their statement is NOT PRECISE at all! Mimicking a census-type study might not be the most optimal decision for the demand query given the time constraint and the potential size of its target population.\n\nRealistically, there is no cheap and efficient way to conduct a census-type study for any of the two queries!\n\nMoving on to one of the core topics in this chapter, we can state that probability is viewed as the language to decode random phenomena that occur in any given population or system of interest. In our example, we have two random phenomena:\n\nFor the demand query, a phenomenon can be represented by the preferred ice cream cone flavour of any randomly selected child between 4 and 11 years old attending the parks of the above eight Canadian cities during the Summer weekends.\nRegarding the time query, a phenomenon of this kind can be represented by any randomly recorded waiting time between two customers during a Summer weekend in any of the above eight Canadian cities.\n\nNow, let us finally define what we mean by probability along with the inherent concept of sample space.\n\n\nDefinition of probability\n\n\nLet \\(A\\) be an event of interest in a random phenomenon of a population or system of interest, whose all possible outcomes belong to a given sample space \\(S\\). Generally, the probability for this event \\(A\\) happening can be mathematically depicted as \\(P(A)\\). Moreover, suppose we observe the random phenomenon \\(n\\) times such as we were running some class of experiment, then \\(P(A)\\) is defined as the following ratio:\n\\[\nP(A) = \\frac{\\text{Number of times event $A$ is observed}}{n},\n\\tag{2.1}\\]\nas the \\(n\\) times we observe the random phenomenon goes to infinity.\nEquation 2.1 will always put \\(P(A)\\) in the following numerical range:\n\\[\n0 \\leq P(A) \\leq 1.\n\\]\n\n\n\n\nDefinition of sample space\n\n\nLet \\(A\\) be an event of interest in a random phenomenon of a population or system of interest. The sample space \\(S\\) of event \\(A\\) denotes the set of all the possible random outcomes we might encounter every time we randomly observe \\(A\\) such as we were running some class of experiment.\nNote each of these outcomes has a determined probability associated with them. If we add up all these probabilities, the probability of the sample space \\(S\\) will be one, i.e.,\n\\[\nP(S) = 1.\n\\tag{2.2}\\]\n\n\n\n2.1.2 Schools of Statistical Thinking\nNote the above definition for the probability of an event \\(A\\) specifically highlights the following:\n\n… as the \\(n\\) times we observe the random phenomenon goes to infinity.\n\nThe “infinity” term is key when it comes to understanding the philosophy behind the frequentist school of statistical thinking in contrast to its Bayesian counterpart. In general, the frequentist way of practicing statistics in terms of probability and inference is the approach we usually learn in introductory courses, more specifically when it comes to hypothesis testing and confidence intervals which will be explored in Section 2.3. That said, the Bayesian approach is another way of practicing statistical inference. Its philosophy differs in what information is used to infer our population parameters of interest. Below, we briefly define both schools of thinking.\n\n\nDefinition of frequentist statistics\n\n\nThis statistical school of thinking heavily relies on the frequency of events to estimate specific parameters of interest in a population or system. This frequency of events is reflected in the repetition of \\(n\\) experiments involving a random phenomenon within this population or system.\nUnder the umbrella of this approach, we assume that our governing parameters are fixed. Note that, within the philosophy of this school of thinking, we can only make precise and accurate predictions as long as we repeat our \\(n\\) experiments as many times as possible, i.e.,\n\\[\nn \\rightarrow \\infty.\n\\]\n\n\n\n\nDefinition of Bayesian statistics\n\n\nThis statistical school of thinking also relies on the frequency of events to estimate specific parameters of interest in a population or system. Nevertheless, unlike frequentist statistics, Bayesian statisticians use prior knowledge on the population parameters to update their estimations on them along with the current evidence they can gather. This evidence is in the form of the repetition of \\(n\\) experiments involving a random phenomenon. All these ingredients allow Bayesian statisticians to make inference by conducting appropriate hypothesis testings, which are designed differently from their mainstream frequentist counterpart.\n\n\nThe unique known portrait of Reverend Thomas Bayes according to O’Donnell, T. (1936), even though Bellhouse (2004) argues it might not be a Bayes’ portrait.\n\nUnder the umbrella of this approach, we assume that our governing parameters are random; i.e., they have their own sample space and probabilities associated to their corresponding outcomes. The statistical process of inference is heavily backed up by probability theory mostly in the form of the Bayes theorem (named after Reverend Thomas Bayes, an English statistician from the 18th century). This theorem uses our current evidence along with our prior beliefs to deliver a posterior distribution of our random parameter(s) of interest.\n\n\nLet us put the definitions for the above schools of statistical thinking into a more concrete example. We can use the demand query from our ice cream case as a starting point. More concretely, we can dig more into a standalone population parameter such as the probability that a randomly selected child between 4 and 11 years old, attending the parks of the above eight Canadian cities during the Summer weekends, prefers the chocolate-flavoured ice cream cone over the vanilla one. Think about the following two hypothetical questions:\n\nFrom a frequentist point of view, what is the estimated probability of preferring chocolate over vanilla after randomly surveying \\(n = 100\\) children from our population of interest?\nUsing a Bayesian approach, suppose the marketing team has found ten prior market studies on similar children populations on their preferred ice cream flavour (between chocolate and vanilla). Therefore, along with our actual random survey of \\(n = 100\\) children from our population of interest, what is the posterior estimation of the probability of preferring chocolate over vanilla?\n\nBy comparing the above (a) and (b), we can see one characteristic in common when it comes to the estimation of the probability of preferring chocolate over vanilla: both frequentist and Bayesian approaches rely on the gathered evidence coming from the random survey of \\(n = 100\\) children from our population of interest. On the one hand, the frequentist approach solely relies on observed data to estimate this single probability of preferring chocolate over vanilla. On the other hand, the Bayesian approach uses the observed data in conjunction with the prior knowledge provided by the ten estimated probabilities to deliver a whole posterior distribution (i.e., the posterior estimation) of the probability of preferring chocolate over vanilla.\n\n\nHeads-up on the debate between frequentist and Bayesian statistics!\n\n\nEven though most of us began our statistical journey in a frequentist framework, we might be tempted to state that a Bayesian paradigm for parameter estimation and inference is better than a frequentist one since the former only takes into account the observed evidence without the prior knowledge on our parameters of interest.\n\n\nImage by Manfred Steger via Pixabay.\n\nIn the statistical community, there could be a fascinating debate between the pros and cons of each school of thinking. That said, it is crucial to state that no paradigm is considered wrong! Instead, using a pragmatic strategy of performing statistics according to our data science context is more convenient.\n\n\n\n\nTip on further Bayesian and frequentist insights!\n\n\nLet us check the following two examples (aside from our ice cream case) to illustrate the above pragmatic way of doing things:\n\nTake the production of cellular phones from a given model in a set of manufacturing facilities as the context. Hence, one might find a frequentist estimation of the proportion of defective items as a quicker and more efficient way to correct any given manufacturing process. That is, we will sample products from our finalized batches and check their status (defective or non-defective, our observed evidence) to deliver a proportion estimation of defective items.\nNow, take a physician’s context. It would not make a lot of sense to study the probability that a patient develops a certain disease by only using a frequentist approach, i.e., looking at the current symptoms which account for the observed evidence. In lieu, a Bayesian approach would be more suitable to study this probability which uses the observed evidence combined with the patient’s history (i.e., the prior knowledge) to deliver our posterior belief on the disease probability.\n\n\n\nHaving said all this, it is important to reiterate that the focus of this textbook is purely frequentist in regards to data modelling in regression analysis. If you would like to explore the fundamentals of the Bayesian paradigm; Johnson, Ott, and Dogucu (2022) have developed an amazing textbook on the basic probability theory behind this school of statistical thinking along with a whole variety regression techniques including the parameter estimation rationale.\n\n2.1.3 The Random Variables\nMoving along…\nCasella and Berger (2024) and Soch et al. (2024)\n\n\nDefinition of random variable\n\n\nA random variable is a function where the input values correspond to real numbers assigned to events belonging to the sample space \\(S\\), and whose outcome is one of these real numbers after executing a given random experiment. For instance, a random variable (and its support, i.e., real numbers) is depicted with an uppercase such that\n\\[Y \\in \\mathbb{R}.\\]\n\n\n\n\nDefinition of discrete random variable\n\n\nLet \\(Y\\) be a random variable whose support is \\(\\mathcal{Y}\\). If this support \\(\\mathcal{Y}\\) corresponds to a finite set or a countably infinite set of possible values, then \\(Y\\) is considered a discrete random variable.\nFor instance, we can encounter discrete random variables which could be classified as\n\n\nbinary (i.e., a finite set of two possible values),\n\ncategorical (either nominal or ordinal, which have a finite set of three or more possible values), or\n\ncounts (which might have a finite set or a countably infinite set of possible values as integers).\n\n\n\nImage by Pexels via Pixabay.\n\n\n\n\n\nDefinition of continuous random variable\n\n\nLet \\(Y\\) be a random variable whose support is \\(\\mathcal{Y}\\). If this support \\(\\mathcal{Y}\\) corresponds to an uncountably infinite set of possible values, then \\(Y\\) is considered a continuous random variable.\nNote a continuous random variable could be\n\n\ncompletely unbounded (i.e., its set of possible values goes from \\(-\\infty\\) to \\(\\infty\\) as in \\(-\\infty &lt; y &lt; \\infty\\)),\n\npositively unbounded (i.e., its set of possible values goes from \\(0\\) to \\(\\infty\\) as in \\(0 \\leq y &lt; \\infty\\)),\n\nnegatively unbounded (i.e., its set of possible values goes from \\(-\\infty\\) to \\(0\\) as in \\(-\\infty &lt; y \\leq 0\\)), or\n\nbounded between two values \\(a\\) and \\(b\\) (i.e., its set of possible values goes from \\(a\\) to \\(b\\) as in \\(a \\leq y \\leq b\\)).\n\n\n\nImage by arielrobin via Pixabay.\n\n\n\n\n2.1.4 The Wonders of Generative Modelling and Probability Distributions\n\n\nDefinition of generative model\n\n\nSuppose you observe some data \\(y\\) from a population or system of interest. Moreover, let us assume this population or system is governed by \\(k\\) parameters contained in the following vector:\n\\[\n\\boldsymbol{\\theta} = (\\theta_1, \\theta_2, \\cdots, \\theta_k)^T.\n\\]\nIf we state that our observed data \\(y\\) follows certain probability distribution \\(\\mathcal{D}(\\cdot)\\), then we will have a generative model \\(m\\) such that\n\\[\nm: y \\sim \\mathcal{D}(\\boldsymbol{\\theta}).\n\\]\n\n\nImage by Manfred Stege via Pixabay.\n\n\n\n\n\nDefinition of probability distribution\n\n\nWhen we set a random variable \\(Y\\), we also set a new set of \\(v\\) possible outcomes \\(\\mathcal{Y} = \\{ y_1, \\dots, y_v\\}\\) coming from the sample space \\(S\\). This new set of possible outcomes \\(\\mathcal{Y}\\) corresponds to the range of the random variable \\(Y\\) (i.e., all the possible values that could be taken on once we execute a given random experiment involving \\(Y\\)).\nThat said, let us suppose we have a sample space of \\(u\\) elements defined as\n\\[\nS = \\{ s_1, \\dots, s_u \\},\n\\]\nwhere each one of these elements has a probability assigned via a function \\(P_S(\\cdot)\\) such that\n\\[\nP(S) = \\sum_{i = 1}^u P_S(s_i) = 1.\n\\]\nwhich has to satisfy Equation 2.2.\nThen, the probability distribution of \\(Y\\), i.e., \\(P_Y(\\cdot)\\) assigns a probability to each observed value \\(Y = y_j\\) (with \\(j = 1, \\dots, v\\)) if and only if the outcome of the random experiment belongs to the sample space, i.e., \\(s_i \\in S\\) (for \\(i = 1, \\dots, u\\)) such that \\(Y(s_i) = y_j\\):\n\\[\nP_Y(Y = y_j) = P \\left( \\left\\{ s_i \\in S : Y(s_i) = y_j \\right\\} \\right).\n\\]\n\n\n\n\nDefinition of probability mass function\n\n\nLet \\(Y\\) be a discrete random variable whose support is \\(\\mathcal{Y}\\). Moreover, suppose that \\(Y\\) has a probability distribution such that\n\\[\nP_Y(Y = y) : \\mathbb{R} \\rightarrow [0, 1]\n\\]\nwhere, for all \\(y \\notin \\mathcal{Y}\\), we have\n\\[\nP_Y(Y = y) = 0\n\\]\nand\n\\[\n\\sum_{y \\in \\mathcal{Y}} P_Y(Y = y) = 1.\n\\] Then, \\(P_Y(Y = y)\\) is considered a probability mass function (PMF).\n\n\n\n\nDefinition of probability density function\n\n\nLet \\(Y\\) be a continuous random variable whose support is \\(\\mathcal{Y}\\). Furthermore, consider a function \\(f_Y(y)\\) such that\n\\[\nf_Y(y) : \\mathbb{R} \\rightarrow \\mathbb{R}\n\\]\nwith\n\\[\nf_Y(y) \\geq 0.\n\\]\nThen, \\(f_Y(y)\\) is considered a probability density function (PDF) if the probability of \\(Y\\) taking on a value within the range represented by the subset \\(A \\subset \\mathcal{Y}\\) is equal to\n\\[\nP_Y(Y \\in A) = \\int_A f_Y(y) \\mathrm{d}y\n\\]\nwith\n\\[\n\\int_{\\mathcal{Y}} f_Y(y) \\mathrm{d}y = 1.\n\\]\n\n\n\n2.1.5 Characterizing Probability Distributions\n\n\nDefinition of measure of central tendency\n\n\nProbabilistically, a measure of central tendency is defined as a metric that identifies a central or typical value of a given probability distribution. In other words, a measure of central tendency refers to a central or typical value that a given random variable might take when we observe various realizations of this variable over a long period.\n\n\nImage by Manfred Stege via Pixabay.\n\n\n\n\n\nDefinition of measure of uncertainty\n\n\nProbabilistically, a measure of uncertainty refers to the spread of a given random variable when we observe its different realizations in the long term. Note a larger spread indicates more variability in these realizations. On the other hand, a smaller spread denotes less variability in these realizations.\n\n\nImage by Manfred Stege via Pixabay.\n\n\n\n\n\nDefinition of expected value\n\n\nLet \\(Y\\) be a random variable whose support is \\(\\mathcal{Y}\\). In general, the expected value or mean \\(\\mathbb{E}(Y)\\) of this random variable is defined as a weighted average according to its corresponding probability distribution. In other words, this measure of central tendency \\(\\mathbb{E}(Y)\\) aims to find the middle value of this random variable by weighting all its possible values in its support \\(\\mathcal{Y}\\) as dictated by its probability distribution.\nGiven the above definition, when \\(Y\\) is a discrete random variable whose PMF is \\(P_Y(Y = y)\\), then its expected value is mathematically defined as\n\\[\n\\mathbb{E}(Y) = \\sum_{y \\in \\mathcal{Y}} y \\cdot P_Y(Y = y).\n\\tag{2.3}\\]\nWhen \\(Y\\) is a continuous random variable whose PDF is \\(f_Y(y)\\), its expected value is mathematically defined as\n\\[\n\\mathbb{E}(Y) = \\int_{\\mathcal{Y}} y \\cdot f_Y(y) \\mathrm{d}y.\n\\tag{2.4}\\]\n\n\nImage by Manfred Stege via Pixabay.\n\n\n\n\n\nDefinition of cumulative distribution function\n\n\nLet \\(Y\\) be a random variable either discrete or continuous. Its cumulative distribution function (CDF) \\(F_Y(y)  : \\mathbb{R} \\rightarrow [0, 1]\\) refers to the probability that \\(Y\\) is less or equal than an observed value \\(y\\):\n\\[\nF_Y(y) = P(Y \\leq y).\n\\tag{2.5}\\]\nThen, we have the following by type of random variable:\n\nWhen \\(Y\\) is discrete, whose support is \\(\\mathcal{Y}\\), suppose it has a PMF \\(P_Y(Y = y)\\). Then, the CDF is mathematically represented as:\n\n\\[\nF_Y(y) = \\sum_{\\substack{t \\in \\mathcal{Y} \\\\ t \\leq y}} P_Y(Y = t).\n\\tag{2.6}\\]\n\nWhen \\(Y\\) is continuous, whose support is \\(\\mathcal{Y}\\), suppose it has a PDF \\(f_Y(y)\\). Then, the CDF is mathematically represented as:\n\n\\[\nF_Y(y) = \\int_{-\\infty}^y f_Y(t) \\mathrm{d}t.\n\\tag{2.7}\\]\nNote that in Equation 2.6 and Equation 2.7, we use the auxiliary variable \\(t\\) since we do not compute the summation or integral over the observed \\(y\\) given its role on either the PMF or PDF. Therefore, we use this auxiliary variable \\(t\\).\n\n\n\n\nHeads-up on the properties of the cumulative distribution function!\n\n\nIt is important to clarify that a valid CDF \\(F_Y(y)\\) fulfils the following properties:\n\n\n\\(F_Y(y)\\) must never be a decreasing function.\nGiven that \\(F_Y(y)  : \\mathbb{R} \\rightarrow [0, 1]\\), it must never evaluate to be \\(&lt; 0\\) or \\(&gt; 1\\). The output of a CDF is a cumulative probability, hence the previous bounds.\nWhen \\(y \\rightarrow -\\infty\\), if follows that \\(F_Y(y) \\rightarrow 0\\).\nWhen \\(y \\rightarrow \\infty\\), if follows that \\(F_Y(y) \\rightarrow 1\\).\n\nNow, in the case of a CDF corresponding to a continuous random variable \\(Y\\), there is an additional handy property that relates the CDF \\(F_Y(y)\\) to the PDF \\(f_Y(y)\\):\n\\[\nf_Y(y) = \\frac{\\mathrm{d}}{\\mathrm{d}y} F_Y(y).\n\\tag{2.8}\\]\nEquation 2.8 indicates that the PDF of \\(Y\\) can be obtained by taking the first derivative of the CDF with respect to \\(y\\).\n\n\n\n\nTip on the Law of the Unconscious Statistician!\n\n\nThe law of the unconscious statistician (LOTUS) is a particular theorem in probability theory that allows us to compute a wide variety of expected values. Let us properly define it for both discrete and continuous random variables.\n\nTheorem 2.1 Let \\(Y\\) be a discrete random variable whose support is \\(\\mathcal{Y}\\). The LOTUS indicates that the expected value of a general function \\(g(Y)\\) of this random variable \\(Y\\) can be obtained via \\(g(Y)\\) along with the corresponding PMF \\(P_Y(Y = y)\\). Hence, the expected value of \\(g(Y)\\) can be obtained as\n\\[\n\\mathbb{E}\\left[ g(Y) \\right] = \\sum_{y \\in \\mathcal{Y}} g(y) \\cdot P_Y(Y = y).\n\\tag{2.9}\\]\n\nProof. Let us explore the rationale provided by Soch et al. (2024). Thus, we will rename the general function \\(g(Y)\\) as another random variable called \\(Z\\) such that:\n\\[\nZ = g(Y).\n\\tag{2.10}\\]\nNote this function \\(g(Y)\\) can take on equal values \\(g(y_1), g(y_2), \\dots\\) coming from different observed values \\(y_1, y_2, \\dots\\); for example, if\n\\[\ng(y) = y^2\n\\]\nboth\n\\[\ny_1 = 2 \\quad \\text{and} \\quad y_2 = -2\n\\]\nyield\n\\[\ng(y_1) = g(y_2) = 4.\n\\]\nThe above Equation 2.10 is formally called a random variable transformation from the general function of random variable \\(Y\\), \\(g(Y)\\), to a new random variable \\(Z\\). Having said that, when we set up a transformation of this class, there will be a support mapping from this general function \\(g(Y)\\) to \\(Z\\). This will also yield a proper PMF,\n\\[\nP_Z(Z = z) : \\mathbb{R} \\rightarrow [0, 1] \\quad \\forall z \\in \\mathcal{Z},\n\\]\ngiven that \\(g(Y)\\) is a random variable-based function.\nTherefore, using the expected value definition for a discrete random variable as in Equation 2.3, we have the following for \\(Z\\):\n\\[\n\\mathbb{E}(Z) = \\sum_{z \\in \\mathcal{Z}} z \\cdot P_Z(Z = z).\n\\tag{2.11}\\]\nWithin the support \\(\\mathcal{Z}\\), suppose that \\(z_1, z_2, \\dots\\) are the possible different values of \\(Z\\) corresponding to function \\(g(Y)\\). Then, for the \\(i\\)th value \\(z_i\\) in this correspondence, let \\(I_i\\) be the collection of all \\(y_j\\) such that\n\\[\ng(y_j) = z_i.\n\\tag{2.12}\\]\nNow, let us tweak a bit the above expression from Equation 2.11 to include this setting:\n\\[\n\\begin{align*}\n\\mathbb{E}(Z) &= \\sum_{z \\in \\mathcal{Z}} z \\cdot P_Z(Z = z) \\\\\n&= \\sum_{i} z_i \\cdot P_{g(Y)}(Z = z_i) \\\\\n& \\qquad \\text{we subset the summation to all $z_i$ with $Z = g(Y)$}\\\\\n&= \\sum_{i} z_i \\sum_{j \\in I_i} P_Y(Y = y_j). \\\\\n\\end{align*}\n\\tag{2.13}\\]\nThe last line of Equation 2.13 maps the probabilities associated to all \\(z_i\\) in the corresponding PMF of \\(Z\\), \\(P_Z(\\cdot)\\) via the function \\(g(Y)\\), to the original PMF of \\(Y\\), \\(P_Y(\\cdot)\\), for all those \\(y_j\\) contained in the collection \\(I_i\\). Given that certain values \\(z_i\\) can be obtained with more than one value \\(y_j\\), such as in the above example when \\(g(y) = y^2\\) for \\(y_1 = 2\\) and \\(y_2 = -2\\), note we have a second summation of probabilities applied to the PMF of \\(Y\\).\nMoving along with Equation 2.13 in conjunction with Equation 2.12, we have that:\n\\[\n\\begin{align*}\n\\mathbb{E}(Z) &= \\sum_{i} z_i \\sum_{j \\in I_i} P_Y(Y = y_j) \\\\\n&= \\sum_{i} \\sum_{j \\in I_i} z_i \\cdot P_Y(Y = y_j) \\\\\n&= \\sum_{i} \\sum_{j \\in I_i} g(y_j) \\cdot P_Y(Y = y_j).\n\\end{align*}\n\\tag{2.14}\\]\nThe double summation in Equation 2.14 can be summarized into a single one, given neither of the factors on the right-hand side is subindexed by \\(i\\). Furthermore, this standalone summation can be applied to all \\(y \\in \\mathcal{Y}\\) while getting rid of the subindex \\(j\\) in the factors on the right-hand side:\n\\[\n\\begin{align*}\n\\mathbb{E}(Z) &= \\sum_{i} \\sum_{j \\in I_i} g(y_j) \\cdot P_Y(Y = y_j) \\\\\n&= \\sum_{y \\in \\mathcal{Y}} g(y) \\cdot P_Y(Y = y) \\\\\n&= \\mathbb{E}\\left[ g(Y) \\right].\n\\end{align*}\n\\]\nTherefore, we have:\n\\[\n\\mathbb{E}\\left[ g(Y) \\right] = \\sum_{y \\in \\mathcal{Y}} g(y) \\cdot P_Y(Y = y). \\quad \\square\n\\]\n\n\n\nTheorem 2.2 Let \\(Y\\) be a continuous random variable whose support is \\(\\mathcal{Y}\\). The LOTUS indicates that the expected value of a general function \\(g(Y)\\) of this random variable \\(Y\\) can be obtained via \\(g(Y)\\) along with the corresponding PDF \\(f_Y(y)\\). Thus, the expected value of \\(g(Y)\\) can be obtained as\n\\[\n\\mathbb{E}\\left[ g(Y) \\right] = \\int_{\\mathcal{Y}} g(y) \\cdot f_Y(y).\n\\tag{2.15}\\]\n\nProof. Let us explore the rationale provided by Soch et al. (2024). Hence, we will rename the general function \\(g(Y)\\) as another random variable called \\(Z\\) such that:\n\\[\nZ = g(Y).\n\\tag{2.16}\\]\nAs in the discrete LOTUS proof, the above Equation 2.16 is formally called a random variable transformation from the general function of random variable \\(Y,\\) \\(g(Y)\\), to a new random variable \\(Z\\). Therefore, when we set up a transformation of this class, there will be a support mapping from this general function \\(g(Y)\\) to \\(Z\\). This will also yield a proper PDF:\n\\[\nf_Z(z) : \\mathbb{R} \\rightarrow [0, 1] \\quad \\forall z \\in \\mathcal{Z},\n\\]\ngiven that \\(g(Y)\\) is a random variable-based function.\nAnalogous to Equation 2.5, we will use the concept of the CDF for a continuous random variable \\(Z\\):\n\\[\n\\begin{align*}\nF_Z(z) &= P(Z \\leq z) \\\\\n&= P\\left[g(Y) \\leq z \\right] \\\\\n&= P\\left[Y \\leq g^{-1}(z) \\right] \\\\\n&= F_Y\\left[ g^{-1}(z) \\right].\n\\end{align*}\n\\tag{2.17}\\]\nA well-known Calculus result is the inverse function theorem. Assuming that\n\\[\nz = g(y)\n\\]\nis an invertible and differentiable function, then the inverse\n\\[\ny = g^{-1}(z)\n\\tag{2.18}\\]\nmust be differentiable as in:\n\\[\n\\frac{\\mathrm{d}}{\\mathrm{d}z} \\left[ g^{-1}(z) \\right] = \\frac{1}{g' \\left[ g^{-1}(z) \\right]}.\n\\tag{2.19}\\]\nNote that we differentiate Equation 2.18 as follows:\n\\[\n\\frac{\\mathrm{d}}{\\mathrm{d}z} y = \\frac{\\mathrm{d}}{\\mathrm{d}z} \\left[ g^{-1}(z) \\right].\n\\tag{2.20}\\]\nThen, plugging Equation 2.20 into Equation 2.19, we obtain:\n\\[\n\\begin{gather*}\n\\frac{\\mathrm{d}}{\\mathrm{d}z} y = \\frac{1}{g' \\left[ g^{-1}(z) \\right]} \\\\\n\\mathrm{d}y = \\frac{1}{g' \\left[ g^{-1}(z) \\right]} \\mathrm{d}z.\n\\end{gather*}\n\\tag{2.21}\\]\nAnalogous to Equation 2.8, we use the property that relates the CDF \\(F_Z(z)\\) to the PDF \\(f_Z(z)\\):\n\\[\nf_Z(z) = \\frac{\\mathrm{d}}{\\mathrm{d}z} F_Z(z).\n\\]\nUsing Equation 2.17, we have:\n\\[\n\\begin{align*}\nf_Z(z) &= \\frac{\\mathrm{d}}{\\mathrm{d}z} F_Z(z) \\\\\n&= \\frac{\\mathrm{d}}{\\mathrm{d}z} F_Y\\left[ g^{-1}(z) \\right] \\\\\n&= f_Y\\left[ g^{-1}(z) \\right] \\frac{\\mathrm{d}}{\\mathrm{d}z} \\left[ g^{-1}(z) \\right].\n\\end{align*}\n\\]\nThen, via Equation 2.19, it follows that:\n\\[\nf_Z(z) = f_Y\\left[ g^{-1}(z) \\right] \\frac{1}{g' \\left[ g^{-1}(z) \\right]}.\n\\tag{2.22}\\]\nTherefore, using the expected value definition for a continuous random variable as in Equation 2.4, we have for \\(Z\\) that\n\\[\n\\mathbb{E}(Z) = \\int_{\\mathcal{Z}} z \\cdot f_Z(z) \\mathrm{d}z,\n\\]\nwhich yields via Equation 2.22:\n\\[\n\\mathbb{E}(Z) = \\int_{\\mathcal{Z}} z \\cdot f_Y \\left[ g^{-1}(z) \\right] \\frac{1}{g' \\left[ g^{-1}(z) \\right]} \\mathrm{d}z.\n\\]\nUsing Equation 2.18 and Equation 2.21, it follows that:\n\\[\n\\begin{align*}\n\\mathbb{E}(Z) &= \\int_{\\mathcal{Z}} z \\cdot f_Y(y) \\frac{1}{g' \\left[ g^{-1}(z) \\right]} \\mathrm{d}z \\\\\n&= \\int_{\\mathcal{Y}} g(y) \\cdot f_Y(y) \\mathrm{d}y.\n\\end{align*}\n\\]\nNote the last line in the above equation changes the integration limits to the support of \\(Y\\), given all terms end up depending on \\(y\\) on the right-hand side.\nFinally, given the random variable transformation from Equation 2.16, we have:\n\\[\n\\mathbb{E}\\left[ g(X) \\right] = \\int_{\\mathcal{Y}} g(y) \\cdot f_Y(y) \\mathrm{d}y. \\quad \\square\n\\]\n\n\n\n\n\n\nDefinition of variance\n\n\nLet \\(Y\\) be a discrete or continuous random variable whose support is \\(\\mathcal{Y}\\) with a mean represented by \\(\\mathbb{E}(Y)\\). Then, the variance of \\(Y\\) is the mean of the squared deviation from the corresponding mean as follows:\n\\[\n\\text{Var}(Y) = \\mathbb{E}\\left\\{[ Y - \\mathbb{E}(Y)]^2 \\right\\}. \\\\\n\\tag{2.23}\\]\nNote the expression above is equivalent to:\n\\[\n\\text{Var}(Y) = \\mathbb{E}(Y^2) - \\left[ \\mathbb{E}(Y) \\right]^2.\n\\tag{2.24}\\]\n\n\nImage by Manfred Stege via Pixabay.\n\n\n\n\n\nHeads-up on the two mathematical expressions of the variance!\n\n\nProving the equivalence of Equation 2.23 and Equation 2.24, requires the introduction of some further properties of the expected value of a random variable while using the LOTUS. We will dig into the insights provided by Casella and Berger (2024).\n\nTheorem 2.3 Let \\(Y\\) be a discrete or continuous random variable. Furthermore, let \\(a\\), \\(b\\), and \\(c\\) be constants. Thus, for any functions \\(g_1(y)\\) and \\(g_2(x)\\) whose means exist, we have that:\n\\[\n\\mathbb{E}\\left[ a g_1(Y) + b g_2(Y) + c \\right] = a \\mathbb{E}\\left[ g_1(Y) \\right] + b \\mathbb{E}\\left[ g_2(Y) \\right] + c.\n\\tag{2.25}\\]\nFirstly, let us prove Equation 2.25 for the discrete case.\n\nProof. Let \\(Y\\) be a discrete random variable whose support is \\(\\mathcal{Y}\\) and PMF is \\(P_Y(Y = y)\\). Let us apply the LOTUS as in Equation 2.9:\n\\[\n\\mathbb{E}\\left[ a g_1(Y) + b g_2(Y) + c \\right] = \\sum_{y \\in \\mathcal{Y}} \\left[ a g_1(y) + b g_2(y) + c \\right] \\cdot P_Y(Y = y).\n\\] We can distribute the summation across each addend as follows:\n\\[\n\\begin{align*}\n\\mathbb{E}\\left[ a g_1(Y) + b g_2(Y) + c \\right] &= \\sum_{y \\in \\mathcal{Y}} \\left[ a g_1(y) \\right] \\cdot P_Y(Y = y) + \\\\\n& \\qquad \\sum_{y \\in \\mathcal{Y}} \\left[ b g_2(y) \\right] \\cdot P_Y(Y = y) + \\\\\n& \\qquad \\sum_{y \\in \\mathcal{Y}} c \\cdot P_Y(Y = y).\n\\end{align*}\n\\]\nLet us take the constants out of the corresponding summations:\n\\[\n\\begin{align*}\n\\mathbb{E}\\left[ a g_1(Y) + b g_2(Y) + c \\right] &= a \\sum_{y \\in \\mathcal{Y}} g_1(y) \\cdot P_Y(Y = y) + \\\\\n& \\qquad b \\sum_{y \\in \\mathcal{Y}} g_2(y) \\cdot P_Y(Y = y) + \\\\\n& \\qquad c \\underbrace{\\sum_{y \\in \\mathcal{Y}} P_Y(Y = y)}_1 \\\\\n&= a \\underbrace{\\sum_{y \\in \\mathcal{Y}} g_1(y) \\cdot P_Y(Y = y)}_{\\mathbb{E} \\left[ g_1(Y) \\right]} + \\\\\n& \\qquad b \\underbrace{\\sum_{y \\in \\mathcal{Y}} g_2(y) \\cdot P_Y(Y = y)}_{\\mathbb{E} \\left[ g_2(Y) \\right]} + c.\n\\end{align*}\n\\]\nFor the first and second addends on the right-hand side in the above equation, let us apply the LOTUS again:\n\\[\n\\mathbb{E}\\left[ a g_1(Y) + b g_2(Y) + c \\right] = a \\mathbb{E} \\left[ g_1(Y) \\right] + b \\mathbb{E} \\left[ g_2(Y) \\right] + c. \\quad \\square\n\\]\n\nSecondly, let us prove Equation 2.25 for the continuous case.\n\nProof. Let \\(Y\\) be a continuous random variable whose support is \\(\\mathcal{Y}\\) and PDF is \\(f_Y(y)\\). Let us apply the LOTUS as in Equation 2.15:\n\\[\n\\mathbb{E}\\left[ a g_1(Y) + b g_2(Y) + c \\right] = \\int_{\\mathcal{Y}} \\left[ a g_1 (y) + b g_2(y) + c \\right] \\cdot f_Y(y) \\mathrm{d}y.\n\\]\nWe distribute the integral on the right-hand side of the above equation:\n\\[\n\\begin{align*}\n\\mathbb{E}\\left[ a g_1(Y) + b g_2(Y) + c \\right] &= \\int_{\\mathcal{Y}} \\left[ a g_1 (y) \\right] \\cdot f_Y(y) \\mathrm{d}y + \\\\\n& \\qquad \\int_{\\mathcal{Y}} \\left[ b g_2(y) \\right] \\cdot f_Y(y) \\mathrm{d}y + \\\\\n& \\qquad \\int_{\\mathcal{Y}} c \\cdot f_Y(y) \\mathrm{d}y.\n\\end{align*}\n\\]\nLet us take the constants out of the corresponding integrals:\n\\[\n\\begin{align*}\n\\mathbb{E}\\left[ a g_1(Y) + b g_2(Y) + c \\right] &= a \\int_{\\mathcal{Y}} g_1 (y) \\cdot f_Y(y) \\mathrm{d}y + \\\\\n& \\qquad b \\int_{\\mathcal{Y}} g_2(y) \\cdot f_Y(y) \\mathrm{d}y + \\\\\n& \\qquad c \\underbrace{\\int_{\\mathcal{Y}} f_Y(y) \\mathrm{d}y}_{1} \\\\\n&= a \\underbrace{\\int_{\\mathcal{Y}} g_1 (y) \\cdot f_Y(y) \\mathrm{d}y}_{\\mathbb{E} \\left[ g_1(Y) \\right]} + \\\\\n& \\qquad b \\underbrace{\\int_{\\mathcal{Y}} g_2(y) \\cdot f_Y(y) \\mathrm{d}y}_{\\mathbb{E} \\left[ g_2(Y) \\right]} + c.\n\\end{align*}\n\\]\nFor the first and second addends on the right-hand side in the above equation, let us apply the LOTUS again:\n\\[\n\\mathbb{E}\\left[ a g_1(Y) + b g_2(Y) + c \\right] = a \\mathbb{E} \\left[ g_1(Y) \\right] + b \\mathbb{E} \\left[ g_2(Y) \\right] + c. \\quad \\square\n\\]\n\n\nFinally, after applying some algebraic rearrangements and the expected value properties shown in Equation 2.25, Equation 2.23 and Equation 2.24 are equivalent as follows:\n\nProof. \\[\n\\begin{align*}\n\\text{Var}(Y) &= \\mathbb{E}\\left\\{[ Y - \\mathbb{E}(Y)]^2 \\right\\} \\\\\n&= \\mathbb{E} \\left\\{ Y^2 - 2Y \\mathbb{E}(Y) + \\left[ \\mathbb{E}(Y) \\right]^2 \\right\\} \\\\\n&= \\mathbb{E}(Y^2) - \\mathbb{E} \\left[ 2Y \\mathbb{E}(Y) \\right] + \\mathbb{E} \\left[ \\mathbb{E}(Y) \\right]^2 \\\\\n& \\qquad \\text{distributing the expected value operator} \\\\\n&= \\mathbb{E}(Y^2) - 2 \\mathbb{E} \\left[ Y \\mathbb{E}(Y) \\right] + \\mathbb{E} \\left[ \\mathbb{E}(Y) \\right]^2 \\\\\n& \\qquad \\text{since $2$ is a constant} \\\\\n&= \\mathbb{E}(Y^2) - 2 \\mathbb{E}(Y) \\mathbb{E} \\left( Y \\right) + \\left[ \\mathbb{E}(Y) \\right]^2 \\\\\n& \\qquad \\text{since $\\mathbb{E}(Y)$ is a constant} \\\\\n&= \\mathbb{E}(Y^2) - 2 \\left[ \\mathbb{E}(Y) \\right]^2 + \\left[ \\mathbb{E}(Y) \\right]^2 \\\\\n&= \\mathbb{E}(Y^2) - \\left[ \\mathbb{E}(Y) \\right]^2.  \\qquad \\qquad \\qquad \\qquad \\qquad \\square\n\\end{align*}\n\\]\n\n\n\n\n2.1.6 The Rationale in Random Sampling\n\n\nDefinition of conditional probability\n\n\nSuppose you have two events of interest, \\(A\\) and \\(B\\), in a random phenomenon of a population or system of interest. These two events belong to the sample space \\(S\\). Moreover, assume that the probability of event \\(B\\) is such that\n\\[\nP(B) &gt; 0,\n\\]\nwhich is considered the conditioning event.\nHence, the conditional probability event \\(A\\) given event \\(B\\) is defined as\n\\[\nP(A | B) = \\frac{P(A \\cap B)}{P(B)},\n\\tag{2.26}\\]\nwhere \\(P(A \\cap B)\\) is read as the probability of the intersection of events \\(A\\) and \\(B\\).\n\n\nImage by Pexels via Pixabay.\n\n\n\n\n\nTip on the rationale behind conditional probability!\n\n\nWe can delve into the rationale of Equation 2.26 by using a handy probabilistic concept called cardinality, which refers to the corresponding total number of possible outcomes in a random phenomenon belonging to any given event or sample space.\n\nProof. Let \\(|S|\\) be the cardinality corresponding to the sample space in a random phenomenon. Hence, as in Equation 2.2, we have that:\n\\[\nP(S) = \\frac{|S|}{|S|} = 1.\n\\]\nMoreover, suppose that \\(A\\) is the primary event of interest whose cardinality is represented by \\(|A|\\). Alternatively to Equation 2.1, the probability of \\(A\\) can be represented as\n\\[\nP(A) = \\frac{|A|}{|S|}.\n\\]\nOn the other hand, the cardinality of the conditioning event is\n\\[\nP(B) = \\frac{|B|}{|S|}.\n\\tag{2.27}\\]\nNow, let \\(|A \\cap B|\\) be the cardinality of the intersection between events \\(A\\) and \\(B\\). Its probability can be represented as:\n\\[\nP(A \\cap B) = \\frac{|A \\cap B|}{|B|}.\n\\tag{2.28}\\]\nAnalogous to Equation 2.27 and Equation 2.28, we can view the conditional probability \\(P(A | B)\\) as an updated probability of the primary event \\(A\\) restricted to the cardinality of the conditioning event \\(|B|\\). This places \\(|A \\cap B|\\) in the numerator and \\(|B|\\) in the denominator as follows:\n\\[\nP(A | B) = \\frac{|A \\cap B|}{|B|}.\n\\tag{2.29}\\]\nTherefore, we can play around with Equation 2.29 along with Equation 2.27 and Equation 2.28 as follows:\n\\[\n\\begin{align*}\nP(A \\cap B) &= \\frac{|A \\cap B|}{|B|} \\\\\n&= \\frac{\\frac{|A \\cap B}{|S|}}{\\frac{|B|}{|S|}} \\qquad \\text{dividing numerator and denominator over $|S|$} \\\\\n&= \\frac{P(A \\cap B)}{P(B)}. \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\quad \\square\n\\end{align*}\n\\]\n\n\n\n\n\nDefinition of the Bayes’ rule\n\n\nSuppose you have two events of interest, \\(A\\) and \\(B\\), in a random phenomenon of a population or system of interest. From Equation 2.26, we can state the following expression for the conditional probability of \\(A\\) given \\(B\\):\n\\[\nP(A | B) = \\frac{P(A \\cap B)}{P(B)} \\quad \\text{if $P(B) &gt; 0$.}\n\\tag{2.30}\\]\nNote the conditional probability of \\(B\\) given \\(A\\) can be stated as:\n\\[\n\\begin{align*}\nP(B | A) &= \\frac{P(B \\cap A)}{P(A)} \\quad \\text{if $P(A) &gt; 0$} \\\\\n&= \\frac{P(A \\cap B)}{P(A)} \\quad \\text{since $P(B \\cap A) = P(A \\cap B)$.}\n\\end{align*}\n\\tag{2.31}\\]\nThen, we can manipulate Equation 2.31 as follows:\n\\[\nP(A \\cap B) = P(B | A) \\times P(A).\n\\]\nThe above result can be plugged into Equation 2.30:\n\\[\n\\begin{align*}\nP(A | B) &= \\frac{P(A \\cap B)}{P(B)} \\\\\n&= \\frac{P(B | A) \\times P(A)}{P(B)}.\n\\end{align*}\n\\tag{2.32}\\]\nEquation 2.32 is called the Bayes’ rule. We are basically flipping around conditional probabilities.\n\n\n\n\nDefinition of independence\n\n\nSuppose you have two events of interest, \\(A\\) and \\(B\\), in a random phenomenon of a population or system of interest. These two events are statistically independent if event \\(B\\) does not affect event \\(A\\) and vice versa. Therefore, the probability of their corresponding intersection is given by:\n\\[\nP(A \\cap B) = P(A) \\times P(B).\n\\tag{2.33}\\]\nLet us expand the above definition to a random variable framework:\n\nSuppose you have a set of \\(n\\) discrete random variables \\(Y_1, \\dots, Y_n\\) whose supports are \\(\\mathcal{Y_1}, \\dots, \\mathcal{Y_n}\\) with PMFs \\(P_{Y_1}(Y_1 = y_1), \\dots, P_{Y_n}(Y_n = y_n)\\) respectively. That said, the joint PMF of these \\(n\\) random variables is the multiplication of their corresponding standalone PMFs:\n\n\\[\n\\begin{align*}\nP_{Y_1, \\dots, Y_n}(Y_1 = y_1, \\dots, Y_n = y_n) &= \\prod_{i = 1}^n P_{Y_i}(Y_i = y_i) \\\\\n& \\qquad \\text{for all} \\\\\n& \\qquad \\quad y_i \\in \\mathcal{Y}_i, i = 1, \\dots, n.\n\\end{align*}\n\\tag{2.34}\\]\n\nSuppose you have a set of \\(n\\) continuous random variables \\(Y_1, \\dots, Y_n\\) whose supports are \\(\\mathcal{Y_1}, \\dots, \\mathcal{Y_n}\\) with PDFs \\(f_{Y_1}(y_1), \\dots, f_{Y_n}(y_n)\\) respectively. That said, the joint PDF of these \\(n\\) random variables is the multiplication of their corresponding standalone PDFs:\n\n\\[\n\\begin{align*}\nf_{Y_1, \\dots, Y_n}(y_1, \\dots, y_n) &= \\prod_{i = 1}^n f_{Y_i}(y_i) \\\\\n& \\qquad \\text{for all} \\\\\n& \\qquad \\quad y_i \\in \\mathcal{Y}_i, i = 1, \\dots, n.\n\\end{align*}\n\\tag{2.35}\\]\n\n\n\n\nTip on the rationale behind the rule of independent events!\n\n\nWe can delve into the rationale of Equation 2.33 by using the Bayes’ rule from Equation 2.32 along with the basic conditional probability formula from Equation 2.26.\n\nProof. Firstly, let us assume that a given event \\(B\\) does not affect event \\(A\\) which can be probabilistically represented as\n\\[\nP(A | B) = P(A).\n\\tag{2.36}\\]\nIf the statement in Equation 2.36 holds, by using the Bayes’ rule from Equation 2.32, we have the following manipulation for the below conditional probability formula:\n\\[\n\\begin{align*}\nP(B | A) &= \\frac{P(B \\cap A)}{P(A)} \\\\\n&= \\frac{P(A \\cap B)}{P(A)} \\qquad \\text{since $P(B \\cap A) = P(A \\cap B$)} \\\\\n&= \\frac{P(A | B) \\times P(B)}{P(A)} \\qquad \\text{by the Bayes' rule} \\\\\n&= \\frac{P(A) \\times P(B)}{P(A)} \\qquad \\text{since $P(A | B) = P(A)$} \\\\\n&= P(B).\n\\end{align*}\n\\]\nThen, again by using the Bayes’ rule, we obtain \\(P(B \\cap A)\\) as follows:\n\\[\n\\begin{align*}\nP(B \\cap A) &= P(B | A) \\times P(A) \\\\\n&= P(B) \\times P(A) \\qquad \\text{since $P(B | A) = P(B)$.}\n\\end{align*}\n\\]\nFinally, we have that:\n\\[\n\\begin{align*}\nP(A \\cap B) &= P(B \\cap A) \\\\\n&= P(B) \\times P(A) \\\\\n&= P(A) \\times P(B). \\qquad \\square\n\\end{align*}\n\\]\n\n\n\n\n\nDefinition of random sample\n\n\nA random sample is a collection of random variables \\(Y_1, \\dots, Y_n\\) of size \\(n\\) coming from a given population or system of interest. Note that the most elementary definition of a random sample assumes that these \\(n\\) random variables are mutually independent and identically distributed (which is abbreviated as iid).\nThe fact that these \\(n\\) random variables are identically distributed indicates that they have the same mathematical form for their corresponding PMFs or PDFs, depending on whether they are discrete or continuous respectively. Hence, under a generative modelling approach in a population or system of interest governed by \\(k\\) parameters contained in the vector\n\\[\n\\boldsymbol{\\theta} = (\\theta_1, \\theta_2, \\cdots, \\theta_k)^T,\n\\]\nwe can apply the iid property in an elementary random sample to obtain the following joint probability distributions:\n\nIn the case of \\(n\\) iid discrete random variables \\(Y_1, \\dots, Y_n\\) whose common standalone PMF is \\(P_Y(Y = y)\\) with support \\(\\mathcal{Y}\\), the joint PMF is mathematically expressed as\n\n\\[\n\\begin{align*}\nP_{Y_1, \\dots, Y_n}(Y_1 = y_1, \\dots, Y_n = y_n | \\boldsymbol{\\theta}) &= \\prod_{i = 1}^n P_Y(Y = y_i | \\boldsymbol{\\theta}) \\\\\n& \\qquad \\text{for all} \\\\\n& \\qquad \\quad y_i \\in \\mathcal{Y}, i = 1, \\dots, n.\n\\end{align*}\n\\tag{2.37}\\]\n\nIn the case of \\(n\\) iid continuous random variables \\(Y_1, \\dots, Y_n\\) whose common standalone PDF is \\(f_Y(y)\\) with support \\(\\mathcal{Y}\\), the joint PDF is mathematically expressed as\n\n\\[\n\\begin{align*}\nf_{Y_1, \\dots, Y_n}(y_1, \\dots, y_n | \\boldsymbol{\\theta}) &= \\prod_{i = 1}^n f_Y(y_i | \\boldsymbol{\\theta}) \\\\\n& \\qquad \\text{for all} \\\\\n& \\qquad \\quad y_i \\in \\mathcal{Y}, i = 1, \\dots, n.\n\\end{align*}\n\\tag{2.38}\\]\nUnlike Equation 2.34 and Equation 2.35, note that Equation 2.37 and Equation 2.38 indicate the subscript \\(Y\\) in the corresponding probability distributions since we have identically distributed random variables. Furthermore, the joint distributions are conditioned on the population parameter vector \\(\\boldsymbol{\\theta}\\) which reflects our generative modelling approach.\n\n\nImage by Pexels via Pixabay.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Cuisine: A Review on Probability and Frequentist Statistical Inference</span>"
    ]
  },
  {
    "objectID": "book/02-stats-review.html#sec-mle",
    "href": "book/02-stats-review.html#sec-mle",
    "title": "2  Basic Cuisine: A Review on Probability and Frequentist Statistical Inference",
    "section": "\n2.2 What is Maximum Likelihood Estimation?",
    "text": "2.2 What is Maximum Likelihood Estimation?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Cuisine: A Review on Probability and Frequentist Statistical Inference</span>"
    ]
  },
  {
    "objectID": "book/02-stats-review.html#sec-basics-inf",
    "href": "book/02-stats-review.html#sec-basics-inf",
    "title": "2  Basic Cuisine: A Review on Probability and Frequentist Statistical Inference",
    "section": "\n2.3 Basics of Frequentist Statistical Inference",
    "text": "2.3 Basics of Frequentist Statistical Inference\n\n\n\n\n\nFigure 2.2: Results stage from the data science workflow in Figure 1.1. This stage is directly followed by storytelling and preceded by goodness of fit.\n\n\n\n\n\n\n\nFigure 2.3: A classical-based hypothesis testing workflow structured in four substages: general settings, hypotheses definitions, test flavour and components, and inferential conclusions.\n\n\n\n2.3.1 General Settings\n\n\n\n\n\nFigure 2.4: General settings substage from the classical-based hypothesis testing workflow in Figure 2.3. This substage is directly followed by the hypotheses definitions.\n\n\n\n\nDefinition of hypothesis testing\n\n\nA frequentist hypothesis testing is\n\n\n\n\nDefinition of null hypothesis\n\n\nA null hypothesis is\n\n\n\n\nDefinition of alternative hypothesis\n\n\nAn alternative hypothesis is\n\n\n\n\nDefinition of type I error\n\n\nType I error is defined as\n\n\n\n\nDefinition of type II error\n\n\nType II error is defined as\n\n\n\n\nDefinition of significance level\n\n\nSignificance level is defined as\n\n\n\n\nDefinition of power\n\n\nThe statistical power of a test is defined as\n\n\n\n2.3.2 Hypotheses Definitions\n\n\n\n\n\nFigure 2.5: Hypotheses definitions substage from the classical-based hypothesis testing workflow in Figure 2.3. This substage is directly preceded by general settings and followed by test flavour and components.\n\n\n\n2.3.3 Test Flavour and Components\n\n\n\n\n\nFigure 2.6: Test flavour and components substage from the classical-based hypothesis testing workflow in Figure 2.3. This substage is directly preceded by hypotheses definitions and followed by inferential conclusions.\n\n\n\n\nDefinition of observed effect\n\n\nAn observed effect is\n\n\n\n\nDefinition of standard error\n\n\nAn standard error is\n\n\n\n\nDefinition of test statistic\n\n\nA test statistic is\n\n\n\n2.3.4 Inferential Conclusions\n\n\n\n\n\nFigure 2.7: Inferential conclusions substage from the classical-based hypothesis testing workflow in Figure 2.3. This substage is directly preceded by rest flavour and components and followed by the corresponding delivery significance conclusion within the results stage of the data science workflow as shown in Figure 2.2.\n\n\n\n\nDefinition of critical value\n\n\nA critical value is\n\n\n\n\nDefinition of \\(p\\)-value\n\n\nA \\(p\\)-value is\n\n\n\n\nDefinition of confidence interval\n\n\nA confidence interval is",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Cuisine: A Review on Probability and Frequentist Statistical Inference</span>"
    ]
  },
  {
    "objectID": "book/02-stats-review.html#sec-sup-learning-regression",
    "href": "book/02-stats-review.html#sec-sup-learning-regression",
    "title": "2  Basic Cuisine: A Review on Probability and Frequentist Statistical Inference",
    "section": "\n2.4 Supervised Learning and Regression Analysis",
    "text": "2.4 Supervised Learning and Regression Analysis\n\n\n\n\nBellhouse, D. R. 2004. “The Reverend Thomas Bayes, FRS: A Biography to Celebrate the Tercentenary of His Birth.” Statistical Science 19 (1): 3–43. https://doi.org/10.1214/088342304000000189.\n\n\nCasella, G., and R. Berger. 2024. Statistical Inference. Chapman & Hall/CRC Texts in Statistical Science. CRC Press. https://www.taylorfrancis.com/books/mono/10.1201/9781003456285/statistical-inference-roger-berger-george-casella.\n\n\nJohnson, A. A., M. Q. Ott, and M. Dogucu. 2022. Bayes Rules!: An Introduction to Applied Bayesian Modeling. Chapman & Hall/CRC Texts in Statistical Science. CRC Press. https://www.bayesrulesbook.com/.\n\n\nO’Donnell, T. 1936. History of Life Insurance in Its Formative Years. Compiled from Approved Sources by T. O’Donnell. Chicago.\n\n\nSoch, Joram, The Book of Statistical Proofs, Maja, Pietro Monticone, Thomas J. Faulkenberry, Alex Kipnis, Kenneth Petrykowski, et al. 2024. “StatProofBook/StatProofBook.github.io: StatProofBook 2023.” Zenodo. https://doi.org/10.5281/zenodo.10495684.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Cuisine: A Review on Probability and Frequentist Statistical Inference</span>"
    ]
  },
  {
    "objectID": "book/continuous-zone.html",
    "href": "book/continuous-zone.html",
    "title": "Continuous Cuisine",
    "section": "",
    "text": "mindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n    Discrete &lt;br/&gt;Outcome Y\n\n\n\n\n\n\n\n\nFigure 1: Initial regression analysis mind map where, depending on the type of outcome \\(Y\\), we will split out modelling techniques into two large zones: discrete and continuous.",
    "crumbs": [
      "Continuous Cuisine"
    ]
  },
  {
    "objectID": "book/03-ols.html",
    "href": "book/03-ols.html",
    "title": "3  Zestylicious Ordinary Least-squares Regression",
    "section": "",
    "text": "3.1 Introduction\nWhen looking at data, we often want to know how different factors affect each other. For instance, if you have data on student finances, you might ask:\nOnce you have this financial data, the next step is to analyze it to find answers. One straightforward method for doing this is through regression analysis, and the simplest form is called Ordinary Least Squares (OLS).",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Zestylicious Ordinary Least-squares Regression</span>"
    ]
  },
  {
    "objectID": "book/03-ols.html#introduction",
    "href": "book/03-ols.html#introduction",
    "title": "3  Zestylicious Ordinary Least-squares Regression",
    "section": "",
    "text": "How does having a job affect a student’s leftover money at the end of the month?\nWhat impact does receiving a monthly allowance have on their net savings?",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Zestylicious Ordinary Least-squares Regression</span>"
    ]
  },
  {
    "objectID": "book/03-ols.html#what-is-ordinary-least-squares-ols",
    "href": "book/03-ols.html#what-is-ordinary-least-squares-ols",
    "title": "3  Zestylicious Ordinary Least-squares Regression",
    "section": "\n3.2 What is Ordinary Least Squares (OLS)?",
    "text": "3.2 What is Ordinary Least Squares (OLS)?\nOrdinary Least Squares (OLS) is a fundamental method in regression analysis for estimating the relationship between a dependent variable and one or more independent variables. In simple terms, OLS is like drawing the best straight line through a scatterplot of data points. Imagine you plotted students’ net savings on a graph, and each point represents a student’s financial outcome. OLS finds the line that best follows the trend of these points by minimizing the overall distance (error) between what the line predicts and what the actual data shows.\nOLS is widely used because it is:\n\n\nSimple: Easy to understand and compute.\n\nClear: Provides straightforward numbers (coefficients) that tell you how much each factor influences the outcome.\n\nVersatile: Applicable in many fields, from economics to social sciences, to help make informed decisions.\n\nIn this chapter, we will break down how OLS works in plain language, explore its underlying assumptions, and discuss its practical applications and limitations. This will give you a solid foundation in regression analysis, paving the way for more advanced techniques later on.",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Zestylicious Ordinary Least-squares Regression</span>"
    ]
  },
  {
    "objectID": "book/03-ols.html#the-best-line",
    "href": "book/03-ols.html#the-best-line",
    "title": "3  Zestylicious Ordinary Least-squares Regression",
    "section": "\n3.3 The “Best Line”",
    "text": "3.3 The “Best Line”\nWhen using Ordinary Least Squares (OLS) to fit a regression line, our goal is to find the line that best represents the relationship between our dependent variable \\(Y\\) and independent variable \\(X\\). But what does “best” mean?\nImagine you have a scatter plot of data points. Now, consider drawing two different lines through this plot. Each one of these lines represent a set of predictions. They also represent a way to represent the relationship between the dependent variable \\(Y\\) and independent variable \\(X\\)\n\n\nLine A (Blue): A line that follows the general trend of the data very well.\n\nLine B (Red): A line that doesn’t capture the trend as accurately.\n\n\n\n\n\n\n\n\n\n\n3.3.1 Understanding Residuals\nFor each data point, the residual is the vertical distance between the actual \\(Y\\) value and the predicted \\(Y\\) value (denoted \\(\\hat{Y}\\)) on the line. In simple terms, it tells us how far off our prediction is for each point given the same \\(X\\) value. If a line fits well, these residuals will be small, meaning our predictions of the \\(Y\\) variable are close to the actual value.\nOLS quantifies how well a line fits the data by calculating the Sum of Squared Errors (SSE). The SSE is obtained by:\n\nComputing the residual for each data point.\nSquaring each residual (this ensures that errors do not cancel each other out).\nSumming all these squared values.\n\n\\[\nSSE=\\sum_{i=1}^{n} (Y_i - \\hat{Y}_i)^2\n\\]\nA lower SSE indicates a line that is closer to the actual data points. OLS chooses the best line by finding the one with the smallest SSE.\n\n3.3.2 Quantifying the Fit with SSE\nWe can compare the two lines by computing their SSE. The code below calculates and prints the SSE for each line:\n\n# Calculate the Sum of Squared Errors for the correct model (Blue)\nsse_correct &lt;- sum((df$Price - df$Predicted_Correct)^2)\n\n# Calculate the Sum of Squared Errors for the manually adjusted model (Red)\nsse_wrong &lt;- sum((df$Price - df$Predicted_Wrong)^2)\n\n# Print the SSEs for each line\ncat(\"SSE for Best-Fit Line (Blue line):\", sse_correct, \"\\n\")\n\nSSE for Best-Fit Line (Blue line): 83.23529 \n\ncat(\"SSE for Worse-Fit Line (Red line):\", sse_wrong, \"\\n\")\n\nSSE for Worse-Fit Line (Red line): 3972 \n\n\nWhen you run this code, you’ll observe that the blue line (Line A) has a much lower SSE compared to the red line (Line B). This tells us that the blue line is a better fit for the data because its predictions are, on average, closer to the actual values.\nIn summary, OLS selects the “best line” by minimizing the sum of squared errors, ensuring that the total error between predicted and actual values is as small as possible.\n\n3.3.3 Why Squared Errors?\nWhen measuring how far off our predictions are, errors can be positive (if our prediction is too low) or negative (if it’s too high). If we simply added these errors together, they could cancel each other out, hiding the true size of the mistakes. By squaring each error, we convert all numbers to positive values so that every mistake counts.\nIn addition, squaring makes big errors count a lot more than small ones. This means that a large mistake will have a much bigger impact on the overall error, encouraging the model to reduce those large errors and improve its overall accuracy.\n\n3.3.4 The Mathematical Formulation of the OLS Model\nNow that we understand how OLS finds the best-fitting line by minimizing the differences between the actual and predicted values, let’s look at the math behind it.\nIn a simple linear regression with one predictor, we express the relationship between the outcome \\(Y\\) and the predictor \\(X\\) using the following equation. Note that OLS fits a straight line to the data, which is why the equation takes the familiar form of a straight line:\n\\[\nY=\\beta_0+\\beta_1X+\\epsilon\n\\]\nHere’s what each part of the equation means:\n\n\n\\(Y\\) is the dependent variable or the outcome we want to predict.\n\n\\(X\\) is the independent variable or the predictor that we believe influences \\(Y\\).\n\n\\(\\beta_0\\) is the intercept. It represents the predicted value of \\(Y\\) when \\(X=0\\).\n\n\\(\\beta_1\\) is the slope. It tells us how much \\(Y\\) is expected to change for each one-unit increase in \\(X\\).\n\n\\(\\epsilon\\) is the error term. It captures the random variation in \\(Y\\) that cannot be explained by \\(X\\).\n\nThis equation provides a clear mathematical framework for understanding how changes in \\(X\\) are expected to affect \\(Y\\), while also accounting for random variation. In the upcoming section, we will explore our toy dataset to showcase this equation and OLS in action.",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Zestylicious Ordinary Least-squares Regression</span>"
    ]
  },
  {
    "objectID": "book/03-ols.html#case-study-understanding-financial-behaviors",
    "href": "book/03-ols.html#case-study-understanding-financial-behaviors",
    "title": "3  Zestylicious Ordinary Least-squares Regression",
    "section": "\n3.4 Case Study: Understanding Financial Behaviors",
    "text": "3.4 Case Study: Understanding Financial Behaviors\nTo demonstrate Ordinary Least Squares (OLS) in action, we will walk through a case study using a toy dataset. This case study will help us understand the financial behaviors of students and identify the factors that influence their Net_Money, the amount of money left over at the end of each month. We will approach this case study using the data science workflow described in a previous chapter, ensuring a structured approach to problem-solving and model building.\n\n3.4.1 The Dataset\nOur dataset captures various aspects of students’ financial lives. Each row represents a student, and the columns describe different characteristics. Below is a breakdown of the variables:\n\n\n\n\n\n\nVariable Name\nDescription\n\n\n\nHas_Job\nWhether the student has a job (0 = No, 1 = Yes).\n\n\nYear_of_Study\nThe student’s current year of study (e.g., 1st year, 2nd year, etc.).\n\n\nFinancially_Dependent\nWhether the student is financially dependent on someone else (0 = No, 1 = Yes).\n\n\nMonthly_Allowance\nThe amount of financial support the student receives each month.\n\n\nCooks_at_Home\nWhether the student prepares their own meals (0 = No, 1 = Yes).\n\n\nLiving_Situation\nThe student’s living arrangement (e.g., living with family, in a shared apartment, etc.).\n\n\nHousing_Type\nThe type of housing the student lives in (e.g., rented, owned, dormitory).\n\n\nGoes_Out_Spends_Money\nHow frequently the student goes out and spends money (1 = rarely, 5 = very often).\n\n\nDrinks_Alcohol\nWhether the student drinks alcohol (0 = No, 1 = Yes).\n\n\nNet_Money\nThe amount of money the student has left at the end of the month after income and expenses.\n\n\nMonthly_Earnings\nThe student’s earnings from any part-time jobs or other income sources.\n\n\n\nHere’s a sample of the dataset:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHas_Job\nYear_of_Study\nFinancially_Dependent\nMonthly_Allowance\nCooks_at_Home\nLiving_Situation\nHousing_Type\nGoes_Out_Spends_Money\nDrinks_Alcohol\nNet_Money\nMonthly_Earnings\n\n\n\n0\n1\n0\n658.99\n0\n3\n1\n6\n0\n529.34\n0.00\n\n\n1\n3\n0\n592.55\n0\n3\n2\n3\n1\n992.72\n941.92\n\n\n1\n4\n1\n602.54\n0\n2\n2\n2\n1\n557.30\n876.57\n\n\n\n\nThis dataset provides a structured way to analyze the financial habits of students and determine which factors contribute most to their financial stability.\n\n3.4.2 The Problem We’re Trying to Solve\nOur goal in this case study is to understand which factors impact a student’s net money. Specifically, we aim to identify which characteristics, such as having a job, monthly earnings, or financial support, explain why some students have more money left over at the end of the month than others.\nThe key question we want to answer is:\n\nWhich factors have the biggest influence on a student’s net money?\n\nBy applying OLS to this dataset, we can:\n\nMeasure how much each factor contributes to variations in net money. For example, we can determine the increase in net money associated with a one-unit increase in monthly earnings.\nIdentify whether each factor has a positive or negative effect on net money.\nUnderstand the unique contribution of each variable while accounting for the influence of others. This helps us isolate the effect of, say, having a job from that of receiving financial support.\nPredict a student’s net money based on their characteristics. These insights could help institutions design targeted financial literacy programs or interventions to improve financial stability.\nEvaluate the overall performance of our model using statistical measures such as R-squared and p-values. This not only confirms the significance of our findings but also guides improvements in future analyses.\n\nIn summary, using OLS in this case study allows us to break down complex financial behaviors into understandable components. This powerful tool provides clear, actionable insights into which factors are most important, paving the way for more informed decisions and targeted interventions.\n\n3.4.3 Study Design\nNow that we’ve introduced our case study and dataset, it’s time to follow the data science workflow step by step. The first step is to define the main statistical inquiries we want to address. As mentioned earlier, our key question is:\n\nWhich factors have the biggest influence on a student’s net money?\n\nTo answer this question, we will adopt an inferential analysis approach rather than a predictive analysis approach. Let’s quickly review the difference between these two methods:\nInferential vs. Predictive Analysis\n\n\nInferential Analysis explores and quantifies the relationships between explanatory variables (e.g., student characteristics) and the response variable (Net Money). For example, we might ask: Does having a part-time job significantly affect a student’s net money, and by how much? The goal here is to understand these effects and assess their statistical significance.\n\nPredictive Analysis focuses on accurately forecasting the response variable using new data. In this case, the question could be: Can we predict a student’s net money based on factors like monthly earnings, living situation, and spending habits? The emphasis is on building a model that produces reliable predictions, even if it doesn’t fully explain the underlying relationships.\n\n3.4.4 Applying Study Design to Our Case Study\nFor our case study, we are interested in understanding how factors such as Has_Job, Monthly_Earnings, and Spending_Habits affect a student’s Net Money. This leads us to adopt an inferential approach. We aim to answer questions like:\n\nDoes having a part-time job lead to significantly higher net money?\nHow much do a student’s monthly earnings influence their financial situation?\nDo spending habits, like going out frequently, decrease a student’s net money?\n\nUsing OLS, we will estimate the impact of each factor and determine whether these effects are statistically significant. This inferential analysis will help us understand which variables have the greatest influence on students’ financial outcomes.\nIf our goal were instead to predict a student’s future Net Money based on their characteristics, we would adopt a predictive approach. Although our focus here is on inference, it’s important to recognize that OLS is versatile and can be applied in both contexts.",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Zestylicious Ordinary Least-squares Regression</span>"
    ]
  },
  {
    "objectID": "book/03-ols.html#data-collection-and-wrangling",
    "href": "book/03-ols.html#data-collection-and-wrangling",
    "title": "3  Zestylicious Ordinary Least-squares Regression",
    "section": "\n3.5 Data Collection and Wrangling",
    "text": "3.5 Data Collection and Wrangling\nWith the statistical questions clearly defined, the next step is to ensure that the data is appropriately prepared for analysis. Although we already have the dataset, it is valuable to consider how this data could have been collected to better understand its context and potential limitations.\n\n3.5.1 Data Collection\nFor a study like ours, data on students’ financial behaviors could have been collected through various methods:\n\n\nSurveys: Students might have been asked about their employment status, earnings, and spending habits through structured questionnaires. While surveys can capture self-reported financial behaviors, they may suffer from recall bias or social desirability bias.\n\nAdministrative Data: Universities or employers may maintain records on student income and employment, providing a more objective source of financial information. However, access to such data may be limited due to privacy regulations.\n\nFinancial Tracking Apps: Digital financial management tools can offer detailed, real-time data on student income and spending patterns. While these apps provide high granularity, they may introduce selection bias, as only students who use such apps would be represented in the dataset.\n\nRegardless of the data collection method, each approach presents challenges, such as missing data, reporting errors, or sample biases. Addressing these issues is a critical aspect of data wrangling.\n\n3.5.2 Data Wrangling\nNow that our dataset is ready, the next step is to clean and organize it so that it’s in the best possible shape for analysis using OLS. Data wrangling involves several steps that ensure our data is accurate, consistent, and ready for modeling. Here are some key tasks:\nHandling Missing Data\nThe first task is to ensure data integrity by checking for missing values. Missing data can occur for various reasons, such as unrecorded responses or errors in data entry. When we find missing values—for example, if some students don’t have recorded earnings or net money—we must decide how to handle these gaps. Common strategies include:\n\n\nRemoving incomplete records: If the amount of missing data is minimal or missingness is random.\n\nImputing missing values: Using logical estimates or averages if missingness follows a systematic pattern.\n\nIn our toy dataset, there are no missing values, as confirmed by:\n\ncolSums(is.na(data))\n\n              Has_Job         Year_of_Study Financially_Dependent \n                    0                     0                     0 \n    Monthly_Allowance         Cooks_at_Home      Living_Situation \n                    0                     0                     0 \n         Housing_Type Goes_Out_Spends_Money        Drinks_Alcohol \n                    0                     0                     0 \n            Net_Money      Monthly_Earnings \n                    0                     0 \n\n\nEncoding Categorical Variables\nFor regression analysis, we need to convert categorical variables into numerical representations. In R, binary variables like Has_Job and Drinks_Alcohol should be transformed into factors so that the model correctly interprets them as categorical data rather than continuous numbers. For example:\n\n# Convert binary categorical variables to factors\ndata &lt;- data |&gt;\n  mutate(Has_Job = as.factor(Has_Job),\n         Drinks_Alcohol = as.factor(Drinks_Alcohol),\n         Financially_Dependent = as.factor(Financially_Dependent),\n         Cooks_at_Home = as.factor(Cooks_at_Home))\n\nDetecting and Handling Outliers\nOutliers in continuous variables like Monthly_Earnings and Net_Money can distort the regression analysis by skewing results. We use the Interquartile Range (IQR) method to identify these extreme values. Specifically, any observation falling below 1.5 times the IQR below the first quartile (Q1) or above 1.5 times the IQR above the third quartile (Q3) is flagged as an outlier. These outliers are then treated as missing values and removed:\n\n# Using IQR method to filter out extreme values in continuous variables\nremove_outliers &lt;- function(x) {\n  Q1 &lt;- quantile(x, 0.25, na.rm = TRUE)\n  Q3 &lt;- quantile(x, 0.75, na.rm = TRUE)\n  IQR &lt;- Q3 - Q1\n  x[x &lt; (Q1 - 1.5 * IQR) | x &gt; (Q3 + 1.5 * IQR)] &lt;- NA\n  return(x)\n}\n\ndata &lt;- data |&gt;\n  mutate(across(c(Monthly_Earnings, Net_Money), remove_outliers))\n\n# Remove rows with newly introduced NAs due to outlier handling\ndata &lt;- na.omit(data)\n\nSplitting the Data for Model Training\nTo ensure that our OLS model generalizes well to unseen data, we split the dataset into training and testing subsets. The training set is used to estimate the model parameters, and the testing set is used to evaluate the model’s performance. This split is typically done in an 80/20 ratio, as shown below:\n\n# Splitting the dataset into training and testing sets\nset.seed(123)  # For reproducibility\ntrain_indices &lt;- sample(seq_len(nrow(data)), size = 0.8 * nrow(data))\ntrain_data &lt;- data[train_indices, ]\ntest_data &lt;- data[-train_indices, ]\n\nBy following these steps, checking for missing values, encoding categorical variables, handling outliers, and splitting the data, we ensure that our dataset is clean, well-organized, and ready for regression analysis using OLS.\nIt’s important to note, however, that these are just a few of the many techniques available during the data wrangling stage. Depending on the dataset and the specific goals of your analysis, you might also consider additional strategies such as feature scaling, normalization, advanced feature engineering, handling duplicate records, or addressing imbalanced data. Each of these techniques comes with its own set of solutions, and the optimal approach will depend on the unique challenges and objectives of your case.",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Zestylicious Ordinary Least-squares Regression</span>"
    ]
  },
  {
    "objectID": "book/03-ols.html#exploratory-data-analysis-eda",
    "href": "book/03-ols.html#exploratory-data-analysis-eda",
    "title": "3  Zestylicious Ordinary Least-squares Regression",
    "section": "\n3.6 Exploratory Data Analysis (EDA)",
    "text": "3.6 Exploratory Data Analysis (EDA)\nBefore diving into data modeling, it is crucial to develop a deep understanding of the relationships between variables in the dataset. This stage, known as Exploratory Data Analysis (EDA), helps us visualize and summarize the data, uncover patterns, detect anomalies, and test key assumptions that will inform our modeling decisions.\n\n3.6.1 Classifying Variables\nThe first step in EDA is to classify variables according to their types. This classification guides the selection of appropriate visualization techniques and modeling strategies. In our toy dataset, we categorize variables as follows:\n\n\nNet_Money serves as the response variable, representing a continuous outcome constrained by realistic income and expenses.\n\nThe regressors include a mix of binary, categorical, ordinal, and continuous variables.\n\nBinary variables, such as Has_Job and Drinks_Alcohol, take on only two values and need to be encoded for modeling.\nCategorical variables, like Living_Situation and Housing_Type, represent qualitative distinctions between different student groups.\nSome predictors, like Year_of_Study and Goes_Out_Spends_Money, follow an ordinal structure, meaning they have a meaningful ranking but no consistent numerical spacing.\nFinally, Monthly_Allowance and Monthly_Earnings are continuous variables, requiring attention to their distributions and potential outliers.\n\nBy classifying variables correctly at the outset, we ensure that they are analyzed and interpreted appropriately throughout the modeling process.\n\n3.6.2 Visualizing Variable Distributions\nOnce variables are classified, the next step is to explore their distributions. Understanding how variables are distributed is crucial for identifying potential issues such as skewness, outliers, or missing values. We employ different visualizations depending on the variable type:\nContinuous Variables\nWe begin by examining continuous variables, which are best visualized using histograms and boxplots.\nHistograms\nHistograms display the frequency distribution of a continuous variable. They allow us to assess the overall shape, central tendency, and spread of the data. For example, the histogram of Net_Money helps us determine if the variable follows a roughly normal distribution or if it is skewed. A normal distribution often appears bell-shaped, while skewness can indicate that the data might benefit from transformations (like logarithmic transformations) to meet the assumptions of regression analysis. In our case, the histogram below shows that Net_Money appears roughly normal.\n\n# Histogram of Net_Money\nhist(train_data$Net_Money, \n     main = \"Distribution of Net Money\", \n     xlab = \"Net Money\", \n     col = \"blue\", \n     border = \"white\")\n\n\n\n\n\n\n\nBoxplots\nBoxplots provide a concise summary of a variable’s distribution by displaying its quartiles and highlighting potential outliers. Outliers are typically defined as data points that fall below Q1 - 1.5 * IQR or above Q3 + 1.5 * IQR. The boxplot below visualizes Net_Money and helps us quickly assess if there are any extreme values that might skew the analysis. In this case, the boxplot suggests that there are no significant outliers according to the IQR method (the method commonly used by ggplot to identify outliers).\n\n# Boxplot of Net Money\nboxplot(train_data$Net_Money, \n        main = \"Boxplot of Net Money\", \n        ylab = \"Net Money\", \n        col = \"lightblue\")\n\n\n\n\n\n\n\nBy visualizing the distribution of Net_Money with these plots, we gain valuable insights into its behavior. This understanding not only informs whether transformations are needed but also prepares us for deeper analysis as we move forward with regression modeling.\nCategorical and Ordinal Variables\nCategorical variables require a different approach from continuous ones because they represent distinct groups rather than numerical values. For these variables, bar charts are very effective. They display the frequency of each category, helping us understand the distribution of qualitative attributes.\nFor example, consider the variable Living_Situation. The bar chart below shows how many students fall into each category. From the chart, we can see that category 1 is more heavily represented, while categories 2 and 3 have roughly similar counts. This insight can be critical—if a category is underrepresented, you might need to consider grouping it with similar categories or applying techniques such as one-hot encoding to ensure that each category contributes appropriately to the model.\n\n# Bar plot of Living Situation\nbarplot(table(train_data$Living_Situation), \n        main = \"Living Situation Distribution\", \n        xlab = \"Living Situation\", \n        ylab = \"Frequency\", \n        col = \"purple\")\n\n\n\n\n\n\n\nFor ordinal variables (which have a natural order but not a fixed numerical interval), you might still use bar charts to show the ranking or frequency of each level. Additionally, understanding these distributions can help you decide whether to treat them as categorical variables or convert them into numeric scores for analysis.\nExploring Relationships Between Variables\nBeyond examining individual variables, it is crucial to explore how they interact with one another—especially the predictors and the response variable. Understanding these relationships helps identify which predictors might be influential in the model and whether any issues, like multicollinearity, could affect regression estimates.\nCorrelation Matrices\nFor continuous variables, correlation matrices provide a numerical summary of how strongly pairs of variables are related. High correlations between predictors might signal multicollinearity, which can distort model estimates. For demonstration, consider the correlation matrix computed for Net_Money, Monthly_Allowance, and Monthly_Earnings:\n\n# Correlation matrix\ncor_matrix &lt;- cor(train_data[, c(\"Net_Money\", \"Monthly_Allowance\", \"Monthly_Earnings\")], use = \"complete.obs\")\nprint(cor_matrix)\n\n                  Net_Money Monthly_Allowance Monthly_Earnings\nNet_Money         1.0000000        0.28835746       0.75743542\nMonthly_Allowance 0.2883575        1.00000000      -0.03669097\nMonthly_Earnings  0.7574354       -0.03669097       1.00000000\n\n\nIn the output, we observe a strong positive correlation (corr = 0.757) between Monthly_Earnings and Net_Money. This result is intuitive. Higher earnings typically lead to more money left at the end of the month, resulting in a higher Net_Money.\nScatterplots\nScatter plots visually depict the relationship between two continuous variables. For example, plotting Monthly_Allowance against Net_Money helps us assess whether students with higher allowances tend to have higher or lower net savings. In the scatter plot below, a slightly positive trend is visible. However, the points are quite scattered, indicating that while there may be a relationship, it is not overwhelmingly strong. Such visual insights might prompt further investigation, perhaps considering polynomial transformations or interaction terms if nonlinearity is suspected.\n\n# Scatter plot of Monthly Allowance vs. Net Money\nplot(train_data$Monthly_Allowance, train_data$Net_Money, \n     main = \"Net Money vs. Monthly Allowance\", \n     xlab = \"Monthly Allowance\", \n     ylab = \"Net Money\", \n     col = \"blue\", \n     pch = 19)\nabline(lm(Net_Money ~ Monthly_Allowance, data = train_data), col = \"red\", lwd = 2)\n\n\n\n\n\n\n\nBoxplots for Categorical Variables\nFor categorical predictors, boxplots are an excellent tool to compare the distribution of the response variable across different groups. For instance, examining how Net_Money varies by Living_Situation can reveal whether students in different living arrangements experience different financial outcomes. In the boxplot below, the distributions of Net_Money across categories of Living_Situation appear quite similar. This similarity may suggest that Living_Situation has little impact on Net_Money in our dataset.\n\n# Boxplot of Net Money by Living Situation\nboxplot(Net_Money ~ Living_Situation, \n        data = train_data, \n        main = \"Net Money by Living Situation\", \n        xlab = \"Living Situation\", \n        ylab = \"Net Money\", \n        col = \"lightgreen\")\n\n\n\n\n\n\n\nSummary Statistics\nIn addition to visual exploration, descriptive statistics provide a numerical summary of the dataset that is especially useful for beginners. Summary statistics give you a snapshot of the central tendency and spread of your data, helping you quickly grasp its overall characteristics.\nFor instance, if you notice that the mean of Monthly_Earning is significantly higher than its median, it might suggest that a few high values (or outliers) are skewing the data.\n\n# Summary statistics for numerical variables\nsummary(train_data[, c(\"Net_Money\", \"Monthly_Allowance\", \"Monthly_Earnings\")])\n\n   Net_Money        Monthly_Allowance Monthly_Earnings\n Min.   :-1587.52   Min.   :  51.33   Min.   :   0    \n 1st Qu.: -399.87   1st Qu.: 402.50   1st Qu.:   0    \n Median :   78.36   Median : 500.55   Median : 291    \n Mean   :  120.74   Mean   : 501.85   Mean   : 502    \n 3rd Qu.:  618.59   3rd Qu.: 603.46   3rd Qu.:1014    \n Max.   : 1932.42   Max.   :1088.94   Max.   :1763    \n\n\n\n3.6.3 Key Takeaways from EDA\nConducting Exploratory Data Analysis (EDA) allows us to gain an initial understanding of the data and its underlying patterns before moving on to model building. Through EDA, we identify the types of variables present, examine their distributions, and uncover potential issues such as skewness, outliers, or multicollinearity. This process helps to highlight which variables might be strong predictors and which may require additional transformation or treatment. For instance, a strong correlation between two variables, like Monthly_Earnings and Net_Money, signals that earnings are likely a key driver of net savings. At the same time, observing differences in distributions or spotting similar patterns across groups in boxplots can inform us about the impact of categorical factors like Living_Situation.\nIt is important to remember that the insights gained from EDA are preliminary and primarily serve to inform further analysis. When we explore relationships between only two variables, we might overlook the influence of other factors, which could lead to misleading conclusions if taken in isolation. EDA is a crucial step for forming initial hypotheses and guiding decisions regarding data transformations, feature engineering, and the overall modeling strategy. With this foundation, we are better prepared to build a robust Ordinary Least Squares (OLS) regression model on data that has been carefully examined and understood.",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Zestylicious Ordinary Least-squares Regression</span>"
    ]
  },
  {
    "objectID": "book/03-ols.html#data-modelling",
    "href": "book/03-ols.html#data-modelling",
    "title": "3  Zestylicious Ordinary Least-squares Regression",
    "section": "\n3.7 Data Modelling",
    "text": "3.7 Data Modelling\nAfter conducting Exploratory Data Analysis (EDA), we transition to the modeling stage, where we apply a structured approach to uncover relationships between variables and predict outcomes. In this section, we focus on Ordinary Least Squares (OLS) regression, a widely used statistical technique for modeling linear relationships.\nOLS aims to estimate the effect of multiple predictors on an outcome variable by minimizing the sum of squared differences between observed and predicted values. This approach helps quantify financial behaviors, allowing us to interpret the impact of various factors on students’ net financial balance.\n\n3.7.1 Choosing a Suitable Regression Model\nThe choice of regression model depends on the patterns identified in EDA and the objectives of our analysis. Regression techniques vary in complexity, with some handling simple linear relationships and others accounting for more nuanced effects. Below are common approaches:\n\n\nSimple Linear Regression models the relationship between a single predictor and the response variable. This approach is suitable when we suspect a dominant factor driving financial balance.\n\nMultiple Linear Regression extends simple regression by incorporating multiple predictors, allowing us to account for various financial influences simultaneously.\n\nPolynomial Regression captures non-linear relationships by introducing polynomial terms of predictors, useful when relationships observed in scatter plots are curved rather than strictly linear.\n\nLog-Linear Models transform skewed distributions to improve interpretability and meet regression assumptions.\n\nRegularized Regression (Ridge and Lasso) applies penalties to regression coefficients to handle multicollinearity and enhance model generalization by reducing overfitting.\n\nGiven that our goal is to examine how multiple factors—such as income, expenses, and living arrangements—affect students’ financial balance, we select Multiple Linear Regression via OLS. This method allows us to quantify the influence of each predictor while controlling for confounding effects.\n\n3.7.2 Defining Modeling Parameters\nOnce we select OLS regression, we define the key modeling components: the response variable (dependent variable) and the predictor variables (independent variables).\nResponse Variable (Y):\nThe response variable, also known as the dependent variable, represents the financial outcome we aim to explain:\n\n\nNet_Money: The dependent variable representing financial balance.\nPredictor Variables (X):\nEach predictor variable is chosen based on its theoretical and statistical relevance in explaining financial behavior:\n\n\nHas_Job (Binary) – Indicates whether the student has a job (1 = Yes, 0 = No).\n\nFinancially_Dependent (Binary) – Identifies students who rely on external financial support.\n\nYear_of_Study (Ordinal) – Represents academic seniority (higher values indicate later years).\n\nGoes_Out_Spends_Money (Ordinal) – Measures spending behavior on a scale from 1 to 6.\n\nDrinks_Alcohol (Binary) – Identifies whether a student consumes alcohol, which may impact discretionary spending.\n\nMonthly_Allowance (Continuous) – Represents financial support received from family or scholarships.\n\nMonthly_Earnings (Continuous) – Reflects the student’s personal income from work.\n\nLiving_Situation (Categorical) – Encodes different living arrangements (e.g., dormitory, shared apartment, living with family).\n\nHousing_Type (Categorical) – Further distinguishes between different types of housing situations.\n\nCooks_at_Home (Binary) – Indicates whether the student regularly prepares meals at home.\n\nThese predictors capture a mix of economic, behavioral, and lifestyle factors, providing a comprehensive view of the drivers of student financial balance.\n\n3.7.3 Setting Up the Modeling Equation\nWith all predictors defined, the OLS regression equation models the relationship between Net_Money and the predictor variables:\n\\[\n\\begin{align}\n\\text{Net_Money} = \\beta_0 \\\\\n               & + \\beta_1 \\times \\text{Has_Job} \\\\\n               & + \\beta_2 \\times \\text{Financially_Dependent} \\\\\n               & + \\beta_3 \\times \\text{Year_of_Study} \\\\\n               & + \\beta_4 \\times \\text{Goes_Out_Spends_Money} \\\\\n               & + \\beta_5 \\times \\text{Drinks_Alcohol} \\\\\n               & + \\beta_6 \\times \\text{Monthly_Allowance} \\\\\n               & + \\beta_7 \\times \\text{Monthly_Earnings} \\\\\n               & + \\beta_8 \\times \\text{Living_Situation} \\\\\n               & + \\beta_9 \\times \\text{Housing_Type} \\\\\n               & + \\beta_{10} \\times \\text{Cooks_at_Home} \\\\\n               & + \\epsilon\n\\end{align}\n\\]\nwhere:\n\n\n\\(\\beta_0\\) represents the intercept, or the baseline Net Money when all predictors are set to zero.\n\n\\(\\beta_1, \\beta_2, ..., \\beta_{10}\\) are the regression coefficients, quantifying the impact of each predictor on financial balance.\n\n\\(\\epsilon\\) is the error term, accounting for unexplained variability and random noise.\n\nEach coefficient provides insight into how Net_Money changes when a specific predictor increases by one unit, holding all other factors constant. For example:\n\n\n\\(\\beta_5\\) (Drinks Alcohol) measures the financial impact of alcohol consumption, which may reflect higher discretionary spending.\n\n\\(\\beta_6\\) (Monthly Allowance) quantifies the increase in Net_Money per additional dollar of allowance.\n\n\\(\\beta_10\\) (Cooks at Home) indicates how much more (or less) financially stable students are when they cook at home instead of eating out.\n\nIf significant interaction effects exist—such as students who live independently having a different financial impact from increased earnings compared to those living with family—we can extend the model by adding interaction terms.",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Zestylicious Ordinary Least-squares Regression</span>"
    ]
  },
  {
    "objectID": "book/03-ols.html#estimation",
    "href": "book/03-ols.html#estimation",
    "title": "3  Zestylicious Ordinary Least-squares Regression",
    "section": "\n3.8 Estimation",
    "text": "3.8 Estimation\nWith the data modeling stage completed, we now move to estimation, where we fit the Ordinary Least Squares (OLS) regression model to the data and obtain numerical estimates for the regression coefficients. These estimates quantify how much each predictor contributes to the response variable, allowing us to measure their individual effects on Net Money.\nThe goal of estimation is to determine the best-fitting regression line by minimizing the sum of squared residuals—the differences between the observed and predicted values. This step provides a mathematical basis for analyzing financial behaviors in students.\n\n3.8.1 Fitting the Model\nTo estimate the regression coefficients, we fit the OLS model to the training data using Python (statsmodels) or R (lm). The model is trained using least squares estimation, which finds the coefficients that minimize the total squared error between observed values and predictions.\nIn R, we can fit the regression model using the lm() function:\n\n# Load necessary library\nlibrary(stats)\n\n# Fit the OLS model\nols_model &lt;- lm(Net_Money ~ Has_Job + Financially_Dependent + Year_of_Study + Goes_Out_Spends_Money + Drinks_Alcohol + Monthly_Allowance + Monthly_Earnings + Living_Situation + Housing_Type + Cooks_at_Home, data = train_data)\n\n# Display summary of model results\nsummary(ols_model)\n\n\nCall:\nlm(formula = Net_Money ~ Has_Job + Financially_Dependent + Year_of_Study + \n    Goes_Out_Spends_Money + Drinks_Alcohol + Monthly_Allowance + \n    Monthly_Earnings + Living_Situation + Housing_Type + Cooks_at_Home, \n    data = train_data)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-742.4 -144.9   14.7  157.9  675.1 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            -595.37433   46.68928 -12.752  &lt; 2e-16 ***\nHas_Job1                 73.93112   39.75871   1.859   0.0633 .  \nFinancially_Dependent1 -499.36309   15.42689 -32.370  &lt; 2e-16 ***\nYear_of_Study           -96.51877    6.85478 -14.081  &lt; 2e-16 ***\nGoes_Out_Spends_Money   -54.60494    3.93783 -13.867  &lt; 2e-16 ***\nDrinks_Alcohol1        -145.10637   15.74322  -9.217  &lt; 2e-16 ***\nMonthly_Allowance         1.47138    0.05200  28.295  &lt; 2e-16 ***\nMonthly_Earnings          0.94906    0.03704  25.625  &lt; 2e-16 ***\nLiving_Situation        102.95241    9.32478  11.041  &lt; 2e-16 ***\nHousing_Type             56.65388    9.72781   5.824 8.38e-09 ***\nCooks_at_Home1          -96.31098   15.83074  -6.084 1.83e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 216.4 on 786 degrees of freedom\nMultiple R-squared:  0.9018,    Adjusted R-squared:  0.9006 \nF-statistic: 722.1 on 10 and 786 DF,  p-value: &lt; 2.2e-16\n\n\n\n3.8.2 Interpreting the Coefficients\nAfter fitting the model, we examine the estimated coefficients to understand their impact. Each coefficient obtained from the OLS regression represents the expected change in Net_Money for a one-unit increase in the corresponding predictor, holding all other variables constant. The estimated regression equation can be expressed as:\n\\[\n\\begin{align}\n\\text{Net_Money} = -595.37 \\\\\n               & + 73.93 \\times \\text{Has_Job} \\\\\n               & - 499.36 \\times \\text{Financially_Dependent} \\\\\n               & - 96.52 \\times \\text{Year_of_Study} \\\\\n               & - 54.60 \\times \\text{Goes_Out_Spends_Money} \\\\\n               & - 145.11 \\times \\text{Drinks_Alcohol} \\\\\n               & + 1.47 \\times \\text{Monthly_Allowance} \\\\\n               & + 0.95 \\times \\text{Monthly_Earnings} \\\\\n               & + 102.95 \\times \\text{Living_Situation} \\\\\n               & + 56.65 \\times \\text{Housing_Type} \\\\\n               & - 96.31 \\times \\text{Cooks_at_Home} \\\\\n               & + \\epsilon\n\\end{align}\n\\]\nFor example:\n\nThe intercept (\\(\\beta_0=-595.37\\)) represents the expected financial balance for a student who has zero income, allowance, and falls at the baseline category for all categorical variables.\nA \\(1 increase in Monthly Allowance (\\)_6=1.47$) is associated with a $1.47 increase in Net Money, meaning students with higher allowances tend to have a higher financial balance.\n\nThese estimates provide an initial understanding of the direction and magnitude of relationships between predictors and financial balance. However, before drawing conclusions, we need to validate model assumptions and evaluate the statistical significance of each coefficient.",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Zestylicious Ordinary Least-squares Regression</span>"
    ]
  },
  {
    "objectID": "book/03-ols.html#goodness-of-fit",
    "href": "book/03-ols.html#goodness-of-fit",
    "title": "3  Zestylicious Ordinary Least-squares Regression",
    "section": "\n3.9 Goodness of Fit",
    "text": "3.9 Goodness of Fit\nAfter estimating the regression coefficients, the next step is to assess how well the model fits the data and whether it satisfies the assumptions of Ordinary Least Squares (OLS) regression. This evaluation ensures that the model is not only statistically valid but also generalizes well to unseen data. A well-fitting model should explain a substantial proportion of variation in the response variable while adhering to key statistical assumptions. If these assumptions are violated, model estimates may be biased, leading to misleading conclusions.\n\n3.9.1 Checking Model Assumptions\nOLS regression is built on several fundamental assumptions:\n\nlinearity\nindependence of errors\nhomoscedasticity\nnormality of residuals\n\nIf these assumptions hold, OLS provides unbiased, efficient, and consistent estimates. We assess each assumption through diagnostic plots and statistical tests.\nLinearity\nA core assumption of OLS is that the relationship between each predictor and the response variable is linear. If this assumption is violated, the model may systematically under- or overestimate Net_Money, leading to biased predictions. The Residuals vs. Fitted values plot is a common diagnostic tool for checking linearity. In a well-specified linear model, residuals should be randomly scattered around zero, without any discernible patterns. If the residuals exhibit a U-shaped or curved pattern, this suggests a non-linear relationship, indicating that transformations such as logarithmic, square root, or polynomial terms may be necessary.\nTo visualize linearity, we plot the residuals against the fitted values:\n\n# Residuals vs Fitted plot (R)\nplot(ols_model$fitted.values, residuals(ols_model), \n     main = \"Residuals vs Fitted\", xlab = \"Fitted Values\", ylab = \"Residuals\")\nabline(h = 0, col = \"red\")\n\n\n\n\n\n\n\nIf the residual plot displays a clear trend, polynomial regression or feature engineering may be required to better capture the underlying data structure.\nIndependence of Errors\nThe residuals, or errors, in an OLS model should be independent of one another. This assumption is particularly relevant in time-series or sequential data, where errors from one observation might influence subsequent observations, leading to autocorrelation. If the errors are correlated, the estimated standard errors will be biased, making hypothesis testing unreliable.\nThe Durbin-Watson test is commonly used to detect autocorrelation. This test produces a statistic that ranges between 0 and 4, where values close to 2 indicate no significant autocorrelation, while values near 0 or 4 suggest positive or negative correlation in the residuals.\n\ndwtest(ols_model)\n\n\n    Durbin-Watson test\n\ndata:  ols_model\nDW = 1.9581, p-value = 0.2777\nalternative hypothesis: true autocorrelation is greater than 0\n\n\nIf the test suggests autocorrelation, a possible solution is to use time-series regression models such as Autoregressive Integrated Moving Average (ARIMA) or introduce lagged predictors to account for dependencies in the data.\nHomoscedasticity (Constant Variance of Errors)\nOLS regression assumes that the variance of residuals remains constant across all fitted values. If this assumption is violated, the model exhibits heteroscedasticity, where the spread of residuals increases or decreases systematically. This can result in inefficient coefficient estimates, making some predictors appear statistically significant when they are not.\nTo check for heteroscedasticity, we plot residuals against the fitted values and conduct a Breusch-Pagan test, which formally tests whether residual variance is constant.\n\nncvTest(ols_model)  # Test for homoscedasticity\n\nNon-constant Variance Score Test \nVariance formula: ~ fitted.values \nChisquare = 0.4018794, Df = 1, p = 0.52612\n\n\nIf heteroscedasticity is detected, solutions include applying weighted least squares (WLS) regression, transforming the dependent variable (e.g., using a log transformation), or computing robust standard errors to correct for variance instability.\nNormality of Residuals\nFor valid hypothesis testing and confidence interval estimation, OLS assumes that residuals follow a normal distribution. If residuals deviate significantly from normality, statistical inference may be unreliable, particularly for small sample sizes.\nA Q-Q plot (Quantile-Quantile plot) is used to assess normality. If residuals are normally distributed, the points should lie along the reference line.\n\nqqnorm(residuals(ols_model))\nqqline(residuals(ols_model), col = \"red\")\n\n\n\n\n\n\n\nIf the plot reveals heavy tails or skewness, potential solutions include applying log or Box-Cox transformations to normalize the distribution. In cases where normality is severely violated, using a non-parametric model or bootstrapping confidence intervals may be appropriate.\n\n3.9.2 Evaluating Model Fit\nA good model should explain a large proportion of variance in the response variable.\nR-Squared\nBeyond checking assumptions, it is essential to assess how well the model explains variability in the response variable. One of the most commonly used metrics is R-Squared (\\(R^2\\)), which measures the proportion of variance in Net_Money that is explained by the predictors. An \\(R^2\\) value close to 1 indicates a strong model fit, whereas a low value suggests that important predictors may be missing or that the model is poorly specified.\nWe can retrieve the R-squared and Adjusted R-squared values from the model summary:\n\nsummary(ols_model)$r.squared  # R-squared value\n\n[1] 0.9018396\n\nsummary(ols_model)$adj.r.squared  # Adjusted R-squared\n\n[1] 0.9005907\n\n\nWhile \\(R^2\\) provides insight into model fit, it has limitations. Adding more predictors will always increase \\(R^2\\), even if those predictors have little explanatory power. Adjusted R-squared accounts for this by penalizing unnecessary variables, making it a better indicator of true model performance.\nA high \\(R^2\\) does not imply causation, nor does it confirm that the model is free from omitted variable bias or multicollinearity. Therefore, a strong goodness-of-fit measure should be complemented by careful assessment of residual behavior and coefficient significance.\nIdentifying Outliers and Influential Points\nOutliers and influential observations can distort regression estimates, making it crucial to detect and address them appropriately. One way to identify extreme residuals is through residual plots, where large deviations from zero may indicate problematic data points.\n\nplot(residuals(ols_model), main = \"Residual Plot\", ylab = \"Residuals\")\nabline(h = 0, col = \"red\")\n\n\n\n\n\n\n\nAnother important diagnostic tool is Cook’s Distance, which measures the influence of each observation on the regression results. Data points with Cook’s Distance values greater than 0.5 may significantly impact model estimates.\n\ncook_values &lt;- cooks.distance(ols_model)\nplot(cook_values, type = \"h\", main = \"Cook's Distance\")\n\n\n\n\n\n\n\nIf influential points are identified, the next steps involve investigating data quality, testing robust regression techniques, or applying Winsorization, which involves replacing extreme values with more moderate ones to reduce their impact.",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Zestylicious Ordinary Least-squares Regression</span>"
    ]
  },
  {
    "objectID": "book/03-ols.html#results",
    "href": "book/03-ols.html#results",
    "title": "3  Zestylicious Ordinary Least-squares Regression",
    "section": "\n3.10 Results",
    "text": "3.10 Results\nAfter validating the goodness of fit, we now assess how well the model performs in both predictive analysis and inferential analysis. This step involves using the trained model to generate predictions on unseen data and evaluating how well it generalizes beyond the training set. Additionally, we analyze the estimated regression coefficients to draw meaningful conclusions about student financial behaviors.\n\n3.10.1 Predictive Analysis\nA key objective of regression modeling is to generate reliable predictions. To assess how well our model generalizes, we apply it to the test dataset—a portion of the original data that was not used for model training. If the model’s predictions align closely with actual outcomes, we can conclude that it has strong predictive power.\nIn R, we use the predict() function to apply the trained OLS model to the test dataset:\n\n# Generate predictions on the test set\ny_pred &lt;- predict(ols_model, newdata=test_data)\n\nOnce predictions are generated, we evaluate their accuracy using common regression error metrics.\nPerformance Metrics\nModel accuracy is assessed using four standard error metrics:\n\n\nMean Absolute Error (MAE) measures the average absolute differences between predicted and actual values. A lower MAE indicates better model accuracy.\n\nMean Squared Error (MSE) calculates the average squared differences between predicted and actual values, penalizing larger errors more heavily.\n\nRoot Mean Squared Error (RMSE) is the square root of MSE, making it easier to interpret since it retains the same units as the dependent variable (Net_Money).\n\nR-squared (\\(R^2\\)) quantifies the proportion of variance in Net_Money explained by the model. A higher \\(R^2\\) value indicates better model performance.\n\nThese metrics can be computed as follows:\n\n# Extract response variable from test data\ny_test &lt;- test_data$Net_Money\n\n# Calculate metrics in R\nmae &lt;- mean(abs(y_test - y_pred))\nmse &lt;- mean((y_test - y_pred)^2)\nrmse &lt;- sqrt(mse)\nr2 &lt;- summary(ols_model)$r.squared\n\ncat(sprintf(\"MAE: %.2f, MSE: %.2f, RMSE: %.2f, R-squared: %.2f\", mae, mse, rmse, r2))\n\nMAE: 183.76, MSE: 54660.22, RMSE: 233.80, R-squared: 0.90\n\n\nIf the RMSE is significantly larger than MAE, it suggests that the model is highly sensitive to large prediction errors, meaning that certain extreme values are having a disproportionate impact on the model’s performance. If the R-squared value is low, it may indicate that important predictors are missing from the model or that the relationship between predictors and Net_Money is more complex than a linear relationship can capture.\n\n3.10.2 Inferential Analysis\nBeyond prediction, OLS regression allows us to interpret the estimated coefficients to uncover patterns in students’ financial behaviors. Each coefficient represents the expected change in Net_Money for a one-unit increase in the corresponding predictor, assuming all other variables remain constant.\nInsights from Regression Coefficients\nHere are a few insights that we can extract from the regression model result:\n\nThe intercept (-595.37) represents the estimated financial balance for a baseline student (someone with Has_Job = 0, Financially_Dependent = 0, Year_of_Study = 0, etc.). Since a zero value for Year_of_Study is not meaningful in our context, the intercept itself has limited interpretability but serves as the starting point for estimating Net_Money based on predictor values.\nFinancial Dependency (Financially_Dependent) has a strong negative effect (-499.36, p &lt; 2e-16), meaning that students who rely financially on others (e.g., parents, guardians) tend to have significantly lower Net_Money. This could be due to a lack of independent income sources or higher expenses associated with dependence on external financial support.\nSocial Spending Habits (Goes_Out_Spends_Money) also have a negative impact (-54.60, p &lt; 2e-16), meaning that students who frequently go out and spend money experience a decline in Net_Money. This result aligns with expectations, as higher discretionary spending directly reduces available financial balance.\nCooking at Home (Cooks_at_Home) has a negative effect (-96.31, p = 1.83e-09), which might seem counterintuitive at first. One possible explanation is that students who cook at home may already have lower budgets, leading them to adopt cost-saving habits, rather than the habit itself directly causing financial decline.\nOverall, the model explains 90.18% of the variance in Net_Money (\\(R^2\\) = 0.9018, Adjusted \\(R^2\\) = 0.9006), suggesting a strong predictive capability. The F-statistic (722.1, p &lt; 2.2e-16) confirms that the model as a whole is statistically significant.\n\nThese findings provide a comprehensive view of student financial behaviors, reinforcing expected relationships (such as the role of allowances and earnings) while also highlighting unexpected trends (such as the negative effect of cooking at home). The next step is to integrate these results into a cohesive narrative, translating statistical insights into actionable recommendations.",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Zestylicious Ordinary Least-squares Regression</span>"
    ]
  },
  {
    "objectID": "book/03-ols.html#storytelling",
    "href": "book/03-ols.html#storytelling",
    "title": "3  Zestylicious Ordinary Least-squares Regression",
    "section": "\n3.11 Storytelling",
    "text": "3.11 Storytelling\nThe final step in our data science workflow is storytelling, where we translate our analytical findings into actionable insights. This stage ensures that our results are clearly understood by both technical and non-technical audiences. Effective storytelling involves summarizing insights, using visuals for clarity, and making data-driven recommendations.\n\n\nFun fact!\n\n\nZestylicious! That mouth-puckering, lemon-squirted, totally tangy kick!\n\n\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n\n\n\n\n\n\n\n\nFigure 3.2",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Zestylicious Ordinary Least-squares Regression</span>"
    ]
  },
  {
    "objectID": "book/04-gamma.html",
    "href": "book/04-gamma.html",
    "title": "4  Smoketastic Gamma Regression",
    "section": "",
    "text": "Fun fact!\n\n\nSmoketastic! For foods that seem to have been grilled by a campfire enthusiast.\n\n\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n\n\n\n\n\n\n\n\nFigure 4.1",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Smoketastic Gamma Regression</span>"
    ]
  },
  {
    "objectID": "book/05-beta.html",
    "href": "book/05-beta.html",
    "title": "5  Soup-erb Beta Regression",
    "section": "",
    "text": "Fun fact!\n\n\nSoup-erb! Soup that’s so heartwarming it feels like a cozy hug.\n\n\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n\n\n\n\n\n\n\n\nFigure 5.1",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Soup-erb Beta Regression</span>"
    ]
  },
  {
    "objectID": "book/06-parametric-survival.html",
    "href": "book/06-parametric-survival.html",
    "title": "6  Crunchified Parametric Survival Regression",
    "section": "",
    "text": "Fun fact!\n\n\nCrunchified! Extra crunchy, borderline noisy; could probably shatter glass.\n\n\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}\n        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(\n          (Exponential &lt;br/&gt;Outcome Y)\n          (Weibull &lt;br/&gt;Outcome Y)\n          (Lognormal &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n\n\n\n\n\n\n\n\nFigure 6.1",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Crunchified Parametric Survival Regression</span>"
    ]
  },
  {
    "objectID": "book/07-semiparametric-survival.html",
    "href": "book/07-semiparametric-survival.html",
    "title": "7  Butteryfied Semiparametric Survival Regression",
    "section": "",
    "text": "Fun fact!\n\n\nButteryfied! So rich and buttery it practically slides off the plate.\n\n\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}\n        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(\n          (Exponential &lt;br/&gt;Outcome Y)\n          (Weibull &lt;br/&gt;Outcome Y)\n          (Lognormal &lt;br/&gt;Outcome Y)\n        )Chapter 7: &lt;br/&gt;Semiparametric &lt;br/&gt;Survival &lt;br/&gt;Regression(\n          (Cox Proportional &lt;br/&gt;Hazards Model)\n            (Hazard Function &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n\n\n\n\n\n\n\n\nFigure 7.1",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Butteryfied Semiparametric Survival Regression</span>"
    ]
  },
  {
    "objectID": "book/discrete-zone.html",
    "href": "book/discrete-zone.html",
    "title": "Discrete Cuisine",
    "section": "",
    "text": "mindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}\n        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(\n          (Exponential &lt;br/&gt;Outcome Y)\n          (Weibull &lt;br/&gt;Outcome Y)\n          (Lognormal &lt;br/&gt;Outcome Y)\n        )Chapter 7: &lt;br/&gt;Semiparametric &lt;br/&gt;Survival &lt;br/&gt;Regression(\n          (Cox Proportional &lt;br/&gt;Hazards Model)\n            (Hazard Function &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n\n\n\n\n\n\n\n\nFigure 1",
    "crumbs": [
      "Discrete Cuisine"
    ]
  },
  {
    "objectID": "book/08-binary-logistic.html",
    "href": "book/08-binary-logistic.html",
    "title": "8  Sauce-sational Binary Logistic Regression",
    "section": "",
    "text": "Fun fact!\n\n\nSauce-sational! When the sauce is so good, it’s basically soup.\n\n\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}\n        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(\n          (Exponential &lt;br/&gt;Outcome Y)\n          (Weibull &lt;br/&gt;Outcome Y)\n          (Lognormal &lt;br/&gt;Outcome Y)\n        )Chapter 7: &lt;br/&gt;Semiparametric &lt;br/&gt;Survival &lt;br/&gt;Regression(\n          (Cox Proportional &lt;br/&gt;Hazards Model)\n            (Hazard Function &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n      {{Binary &lt;br/&gt;Outcome Y}}\n        {{Ungrouped &lt;br/&gt;Data}}\n          )Chapter 8: &lt;br/&gt;Binary Logistic &lt;br/&gt;Regression(\n            (Bernoulli &lt;br/&gt;Outcome Y)\n\n\n\n\n\n\n\n\nFigure 8.1",
    "crumbs": [
      "Discrete Cuisine",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Sauce-sational Binary Logistic Regression</span>"
    ]
  },
  {
    "objectID": "book/09-binomial-logistic.html",
    "href": "book/09-binomial-logistic.html",
    "title": "9  Cheesified Binomial Logistic Regression",
    "section": "",
    "text": "Fun fact!\n\n\nCheesified! Oozing with cheese in every crevice; a cheese lover’s paradise.\n\n\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma &lt;br/&gt;Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}\n        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(\n          (Exponential &lt;br/&gt;Outcome Y)\n          (Weibull &lt;br/&gt;Outcome Y)\n          (Lognormal &lt;br/&gt;Outcome Y)\n        )Chapter 7: &lt;br/&gt;Semiparametric &lt;br/&gt;Survival &lt;br/&gt;Regression(\n          (Cox Proportional &lt;br/&gt;Hazards Model)\n            (Hazard Function &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n      {{Binary &lt;br/&gt;Outcome Y}}\n        {{Ungrouped &lt;br/&gt;Data}}\n          )Chapter 8: &lt;br/&gt;Binary Logistic &lt;br/&gt;Regression(\n            (Bernoulli &lt;br/&gt;Outcome Y)\n        {{Grouped &lt;br/&gt;Data}}\n          )Chapter 9: &lt;br/&gt;Binomial Logistic &lt;br/&gt;Regression(\n            (Binomial &lt;br/&gt;Outcome Y)\n\n\n\n\n\n\n\n\nFigure 9.1",
    "crumbs": [
      "Discrete Cuisine",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Cheesified Binomial Logistic Regression</span>"
    ]
  },
  {
    "objectID": "book/10-classical-poisson.html",
    "href": "book/10-classical-poisson.html",
    "title": "10  Bubblarious Classical Poisson Regression",
    "section": "",
    "text": "Fun fact!\n\n\nBubblarious! For all the boba, fizzy drinks, and seltzers that go pop!\n\n\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}\n        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(\n          (Exponential &lt;br/&gt;Outcome Y)\n          (Weibull &lt;br/&gt;Outcome Y)\n          (Lognormal &lt;br/&gt;Outcome Y)\n        )Chapter 7: &lt;br/&gt;Semiparametric &lt;br/&gt;Survival &lt;br/&gt;Regression(\n          (Cox Proportional &lt;br/&gt;Hazards Model)\n            (Hazard Function &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n      {{Binary &lt;br/&gt;Outcome Y}}\n        {{Ungrouped &lt;br/&gt;Data}}\n          )Chapter 8: &lt;br/&gt;Binary Logistic &lt;br/&gt;Regression(\n            (Bernoulli &lt;br/&gt;Outcome Y)\n        {{Grouped &lt;br/&gt;Data}}\n          )Chapter 9: &lt;br/&gt;Binomial Logistic &lt;br/&gt;Regression(\n            (Binomial &lt;br/&gt;Outcome Y)\n      {{Count &lt;br/&gt;Outcome Y}}\n        {{Equidispersed &lt;br/&gt;Data}}\n          )Chapter 10: &lt;br/&gt;Classical Poisson &lt;br/&gt;Regression(\n            (Poisson &lt;br/&gt;Outcome Y)\n\n\n\n\n\n\n\n\nFigure 10.1",
    "crumbs": [
      "Discrete Cuisine",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Bubblarious Classical Poisson Regression</span>"
    ]
  },
  {
    "objectID": "book/11-negative-binomial.html",
    "href": "book/11-negative-binomial.html",
    "title": "11  Umami-zing Negative Binomial Regression",
    "section": "",
    "text": "Fun fact!\n\n\nUmami-zing! Savory to the point where you start craving a second plate… and a third.\n\n\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}\n        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(\n          (Exponential &lt;br/&gt;Outcome Y)\n          (Weibull &lt;br/&gt;Outcome Y)\n          (Lognormal &lt;br/&gt;Outcome Y)\n        )Chapter 7: &lt;br/&gt;Semiparametric &lt;br/&gt;Survival &lt;br/&gt;Regression(\n          (Cox Proportional &lt;br/&gt;Hazards Model)\n            (Hazard Function &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n      {{Binary &lt;br/&gt;Outcome Y}}\n        {{Ungrouped &lt;br/&gt;Data}}\n          )Chapter 8: &lt;br/&gt;Binary Logistic &lt;br/&gt;Regression(\n            (Bernoulli &lt;br/&gt;Outcome Y)\n        {{Grouped &lt;br/&gt;Data}}\n          )Chapter 9: &lt;br/&gt;Binomial Logistic &lt;br/&gt;Regression(\n            (Binomial &lt;br/&gt;Outcome Y)\n      {{Count &lt;br/&gt;Outcome Y}}\n        {{Equidispersed &lt;br/&gt;Data}}\n          )Chapter 10: &lt;br/&gt;Classical Poisson &lt;br/&gt;Regression(\n            (Poisson &lt;br/&gt;Outcome Y)\n        {{Overdispersed &lt;br/&gt;Data}}\n          )Chapter 11: &lt;br/&gt;Negative Binomial &lt;br/&gt;Regression(\n            (Negative Binomial &lt;br/&gt;Outcome Y)\n\n\n\n\n\n\n\n\nFigure 11.1",
    "crumbs": [
      "Discrete Cuisine",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Umami-zing Negative Binomial Regression</span>"
    ]
  },
  {
    "objectID": "book/12-zero-inflated-poisson.html",
    "href": "book/12-zero-inflated-poisson.html",
    "title": "12  Spicetacular Zero-Inflated Poisson Regression",
    "section": "",
    "text": "Fun fact!\n\n\nSpicetacular! The kind of spicy that requires a fire extinguisher at the ready.\n\n\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}\n        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(\n          (Exponential &lt;br/&gt;Outcome Y)\n          (Weibull &lt;br/&gt;Outcome Y)\n          (Lognormal &lt;br/&gt;Outcome Y)\n        )Chapter 7: &lt;br/&gt;Semiparametric &lt;br/&gt;Survival &lt;br/&gt;Regression(\n          (Cox Proportional &lt;br/&gt;Hazards Model)\n            (Hazard Function &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n      {{Binary &lt;br/&gt;Outcome Y}}\n        {{Ungrouped &lt;br/&gt;Data}}\n          )Chapter 8: &lt;br/&gt;Binary Logistic &lt;br/&gt;Regression(\n            (Bernoulli &lt;br/&gt;Outcome Y)\n        {{Grouped &lt;br/&gt;Data}}\n          )Chapter 9: &lt;br/&gt;Binomial Logistic &lt;br/&gt;Regression(\n            (Binomial &lt;br/&gt;Outcome Y)\n      {{Count &lt;br/&gt;Outcome Y}}\n        {{Equidispersed &lt;br/&gt;Data}}\n          )Chapter 10: &lt;br/&gt;Classical Poisson &lt;br/&gt;Regression(\n            (Poisson &lt;br/&gt;Outcome Y)\n        {{Overdispersed &lt;br/&gt;Data}}\n          )Chapter 11: &lt;br/&gt;Negative Binomial &lt;br/&gt;Regression(\n            (Negative Binomial &lt;br/&gt;Outcome Y)\n        {{Overdispersed or &lt;br/&gt;Underdispersed &lt;br/&gt;Data}}\n        {{Zero Inflated &lt;br/&gt;Data}}\n          )Chapter 12: &lt;br/&gt;Zero Inflated Poisson &lt;br/&gt;Regression(\n            (Zero Inflated &lt;br/&gt;Poisson &lt;br/&gt;Outcome Y)\n\n\n\n\n\n\n\n\nFigure 12.1",
    "crumbs": [
      "Discrete Cuisine",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Spicetacular Zero-Inflated Poisson Regression</span>"
    ]
  },
  {
    "objectID": "book/13-generalized-poisson.html",
    "href": "book/13-generalized-poisson.html",
    "title": "13  Herbalicious Generalized Poisson Regression",
    "section": "",
    "text": "Fun fact!\n\n\nHerbalicious! Loaded with herbs and greens; like chewing through a botanical garden.\n\n\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: &lt;br/&gt;Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}\n        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(\n          (Exponential &lt;br/&gt;Outcome Y)\n          (Weibull &lt;br/&gt;Outcome Y)\n          (Lognormal &lt;br/&gt;Outcome Y)\n        )Chapter 7: &lt;br/&gt;Semiparametric &lt;br/&gt;Survival &lt;br/&gt;Regression(\n          (Cox Proportional &lt;br/&gt;Hazards Model)\n            (Hazard Function &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n      {{Binary &lt;br/&gt;Outcome Y}}\n        {{Ungrouped &lt;br/&gt;Data}}\n          )Chapter 8: &lt;br/&gt;Binary Logistic &lt;br/&gt;Regression(\n            (Bernoulli &lt;br/&gt;Outcome Y)\n        {{Grouped &lt;br/&gt;Data}}\n          )Chapter 9: &lt;br/&gt;Binomial Logistic &lt;br/&gt;Regression(\n            (Binomial &lt;br/&gt;Outcome Y)\n      {{Count &lt;br/&gt;Outcome Y}}\n        {{Equidispersed &lt;br/&gt;Data}}\n          )Chapter 10: &lt;br/&gt;Classical Poisson &lt;br/&gt;Regression(\n            (Poisson &lt;br/&gt;Outcome Y)\n        {{Overdispersed &lt;br/&gt;Data}}\n          )Chapter 11: &lt;br/&gt;Negative Binomial &lt;br/&gt;Regression(\n            (Negative Binomial &lt;br/&gt;Outcome Y)\n        {{Zero Inflated &lt;br/&gt;Data}}\n          )Chapter 12: &lt;br/&gt;Zero Inflated &lt;br/&gt;Poisson &lt;br/&gt;Regression(\n            (Zero Inflated &lt;br/&gt;Poisson &lt;br/&gt;Outcome Y)\n        {{Overdispersed or &lt;br/&gt;Underdispersed &lt;br/&gt;Data}}\n          )Chapter 13: &lt;br/&gt;Generalized &lt;br/&gt;Poisson &lt;br/&gt;Regression(\n            (Generalized &lt;br/&gt;Poisson &lt;br/&gt;Outcome Y)\n\n\n\n\n\n\n\n\nFigure 13.1",
    "crumbs": [
      "Discrete Cuisine",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Herbalicious Generalized Poisson Regression</span>"
    ]
  },
  {
    "objectID": "book/14-multinomial-logistic.html",
    "href": "book/14-multinomial-logistic.html",
    "title": "14  Picklified Multinomial Logistic Regression",
    "section": "",
    "text": "Fun fact!\n\n\nPicklified! When everything, even dessert, tastes a bit pickled!\n\n\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}\n        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(\n          (Exponential &lt;br/&gt;Outcome Y)\n          (Weibull &lt;br/&gt;Outcome Y)\n          (Lognormal &lt;br/&gt;Outcome Y)\n        )Chapter 7: &lt;br/&gt;Semiparametric &lt;br/&gt;Survival &lt;br/&gt;Regression(\n          (Cox Proportional &lt;br/&gt;Hazards Model)\n            (Hazard Function &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n      {{Binary &lt;br/&gt;Outcome Y}}\n        {{Ungrouped &lt;br/&gt;Data}}\n          )Chapter 8: &lt;br/&gt;Binary Logistic &lt;br/&gt;Regression(\n            (Bernoulli &lt;br/&gt;Outcome Y)\n        {{Grouped &lt;br/&gt;Data}}\n          )Chapter 9: &lt;br/&gt;Binomial Logistic &lt;br/&gt;Regression(\n            (Binomial &lt;br/&gt;Outcome Y)\n      {{Count &lt;br/&gt;Outcome Y}}\n        {{Equidispersed &lt;br/&gt;Data}}\n          )Chapter 10: &lt;br/&gt;Classical Poisson &lt;br/&gt;Regression(\n            (Poisson &lt;br/&gt;Outcome Y)\n        {{Overdispersed &lt;br/&gt;Data}}\n          )Chapter 11: &lt;br/&gt;Negative Binomial &lt;br/&gt;Regression(\n            (Negative Binomial &lt;br/&gt;Outcome Y)\n        {{Zero Inflated &lt;br/&gt;Data}}\n          )Chapter 12: &lt;br/&gt;Zero Inflated &lt;br/&gt;Poisson &lt;br/&gt;Regression(\n            (Zero Inflated &lt;br/&gt;Poisson &lt;br/&gt;Outcome Y)\n        {{Overdispersed or &lt;br/&gt;Underdispersed &lt;br/&gt;Data}}\n          )Chapter 13: &lt;br/&gt;Generalized &lt;br/&gt;Poisson &lt;br/&gt;Regression(\n            (Generalized &lt;br/&gt;Poisson &lt;br/&gt;Outcome Y)\n      {{Categorical &lt;br/&gt;Outcome Y}}\n        {{Nominal &lt;br/&gt;Outcome Y}}\n          )Chapter 14: &lt;br/&gt;Multinomial &lt;br/&gt;Logistic &lt;br/&gt;Regression(\n            (Multinomial &lt;br/&gt;Outcome Y)\n\n\n\n\n\n\n\n\nFigure 14.1",
    "crumbs": [
      "Discrete Cuisine",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Picklified Multinomial Logistic Regression</span>"
    ]
  },
  {
    "objectID": "book/15-ordinal-logistic.html",
    "href": "book/15-ordinal-logistic.html",
    "title": "15  Tang-tastic Ordinal Logistic Regression",
    "section": "",
    "text": "Fun fact!\n\n\nTang-tastic! So tangy it could wake you up better than coffee.\n\n\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}\n        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(\n          (Exponential &lt;br/&gt;Outcome Y)\n          (Weibull &lt;br/&gt;Outcome Y)\n          (Lognormal &lt;br/&gt;Outcome Y)\n        )Chapter 7: &lt;br/&gt;Semiparametric &lt;br/&gt;Survival &lt;br/&gt;Regression(\n          (Cox Proportional &lt;br/&gt;Hazards Model)\n            (Hazard Function &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n      {{Binary &lt;br/&gt;Outcome Y}}\n        {{Ungrouped &lt;br/&gt;Data}}\n          )Chapter 8: &lt;br/&gt;Binary Logistic &lt;br/&gt;Regression(\n            (Bernoulli &lt;br/&gt;Outcome Y)\n        {{Grouped &lt;br/&gt;Data}}\n          )Chapter 9: &lt;br/&gt;Binomial Logistic &lt;br/&gt;Regression(\n            (Binomial &lt;br/&gt;Outcome Y)\n      {{Count &lt;br/&gt;Outcome Y}}\n        {{Equidispersed &lt;br/&gt;Data}}\n          )Chapter 10: &lt;br/&gt;Classical Poisson &lt;br/&gt;Regression(\n            (Poisson &lt;br/&gt;Outcome Y)\n        {{Overdispersed &lt;br/&gt;Data}}\n          )Chapter 11: &lt;br/&gt;Negative Binomial &lt;br/&gt;Regression(\n            (Negative Binomial &lt;br/&gt;Outcome Y)\n        {{Overdispersed or &lt;br/&gt;Underdispersed &lt;br/&gt;Data}}\n          )Chapter 13: &lt;br/&gt;Generalized &lt;br/&gt;Poisson &lt;br/&gt;Regression(\n            (Generalized &lt;br/&gt;Poisson &lt;br/&gt;Outcome Y)\n        {{Zero Inflated &lt;br/&gt;Data}}\n          )Chapter 12: &lt;br/&gt;Zero Inflated &lt;br/&gt;Poisson &lt;br/&gt;Regression(\n            (Zero Inflated &lt;br/&gt;Poisson &lt;br/&gt;Outcome Y)\n      {{Categorical &lt;br/&gt;Outcome Y}}\n        {{Nominal &lt;br/&gt;Outcome Y}}\n          )Chapter 14: &lt;br/&gt;Multinomial &lt;br/&gt;Logistic &lt;br/&gt;Regression(\n            (Multinomial &lt;br/&gt;Outcome Y)\n        {{Ordinal &lt;br/&gt;Outcome Y}}\n          )Chapter 15: &lt;br/&gt;Ordinal &lt;br/&gt;Logistic &lt;br/&gt;Regression(\n            (Logistic &lt;br/&gt;Distributed &lt;br/&gt;Cumulative Outcome &lt;br/&gt;Probability)\n\n\n\n\n\n\n\n\nFigure 15.1",
    "crumbs": [
      "Discrete Cuisine",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Tang-tastic Ordinal Logistic Regression</span>"
    ]
  },
  {
    "objectID": "book/references.html",
    "href": "book/references.html",
    "title": "References",
    "section": "",
    "text": "Bellhouse, D. R. 2004. “The Reverend Thomas\nBayes, FRS: A Biography to Celebrate the Tercentenary of His\nBirth.” Statistical Science 19 (1): 3–43. https://doi.org/10.1214/088342304000000189.\n\n\nCasella, G., and R. Berger. 2024. Statistical Inference.\nChapman & Hall/CRC Texts in Statistical Science. CRC Press. https://www.taylorfrancis.com/books/mono/10.1201/9781003456285/statistical-inference-roger-berger-george-casella.\n\n\nConsul, P. C., and G. C. Jain. 1973. “A Generalization of the\nPoisson Distribution.” Technometrics 15 (4): 791–99. http://www.jstor.org/stable/1267389.\n\n\nEarlom, Richard. 1793. “Brook Taylor - National Portrait\nGallery.” NPG D6930; Brook Taylor - Portrait - National\nPortrait Gallery. National Portrait Gallery. https://www.npg.org.uk/collections/search/portrait/mw40921/Brook-Taylor.\n\n\nGelbart, Michael. 2017. “Data Science Terminology.” UBC\nMDS. Master of Data Science at the University of British Columbia.\nhttps://ubc-mds.github.io/resources_pages/terminology/.\n\n\nGregory, James. 1668. Vera circuli et\nhyperbolae quadratura cui accedit geometria pars vniuersalis inseruiens\nquantitatum curuarum transmutationi & mensurae. Authore Iacobo\nGregorio Abredonensi. Padua, Italy: Patavii: typis heredum\nPauli Frambotti bibliop. https://archive.org/details/ita-bnc-mag-00001357-001/page/n10/mode/2up.\n\n\nHarding, Edward. 1798. Portrait of Colin MacLaurin.\nCourtesy of the Smithsonian Libraries and Archives. https://library.si.edu/image-gallery/72863.\n\n\nJohnson, A. A., M. Q. Ott, and M. Dogucu. 2022. Bayes Rules!: An\nIntroduction to Applied Bayesian Modeling. Chapman & Hall/CRC\nTexts in Statistical Science. CRC Press. https://www.bayesrulesbook.com/.\n\n\nMaclaurin, Colin. 1742. A Treatise of Fluxions. Edinburgh,\nScotland: Printed for the Author by T.W.; T. Ruddimans. https://archive.org/details/treatiseonfluxio02macl/page/n5/mode/2up.\n\n\nO’Donnell, T. 1936. History of Life Insurance\nin Its Formative Years. Compiled from Approved Sources by T.\nO’Donnell. Chicago.\n\n\nR Core Team. 2024. “R: A Language and Environment for Statistical\nComputing.” Vienna, Austria: R Foundation for Statistical\nComputing. https://www.R-project.org/.\n\n\nScotland, National Galleries of. n.d. Professor James Gregory, 1638\n- 1675 (1). Mathematician. Professor James Gregory, 1638 - 1675\n(1). Mathematician | National Galleries. https://www.nationalgalleries.org/art-and-artists/31132/professor-james-gregory-1638-1675-mathematician.\n\n\nSoch, Joram, The Book of Statistical Proofs, Maja, Pietro Monticone,\nThomas J. Faulkenberry, Alex Kipnis, Kenneth Petrykowski, et al. 2024.\n“StatProofBook/StatProofBook.github.io:\nStatProofBook 2023.” Zenodo. https://doi.org/10.5281/zenodo.10495684.\n\n\nTaylor, Brook. 1715. Methodus incrementorum\ndirecta & inversa. Auctore Brook Taylor, LL. D. & Regiae\nSocietatis Secretario. London, England: Typis Pearsonianis\nProstant apud Gul. Innys ad Insignia Principis in Coemeterio Paulino\nMDCCXV. https://archive.org/details/bim_eighteenth-century_methodus-incrementorum-d_taylor-brook_1717.\n\n\nThe Pandas Development Team. 2024. “Pandas-Dev/Pandas:\nPandas.” Zenodo. https://doi.org/10.5281/zenodo.3509134.\n\n\nVan Rossum, Guido, and Fred L. Drake. 2009. Python 3 Reference\nManual. Scotts Valley, CA: CreateSpace.\n\n\nWeisstein, Eric W. n.d. “Taylor Series.” From\nMathWorld–A Wolfram Web Resource. https://mathworld.wolfram.com/TaylorSeries.html.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy\nD’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019.\n“Welcome to the tidyverse.”\nJournal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "book/A-dictionary.html",
    "href": "book/A-dictionary.html",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "",
    "text": "A\nMachine learning and statistics comprise a substantial synergy that is reflected in data science. Thus, it is imperative to construct solid bridges between both disciplines to ensure everything is clear regarding their tremendous amount of jargon and terminology. This ML-Stats dictionary (ML stands for Machine Learning) aims to be one of these bridges in this textbook, especially within supervised learning and regression analysis contexts.\nBelow, you will find definitions either highlighted in blue if they correspond to statistical terminology or magenta if the terminology is machine learning-related. These definitions come from all definition admonitions, such as in (Definition-sample?). This colour scheme strives to combine all terminology to switch from one field to another easily. With practice and time, we should be able to jump back and forth when using these concepts.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#a",
    "href": "book/A-dictionary.html#a",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "",
    "text": "Alternative hypothesis\nAttribute\n\n\nEquivalent to:\n\n\nCovariate, exogeneous variable, explanatory variable, feature, independent variable, input, predictor or regressor.\n\n\nAverage\nLet \\(Y\\) be a random variable whose support is \\(\\mathcal{Y}\\). In general, the expected value or mean \\(\\mathbb{E}(Y)\\) of this random variable is defined as a weighted average according to its corresponding probability distribution. In other words, this measure of central tendency \\(\\mathbb{E}(Y)\\) aims to find the middle value of this random variable by weighting all its possible values in its support \\(\\mathcal{Y}\\) as dictated by its probability distribution.\nGiven the above definition, when \\(Y\\) is a discrete random variable whose probability mass function (PMF) is \\(P_Y(Y = y)\\), then its weighted average is mathematically defined as\n\\[\n\\mathbb{E}(Y) = \\sum_{y \\in \\mathcal{Y}} y \\cdot P_Y(Y = y).\n\\]\nWhen \\(Y\\) is a continuous random variable whose probability density function (PDF) is \\(f_Y(y)\\), its weighted average is mathematically defined as\n\\[\n\\mathbb{E}(Y) = \\int_{\\mathcal{Y}} y \\cdot f_Y(y) \\mathrm{d}y.\n\\]\n\n\nEquivalent to:\n\n\nExpected value or mean.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#b",
    "href": "book/A-dictionary.html#b",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "B",
    "text": "B\nBayesian statistics\nThis statistical school of thinking also relies on the frequency of events to estimate specific parameters of interest in a population or system. Nevertheless, unlike frequentist statistics, Bayesian statisticians use prior knowledge on the population parameters to update their estimations on them along with the current evidence they can gather. This evidence is in the form of the repetition of \\(n\\) experiments involving a random phenomenon. All these ingredients allow Bayesian statisticians to make inference by conducting appropriate hypothesis testings, which are designed differently from their mainstream frequentist counterpart.\nUnder the umbrella of this approach, we assume that our governing parameters are random; i.e., they have their own sample space and probabilities associated to their corresponding outcomes. The statistical process of inference is heavily backed up by probability theory mostly in the form of the Bayes theorem (named after Reverend Thomas Bayes, an English statistician from the 18th century). This theorem uses our current evidence along with our prior beliefs to deliver a posterior distribution of our random parameter(s) of interest.\nBayes’ rule\nSuppose you have two events of interest, \\(A\\) and \\(B\\), in a random phenomenon of a population or system of interest. From Equation A.4, we can state the following expression for the conditional probability of \\(A\\) given \\(B\\):\n\\[\nP(A | B) = \\frac{P(A \\cap B)}{P(B)} \\quad \\text{if $P(B) &gt; 0$.}\n\\tag{A.1}\\]\nNote the conditional probability of \\(B\\) given \\(A\\) can be stated as:\n\\[\n\\begin{align*}\nP(B | A) &= \\frac{P(B \\cap A)}{P(A)} \\quad \\text{if $P(A) &gt; 0$} \\\\\n&= \\frac{P(A \\cap B)}{P(A)} \\quad \\text{since $P(B \\cap A) = P(A \\cap B)$.}\n\\end{align*}\n\\tag{A.2}\\]\nThen, we can manipulate Equation A.2 as follows:\n\\[\nP(A \\cap B) = P(B | A) \\times P(A).\n\\]\nThe above result can be plugged into Equation A.1:\n\\[\n\\begin{align*}\nP(A | B) &= \\frac{P(A \\cap B)}{P(B)} \\\\\n&= \\frac{P(B | A) \\times P(A)}{P(B)}.\n\\end{align*}\n\\tag{A.3}\\]\nEquation A.3 is called the Bayes’ rule. We are basically flipping around conditional probabilities.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#c",
    "href": "book/A-dictionary.html#c",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "C",
    "text": "C\nCritical value\nConditional probability\nSuppose you have two events of interest, \\(A\\) and \\(B\\), in a random phenomenon, in a population or system of interest. These two events belong to the sample space \\(S\\). Moreover, assume that the probability of event \\(B\\) is such that\n\\[\nP(B) &gt; 0,\n\\]\nwhich is considered the conditioning event.\nHence, the conditional probability event \\(A\\) given event \\(B\\) is defined as\n\\[\nP(A | B) = \\frac{P(A \\cap B)}{P(B)},\n\\tag{A.4}\\]\nwhere \\(P(A \\cap B)\\) is read as the probability of the intersection of events \\(A\\) and \\(B\\).\nConfidence interval\nContinuous random variable\nLet \\(Y\\) be a random variable whose support is \\(\\mathcal{Y}\\). If this support \\(\\mathcal{Y}\\) corresponds to an uncountably infinite set of possible values, then \\(Y\\) is considered a continuous random variable.\nNote a continuous random variable could be\n\n\ncompletely unbounded (i.e., its set of possible values goes from \\(-\\infty\\) to \\(\\infty\\) as in \\(-\\infty &lt; y &lt; \\infty\\)),\n\npositively unbounded (i.e., its set of possible values goes from \\(0\\) to \\(\\infty\\) as in \\(0 \\leq y &lt; \\infty\\)),\n\nnegatively unbounded (i.e., its set of possible values goes from \\(-\\infty\\) to \\(0\\) as in \\(-\\infty &lt; y \\leq 0\\)), or\n\nbounded between two values \\(a\\) and \\(b\\) (i.e., its set of possible values goes from \\(a\\) to \\(b\\) as in \\(a \\leq y \\leq b\\)).\nCovariate\n\n\nEquivalent to:\n\n\nAttribute, exogeneous variable, explanatory variable, feature, independent variable, input, predictor or regressor.\n\n\nCumulative distribution function\nLet \\(Y\\) be a random variable either discrete or continuous. Its cumulative distribution function (CDF) \\(F_Y(y)  : \\mathbb{R} \\rightarrow [0, 1]\\) refers to the probability that \\(Y\\) is less or equal than an observed value \\(y\\):\n\\[\nF_Y(y) = P(Y \\leq y).\n\\]\nThen, we have the following by type of random variable:\n\nWhen \\(Y\\) is discrete, whose support is \\(\\mathcal{Y}\\), suppose it has a probability mass function (PMF) \\(P_Y(Y = y)\\). Then, the CDF is mathematically represented as:\n\n\\[\nF_Y(y) = \\sum_{\\substack{t \\in \\mathcal{Y} \\\\ t \\leq y}} P_Y(Y = t).\n\\tag{A.5}\\]\n\nWhen \\(Y\\) is continuous, whose support is \\(\\mathcal{Y}\\), suppose it has a probability density function (PDF) \\(f_Y(y)\\). Then, the CDF is mathematically represented as:\n\n\\[\nF_Y(y) = \\int_{-\\infty}^y f_Y(t) \\mathrm{d}t.\n\\tag{A.6}\\]\nNote that in Equation A.5 and Equation A.6, we use the auxiliary variable \\(t\\) since we do not compute the summation or integral over the observed \\(y\\) given its role on either the PMF or PDF. Therefore, we use this auxiliary variable \\(t\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#d",
    "href": "book/A-dictionary.html#d",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "D",
    "text": "D\nDependent variable\nIn supervised learning, it is the main variable of interest we are trying to learn or predict, or equivalently, the variable we are trying explain in a statistical inference framework.\n\n\nEquivalent to:\n\n\nEndogeneous variable, response variable, outcome, output or target.\n\n\nDiscrete random variable\nLet \\(Y\\) be a random variable whose support is \\(\\mathcal{Y}\\). If this support \\(\\mathcal{Y}\\) corresponds to a finite set or a countably infinite set of possible values, then \\(Y\\) is considered a discrete random variable.\nFor instance, we can encounter discrete random variables which could be classified as\n\n\nbinary (i.e., a finite set of two possible values),\n\ncategorical (either nominal or ordinal, which have a finite set of three or more possible values), or\n\ncounts (which might have a finite set or a countably infinite set of possible values as integers).\nDispersion",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#e",
    "href": "book/A-dictionary.html#e",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "E",
    "text": "E\nEndogeneous variable\n\n\nEquivalent to:\n\n\nDependent variable, outcome, output, response variable or target.\n\n\nEquidispersion\nExpected value\nLet \\(Y\\) be a random variable whose support is \\(\\mathcal{Y}\\). In general, the expected value or mean \\(\\mathbb{E}(Y)\\) of this random variable is defined as a weighted average according to its corresponding probability distribution. In other words, this measure of central tendency \\(\\mathbb{E}(Y)\\) aims to find the middle value of this random variable by weighting all its possible values in its support \\(\\mathcal{Y}\\) as dictated by its probability distribution.\nGiven the above definition, when \\(Y\\) is a discrete random variable whose probability mass function (PMF) is \\(P_Y(Y = y)\\), then its expected value is mathematically defined as\n\\[\n\\mathbb{E}(Y) = \\sum_{y \\in \\mathcal{Y}} y \\cdot P_Y(Y = y).\n\\tag{A.7}\\]\nWhen \\(Y\\) is a continuous random variable whose probability density function (PDF) is \\(f_Y(y)\\), its expected value is mathematically defined as\n\\[\n\\mathbb{E}(Y) = \\int_{\\mathcal{Y}} y \\cdot f_Y(y) \\mathrm{d}y.\n\\tag{A.8}\\]\n\n\nEquivalent to:\n\n\nAverage or mean.\n\n\nExogeneous variable\n\n\nEquivalent to:\n\n\nAttribute, covariate, explanatory variable, feature, independent variable, input, predictor or regressor.\n\n\nExplanatory variable\n\n\nEquivalent to:\n\n\nAttribute, covariate, exogeneous variable, feature, independent variable, input, predictor or regressor.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#f",
    "href": "book/A-dictionary.html#f",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "F",
    "text": "F\nFalse negative\n\n\nEquivalent to:\n\n\nType II error.\n\n\nFalse positive\n\n\nEquivalent to:\n\n\nType I error.\n\n\nFeature\n\n\nEquivalent to:\n\n\nAttribute, covariate, exogeneous variable, explanatory variable, independent variable, input, predictor or regressor.\n\n\nFrequentist statistics\nThis statistical school of thinking heavily relies on the frequency of events to estimate specific parameters of interest in a population or system. This frequency of events is reflected in the repetition of \\(n\\) experiments involving a random phenomenon within this population or system.\nUnder the umbrella of this approach, we assume that our governing parameters are fixed. Note that, within the philosophy of this school of thinking, we can only make precise and accurate predictions as long as we repeat our \\(n\\) experiments as many times as possible, i.e.,\n\\[\nn \\rightarrow \\infty.\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#g",
    "href": "book/A-dictionary.html#g",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "G",
    "text": "G\nGeneralized linear model\nGenerative model\nSuppose you observe some data \\(y\\) from a population or system of interest. Moreover, let us assume this population or system is governed by \\(k\\) parameters contained in the following vector:\n\\[\n\\boldsymbol{\\theta} = (\\theta_1, \\theta_2, \\cdots, \\theta_k)^T.\n\\]\nIf we state that our observed data \\(y\\) follows certain probability distribution \\(\\mathcal{D}(\\cdot)\\), then we will have a generative model \\(m\\) such that\n\\[\nm: y \\sim \\mathcal{D}(\\boldsymbol{\\theta}).\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#h",
    "href": "book/A-dictionary.html#h",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "H",
    "text": "H\nHypothesis testing",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#i",
    "href": "book/A-dictionary.html#i",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "I",
    "text": "I\nIndependence\nSuppose you have two events of interest, \\(A\\) and \\(B\\), in a random phenomenon of a population or system of interest. These two events are statistically independent if event \\(B\\) does not affect event \\(A\\) and vice versa. Therefore, the probability of their corresponding intersection is given by:\n\\[\nP(A \\cap B) = P(A) \\times P(B).\n\\]\nLet us expand the above definition to a random variable framework:\n\nSuppose you have a set of \\(n\\) discrete random variables \\(Y_1, \\dots, Y_n\\) whose supports are \\(\\mathcal{Y_1}, \\dots, \\mathcal{Y_n}\\) with probability mass functions (PMFs) \\(P_{Y_1}(Y_1 = y_1), \\dots, P_{Y_n}(Y_n = y_n)\\) respectively. That said, the joint PMF of these \\(n\\) random variables is the multiplication of their corresponding standalone PMFs:\n\n\\[\n\\begin{align*}\nP_{Y_1, \\dots, Y_n}(Y_1 = y_1, \\dots, Y_n = y_n) &= \\prod_{i = 1}^n P_{Y_i}(Y_i = y_i) \\\\\n& \\qquad \\text{for all} \\\\\n& \\qquad \\quad y_i \\in \\mathcal{Y}_i, i = 1, \\dots, n.\n\\end{align*}\n\\tag{A.9}\\]\n\nSuppose you have a set of \\(n\\) continuous random variables \\(Y_1, \\dots, Y_n\\) whose supports are \\(\\mathcal{Y_1}, \\dots, \\mathcal{Y_n}\\) with probability density functions (PDFs) \\(f_{Y_1}(y_1), \\dots, f_{Y_n}(y_n)\\) respectively. That said, the joint PDF of these \\(n\\) random variables is the multiplication of their corresponding standalone PDFs:\n\n\\[\n\\begin{align*}\nf_{Y_1, \\dots, Y_n}(y_1, \\dots, y_n) &= \\prod_{i = 1}^n f_{Y_i}(y_i) \\\\\n& \\qquad \\text{for all} \\\\\n& \\qquad \\quad y_i \\in \\mathcal{Y}_i, i = 1, \\dots, n.\n\\end{align*}\n\\tag{A.10}\\]\nIndependent variable\n\n\nEquivalent to:\n\n\nAttribute, covariate, exogeneous variable, explanatory variable, feature, input, predictor or regressor.\n\n\nInput\n\n\nEquivalent to:\n\n\nAttribute, covariate, exogeneous variable, explanatory variable, feature, independent variable, predictor or regressor.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#m",
    "href": "book/A-dictionary.html#m",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "M",
    "text": "M\nMean\nLet \\(Y\\) be a random variable whose support is \\(\\mathcal{Y}\\). In general, the expected value or mean \\(\\mathbb{E}(Y)\\) of this random variable is defined as a weighted average according to its corresponding probability distribution. In other words, this measure of central tendency \\(\\mathbb{E}(Y)\\) aims to find the middle value of this random variable by weighting all its possible values in its support \\(\\mathcal{Y}\\) as dictated by its probability distribution.\nGiven the above definition, when \\(Y\\) is a discrete random variable whose probability mass function (PMF) is \\(P_Y(Y = y)\\), then its mean is mathematically defined as\n\\[\n\\mathbb{E}(Y) = \\sum_{y \\in \\mathcal{Y}} y \\cdot P_Y(Y = y).\n\\]\nWhen \\(Y\\) is a continuous random variable whose probability density function (PDF) is \\(f_Y(y)\\), its mean is mathematically defined as\n\\[\n\\mathbb{E}(Y) = \\int_{\\mathcal{Y}} y \\cdot f_Y(y) \\mathrm{d}y.\n\\]\n\n\nEquivalent to:\n\n\nAverage or expected value.\n\n\nMeasure of central tendency\nProbabilistically, a measure of central tendency is defined as a metric that identifies a central or typical value of a given probability distribution. In other words, a measure of central tendency refers to a central or typical value that a given random variable might take when we observe various realizations of this variable over a long period.\nMeasure of uncertainty\nProbabilistically, a measure of uncertainty refers to the spread of a given random variable when we observe its different realizations in the long term. Note a larger spread indicates more variability in these realizations. On the other hand, a smaller spread denotes less variability in these realizations.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#n",
    "href": "book/A-dictionary.html#n",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "N",
    "text": "N\nNull hypothesis",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#o",
    "href": "book/A-dictionary.html#o",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "O",
    "text": "O\nObserved effect\nOutcome\nIn supervised learning, it is the main variable of interest we are trying to learn or predict, or equivalently, the variable we are trying explain in a statistical inference framework.\n\n\nEquivalent to:\n\n\nDependent variable, endogeneous variable, response variable, output or target.\n\n\nOutput\nIn supervised learning, it is the main variable of interest we are trying to learn or predict, or equivalently, the variable we are trying explain in a statistical inference framework.\n\n\nEquivalent to:\n\n\nDependent variable, endogeneous variable, response variable, outcome or target.\n\n\nOverdispersion",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#p",
    "href": "book/A-dictionary.html#p",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "P",
    "text": "P\nParameter\nIt is a characteristic (numerical or even non-numerical, such as a distinctive category) that summarizes the state of our population or system of interest.\nNote the standard mathematical notation for population parameters are Greek letters. Moreover, in practice, these population parameter(s) of interest will be unknown to the data scientist or researcher. Instead, they would use formal statistical inference to estimate them.\nPopulation\nIt is a whole collection of individuals or items that share distinctive attributes. As data scientists or researchers, we are interested in studying these attributes, which we assume are governed by parameters. In practice, we must be as specific as possible when defining our given population such that we would frame our entire data modelling process since its very early stages.\nNote that the term population could be exchanged for the term system, given that certain contexts do not specifically refer to individuals or items. Instead, these contexts could refer to processes whose attributes are also governed by parameters.\nPower\n\n\nEquivalent to:\n\n\nTrue positive rate.\n\n\nPredictor\n\n\nEquivalent to:\n\n\nAttribute, covariate, exogeneous variable, explanatory variable, feature, independent variable, input or regressor.\n\n\nProbability\nLet \\(A\\) be an event of interest in a random phenomenon, in a population or system of interest, whose all possible outcomes belong to a given sample space \\(S\\). Generally, the probability for this event \\(A\\) happening can be mathematically depicted as \\(P(A)\\). Moreover, suppose we observe the random phenomenon \\(n\\) times such as we were running some class of experiment, then \\(P(A)\\) is defined as the following ratio:\n\\[\nP(A) = \\frac{\\text{Number of times event $A$ is observed}}{n},\n\\tag{A.11}\\]\nas the \\(n\\) times we observe the random phenomenon goes to infinity.\nEquation A.11 will always put \\(P(A)\\) in the following numerical range:\n\\[\n0 \\leq P(A) \\leq 1.\n\\]\nProbability distribution\nWhen we set a random variable \\(Y\\), we also set a new set of \\(v\\) possible outcomes \\(\\mathcal{Y} = \\{ y_1, \\dots, y_v\\}\\) coming from the sample space \\(S\\). This new set of possible outcomes \\(\\mathcal{Y}\\) corresponds to the range of the random variable \\(Y\\) (i.e., all the possible values that could be taken on once we execute a given random experiment involving \\(Y\\)).\nThat said, let us suppose we have a sample space of \\(u\\) elements defined as\n\\[\nS = \\{ s_1, \\dots, s_u \\},\n\\]\nwhere each one of these elements has a probability assigned via a function \\(P_S(\\cdot)\\) such that\n\\[\nP(S) = \\sum_{i = 1}^u P_S(s_i) = 1.\n\\]\nwhich has to satisfy Equation A.14.\nThen, the probability distribution of \\(Y\\), i.e., \\(P_Y(\\cdot)\\) assigns a probability to each observed value \\(Y = y_j\\) (with \\(j = 1, \\dots, v\\)) if and only if the outcome of the random experiment belongs to the sample space, i.e., \\(s_i \\in S\\) (for \\(i = 1, \\dots, u\\)) such that \\(Y(s_i) = y_j\\):\n\\[\nP_Y(Y = y_j) = P \\left( \\left\\{ s_i \\in S : Y(s_i) = y_j \\right\\} \\right).\n\\]\nProbability density function\nLet \\(Y\\) be a continuous random variable whose support is \\(\\mathcal{Y}\\). Furthermore, consider a function \\(f_Y(y)\\) such that\n\\[\nf_Y(y) : \\mathbb{R} \\rightarrow \\mathbb{R}\n\\]\nwith\n\\[\nf_Y(y) \\geq 0.\n\\]\nThen, \\(f_Y(y)\\) is considered a probability density function (PDF) if the probability of \\(Y\\) taking on a value within the range represented by the subset \\(A \\subset \\mathcal{Y}\\) is equal to\n\\[\nP_Y(Y \\in A) = \\int_A f_Y(y) \\mathrm{d}y\n\\]\nwith\n\\[\n\\int_{\\mathcal{Y}} f_Y(y) \\mathrm{d}y = 1.\n\\]\nProbability mass function\nLet \\(Y\\) be a discrete random variable whose support is \\(\\mathcal{Y}\\). Moreover, suppose that \\(Y\\) has a probability distribution such that\n\\[\nP_Y(Y = y) : \\mathbb{R} \\rightarrow [0, 1]\n\\]\nwhere, for all \\(y \\notin \\mathcal{Y}\\), we have\n\\[\nP_Y(Y = y) = 0\n\\]\nand\n\\[\n\\sum_{y \\in \\mathcal{Y}} P_Y(Y = y) = 1.\n\\] Then, \\(P_Y(Y = y)\\) is considered a probability mass function (PMF).\n\\(p\\)-value",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#r",
    "href": "book/A-dictionary.html#r",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "R",
    "text": "R\nRandom Sample\nA random sample is a collection of random variables \\(Y_1, \\dots, Y_n\\) of size \\(n\\) coming from a given population or system of interest. Note that the most elementary definition of a random sample assumes that these \\(n\\) random variables are mutually independent and identically distributed (which is abbreviated as iid).\nThe fact that these \\(n\\) random variables are identically distributed indicates that they have the same mathematical form for their corresponding probability mass functions (PMFs) or probability density function (PDFs), depending on whether they are discrete or continuous respectively. Hence, under a generative modelling approach in a population or system of interest governed by \\(k\\) parameters contained in the vector\n\\[\n\\boldsymbol{\\theta} = (\\theta_1, \\theta_2, \\cdots, \\theta_k)^T,\n\\]\nwe can apply the iid property in an elementary random sample to obtain the following joint probability distributions:\n\nIn the case of \\(n\\) iid discrete random variables \\(Y_1, \\dots, Y_n\\) whose common standalone PMF is \\(P_Y(Y = y)\\) with support \\(\\mathcal{Y}\\), the joint PMF is mathematically expressed as\n\n\\[\n\\begin{align*}\nP_{Y_1, \\dots, Y_n}(Y_1 = y_1, \\dots, Y_n = y_n | \\boldsymbol{\\theta}) &= \\prod_{i = 1}^n P_Y(Y = y_i | \\boldsymbol{\\theta}) \\\\\n& \\qquad \\text{for all} \\\\\n& \\qquad \\quad y_i \\in \\mathcal{Y}, i = 1, \\dots, n.\n\\end{align*}\n\\tag{A.12}\\]\n\nIn the case of \\(n\\) iid continuous random variables \\(Y_1, \\dots, Y_n\\) whose common standalone PDF is \\(f_Y(y)\\) with support \\(\\mathcal{Y}\\), the joint PDF is mathematically expressed as\n\n\\[\n\\begin{align*}\nf_{Y_1, \\dots, Y_n}(y_1, \\dots, y_n | \\boldsymbol{\\theta}) &= \\prod_{i = 1}^n f_Y(y_i | \\boldsymbol{\\theta}) \\\\\n& \\qquad \\text{for all} \\\\\n& \\qquad \\quad y_i \\in \\mathcal{Y}, i = 1, \\dots, n.\n\\end{align*}\n\\tag{A.13}\\]\nUnlike Equation A.9 and Equation A.10, note that Equation A.12 and Equation A.13 indicate the subscript \\(Y\\) in the corresponding probability distributions since we have identically distributed random variables. Furthermore, the joint distributions are conditioned on the population parameter vector \\(\\boldsymbol{\\theta}\\) which reflects our generative modelling approach.\n\n\nSomewhat equivalent to:\n\n\nTraining dataset.\n\n\nRandom variable\nA random variable is a function where the input values correspond to real numbers assigned to events belonging to the sample space \\(S\\), and whose outcome is one of these real numbers after executing a given random experiment. For instance, a random variable (and its support, i.e., real numbers) is depicted with an uppercase such that\n\\[Y \\in \\mathbb{R}.\\]\nRegression analysis\nRegressor\n\n\nEquivalent to:\n\n\nAttribute, covariate, exogeneous variable, explanatory variable, feature, independent variable, input or predictor.\n\n\nResponse variable\nIn supervised learning, it is the main variable of interest we are trying to learn or predict, or equivalently, the variable we are trying explain in a statistical inference framework.\n\n\nEquivalent to:\n\n\nDependent variable, endogeneous variable, outcome, output or target.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#s",
    "href": "book/A-dictionary.html#s",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "S",
    "text": "S\nSample space\nLet \\(A\\) be an event of interest in a random phenomenon in a population or system of interest. The sample space \\(S\\) of event \\(A\\) denotes the set of all the possible random outcomes we might encounter every time we randomly observe \\(A\\) such as we were running some class of experiment.\nNote each of these outcomes has a determined probability associated with them. If we add up all these probabilities, the probability of the sample \\(S\\) will be one, i.e.,\n\\[\nP(S) = 1.\n\\tag{A.14}\\]\nSignificance level\nStandard error",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#t",
    "href": "book/A-dictionary.html#t",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "T",
    "text": "T\nTarget\nIn supervised learning, it is the main variable of interest we are trying to learn or predict, or equivalently, the variable we are trying explain in a statistical inference framework.\n\n\nEquivalent to:\n\n\nDependent variable, endogeneous variable, response variable, outcome or output.\n\n\nTest statistic\nTraining dataset\n\n\nSomewhat equivalent to:\n\n\nRandom sample.\n\n\nType I error\n\n\nEquivalent to:\n\n\nFalse positive.\n\n\nType II error\n\n\nEquivalent to:\n\n\nFalse negative.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#u",
    "href": "book/A-dictionary.html#u",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "U",
    "text": "U\nUnderdispersion",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#v",
    "href": "book/A-dictionary.html#v",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "V",
    "text": "V\nVariance\nLet \\(Y\\) be a discrete or continuous random variable whose support is \\(\\mathcal{Y}\\) with a mean represented by \\(\\mathbb{E}(Y)\\). Then, the variance of \\(Y\\) is the mean of the squared deviation from the corresponding mean as follows:\n\\[\n\\text{Var}(Y) = \\mathbb{E}\\left\\{[ Y - \\mathbb{E}(Y)]^2 \\right\\}. \\\\\n\\]\nNote the expression above is equivalent to:\n\\[\n\\text{Var}(Y) = \\mathbb{E}(Y^2) - \\left[ \\mathbb{E}(Y) \\right]^2.\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/B-greek-alphabet.html",
    "href": "book/B-greek-alphabet.html",
    "title": "Appendix B — The Snazzalicious Greek Alphabet",
    "section": "",
    "text": "Fun fact!\n\n\nSnazzalicious! Food that’s dressed up, fancy, and begging for a photo.\n\n\nStatistical notation can be pretty particular and different from usual mathematical notation. One of these particularities is the constant use of Greek letters to denote unknown population parameters in modelling setup, estimation, and statistical inference. In that spirit, throughout this book, we use diverse Greek letters to denote our regression parameters across each of the outlined models in every chapter.\n\n\nImage by meineresterampe via Pixabay.\n\nDuring early learning stages of regression modelling, we may feel overwhelmed by these new letters, which could be unfamiliar. Therefore, whenever confusion arises in any of the main chapters in this book regarding the names of these letters, we recommend checking out the Greek alphabet from Table B.1. Note that frequentist statistical inference mostly uses lowercase letters. With practice over time, you would likely end up memorizing most of this alphabet.\n\n\nTable B.1: Greek alphabet composed of 24 letters, from left to right you can find the name of letter along with its corresponding uppercase and lowercase forms.\n\n\n\nName\nUppercase\nLowercase\n\n\n\nAlpha\n\\(\\text{A}\\)\n\\(\\alpha\\)\n\n\nBeta\n\\(\\text{B}\\)\n\\(\\beta\\)\n\n\nGamma\n\\(\\Gamma\\)\n\\(\\gamma\\)\n\n\nDelta\n\\(\\Delta\\)\n\\(\\delta\\)\n\n\nEpsilon\n\\(\\text{E}\\)\n\\(\\epsilon\\)\n\n\nZeta\n\\(\\text{Z}\\)\n\\(\\zeta\\)\n\n\nEta\n\\(\\text{H}\\)\n\\(\\eta\\)\n\n\nTheta\n\\(\\Theta\\)\n\\(\\theta\\)\n\n\nIota\n\\(\\text{I}\\)\n\\(\\iota\\)\n\n\nKappa\n\\(\\text{K}\\)\n\\(\\kappa\\)\n\n\nLambda\n\\(\\Lambda\\)\n\\(\\lambda\\)\n\n\nMu\n\\(\\text{M}\\)\n\\(\\mu\\)\n\n\nNu\n\\(\\text{N}\\)\n\\(\\nu\\)\n\n\nXi\n\\(\\Xi\\)\n\\(\\xi\\)\n\n\nO\n\\(\\text{O}\\)\n\\(\\text{o}\\)\n\n\nPi\n\\(\\Pi\\)\n\\(\\pi\\)\n\n\nRho\n\\(\\text{P}\\)\n\\(\\rho\\)\n\n\nSigma\n\\(\\Sigma\\)\n\\(\\sigma\\)\n\n\nTau\n\\(\\text{T}\\)\n\\(\\tau\\)\n\n\nUpsilon\n\\(\\Upsilon\\)\n\\(\\upsilon\\)\n\n\nPhi\n\\(\\Phi\\)\n\\(\\phi\\)\n\n\nChi\n\\(\\text{X}\\)\n\\(\\chi\\)\n\n\nPsi\n\\(\\Psi\\)\n\\(\\psi\\)\n\n\nOmega\n\\(\\Omega\\)\n\\(\\omega\\)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>The Snazzalicious Greek Alphabet</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html",
    "href": "book/C-distributional-mind-map.html",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "",
    "text": "D Discrete Random Variables\nA crucial part of the practice of regression analysis is a fair knowledge of all the different probability distributions that would allow us to identify the most suitable regression model. Let us delve into the distributional toolbox to be used in this book.\nFigure C.1 shows all those probability distributions depicted as clouds, in the form of a univariate random variable \\(Y\\), used to model our outcomes of interest in the regression tools explored in each of the core thirteen chapters, i.e., we take a generative modelling approach. Note this mind map splits the outcomes of interest into two large zones: discrete and continuous. Furthermore, this mind map briefly describes a given random variable \\(Y\\) as a quick cheat sheet regarding its support (e.g., nonnegative, bounded, unbounded, etc.) or distributional definition (e.g., success or failure, successes in \\(n\\) trials, etc.).\nSince a given random variable (e.g., the outcome \\(Y\\) in any of the thirteen regression models in this book) will have a probability distribution associated with it, which will define the probability arrangement of each possible value or category \\(Y\\) could take on, we also need a way to summarize all this information via key estimated metrics called measures of central tendency and uncertainty:\nThese metrics allow us to clearly communicate how the outcome \\(Y\\) behaves in our case study, and this is heavily related to the storytelling stage from the data science workflow, as explained in Section 1.2.8. More specifically, the measures of central tendency can be communicated along with our estimated regression parameters, given that these metrics are usually conditioned to our regressors of interest within our modelling framework.\nThere are different measures of central tendency and uncertainty. Nevertheless, we will only focus on the expected value and the variance. Now, suppose \\(Y\\) is a random variable whose support is \\(\\mathcal{Y}\\). Furthermore, let \\(g(Y)\\) be a general function of \\(Y\\).\nBy the law of the unconscious statistician (LOTUS), when \\(Y\\) is a discrete random variable, we have that:\n\\[\n\\mathbb{E} \\left[ g(Y) \\right] = \\displaystyle \\sum_{y \\in \\mathcal{Y}} g(Y) \\cdot P_Y(Y = y),\n\\tag{C.1}\\]\nwhere \\(P_Y(Y = y)\\) is the probability mass function (PMF) of \\(Y\\).\nIf \\(Y\\) is a continuous random variable, by the LOTUS, the mean of function \\(g(Y)\\) is defined as\n\\[\n\\mathbb{E} \\left[ g(Y) \\right] = \\displaystyle \\int_{\\mathcal{Y}} g(Y) \\cdot f_Y(y) \\text{d}y,\n\\tag{C.2}\\]\nwhere \\(f_Y(y)\\) is the probability density function (PDF) of \\(Y\\).\nNote that when \\(g(Y) = y\\) in the discrete case, Equation C.1 becomes\n\\[\n\\mathbb{E} \\left( Y \\right) = \\displaystyle \\sum_{y \\in \\mathcal{Y}} y \\cdot P_Y(Y = y).\n\\tag{C.3}\\]\nOn the other hand, when \\(g(Y) = y\\) in the continuous case, Equation C.2 becomes\n\\[\n\\mathbb{E} \\left( Y \\right) = \\displaystyle \\int_{\\mathcal{Y}} y \\cdot f_Y(y) \\mathrm{d}y.\n\\tag{C.4}\\]\nEither for a discrete or continuous case, the variance is defined as\n\\[\n\\text{Var}(Y) = \\mathbb{E}\\{[Y - \\mathbb{E}(Y)]^2\\}.\n\\]\nAfter applying some algebraic rearrangements and expected value properties, the expression above is equivalent to:\n\\[\n\\text{Var}(Y) = \\mathbb{E}(Y^2) - [\\mathbb{E}(Y)]^2.\n\\tag{C.5}\\]\nwhere \\(\\mathbb{E}(Y^2)\\) can be computed either via Equation C.1 or Equation C.2 depending on the nature of \\(Y\\) with \\(g(Y) = y^2\\).\nNow, for each case depicted as a cloud in Figure C.1, subsequent sections in this appendix will show elaborate on why each corresponding PMF or PDF (depending on the type of random variable, \\(Y\\)) is a proper probability distribution (i.e., all the standalone probabilities over the support of \\(Y\\) add up to one) along with the respective proofs of their corresponding means and variances.\nLet us recall what a discrete random variable is. This type of variable is defined to take on a set of countable values. In other words, these values belong to a finite set. Figure C.1 delves into the following specific probability distributions:\nTable D.1 outlines the parameter(s), support, mean, and variance for each discrete probability distribution utilized to model the target \\(Y\\) in a specific regression tool explained in this book.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#bernoulli",
    "href": "book/C-distributional-mind-map.html#bernoulli",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nD.1 Bernoulli",
    "text": "D.1 Bernoulli\nLet \\(Y\\) be a discrete random variable that is part of a random process or system. \\(Y\\) can only take on the following values:\n\\[\nY =\n\\begin{cases}\n1 \\; \\; \\; \\; \\text{if there is a success},\\\\\n0 \\; \\; \\; \\; \\mbox{otherwise}.\n\\end{cases}\n\\tag{D.1}\\]\nNote that the support of \\(Y\\) in Equation D.1 makes it binary with these outcomes: \\(1\\) for success and \\(0\\) for failure. Then, \\(Y\\) is said to have a Bernoulli distribution with parameter \\(\\pi\\):\n\\[\nY \\sim \\text{Bern}(\\pi).\n\\]\n\nD.1.1 Probability Mass Function\nThe probability mass function (PMF) of \\(Y\\) is the following:\n\\[\nP_Y \\left( Y = y \\mid \\pi \\right) = \\pi^y (1 - \\pi)^{1 - y} \\quad \\text{for $y \\in \\{ 0, 1 \\}$.}\n\\tag{D.2}\\]\nParameter \\(\\pi \\in [0, 1]\\) refers to the probability of success. We can verify Equation D.2 is a proper probability distribution (i.e., all the standalone probabilities over the support of \\(Y\\) add up to one) given that:\n\nProof. \\[\n\\begin{align*}\n\\sum_{y = 0}^1 P_Y \\left( Y = y \\mid \\pi \\right) &=  \\sum_{y = 0}^1 \\pi^y (1 - \\pi)^{1 - y}  \\\\\n&= \\underbrace{\\pi^0}_{1} (1 - \\pi) + \\pi \\underbrace{(1 - \\pi)^{0}}_{1} \\\\\n&= (1 - \\pi) + \\pi \\\\\n&= 1. \\qquad \\qquad \\qquad \\qquad \\quad \\square\n\\end{align*}\n\\]\n\nIndeed, the Bernoulli PMF is a proper probability distribution!\n\n\n\nD.1.2 Expected Value\nVia Equation C.3, the expected value or mean of a Bernoulli-distributed random variable \\(Y\\) can be found as follows:\n\nProof. \\[\n\\begin{align*}\n\\mathbb{E}(Y) &= \\sum_{y = 0}^1 y P_Y \\left( Y = y \\mid \\pi \\right) \\\\\n&= \\sum_{y = 0}^1 y \\left[ \\pi^y (1 - \\pi)^{1 - y} \\right] \\\\\n&= \\underbrace{(0) \\left[ \\pi^0 (1 - \\pi) \\right]}_{0} + (1) \\left[ \\pi (1 - \\pi)^{0} \\right] \\\\\n&= 0 + \\pi \\\\\n&= \\pi. \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\quad \\square\n\\end{align*}\n\\]\n\n\nD.1.3 Variance\nVia Equation C.5 and the Equation C.3 of a discrete expected value, the variance of a Bernoulli-distributed random variable \\(Y\\) can be found as follows:\n\nProof. \\[\n\\begin{align*}\n\\text{Var} (Y) &= \\mathbb{E}(Y^2) - \\left[ \\mathbb{E}(Y)\\right]^2 \\\\\n&= \\mathbb{E}(Y^2) - \\pi^2 \\qquad \\text{since $\\mathbb{E}(Y) = \\pi$} \\\\\n&= \\sum_{y = 0}^1 y^2 P_Y \\left( Y = y \\mid \\pi \\right) - \\pi^2 \\\\\n&= \\left\\{ \\underbrace{(0^2) \\left[ \\pi^0 (1 - \\pi) \\right]}_{0} + \\underbrace{(1^2) \\left[ \\pi (1 - \\pi)^{0} \\right]}_{\\pi} \\right\\} - \\pi^2 \\\\\n&= (0 + \\pi) - \\pi^2 \\\\\n&= \\pi - \\pi^2 \\\\\n&= \\pi (1 - \\pi). \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\quad \\square\n\\end{align*}\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#binomial",
    "href": "book/C-distributional-mind-map.html#binomial",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nD.2 Binomial",
    "text": "D.2 Binomial\nSuppose you execute \\(n\\) independent Bernoulli trials, each one with a probability of success \\(\\pi\\). Let \\(Y\\) be the number of successes obtained within these \\(n\\) Bernoulli trials. Then, \\(Y\\) is said to have a Binomial distribution with parameters \\(n\\) and \\(\\pi\\):\n\\[\nY \\sim \\text{Bin}(n, \\pi).\n\\]\n\nD.2.1 Probability Mass Function\nThe PMF of \\(Y\\) is the following:\n\\[\n\\begin{align*}\nP_Y \\left( Y = y \\mid n, \\pi \\right) &= {n \\choose y} \\pi^y (1 - \\pi)^{n - y} \\\\\n& \\qquad \\qquad \\qquad \\text{for $y \\in \\{ 0, 1, \\dots, n \\}$.}\n\\end{align*}\n\\tag{D.3}\\]\nParameter \\(\\pi \\in [0, 1]\\) refers to the probability of success of each Bernoulli trial and \\(n \\in \\mathbb{N}\\) to the number of trials. On the other hand, the term \\({n \\choose y}\\) indicates the total number of possible combinations for \\(y\\) successes out of our \\(n\\) trials:\n\\[\n{n \\choose y} = \\frac{n!}{y!(n - y)!}.\n\\tag{D.4}\\]\n\nHow can we verify that Equation D.3 is a proper PMF (i.e., all the standalone probabilities over the support of \\(Y\\) add up to one)?\n\nTo elaborate on this, we need to use a handy mathematical result called the binomial theorem.\n\nTheorem D.1 (Binomial Theorem) This theorem is associated to the Pascal’s identity, and it defines the pattern of coefficients in the expansion of a polynomial in the form \\((u + v)^m\\). More specifically, the binomial theorem indicates that if \\(m\\) is a non-negative integer, then the polynomial \\((u + v)^m\\) can be expanded via the following series:\n\\[\n\\begin{align*}\n(u + v)^m &= u^m + {m \\choose 1} u^{m - 1} v + {m \\choose 2} u^{m - 2} v^2 + \\dots + \\\\\n& \\qquad {m \\choose r} u^{m - r} v^r + \\dots + \\\\\n& \\qquad {m \\choose m - 1} u v^{m - 1} + v^m \\\\\n&= \\underbrace{{m \\choose 0}}_1 u^m + {m \\choose 1} u^{m - 1} v + {m \\choose 2} u^{m - 2} v^2 + \\dots + \\\\\n& \\qquad {m \\choose r} u^{m - r} v^r + \\dots + \\\\\n& \\qquad {m \\choose m - 1} u v^{m - 1} + \\underbrace{{m \\choose m}}_1 v^m \\\\\n&= \\sum_{i = 0}^m {m \\choose i} u^{m - i} v^i.\n\\end{align*}\n\\tag{D.5}\\]\n\n\n\nTip on the binomial theorem and Pascal’s identity\n\n\nLet us dig into the proof of the binomial theorem from Equation D.5. This proof will require another important result called the Pascal’s identity. This identity states that for any integers \\(m\\) and \\(k\\), with \\(k \\in \\{ 1, \\dots, m \\}\\), it follows that:\n\nProof. \\[\n\\begin{align*}\n{m \\choose k - 1} + {m \\choose k} &= \\left[ \\frac{m!}{(k - 1)! (m - k + 1)!} \\right] \\\\\n& \\qquad + \\left[ \\frac{m!}{k! (m - k)!} \\right] \\\\\n&= m! \\biggl\\{ \\left[ \\frac{1}{(k - 1)! (m - k + 1)!} \\right] + \\\\\n& \\qquad \\left[ \\frac{1}{k! (m - k)!} \\right] \\biggl\\} \\\\\n&= m! \\Biggl\\{ \\Biggr[ \\frac{k}{\\underbrace{k (k - 1)!}_{k!} (m - k + 1)!} \\Biggr] + \\\\\n& \\qquad \\Biggr[ \\frac{m - k + 1}{k! \\underbrace{(m - k + 1)(m - k)!}_{(m - k + 1)!}} \\Biggr] \\Biggl\\}  \\\\\n&= m! \\left[ \\frac{k + m - k + 1}{k! (m - k + 1)!} \\right] \\\\\n&= m! \\left[ \\frac{m + 1}{k! (m - k + 1)!} \\right] \\\\\n&= \\frac{(m + 1)!}{k! (m + 1 - k)!} \\\\\n&= {m + 1 \\choose k }. \\qquad \\qquad \\qquad \\qquad \\square\n\\end{align*}\n\\tag{D.6}\\]\n\n\nProof. Now, we will use mathematical induction to prove the binomial theorem from Equation D.5. Firstly, on the left-hand side of the theorem, note that when \\(m = 0\\) we have:\n\\[\n(u + v)^0 = 1.\n\\]\nNow, when \\(m = 0\\), for the right-hand side of this equation, we have that\n\\[\n\\sum_{i = 0}^m {m \\choose i} u^{m - i} v^i  = \\sum_{i = 0}^0 {0 \\choose i} u^i v^{i} = {0 \\choose 0} u^0 v^0 = 1.\n\\]\nHence, the binomial theorem holds when \\(m = 0\\). This is what we call the base case in mathematical induction.\nThat said, let us proceed with the inductive hypothesis. We aim to prove that the binomial theorem\n\\[\n\\begin{align*}\n(u + v)^j &= u^j + {j \\choose 1} u^{j - 1} v + {j \\choose 2} u^{j - 2} v^2 + \\dots + \\\\\n& \\qquad {j \\choose r} u^{j - r} v^r + \\dots + \\\\\n& \\qquad {j \\choose j - 1} u v^{j - 1} + v^j \\\\\n&= \\underbrace{{j \\choose 0}}_1 u^j + {j \\choose 1} u^{j - 1} v + {j \\choose 2} u^{j - 2} v^2 + \\dots + \\\\\n& \\qquad {j \\choose r} u^{j - r} v^r + \\dots + \\\\\n& \\qquad {j \\choose j - 1} u v^{j - 1} + \\underbrace{{j \\choose j}}_1 v^j \\\\\n&= \\sum_{i = 0}^j {j \\choose i} u^{j - i} v^i\n\\end{align*}\n\\tag{D.7}\\]\nholds when integer \\(j \\geq 1\\). This is our inductive hypothesis.\nThen, we pave the way to the inductive step. Let us consider the following expansion:\n\\[\n\\begin{align*}\n(u + v)^{j + 1} &= (u + v) (u + v)^j \\\\\n&= (u + v) \\times \\\\\n& \\qquad \\bigg[ u^j + {j \\choose 1} u^{j - 1} v + {j \\choose 2} u^{j - 2} v^2 + \\dots + \\\\\n& \\qquad {j \\choose r} u^{j - r} v^r + \\dots + {j \\choose j - 1} u v^{j - 1} + v^j \\bigg] \\\\\n&= \\bigg[u^{j + 1} + {j \\choose 1} u^j v + {j \\choose 2} u^{j - 1} v^2 + \\dots + \\\\\n& \\qquad {j \\choose r} u^{j - r + 1} v^r + \\dots + \\\\\n& \\qquad {j \\choose j - 1} u^2 v^{j - 1} + u v^j \\bigg] + \\\\\n& \\qquad \\bigg[ u^j v + {j \\choose 1} u^{j - 1} v^2 + {j \\choose 2} u^{j - 2} v^3 + \\dots + \\\\\n& \\qquad {j \\choose r} u^{j - r} v^{r + 1} + \\dots + \\\\\n& \\qquad {j \\choose j - 1} u v^j + {j \\choose j} v^{j + 1} \\bigg] \\\\\n&= u^{j + 1} + \\left[ {j \\choose 0} + {j \\choose 1} \\right] u^j v + \\\\\n& \\qquad \\left[ {j \\choose 1} + {j \\choose 2} \\right] u^{j - 1} v^2 + \\dots + \\\\\n& \\qquad \\left[ {j \\choose r - 1} + {j \\choose r} \\right] u^{j - r + 1} v^r + \\dots + \\\\\n& \\qquad \\left[ {j \\choose j - 1} + {j \\choose j} \\right] u v^j + v^{j + 1}.\n\\end{align*}\n\\tag{D.8}\\]\nLet us plug in the Pascal’s identity from Equation D.6 into Equation D.8:\n\\[\n\\begin{align*}\n(u + v)^{j + 1} &= u^{j + 1} + {j + 1 \\choose 1} u^j v + \\\\\n& \\qquad {j + 1 \\choose 2} u^{j - 1} v^2 + \\dots + \\\\\n& \\qquad {j + 1 \\choose r} u^{j - r + 1} v^r + \\dots + \\\\\n& \\qquad {j + 1 \\choose j} u v^j + v^{j + 1} \\\\\n&= \\underbrace{{j + 1 \\choose 0}}_1 u^{j + 1} + {j + 1 \\choose 1} u^j v + \\\\\n& \\qquad {j + 1 \\choose 2} u^{j - 1} v^2 + \\dots + \\\\\n& \\qquad {j + 1 \\choose r} u^{j - r + 1} v^r + \\dots + \\\\\n& \\qquad {j + 1 \\choose j} u v^j + \\underbrace{{j + 1 \\choose j + 1}}_1 v^{j + 1} \\\\\n&= \\sum_{i = 0}^{j + 1} {j + 1 \\choose i} u^{j + 1 - i} v^i. \\qquad \\quad \\square\n\\end{align*}\n\\tag{D.9}\\]\nNote that the result for \\(j\\) in Equation D.7 also holds for \\(j + 1\\) in Equation D.9. Therefore, by induction, the binomial theorem from Equation D.5 is true for all positive integers \\(m\\).\n\n\n\nAfter the above fruitful digression on the binomial theorem, let us use it to show that our Binomial PMF in Equation D.3 actually adds up to one all over the support of the random variable:\n\nProof. \\[\n\\begin{align*}\n\\sum_{y = 0}^n P_Y \\left( Y = y \\mid n, \\pi \\right) &= \\sum_{y = 0}^n {n \\choose y} \\pi^y (1 - \\pi)^{n - y} \\\\\n&= \\sum_{y = 0}^n {n \\choose y} (1 - \\pi)^{n - y} \\pi^y \\\\\n& \\quad \\qquad \\text{rearranging factors.}\n\\end{align*}\n\\]\nNow, by using the binomial theorem in Equation D.5, let:\n\\[\n\\begin{gather*}\nm  = n\\\\\ni = y \\\\\nu = 1 - \\pi \\\\\nv = \\pi.\n\\end{gather*}\n\\]\nThe above arrangement yields the following result:\n\\[\n\\begin{align*}\n\\sum_{y = 0}^n P_Y \\left( Y = y \\mid n, \\pi \\right) &= (1 - \\pi + \\pi)^n \\\\\n&= 1^n = 1. \\qquad \\square\n\\end{align*}\n\\tag{D.10}\\]\n\nIndeed, the Binomial PMF is a proper probability distribution!\n\n\n\nD.2.2 Expected Value\nVia Equation C.3, the expected value or mean of a Binomial-distributed random variable \\(Y\\) can be found as follows:\n\nProof. \\[\n\\begin{align*}\n\\mathbb{E}(Y) &= \\sum_{y = 0}^n y P_Y \\left( Y = y \\mid n, \\pi \\right) \\\\\n&= \\sum_{y = 1}^n y P_Y \\left( Y = y \\mid n, \\pi \\right) \\\\\n& \\quad \\qquad \\text{for $y = 0$, the addend is equal to zero} \\\\\n&= \\sum_{y = 1}^n y \\left[ {n \\choose y} \\pi^y (1 - \\pi)^{n - y} \\right] \\\\\n&= \\sum_{y = 1}^n y \\left[ \\frac{n!}{y! (n - y)!} \\pi^y (1 - \\pi)^{n - y} \\right] \\\\\n&= \\sum_{y = 1}^n \\left[ \\frac{y n!}{y (y - 1)!(n - y)!} \\pi^y (1 - \\pi)^{n - y} \\right] \\\\\n& \\quad \\qquad \\text{in the denominator, $y! = y (y - 1)!$}\\\\\n&= \\sum_{y = 1}^n \\left[ \\frac{n (n - 1)!}{(y - 1)!(n - y)!} \\pi^y (1 - \\pi)^{n - y} \\right] \\\\\n& \\quad \\qquad \\text{in the numerator, $n! = n (n - 1)!$} \\\\\n&= \\sum_{y = 1}^n \\left[ \\frac{n (n - 1)!}{(y - 1)!(n - y)!} \\pi^{y + 1 - 1} (1 - \\pi)^{n - y} \\right] \\\\\n& \\quad \\qquad \\text{note $\\pi^y = \\pi^{y + 1 - 1}$} \\\\\n&= n \\sum_{y = 1}^n \\left[ \\frac{(n - 1)!}{(y - 1)!(n - y)!} \\pi \\pi^{y - 1} (1 - \\pi)^{n - y} \\right] \\\\\n& \\quad \\qquad \\text{rearranging terms} \\\\\n&= n \\pi \\sum_{y = 1}^n \\left[ \\frac{(n - 1)!}{(y - 1)!(n - y)!} \\pi^{y - 1} (1 - \\pi)^{n - y} \\right].\n\\end{align*}\n\\tag{D.11}\\]\nNow, let us make the following variable rearrangement:\n\\[\n\\begin{gather*}\nm = n - 1 \\\\\nz = y - 1 \\\\\nm - z = n - y.\n\\end{gather*}\n\\]\nGoing back to Equation D.11, and applying our above variable rearrangement within the summation, we have:\n\\[\n\\begin{align*}\n\\mathbb{E}(Y) &= n \\pi \\sum_{z = 0}^m \\left[ \\frac{m!}{z!(m - z)!} \\pi^{z} (1 - \\pi)^{m - z} \\right] \\\\\n&= n \\pi \\sum_{z = 0}^m \\left[ {m \\choose z}\\pi^{z} (1 - \\pi)^{m - z} \\right].\n\\end{align*}\n\\tag{D.12}\\]\nNote that, in the summation of Equation D.12, we encounter the PMF of a random variable \\(Z\\) as follows:\n\\[\nZ \\sim \\text{Bin}(m, \\pi).\n\\]\nSince the summation, where this Binomial PMF of \\(Z\\) is depicted, goes from \\(z = 0\\) to \\(m\\), we can apply our result from Equation D.10:\n\\[\n\\begin{align*}\n\\mathbb{E}(Y) &= n \\pi \\underbrace{\\sum_{z = 0}^m \\left[ {m \\choose z}\\pi^{z} (1 - \\pi)^{m - z} \\right]}_{1} \\\\\n&= n \\pi. \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\quad \\square\n\\end{align*}\n\\]\n\n\nD.2.3 Variance\nVia Equation C.5 and the Equation C.3 of a discrete expected value, the variance of a Binomial-distributed random variable \\(Y\\) can be found as follows:\n\nProof. \\[\n\\begin{align*}\n\\text{Var} (Y) &= \\mathbb{E}(Y^2) - \\left[ \\mathbb{E}(Y)\\right]^2 \\\\\n&= \\mathbb{E}(Y^2) - (n \\pi)^2 \\qquad \\text{since $\\mathbb{E}(Y) = n \\pi$.}\n\\end{align*}\n\\tag{D.13}\\]\nUnlike the Bernoulli random variable, finding \\(\\mathbb{E}(Y^2)\\) is not quite straightforward. We need to play around with the below expected value expression as follows:\n\\[\n\\begin{align*}\n\\mathbb{E}(Y^2) &= \\mathbb{E} \\left[ Y (Y - 1) \\right] + \\mathbb{E}(Y) \\\\\n&= \\mathbb{E} \\left[ Y (Y - 1) \\right] + n \\pi \\qquad \\text{since $\\mathbb{E}(Y) = n \\pi$.}\n\\end{align*}\n\\tag{D.14}\\]\nNow, to find \\(\\mathbb{E} \\left[ Y (Y - 1) \\right]\\), we make the following derivation via Equation C.1 when \\(g(Y) = y (y - 1)\\):\n\\[\n\\begin{align*}\n\\mathbb{E} \\left[ Y (Y - 1) \\right] &= \\sum_{y = 0}^n y (y - 1) P_Y \\left( Y = y \\mid n, \\pi \\right) \\\\\n&= \\sum_{y = 2}^n y (y - 1) P_Y \\left( Y = y \\mid n, \\pi \\right) \\\\\n& \\quad \\qquad \\text{for $y = \\{0, 1\\}$,} \\\\\n& \\quad \\qquad \\text{the addends are equal to zero} \\\\\n&= \\sum_{y = 2}^n y (y - 1) \\left[ {n \\choose y} \\pi^y (1 - \\pi)^{n - y} \\right] \\\\\n&= \\sum_{y = 2}^n y (y - 1) \\left[ \\frac{n!}{y! (n - y)!} \\pi^y (1 - \\pi)^{n - y} \\right] \\\\\n&= \\sum_{y = 2}^n \\left[ \\frac{y (y - 1) n!}{y (y - 1) (y - 2)! (n - y)!} \\pi^y (1 - \\pi)^{n - y} \\right] \\\\\n& \\quad \\qquad \\text{in the denominator, $y! = y (y - 1) (y - 2)!$} \\\\\n&= \\sum_{y = 2}^n \\left[ \\frac{n (n - 1) (n - 2)!}{(y - 2)! (n - y)!} \\pi^y (1 - \\pi)^{n - y} \\right] \\\\\n& \\quad \\qquad \\text{in the numerator, $n! = n (n - 1) (n - 2)!$} \\\\\n&= \\sum_{y = 2}^n \\left[ \\frac{n (n - 1) (n - 2)!}{(y - 2)! (n - y)!} \\pi^{y + 2 - 2} (1 - \\pi)^{n - y} \\right] \\\\\n& \\quad \\qquad \\text{note $\\pi^y = \\pi^{y + 2 - 2}$} \\\\\n&= n (n - 1) \\times \\\\\n& \\qquad \\sum_{y = 2}^n \\left[ \\frac{(n - 2)!}{(y - 2)! (n - y)!} \\pi^2 \\pi^{y - 2} (1 - \\pi)^{n - y} \\right] \\\\\n& \\qquad \\qquad \\text{rearranging terms} \\\\\n&= n (n - 1) \\pi^2 \\times \\\\\n& \\qquad \\sum_{y = 2}^n \\left[ \\frac{(n - 2)!}{(y - 2)! (n - y)!} \\pi^{y - 2} (1 - \\pi)^{n - y} \\right] \\\\\n& \\qquad \\qquad \\text{rearranging terms.}\n\\end{align*}\n\\tag{D.15}\\]\nThen, we make the following variable rearrangement:\n\\[\n\\begin{gather*}\nm = n - 2 \\\\\nz = y - 2 \\\\\nm - z = n - y.\n\\end{gather*}\n\\]\nGoing back to Equation D.15, and applying our above variable rearrangement within the summation, we have:\n\\[\n\\begin{align*}\n\\mathbb{E} \\left[ Y (Y - 1) \\right] &= n (n - 1) \\pi^2 \\sum_{z = 0}^m \\left[ \\frac{m!}{z! (m - z)!} \\pi^{z} (1 - \\pi)^{m - z} \\right] \\\\\n&= n (n - 1) \\pi^2 \\sum_{z = 0}^m \\left[ {m \\choose z} \\pi^{z} (1 - \\pi)^{m - z} \\right].\n\\end{align*}\n\\tag{D.16}\\]\nNote that, in the summation of Equation D.16, we encounter the PMF of a random variable \\(Z\\) as follows:\n\\[\nZ \\sim \\text{Bin}(m, \\pi).\n\\]\nSince the summation, where this Binomial PMF of \\(Z\\) is depicted, goes from \\(z = 0\\) to \\(m,\\) we can apply our result from Equation D.10:\n\\[\n\\begin{align*}\n\\mathbb{E} \\left[ Y (Y - 1) \\right] &= n (n - 1) \\pi^2 \\underbrace{\\sum_{z = 0}^m \\left[ {m \\choose z} \\pi^{z} (1 - \\pi)^{m - z} \\right]}_{1} \\\\\n&= n (n - 1) \\pi^2.\n\\end{align*}\n\\]\nLet us go back to Equation D.14 and plug in the above result:\n\\[\n\\begin{align*}\n\\mathbb{E}(Y^2) &= \\mathbb{E} \\left[ Y (Y - 1) \\right] + n \\pi \\\\\n&= n (n - 1) \\pi^2 + n \\pi. \\\\\n\\end{align*}\n\\]\nFinally, we plug in \\(\\mathbb{E}(Y^2)\\) in Equation D.13:\n\\[\n\\begin{align*}\n\\text{Var} (Y) &= \\mathbb{E}(Y^2) - (n \\pi)^2 \\\\\n&= n (n - 1) \\pi^2 + n \\pi - n^2 \\pi^2 \\\\\n&= n^2 \\pi^2 - n \\pi^2 + n \\pi - n^2 \\pi^2 \\\\\n&= n \\pi - n \\pi^2 \\\\\n&= n \\pi (1 - \\pi). \\qquad \\qquad \\qquad \\square\n\\end{align*}\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#negative-binomial",
    "href": "book/C-distributional-mind-map.html#negative-binomial",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nD.3 Negative Binomial",
    "text": "D.3 Negative Binomial\nSuppose you execute a series of independent Bernoulli trials, each one with a probability of success \\(\\pi\\). Let \\(Y\\) be the number of failures in this series of Bernoulli trials you obtain before experiencing \\(k\\) successes. Therefore, \\(Y\\) is said to have a Negative Binomial distribution with parameters \\(k\\) and \\(\\pi\\):\n\\[\nY \\sim \\text{NegBin}(k, \\pi).\n\\]\n\nD.3.1 Probability Mass Function\nThe PMF of \\(Y\\) is the following:\n\\[\n\\begin{align*}\nP_Y \\left( Y = y \\mid k, \\pi \\right) &= {k + y - 1 \\choose y} \\pi^k (1 - \\pi)^y \\\\\n& \\qquad \\qquad \\qquad \\quad \\text{for $y \\in \\{ 0, 1, \\dots \\}$.}\n\\end{align*}\n\\tag{D.17}\\]\nParameter \\(\\pi \\in [0, 1]\\) refers to the probability of success of each Bernoulli trial, whereas \\(k\\) refers to the number of successes.\n\n\nTip on an alternative Negative Binomial PMF!\n\n\nThere is an alternative parametrization to define a Negative Binomial distribution in which we have a random variable \\(Z\\) defined as the total number of Bernoulli trials (i.e., \\(k\\) successes plus the \\(Y\\) failures depicted in Equation D.17):\n\\[\nZ = Y + k.\n\\]\nThis alternative parametrization of the Negative Binomial distribution yields the following PMF:\n\\[\n\\begin{align*}\nP_Z \\left( Z = z \\mid k, \\pi \\right) &= {z - 1 \\choose k - 1} \\pi^k (1 - \\pi)^{z - k} \\\\\n& \\qquad \\qquad \\qquad \\text{for $z \\in \\{ k, k + 1, \\dots \\}$.}\n\\end{align*}\n\\]\nNevertheless, we will not dig into this version of the Negative Binomial distribution since Chapter 11 delves into a modelling estimation via a joint PMF of the training set involving Equation D.17.\n\n\n\nHow can we verify that Equation D.17 is a proper PMF (i.e., all the standalone probabilities over the support of \\(Y\\) add up to one)?\n\n\nProof. Let us manipulate the factor involving the number of combinations corresponding to how many different possible subsets of size \\(y\\) can be made from the larger set of size \\(k + y - 1\\):\n\\[\n\\begin{align*}\n{k + y - 1 \\choose y} &= \\frac{(k + y - 1)!}{(k + y - 1 - y)! y !} \\\\\n&= \\frac{(k + y - 1)!}{(k - 1)! y!} \\\\\n&= \\frac{(k + y - 1) (k + y - 2) \\cdots (k + 1) (k) (k - 1)!}{(k - 1)! y!} \\\\\n&= \\frac{(\\overbrace{k + y - 1) (k + y - 2) \\cdots (k + 1) k}^{\\text{we have $y$ factors}}}{y!} \\\\\n&= (- 1)^y \\frac{\\overbrace{(-k - y + 1) (-k - y + 2) \\cdots (-k - 1) (-k)}^{\\text{multiplying each factor times $-1$}}}{y!} \\\\\n&= (- 1)^y \\frac{\\overbrace{(-k) (-k - 1) \\cdots (-k - y + 2) (-k - y + 1)}^{\\text{rearranging factors}}}{y!} \\\\\n&= (- 1)^y \\frac{(-k) (-k - 1) \\cdots (-k - y + 2) (-k - y + 1)}{y!} \\times \\\\\n& \\qquad \\frac{(-k - y) (-k - y - 1) \\cdots (1)}{(-k - y) (-k - y - 1) \\cdots (1)} \\\\\n&= (- 1)^y \\frac{(-k) (-k - 1) \\cdots (-k - y + 2) (-k - y + 1)}{y!} \\times \\\\\n& \\qquad \\frac{(-k - y) (-k - y - 1) \\cdots (1)}{(-k - y)!}.\n\\end{align*}\n\\]\nIn the equation above, note that there are still several factors in the numerator, which can be summarized using a factorial as follows:\n\\[\n\\begin{align*}\n(-k)! &= (-k) (-k - 1) \\cdots (-k - y + 2) (-k - y + 1) \\times \\\\\n& \\quad \\qquad (-k - y) (-k - y - 1) \\cdots (1).\n\\end{align*}\n\\]\nTherefore:\n\\[\n\\begin{align*}\n{k + y - 1 \\choose y} &= (- 1)^y \\frac{(-k)!}{(-k - y)! y!}\\\\\n&= (- 1)^y {-k \\choose y}.\n\\end{align*}\n\\]\nNow, let us begin with the summation involving the Negative Binomial PMF depicted in Equation D.17 from \\(0\\) to \\(\\infty\\):\n\\[\n\\begin{align*}\n\\sum_{y = 0}^{\\infty} P_Y \\left( Y = y \\mid k, \\pi \\right) &= \\sum_{y = 0}^{\\infty} {k + y - 1 \\choose y} \\pi^k (1 - \\pi)^y \\\\\n&= \\sum_{y = 0}^{\\infty} (- 1)^y {-k \\choose y} \\pi^k (1 - \\pi)^y \\\\\n&= \\pi^k \\sum_{y = 0}^{\\infty} (- 1)^y {-k \\choose y} (1 - \\pi)^y \\\\\n&= \\pi^k \\sum_{y = 0}^{\\infty} {-k \\choose y} (-1 + \\pi)^y.\n\\end{align*}\n\\tag{D.18}\\]\nOn the right-hand side of Equation D.18 we will add the following factor:\n\\[\n(1)^{-k - y} = 1.\n\\]\nThus:\n\\[\n\\begin{align*}\n\\sum_{y = 0}^{\\infty} P_Y \\left( Y = y \\mid k, \\pi \\right) &= \\pi^k \\sum_{y = 0}^{\\infty} {-k \\choose y} (1)^{-k - y} (-1 + \\pi)^y.\n\\end{align*}\n\\tag{D.19}\\]\nNow, by using the binomial theorem in Equation D.5, let:\n\\[\n\\begin{gather*}\nm  = -k\\\\\ni = y \\\\\nu = 1 \\\\\nv = -1 + \\pi.\n\\end{gather*}\n\\]\nThe above arrangement yields the following result in Equation D.19:\n\\[\n\\begin{align*}\n\\sum_{y = 0}^{\\infty} P_Y \\left( Y = y \\mid k, \\pi \\right) &=  \\pi^k (1 - 1 + \\pi)^{-k} \\\\\n&= \\pi^k (\\pi) ^{-k} \\\\\n&= \\pi^0 \\\\\n&= 1. \\qquad \\qquad \\qquad \\square\n\\end{align*}\n\\tag{D.20}\\]\n\nIndeed, the Negative Binomial PMF is a proper probability distribution!\n\n\n\nD.3.2 Expected Value\nVia Equation C.3, the expected value or mean of a Negative Binomial-distributed random variable \\(Y\\) can be found as follows:\n\nProof. \\[\n\\begin{align*}\n\\mathbb{E}(Y) &= \\sum_{y = 0}^{\\infty} y P_Y \\left( Y = y \\mid k, \\pi \\right) \\\\\n&= \\sum_{y = 1}^{\\infty} y P_Y \\left( Y = y \\mid k, \\pi \\right) \\\\\n& \\quad \\qquad \\text{for $y = 0$, the addend is equal to zero} \\\\\n&= \\sum_{y = 1}^{\\infty} y \\left[ {k + y - 1 \\choose y} \\pi^k (1 - \\pi)^y \\right] \\\\\n&= \\sum_{y = 1}^{\\infty} y \\left[ \\frac{(k + y - 1)!}{y! (k + y - 1 - y)!} \\pi^k (1 - \\pi)^y \\right] \\\\\n&= \\sum_{y = 1}^{\\infty} y \\left[ \\frac{(k + y - 1)!}{y! (k - 1)!} \\pi^k (1 - \\pi)^y \\right] \\\\\n&= \\sum_{y = 1}^{\\infty} y \\Bigg[ \\frac{(k + y - 1)!}{y (y - 1)! \\underbrace{\\left( \\frac{k!}{k} \\right)}_{(k - 1)!}} \\pi^k (1 - \\pi)^y \\Bigg] \\\\\n&= \\sum_{y = 1}^{\\infty} k \\left[ \\frac{(k + y - 1)!}{k! (y - 1)!} \\pi^k (1 - \\pi)^y \\right] \\\\\n&= k \\sum_{y = 1}^{\\infty} \\left[ {k + y - 1 \\choose y - 1} \\pi^k (1 - \\pi)^y \\right] \\\\\n&= k \\sum_{y = 1}^{\\infty} \\left[ {k + y - 1 \\choose y - 1} \\pi^{k + 1 - 1} (1 - \\pi)^{y + 1 - 1} \\right] \\\\\n& \\quad \\qquad \\text{note $\\pi^k = \\pi^{k + 1 - 1}$ and $(1 - \\pi)^y = (1 - \\pi)^{y + 1 - 1}$} \\\\\n&= \\frac{k (1 - \\pi)}{\\pi} \\sum_{y = 1}^{\\infty} \\left[ {k + y - 1 \\choose y - 1} \\pi^{k + 1} (1 - \\pi)^{y - 1} \\right].\n\\end{align*}\n\\tag{D.21}\\]\nNow, let us make the following variable rearrangement:\n\\[\n\\begin{gather*}\nm = k + 1 \\\\\nz = y - 1 \\\\\nm + z - 1  = k + y - 1.\n\\end{gather*}\n\\]\nGoing back to Equation D.21, and applying our above variable rearrangement within the summation, we have:\n\\[\n\\mathbb{E}(Y) = \\frac{k (1 - \\pi)}{\\pi} \\sum_{z = 0}^{\\infty} \\left[ {m + z - 1 \\choose z} \\pi^{m} (1 - \\pi)^{z} \\right].\n\\tag{D.22}\\]\nNote that, in the summation of Equation D.22, we encounter the PMF of a random variable \\(Z\\) as follows:\n\\[\nZ \\sim \\text{NegBin}(m, \\pi).\n\\]\nSince the summation, where this Negative Binomial PMF of \\(Z\\) is depicted, goes from \\(z = 0\\) to \\(\\infty\\), we can apply our result from Equation D.20:\n\\[\n\\begin{align*}\n\\mathbb{E}(Y) &= \\frac{k (1 - \\pi)}{\\pi} \\underbrace{\\sum_{z = 0}^m \\left[ {m + z - 1 \\choose z} \\pi^{m} (1 - \\pi)^{z} \\right]}_{1} \\\\\n&= \\frac{k (1 - \\pi)}{\\pi}. \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\quad \\square\n\\end{align*}\n\\]\n\n\nD.3.3 Variance\nVia Equation C.5 and the Equation C.3 of a discrete expected value, the variance of a Negative Binomial-distributed random variable \\(Y\\) can be found as follows:\n\nProof. \\[\n\\begin{align*}\n\\text{Var} (Y) &= \\mathbb{E}(Y^2) - \\left[ \\mathbb{E}(Y)\\right]^2 \\\\\n&= \\mathbb{E}(Y^2) - \\left[ \\frac{k (1 - \\pi)}{\\pi} \\right]^2 \\quad \\text{since $\\mathbb{E}(Y) = \\frac{k (1 - \\pi)}{\\pi}$.}\n\\end{align*}\n\\tag{D.23}\\]\nNow, we need to play around with the below expected value expression as follows:\n\\[\n\\begin{align*}\n\\mathbb{E}(Y^2) &= \\mathbb{E} \\left[ Y (Y - 1) \\right] + \\mathbb{E}(Y) \\\\\n&= \\mathbb{E} \\left[ Y (Y - 1) \\right] + \\frac{k (1 - \\pi)}{\\pi}.\n\\end{align*}\n\\tag{D.24}\\]\nTo find \\(\\mathbb{E} \\left[ Y (Y - 1) \\right]\\), we make the following derivation via Equation C.1 when \\(g(Y) = y (y - 1)\\):\n\\[\n\\begin{align*}\n\\mathbb{E} \\left[ Y (Y - 1) \\right] &= \\sum_{y = 0}^{\\infty} y (y - 1) P_Y \\left( Y = y \\mid k, \\pi \\right) \\\\\n&= \\sum_{y = 2}^{\\infty} y (y - 1) P_Y \\left( Y = y \\mid k, \\pi \\right) \\\\\n& \\quad \\qquad \\text{for $y = \\{0, 1\\}$,} \\\\\n& \\quad \\qquad \\text{the addends are equal to zero} \\\\\n&= \\sum_{y = 2}^{\\infty} y (y - 1) \\left[ {k + y - 1 \\choose y} \\pi^k (1 - \\pi)^y \\right] \\\\\n&= \\sum_{y = 2}^{\\infty} y (y - 1) \\left[ \\frac{(k + y - 1)!}{y! (k + y - 1 - y)!} \\pi^k (1 - \\pi)^y \\right] \\\\\n&= \\sum_{y = 2}^{\\infty} y (y - 1) \\left[ \\frac{(k + y - 1)!}{y! (k - 1)!} \\pi^k (1 - \\pi)^y \\right] \\\\\n&= \\sum_{y = 2}^{\\infty} \\frac{y (y - 1)}{y (y - 1)} \\left[ \\frac{(k + y - 1)!}{(y - 2)! (k - 1)!} \\pi^k (1 - \\pi)^y \\right] \\\\\n& \\quad \\qquad \\text{in the denominator, $y! = y (y - 1) (y - 2)!$} \\\\\n&= \\sum_{y = 2}^{\\infty} \\Bigg[ \\frac{(k + y - 1)!}{(y - 2)! \\underbrace{\\frac{(k + 1)!}{k (k + 1)}}_{(k - 1)!}} \\pi^k (1 - \\pi)^y \\Bigg] \\\\\n&= \\sum_{y = 2}^{\\infty} \\left[ k (k + 1) \\frac{(k + y - 1)!}{(k + 1)! (y - 2)!} \\pi^k (1 - \\pi)^y \\right] \\\\\n&= k (k + 1) \\sum_{y = 2}^{\\infty} \\left[ {k + y - 1 \\choose y - 2} \\pi^k (1 - \\pi)^y \\right] \\\\\n&= k (k + 1) \\sum_{y = 2}^{\\infty} \\left[ {k + y - 1 \\choose y - 2} \\pi^{k + 2 - 2} (1 - \\pi)^{y + 2 - 2} \\right] \\\\\n& \\quad \\qquad \\text{note $\\pi^k = \\pi^{k + 2 - 2}$ and} \\\\\n& \\quad \\qquad (1 - \\pi)^y = (1 - \\pi)^{y + 2 - 2} \\\\\n&= \\frac{k (k + 1) ( 1 - \\pi)^2}{\\pi^2} \\times \\\\\n& \\qquad \\sum_{y = 2}^{\\infty} \\left[ {k + y - 1 \\choose y - 2} \\pi^{k + 2} (1 - \\pi)^{y - 2} \\right].\n\\end{align*}\n\\tag{D.25}\\]\nThen, we make the following variable rearrangement:\n\\[\n\\begin{gather*}\nm = k + 2\\\\\nz = y - 2 \\\\\nm + z - 1  = k + y - 1.\n\\end{gather*}\n\\]\nGoing back to Equation D.25, and applying our above variable rearrangement within the summation, we have:\n\\[\n\\begin{align*}\n\\mathbb{E} \\left[ Y (Y - 1) \\right] &= \\frac{k (k + 1) ( 1 - \\pi)^2}{\\pi^2} \\times \\\\\n& \\qquad \\sum_{y = 2}^{\\infty} \\left[ {m + z - 1 \\choose z} \\pi^m (1 - \\pi)^z \\right].\n\\end{align*}\n\\tag{D.26}\\]\nNote that, in the summation of Equation D.26, we encounter the PMF of a random variable \\(Z\\) as follows:\n\\[\nZ \\sim \\text{NegBin}(m, \\pi).\n\\]\nSince the summation, where this Binomial PMF of \\(Z\\) is depicted, goes from \\(z = 0\\) to \\(\\infty\\), we can apply our result from Equation D.20:\n\\[\n\\begin{align*}\n\\mathbb{E} \\left[ Y (Y - 1) \\right] &= \\frac{k (k + 1) ( 1 - \\pi)^2}{\\pi^2} \\times \\\\\n& \\qquad \\underbrace{\\sum_{y = 2}^{\\infty} \\left[ {m + z - 1 \\choose z} \\pi^m (1 - \\pi)^z \\right]}_{1} \\\\\n&= \\frac{k (k + 1) ( 1 - \\pi)^2}{\\pi^2}.\n\\end{align*}\n\\]\nLet us go back to Equation D.24 and plug in the above result:\n\\[\n\\begin{align*}\n\\mathbb{E}(Y^2) &= \\mathbb{E} \\left[ Y (Y - 1) \\right] + \\frac{k ( 1 - \\pi)}{\\pi} \\\\\n&= \\frac{k (k + 1) ( 1 - \\pi)^2}{\\pi^2} + \\frac{k ( 1 - \\pi)}{\\pi}.\n\\end{align*}\n\\]\nFinally, we plug in \\(\\mathbb{E}(Y^2)\\) in Equation D.23:\n\\[\n\\begin{align*}\n\\text{Var} (Y) &= \\mathbb{E}(Y^2) - \\left[ \\frac{k (1 - \\pi)}{\\pi} \\right]^2 \\\\\n&= \\frac{k (k + 1) ( 1 - \\pi)^2}{\\pi^2} + \\frac{k ( 1 - \\pi)}{\\pi} - \\left[ \\frac{k (1 - \\pi)}{\\pi} \\right]^2 \\\\\n&= \\frac{k (1 - \\pi)}{\\pi} \\left[ \\frac{(k + 1) (1 - \\pi)}{\\pi} + 1 - \\frac{k (1 - \\pi)}{\\pi} \\right] \\\\\n&= \\frac{k (1 - \\pi)}{\\pi} \\left[ \\frac{(k + 1) (1 - \\pi) + \\pi - k (1 - \\pi)}{\\pi} \\right] \\\\\n&= \\frac{k (1 - \\pi)}{\\pi} \\left( \\frac{k - k \\pi + 1 - \\pi + \\pi - k + k \\pi}{\\pi} \\right) \\\\\n&= \\frac{k (1 - \\pi)}{\\pi} \\left( \\frac{1}{\\pi} \\right) \\\\\n&= \\frac{k (1 - \\pi)}{\\pi^2}. \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\quad \\square\n\\end{align*}\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#classical-poisson",
    "href": "book/C-distributional-mind-map.html#classical-poisson",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nD.4 Classical Poisson",
    "text": "D.4 Classical Poisson\nSuppose you observe the count of events happening in a fixed interval of time or space Let \\(Y\\) be the number of counts considered of integer type. Then, \\(Y\\) is said to have a classical Poisson distribution with a continuous parameter \\(\\lambda\\):\n\\[\nY \\sim \\text{Pois}(\\lambda).\n\\]\n\nD.4.1 Probability Mass Function\nThe PMF of this count-type \\(Y\\) is the following:\n\\[\nP_Y \\left( Y = y \\mid \\lambda \\right) = \\frac{\\lambda^y \\exp{(-\\lambda)}}{y!} \\quad \\text{for $y \\in \\{ 0, 1, 2, \\dots\\}$,}\n\\tag{D.27}\\]\nwhere \\(\\exp{(\\cdot)}\\) depicts the base \\(e\\) (i.e., Euler’s number, \\(e = 2.71828...\\)) and \\(y!\\) is the factorial\n\\[\ny! = y \\times (y - 1) \\times (y - 2) \\times (y - 3) \\times \\cdots \\times 3 \\times 2 \\times 1.  \n\\]\nwith\n\\[\n0! = 1.\n\\]\nThe continuous parameter \\(\\lambda \\in (0, \\infty)\\) represents the average rate at which these events happen (i.e., events per area unit or events per time unit). Curiously, even though the random variable \\(Y\\) is considered discrete in this case, \\(\\lambda\\) is modelled as continuous!\n\nHow can we verify that Equation D.27 is a proper PMF (i.e., all the standalone probabilities over the support of \\(Y\\) add up to one)?\n\nTo elaborate on this, we need to use some mathematical tools called the Taylor series expansions and a derived result called Maclaurin series expansions.\n\n\nHeads-up on the Taylor and Maclaurin series expansions!\n\n\nIn mathematics, there are helpful tools known as Taylor series expansions, which were officially published by English mathematician Brook Taylor in Methodus Incrementorum Directa & Inversa (Taylor 1715).\n\n\nPortrait of mathematician Brook Taylor (Earlom 1793).\n\nHowever, it is essential to note that Scottish mathematician James Gregory introduced the notion of these series expansions in his work Vera Circuli et Hyperbolae Quadratura (Gregory 1668).\n\n\nPortrait of mathematician James Gregory (Scotland, n.d.).\n\nThese series approximate complex mathematical functions through an infinite sum of polynomial terms. For example, in machine learning, the Taylor series expansions can be utilized in gradient-based optimization methods. Specifically, Newton’s method uses these expansions to find roots of equations that cannot be solved analytically, which is common in maximum likelihood-based parameter estimation for the varied regression models discussed throughout this book. Moreover, we can find these series in different engineering and scientific fields such as physics.\nSuppose we have real function \\(f(u)\\) around a point \\(u = a\\), then the one-dimensional infinite Taylor series expansion is given by the expression\n\\[\n\\begin{align*}\nf(u) &= f(a) + f'(a) (u - a) + \\frac{f''(a)}{2!} (u - a)^2 + \\\\\n& \\qquad \\frac{f^{(3)}(a)}{3!} (u - a)^3 + \\frac{f^{(4)}(a)}{4!} (u - a)^4 + \\\\\n& \\qquad \\frac{f^{(5)}(a)}{5!} (u - a)^5 + \\cdots \\\\\n&= \\sum_{j = 0}^{\\infty} \\frac{f^{(j)}(a)}{j!} (u - a)^j.\n\\end{align*}\n\\tag{D.28}\\]\nA complete mathematical derivation of Equation D.28 can be found in Weisstein (n.d.). Moving along, specifically in the last line of this equation which shows an infinite summation, note the following:\n\n\n\\(f^{(j)}(a)\\) indicates the \\(j\\)th order derivative of \\(f(u)\\) and evaluated at point \\(a\\).\n\n\\(j!\\) implicates the factorial of \\(j\\) such that\n\n\\[\nj! = j \\times (j - 1) \\times (j - 2) \\times (j - 3) \\times \\cdots \\times 3 \\times 2 \\times 1.\n\\]\nwith\n\\[\n0! = 1.\n\\]\nIf we go even further with Equation D.28, we have a specific case when \\(a = 0\\) called the Maclaurin series expansions. This case was introduced by the Scottish mathematician Colin Maclaurin in his work A Treatise of Fluxions (Maclaurin 1742).\n\n\nPortrait of mathematician Colin Maclaurin (Harding 1798).\n\nHence, in a Mclaurin series, Equation D.28 becomes:\n\\[\n\\begin{align*}\nf(u) &= f(0) + f'(0) (u) + \\frac{f''(0)}{2!} u^2 + \\\\\n& \\qquad \\frac{f^{(3)}(0)}{3!} u^3 + \\frac{f^{(4)}(0)}{4!} u^4 + \\\\\n& \\qquad \\frac{f^{(5)}(0)}{5!} u^5 + \\cdots \\\\\n&= \\sum_{j = 0}^{\\infty} \\frac{f^{(j)}(0)}{j!} u^j.\n\\end{align*}\n\\tag{D.29}\\]\nDifferent statistical proofs make use of Taylor series expansions as well as the Mclaurin series, and the Poisson distribution is not an exception at all!\n\n\nThe above Mclaurin series in Equation D.29 will help us to show that our Poisson PMF in Equation D.27 actually adds up to one all over the support of the random variable:\n\nProof. \\[\n\\begin{align*}\n\\sum_{y = 0}^{\\infty} P_Y \\left( Y = y \\mid \\lambda \\right) &= \\sum_{y = 0}^{\\infty} \\frac{\\lambda^y \\exp{(-\\lambda)}}{y!} \\\\\n&= \\exp{(-\\lambda)} \\sum_{y = 0}^{\\infty} \\frac{\\lambda^y}{y!} \\\\\n& \\quad \\qquad \\text{factoring out $\\exp{(-\\lambda)}$,} \\\\\n& \\quad \\qquad \\text{since it does not depend on $y$.}\n\\end{align*}\n\\tag{D.30}\\]\nNow, we will focus on the above summation\n\\[\n\\sum_{y = 0}^{\\infty} \\frac{\\lambda^y}{y!}\n\\] and use the Mclaurin series from Equation D.29 by letting\n\\[\nf(u) = \\exp(u).\n\\tag{D.31}\\]\nWe know that all derivatives of the above function are equal\n\\[\nf'(u) = f''(u) = f^{(3)}(u) = f^{(4)}(u) = f^{(5)}(u) = \\cdots = \\exp{(u)},\n\\] which allows us to conclude that the \\(j\\)th derivative is\n\\[\nf^{(j)}(u) = \\exp(u).\n\\]\nThis \\(j\\)th derivative evaluated at \\(u = 0\\) becomes\n\\[\nf^{(j)}(0) = \\exp(0) = 1.\n\\]\nTherefore, the Mclaurin series for Equation D.31 is the following:\n\\[\n\\begin{align*}\nf(u) &= \\exp(u) \\\\\n&= \\sum_{j = 0}^{\\infty} \\frac{\\exp(0)}{j!} u^j \\\\\n&= \\sum_{j = 0}^{\\infty} \\frac{u^j }{j!}.\n\\end{align*}\n\\tag{D.32}\\]\nThat said, using Equation D.32, let:\n\\[\n\\begin{gather*}\n\\lambda = u \\\\\ny = j.\n\\end{gather*}\n\\]\nThus, we have the following:\n\\[\n\\sum_{y = 0}^{\\infty} \\frac{\\lambda^y}{y!} = \\exp{(\\lambda)}.\n\\]\nFinally, going back to Equation D.30:\n\\[\n\\begin{align*}\n\\sum_{y = 0}^{\\infty} P_Y \\left( Y = y \\mid \\lambda \\right) &= \\exp{(-\\lambda)} \\overbrace{\\sum_{y = 0}^{\\infty} \\frac{\\lambda^y}{y!}}^{\\exp{(\\lambda)}} \\\\\n&= \\exp{(-\\lambda)} \\times \\exp{(\\lambda)} \\\\\n&= \\exp{(-\\lambda + \\lambda)} \\\\\n&= \\exp{(0)} \\\\\n&= 1. \\qquad \\qquad \\qquad \\qquad \\square\n\\end{align*}\n\\tag{D.33}\\]\n\nIndeed, the Poisson PMF is a proper probability distribution!\n\n\n\nD.4.2 Expected Value\nVia Equation C.3, the expected value or mean of a Poisson-distributed random variable \\(Y\\) can be found as follows:\n\nProof. \\[\n\\begin{align*}\n\\mathbb{E}(Y) &= \\sum_{y = 0}^{\\infty} y P_Y \\left( Y = y \\mid \\lambda \\right) \\\\\n&= \\sum_{y = 1}^{\\infty} y P_Y \\left( Y = y \\mid \\lambda \\right) \\\\\n& \\quad \\qquad \\text{for $y = 0$, the addend is equal to zero} \\\\\n&= \\sum_{y = 1}^{\\infty} y \\left[ \\frac{\\lambda^y \\exp{(-\\lambda)}}{y!} \\right] \\\\\n&= \\exp{(-\\lambda)} \\sum_{y = 1}^{\\infty} \\frac{y \\lambda^y}{y!} \\\\\n& \\quad \\qquad \\text{factoring out $\\exp{(-\\lambda)}$,} \\\\\n& \\quad \\qquad \\text{since it does not depend on $y$} \\\\\n&= \\exp{(-\\lambda)} \\sum_{y = 1}^{\\infty} \\frac{y \\lambda^y}{y (y - 1)!} \\\\\n& \\quad \\qquad \\text{in the denominator, $y! = y (y - 1)!$}\\\\\n&= \\exp{(-\\lambda)} \\sum_{y = 1}^{\\infty} \\frac{\\lambda^y}{(y - 1)!} \\\\\n&= \\exp{(-\\lambda)} \\sum_{y = 1}^{\\infty} \\frac{\\lambda^{y + 1 - 1}}{(y - 1)!} \\\\\n& \\quad \\qquad \\text{note $\\lambda^y = \\lambda^{y + 1 - 1}$} \\\\\n&= \\exp{(-\\lambda)} \\sum_{y = 1}^{\\infty} \\frac{\\lambda \\lambda^{y - 1}}{(y - 1)!} \\\\\n& \\quad \\qquad \\text{rearranging terms} \\\\\n&= \\lambda \\exp{(-\\lambda)} \\sum_{y = 1}^{\\infty} \\frac{\\lambda^{y - 1}}{(y - 1)!} \\\\\n& \\quad \\qquad \\text{factoring out $\\lambda$,} \\\\\n& \\quad \\qquad \\text{since it does not depend on $y$.} \\\\\n\\end{align*}\n\\tag{D.34}\\]\nThen, let us make the following variable rearrangement:\n\\[\nz = y - 1.\n\\]\nGoing back to Equation D.34, and applying our above variable rearrangement within the summation, we have:\n\\[\n\\mathbb{E}(Y) = \\lambda \\exp{(-\\lambda)} \\sum_{z = 0}^{\\infty} \\frac{\\lambda^z}{z!}\n\\tag{D.35}\\]\nUsing Equation D.32, let:\n\\[\n\\begin{gather*}\n\\lambda = u \\\\\nz = j.\n\\end{gather*}\n\\]\nHence, we have the following:\n\\[\n\\sum_{z = 0}^{\\infty} \\frac{\\lambda^z}{z!} = \\exp{(\\lambda)}.\n\\]\nFinally, going back to Equation D.35:\n\\[\n\\begin{align*}\n\\mathbb{E}(Y) &= \\lambda \\exp{(-\\lambda)} \\overbrace{\\sum_{z = 0}^{\\infty} \\frac{\\lambda^z}{z!}}^{\\exp{(\\lambda)}} \\\\\n&= \\lambda \\exp{(-\\lambda)} \\times \\exp{(\\lambda)} \\\\\n&= \\lambda \\exp{(-\\lambda + \\lambda)} \\\\\n&= \\lambda \\exp{(0)} \\\\\n&= \\lambda. \\qquad \\qquad \\qquad \\qquad \\square\n\\end{align*}\n\\]\n\n\nD.4.3 Variance\nVia Equation C.5 and the Equation C.3 of a discrete expected value, the variance of a Poisson-distributed random variable \\(Y\\) can be found as follows:\n\nProof. \\[\n\\begin{align*}\n\\text{Var} (Y) &= \\mathbb{E}(Y^2) - \\left[ \\mathbb{E}(Y)\\right]^2 \\\\\n&= \\mathbb{E}(Y^2) - \\lambda^2 \\qquad \\text{since $\\mathbb{E}(Y) = \\lambda$.}\n\\end{align*}\n\\tag{D.36}\\]\nNow, we need to play around with the below expected value expression as follows:\n\\[\n\\begin{align*}\n\\mathbb{E}(Y^2) &= \\mathbb{E} \\left[ Y (Y - 1) \\right] + \\mathbb{E}(Y) \\\\\n&= \\mathbb{E} \\left[ Y (Y - 1) \\right] + \\lambda \\qquad \\text{since $\\mathbb{E}(Y) = \\lambda$.}\n\\end{align*}\n\\tag{D.37}\\]\nNow, to find \\(\\mathbb{E} \\left[ Y (Y - 1) \\right]\\), we make the following derivation via Equation C.1 when \\(g(Y) = y (y - 1)\\):\n\\[\n\\begin{align*}\n\\mathbb{E} \\left[ Y (Y - 1) \\right] &= \\sum_{y = 0}^{\\infty} y (y - 1) P_Y \\left( Y = y \\mid \\lambda \\right) \\\\\n&= \\sum_{y = 2}^{\\infty} y (y - 1) P_Y \\left( Y = y \\mid \\lambda \\right) \\\\\n& \\quad \\qquad \\text{for $y = \\{0, 1\\}$,} \\\\\n& \\quad \\qquad \\text{the addends are equal to zero} \\\\\n&= \\sum_{y = 2}^{\\infty} y (y - 1) \\left[ \\frac{\\lambda^y \\exp{(-\\lambda)}}{y!} \\right] \\\\\n&= \\exp{(-\\lambda)} \\sum_{y = 2}^{\\infty} \\left[ \\frac{y (y - 1) \\lambda^y}{y!} \\right] \\\\\n& \\quad \\qquad \\text{factoring out $\\exp{(-\\lambda)}$,} \\\\\n& \\quad \\qquad \\text{since it does not depend on $y$} \\\\\n&= \\exp{(-\\lambda)} \\sum_{y = 2}^{\\infty} \\left[ \\frac{y (y - 1) \\lambda^y}{y (y - 1) (y - 2)!} \\right] \\\\\n& \\quad \\qquad \\text{in the denominator, $y! = y (y - 1) (y - 2)!$} \\\\\n&= \\exp{(-\\lambda)} \\sum_{y = 2}^{\\infty} \\frac{\\lambda^y}{(y - 2)!} \\\\\n&= \\exp{(-\\lambda)} \\sum_{y = 2}^{\\infty} \\frac{\\lambda^{y + 2 - 2}}{(y - 2)!} \\\\\n& \\quad \\qquad \\text{note $\\lambda^y = \\lambda^{y + 2 - 2} $} \\\\\n&= \\lambda^2 \\exp{(-\\lambda)} \\sum_{y = 2}^{\\infty} \\frac{\\lambda^{y - 2}}{(y - 2)!} \\\\\n& \\quad \\qquad \\text{factoring out $\\lambda^2$,} \\\\\n& \\quad \\qquad \\text{since it does not depend on $y$.} \\\\\n\\end{align*}\n\\tag{D.38}\\]\nThen, we make the following variable rearrangement:\n\\[\nz = y - 2.\n\\]\nGoing back to Equation D.38, and applying our above variable rearrangement within the summation, we have:\n\\[\n\\mathbb{E} \\left[ Y (Y - 1) \\right] = \\lambda^2 \\exp{(-\\lambda)} \\sum_{z = 0}^{\\infty} \\frac{\\lambda^z}{z!}.\n\\tag{D.39}\\]\nUsing Equation D.32, let:\n\\[\n\\begin{gather*}\n\\lambda = u \\\\\nz = j.\n\\end{gather*}\n\\]\nThus, we have the following:\n\\[\n\\sum_{z = 0}^{\\infty} \\frac{\\lambda^z}{z!} = \\exp{(\\lambda)}.\n\\]\nGoing back to Equation D.39:\n\\[\n\\begin{align*}\n\\mathbb{E} \\left[ Y (Y - 1) \\right] &= \\lambda^2 \\exp{(-\\lambda)} \\overbrace{\\sum_{z = 0}^{\\infty} \\frac{\\lambda^z}{z!}}^{\\exp{(\\lambda)}} \\\\\n&= \\lambda^2 \\exp{(-\\lambda)} \\times \\exp{\\lambda} \\\\\n&= \\lambda^2 \\exp{(-\\lambda + \\lambda)} \\\\\n&= \\lambda^2 \\exp{(0)} \\\\\n&= \\lambda^2.\n\\end{align*}\n\\tag{D.40}\\]\nLet us retake Equation D.37 and plug in the above result:\n\\[\n\\begin{align*}\n\\mathbb{E}(Y^2) &= \\mathbb{E} \\left[ Y (Y - 1) \\right] + \\lambda \\\\\n&= \\lambda^2 + \\lambda. \\\\\n\\end{align*}\n\\]\nFinally, we plug in \\(\\mathbb{E}(Y^2)\\) in Equation D.36:\n\\[\n\\begin{align*}\n\\text{Var} (Y) &= \\mathbb{E}(Y^2) - \\lambda^2 \\\\\n&= \\lambda^2 + \\lambda - \\lambda^2 \\\\\n&= \\lambda. \\qquad \\qquad \\square\n\\end{align*}\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#generalized-poisson",
    "href": "book/C-distributional-mind-map.html#generalized-poisson",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nD.5 Generalized Poisson",
    "text": "D.5 Generalized Poisson\nThe generalized Poisson (GP) distribution is viewed as the general Poisson case. It was introduced by Consul and Jain (1973). Suppose you observe the count of events happening in a fixed interval of time or space. Let \\(Y\\) be the number of counts considered of integer type. Then, \\(Y\\) is said to have a GP distribution with continuous parameters \\(\\lambda\\) and \\(\\theta\\):\n\\[\nY \\sim \\text{GP}(\\lambda, \\theta).\n\\]\n\nD.5.1 Probability Mass Function\nThe PMF of this count-type \\(Y\\) is the following:\n\\[\n\\begin{align*}\nP_Y \\left( Y = y \\mid \\lambda, \\theta \\right) &= \\frac{\\lambda (\\lambda + y \\theta)^{y - 1} \\exp{\\left[ -(\\lambda + y \\theta) \\right]}}{y!} \\\\\n& \\qquad \\qquad \\qquad \\text{for $y \\in \\{ 0, 1, 2, \\dots\\}$,}\n\\end{align*}\n\\tag{D.41}\\]\nwhere \\(\\exp{(\\cdot)}\\) depicts the base \\(e\\) (i.e., Euler’s number, \\(e = 2.71828...\\)) and \\(y!\\) is the factorial\n\\[\ny! = y \\times (y - 1) \\times (y - 2) \\times (y - 3) \\times \\cdots \\times 3 \\times 2 \\times 1.  \n\\]\nwith\n\\[\n0! = 1.\n\\]\nThe continuous parameter \\(\\lambda \\in (0, \\infty)\\) represents the average rate at which these events happen (i.e., events per area unit or events per time unit). As in the case of the classical Poisson case, even though the GP random variable \\(Y\\) is considered discrete, \\(\\lambda\\) is modelled as continuous!\nOn the other hand, the continuous and bounded parameter \\(\\theta \\in (-1, 1)\\) controls for dispersion present in the GP random variable Y as follows:\n\nWhen \\(0 &lt; \\theta &lt; 1\\), the GP \\(Y\\) shows overdispersion which implies that \\[\\text{Var}(Y) &gt; \\mathbb{E}(Y).\\]\nWhen \\(-1 &lt; \\theta &lt; 0\\), the GP \\(Y\\) shows underdispersion which implies that \\[\\text{Var}(Y) &lt; \\mathbb{E}(Y).\\]\nWhen \\(\\theta = 0\\), the PMF of the GP \\(Y\\) in Equation D.41 becomes the classical Poisson PMF from Equation D.27: \\[\n\\begin{align*}\nP_Y \\left( Y = y \\mid \\lambda, \\theta = 0 \\right) &= \\frac{\\lambda (\\lambda + y \\theta)^{y - 1} \\exp{\\left[ -(\\lambda + y \\theta) \\right]}}{y!} \\\\\n&= \\frac{\\lambda (\\lambda)^{y - 1} \\exp{\\left( -\\lambda \\right)}}{y!} \\qquad \\text{setting $\\theta = 0$} \\\\\n&= \\frac{\\lambda^y \\exp{\\left( -\\lambda \\right)}}{y!} \\\\\n& \\qquad \\qquad \\qquad \\text{for $y \\in \\{ 0, 1, 2, \\dots\\}$.}\n\\end{align*}\n\\]\n\n\n\nHeads-up on equidispersion in a generalized Poisson random variable!\n\n\nIn a GP-distributed \\(Y\\), when \\(\\theta = 0\\) in its corresponding PMF, we have equidispersion which implies \\[\n\\mathbb{E}(Y \\mid \\theta = 0) = \\frac{\\lambda}{1 - \\theta} = \\lambda\n\\] \\[\n\\text{Var}(Y \\mid \\theta = 0) = \\frac{\\lambda}{(1 - \\theta)^2} = \\lambda\n\\] \\[\n\\mathbb{E}(Y \\mid \\theta = 0) = \\text{Var}(Y).\n\\]\n\n\n\nHow can we verify that Equation D.41 is a proper PMF (i.e., all the standalone probabilities over the support of \\(Y\\) add up to one)?\n\n\nD.5.2 Expected Value\n\nD.5.3 Variance",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#zero-inflated-poisson",
    "href": "book/C-distributional-mind-map.html#zero-inflated-poisson",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nD.6 Zero-inflated Poisson",
    "text": "D.6 Zero-inflated Poisson",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#multinomial",
    "href": "book/C-distributional-mind-map.html#multinomial",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nD.7 Multinomial",
    "text": "D.7 Multinomial",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#exponential",
    "href": "book/C-distributional-mind-map.html#exponential",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nE.3 Exponential",
    "text": "E.3 Exponential",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/D-regression-mind-map.html",
    "href": "book/D-regression-mind-map.html",
    "title": "Appendix D — The Sugartastic Regression Mind Map",
    "section": "",
    "text": "Fun fact!\n\n\nSugartastic! So sweet, it could power a carnival’s worth of cotton candy machines.\n\n\nThe regression mind map is a key component of the philosophy behind this book, besides the data science workflow from Section 1.2 and the ML-Stats dictionary found in Appendix A. Figure D.1 shows this regression mind map split in two zones by colour: discrete and continuous. This regression mind map is handy when executing the data modelling stage from the data science workflow, as explained in Section 1.2.4. Recall the first step in this stage is to choose a suitable regression model, and we made this decision in the function of the type of outcome \\(Y\\) we are dealing with. That said, the distributional mind map from Figure C.1 complements the regression mind map when identifying the correct type of outcome \\(Y\\).\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}\n        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(\n          (Exponential &lt;br/&gt;Outcome Y)\n          (Weibull &lt;br/&gt;Outcome Y)\n          (Lognormal &lt;br/&gt;Outcome Y)\n        )Chapter 7: &lt;br/&gt;Semiparametric &lt;br/&gt;Survival &lt;br/&gt;Regression(\n          (Cox Proportional &lt;br/&gt;Hazards Model)\n            (Hazard Function &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n      {{Binary &lt;br/&gt;Outcome Y}}\n        {{Ungrouped &lt;br/&gt;Data}}\n          )Chapter 8: &lt;br/&gt;Binary Logistic &lt;br/&gt;Regression(\n            (Bernoulli &lt;br/&gt;Outcome Y)\n        {{Grouped &lt;br/&gt;Data}}\n          )Chapter 9: &lt;br/&gt;Binomial Logistic &lt;br/&gt;Regression(\n            (Binomial &lt;br/&gt;Outcome Y)\n      {{Count &lt;br/&gt;Outcome Y}}\n        {{Equidispersed &lt;br/&gt;Data}}\n          )Chapter 10: &lt;br/&gt;Classical Poisson &lt;br/&gt;Regression(\n            (Poisson &lt;br/&gt;Outcome Y)\n        {{Overdispersed &lt;br/&gt;Data}}\n          )Chapter 11: &lt;br/&gt;Negative Binomial &lt;br/&gt;Regression(\n            (Negative Binomial &lt;br/&gt;Outcome Y)\n        {{Overdispersed or &lt;br/&gt;Underdispersed &lt;br/&gt;Data}}\n          )Chapter 13: &lt;br/&gt;Generalized &lt;br/&gt;Poisson &lt;br/&gt;Regression(\n            (Generalized &lt;br/&gt;Poisson &lt;br/&gt;Outcome Y)\n        {{Zero Inflated &lt;br/&gt;Data}}\n          )Chapter 12: &lt;br/&gt;Zero Inflated &lt;br/&gt;Poisson &lt;br/&gt;Regression(\n            (Zero Inflated &lt;br/&gt;Poisson &lt;br/&gt;Outcome Y)\n      {{Categorical &lt;br/&gt;Outcome Y}}\n        {{Nominal &lt;br/&gt;Outcome Y}}\n          )Chapter 14: &lt;br/&gt;Multinomial &lt;br/&gt;Logistic &lt;br/&gt;Regression(\n            (Multinomial &lt;br/&gt;Outcome Y)\n        {{Ordinal &lt;br/&gt;Outcome Y}}\n          )Chapter 15: &lt;br/&gt;Ordinal &lt;br/&gt;Logistic &lt;br/&gt;Regression(\n            (Logistic &lt;br/&gt;Distributed &lt;br/&gt;Cumulative Outcome &lt;br/&gt;Probability)\n\n\n\n\n\n\n\n\nFigure D.1: Regression analysis mind map depicting all modelling techniques to be explored in this book. Depending on the type of outcome \\(Y\\), these techniques are split into two large zones: discrete and continuous.\n\n\nSuppose we start reading this regression map clockwise in the continuous zone. In that case, note this zone starts the cloud corresponding to Chapter 3 on the classical regression model called Ordinary Least-squares (OLS). Moreover, we can see that OLS is meant for an unbounded outcome \\(Y \\in (-\\infty, \\infty)\\). Then, we can proceed to the distributional assumption on \\(Y\\) in OLS, which would be Normal. Following up with the cloud corresponding to Chapter 4 on Gamma regression, we can see this model is meant for a nonnegative outcome \\(Y \\in [0, \\infty)\\) where we assume a Gamma distribution for \\(Y\\). This way of reading the continuous zone in the mind map will persist until the survival analysis models: Chapter 6 and Chapter 7.\nThen, we can proceed to the discrete zone with the cloud corresponding to Chapter 8 on the generalized linear model (GLM) called Binary Logistic regression which aims to model a binary outcome \\(Y \\in \\{0, 1 \\}\\). Note that the Binary Logistic regression model is meant for ungrouped data where each row in the training dataset contains unique feature values. Hence, in this modelling case, we assume the outcome \\(Y\\) as a Bernoulli trial where \\(1\\) indicates a success and \\(0\\) indicates a failure. Then, suppose we take another clockwise case such as Chapter 10 on the GLM Classical Poisson regression, this model is suitable for count-type outcomes where equidispersion is present (i.e., the mean of the counts is equal to its corresponding variance). Finally, this model assumes that the outcome is Poisson-distributed. This way of reading the discrete zone in the mind map will persist until Chapter 15 on Ordinal Logistic Regression.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>The Sugartastic Regression Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#weibull",
    "href": "book/C-distributional-mind-map.html#weibull",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nE.1 Weibull",
    "text": "E.1 Weibull",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#lognormal",
    "href": "book/C-distributional-mind-map.html#lognormal",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nE.2 Lognormal",
    "text": "E.2 Lognormal",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#gamma",
    "href": "book/C-distributional-mind-map.html#gamma",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nE.4 Gamma",
    "text": "E.4 Gamma",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#logistic",
    "href": "book/C-distributional-mind-map.html#logistic",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nE.5 Logistic",
    "text": "E.5 Logistic",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#normal",
    "href": "book/C-distributional-mind-map.html#normal",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nE.6 Normal",
    "text": "E.6 Normal",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#beta",
    "href": "book/C-distributional-mind-map.html#beta",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nE.7 Beta",
    "text": "E.7 Beta\n\n\n\n\nConsul, P. C., and G. C. Jain. 1973. “A Generalization of the Poisson Distribution.” Technometrics 15 (4): 791–99. http://www.jstor.org/stable/1267389.\n\n\nEarlom, Richard. 1793. “Brook Taylor - National Portrait Gallery.” NPG D6930; Brook Taylor - Portrait - National Portrait Gallery. National Portrait Gallery. https://www.npg.org.uk/collections/search/portrait/mw40921/Brook-Taylor.\n\n\nGregory, James. 1668. Vera circuli et hyperbolae quadratura cui accedit geometria pars vniuersalis inseruiens quantitatum curuarum transmutationi & mensurae. Authore Iacobo Gregorio Abredonensi. Padua, Italy: Patavii: typis heredum Pauli Frambotti bibliop. https://archive.org/details/ita-bnc-mag-00001357-001/page/n10/mode/2up.\n\n\nHarding, Edward. 1798. Portrait of Colin MacLaurin. Courtesy of the Smithsonian Libraries and Archives. https://library.si.edu/image-gallery/72863.\n\n\nMaclaurin, Colin. 1742. A Treatise of Fluxions. Edinburgh, Scotland: Printed for the Author by T.W.; T. Ruddimans. https://archive.org/details/treatiseonfluxio02macl/page/n5/mode/2up.\n\n\nScotland, National Galleries of. n.d. Professor James Gregory, 1638 - 1675 (1). Mathematician. Professor James Gregory, 1638 - 1675 (1). Mathematician | National Galleries. https://www.nationalgalleries.org/art-and-artists/31132/professor-james-gregory-1638-1675-mathematician.\n\n\nTaylor, Brook. 1715. Methodus incrementorum directa & inversa. Auctore Brook Taylor, LL. D. & Regiae Societatis Secretario. London, England: Typis Pearsonianis Prostant apud Gul. Innys ad Insignia Principis in Coemeterio Paulino MDCCXV. https://archive.org/details/bim_eighteenth-century_methodus-incrementorum-d_taylor-brook_1717.\n\n\nWeisstein, Eric W. n.d. “Taylor Series.” From MathWorld–A Wolfram Web Resource. https://mathworld.wolfram.com/TaylorSeries.html.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  }
]