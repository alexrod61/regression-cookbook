[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Regression Cookbook (in development)",
    "section": "",
    "text": "Preface\nData science is a field in which we become aware of the fascinating overlap between machine learning and statistics. Many data science students usually come across everyday machine learning and statistics concepts or ideas that might only differ in names. For instance, simple terms such as weights in supervised learning (and their statistical counterpart as regression coefficients) might be misleading for students starting their data science formation. On the other hand, from an instructor’s perspective in a data science program that subsets its courses in machine learning in Python and statistics in R, regression courses in R also demand the inclusion of Python-related packages as alternative tools. Furthermore, in a graduate program such as the Master of Data Science (MDS) at the University of British Columbia, this is especially critical for students whose career plan leans towards the industry job market where Python is more heavily used.\nThat said, we can state that data science is a substantial synergy between machine learning and statistics. Nevertheless, many gaps between both disciplines still need to be addressed. Thus, closing these critical gaps is imperative in a domain with accelerated growth, such as data science. In this regard, the MDS Stat-ML dictionary has inspired us to write this textbook. It basically consists of common ground between foundational supervised learning models from machine learning and regression models commonly used in statistics. We strive to explore linear modelling approaches as a primary step while highlighting different terminology found in both fields. Furthermore, this discussion is more comprehensive than a simple conceptual exploration. Hence, the second step is hands-on practice via the corresponding Python packages for machine learning and R for statistics.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#g.-alexi-rodríguez-arelis",
    "href": "index.html#g.-alexi-rodríguez-arelis",
    "title": "The Regression Cookbook (in development)",
    "section": "G. Alexi Rodríguez-Arelis",
    "text": "G. Alexi Rodríguez-Arelis\n\n\n\n\n\n\n\n\n\n\n\nI'm an Assistant Professor of Teaching in the Department of Statistics and Master of Data Science at the University of British Columbia. Throughout my academic and professional journey, I've been involved in diverse fields, such as credit risk management, statistical consulting, and data science teaching. My doctoral research in statistics is primarily focused on computer experiments that emulate scientific and engineering systems via Gaussian stochastic processes (i.e., kriging regression). I'm incredibly passionate about teaching regression topics while combining statistical and machine learning contexts.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#andy-tai",
    "href": "index.html#andy-tai",
    "title": "The Regression Cookbook (in development)",
    "section": "Andy Tai",
    "text": "Andy Tai\n\n\n\n\n\n\n\n\n\n\n\nI'm a Postdoctoral Teaching and Learning Fellow in the Department of Statistics and Master of Data Science at the University of British Columbia. Throughout my academic and professional journey, I've been involved in diverse fields, such as addiction psychiatry, machine learning, and data science teaching. My doctoral research in neuroscience primarily focused on using machine learning to predict the risk of fatal overdose. I am interested in leveraging data science and machine learning to solve complex problems, and I strive to inspire others to explore the vast potential of these fields.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#ben-chen",
    "href": "index.html#ben-chen",
    "title": "The Regression Cookbook (in development)",
    "section": "Ben Chen",
    "text": "Ben Chen\n\n\n\n\n\n\n\n\n\n\n\nI hold a Master's degree in Data Science from the University of British Columbia, and I am passionate about educating others in the fields of statistics and data science. With experience teaching students how to use statistical methods and data science tools, I also enjoy sharing my knowledge through writing. My blog focuses on making complex statistical concepts accessible to everyone. Additionally, I've worked on a variety of data science projects, ranging from developing recommendation systems to building Generative Adversarial Network (GAN) models.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "The Regression Cookbook (in development)",
    "section": "",
    "text": "Special thanks to Jonathan Graves, who mentioned the cookbook term when this textbook was conceptualized during very early stages.↩︎",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "book/privacy-policy.html",
    "href": "book/privacy-policy.html",
    "title": "Website Privacy Policy",
    "section": "",
    "text": "Information Collection and Use\nWe use Google Analytics, a web analytics service provided by Google, LLC. (“Google”). Google Analytics uses cookies to help analyze how students interact with the textbook, including tracking which sections are accessed most frequently. Information generated by cookies about your use of our website (including IP address) will be transmitted to and stored by Google on servers in the United States.\nGoogle will use this information solely for evaluating textbook usage, compiling usage reports to enhance the educational effectiveness of the textbook, and providing related services.\nYou may refuse the use of cookies by selecting the appropriate settings in your browser; however, please note this may affect your textbook browsing experience.",
    "crumbs": [
      "Website Privacy Policy"
    ]
  },
  {
    "objectID": "book/privacy-policy.html#personal-information",
    "href": "book/privacy-policy.html#personal-information",
    "title": "Website Privacy Policy",
    "section": "Personal Information",
    "text": "Personal Information\nWe do not collect personally identifiable information through Google Analytics. Any personally identifiable information, such as your name and email address, would only be collected if voluntarily submitted for specific educational purposes (e.g., feedback or course-related inquiries). We will never sell or distribute your personal information to third parties.\nFor any questions or concerns, please contact us at alexrod@stat.ubc.ca.",
    "crumbs": [
      "Website Privacy Policy"
    ]
  },
  {
    "objectID": "book/audience-scope.html",
    "href": "book/audience-scope.html",
    "title": "Audience and Scope",
    "section": "",
    "text": "This book mainly focuses on regression analysis and its supervised learning counterpart. Thus, it is not introductory statistics and machine learning material. Also, some coding background on R (R Core Team 2024) and/or Python (Van Rossum and Drake 2009) is recommended. That said, the following topics are suggested as fundamental reviews:\n\nMutivariable differential calculus and linear algebra. Certain sections of each chapter pertain to modelling estimation. Therefore, topics such as partial derivatives and matrix algebra are a great asset. You can find helpful learning resources on the MDS webpage.\nBasic Python programming. When necessary, Python {pandas} (The Pandas Development Team 2024) library will be used to perform data wrangling. The MDS course DSCI 511 (Programming for Data Science) is an ideal example of a quick review.\n\n\n\n\nImage by Lubos Houska via Pixabay.\n\n\n\nBasic R programming. Knowledge of data wrangling and plotting through R {tidyverse} (Wickham et al. 2019) is recommended for hands-on practice via the cases provided in each one of the chapters of this book. The MDS courses DSCI 523 (Programming for Data Manipulation) and DSCI 531 (Data Visualization I) are ideal examples of a quick review.\nFoundations of probability and basic distributional knowledge. The reader should be familiar with elemental discrete and continuous distributions since they are a vital component of any given regression or supervised learning model. The MDS course DSCI 551 (Descriptive Statistics and Probability for Data Science) is an ideal example of a quick review.\nFoundations of frequentist statistical inference. One of the data science paradigms to be covered in this book is statistical inference, i.e., identifying relationships between different variables in a given population or system of interest via a sampled dataset. I only aim to cover a frequentist approach using inferential tools such as parameter estimation, hypothesis testing, and confidence intervals. The MDS course DSCI 552 (Statistical Inference and Computation I) is an ideal example of a quick review.\nFoundations of supervised learning. The second data science paradigm to be covered pertains to prediction, which is core in machine learning. The reader should be familiar with basic terminology, such as training and testing data, overfitting, underfitting, cross-validation, etc. The MDS course DSCI 571 (Machine Learning I) provides these foundations.\nFoundations of feature and model selection. This prerequisite also relates to machine learning and its corresponding prediction paradigm. Basic knowledge of prediction accuracy and variable selection tools is recommended. The MDS course DSCI 573 (Feature and Model Selection) is an ideal example of a quick review.\n\n\n\nA further remark on probability and statistical inference\n\n\nIn case the reader is not 100% familiar with probabilistic and inferential topics, as discussed above, we will provide a fundamental refresher in 2  Basic Cuisine: A Review on Probability and Frequentist Statistical Inference with crucial points that are needed to follow along the statistical way each one of the chapters is delivered (more specifically for modelling estimation/training matters!).\n\nFurthermore, this refresher will be integrated into the three big pillars that will be fully expanded in this book, more concretely in 1  Getting Ready for Regression Cooking!: a data science workflow, the right workflow flavour (inferential or predictive), and a regression toolbox.\n\n\n\n\n\n\nR Core Team. 2024. “R: A Language and Environment for Statistical Computing.” Vienna, Austria: R Foundation for Statistical Computing. https://www.R-project.org/.\n\n\nThe Pandas Development Team. 2024. “Pandas-Dev/Pandas: Pandas.” Zenodo. https://doi.org/10.5281/zenodo.3509134.\n\n\nVan Rossum, Guido, and Fred L. Drake. 2009. Python 3 Reference Manual. Scotts Valley, CA: CreateSpace.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy D’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019. “Welcome to the tidyverse.” Journal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.",
    "crumbs": [
      "Audience and Scope"
    ]
  },
  {
    "objectID": "book/01-intro.html",
    "href": "book/01-intro.html",
    "title": "1  Getting Ready for Regression Cooking!",
    "section": "",
    "text": "1.1 The ML-Stats Dictionary\nMachine learning and statistics often overlap, especially in regression modelling. Topics covered in a regression-focused course, under a purely statistical framework, can also appear in machine learning-based courses on supervised learning, but the terminology can differ. Recognizing this overlap, the Master of Data Science (MDS) program at the University of British Columbia (UBC) provides the MDS Stat-ML dictionary (Gelbart 2017) under the following premises:\nBoth disciplines have a tremendous amount of jargon and terminology. As mentioned in the Preface, machine learning and statistics construct a substantial synergy reflected in data science. Despite this overlap, misunderstandings can still happen due to differences in terminology. To prevent this, we need clear bridges between these disciplines. Therefore, the above definition callout box will pave the way to a complimentary resource called the ML-Stats dictionary (ML stands for Machine Learning). This ML-Stats dictionary clarifies terminology that differs between statistics and machine learning, specifically in the context of supervised learning and regression analysis.\nNote that Appendix A will be the section in this book where the reader can find all those statistical and machine learning-related terms in alphabetical order. Notable terms (either statistical or machine learning-related) will include an admonition identifying which terms (again, either statistical or machine learning-related) are equivalent or somewhat equivalent (or even NOT equivalent if that is the case!).\nHence, in Appendix A, readers will find all those statistical and machine learning-related terms in alphabetical order as in a regular dictionary. Notable terms will include clear notes on their equivalence or non-equivalence. For instance, consider the statistical term dependent variable:\nThen, the above definition will be followed by this admonition:\nAbove, we have identified four equivalent terms for the term dependent variable. Furthermore, these terms can be statistical or machine learning-related. Finally, it is important to highlight we will start using this colour scheme in Chapter 2.\nNext, we will introduce the three main foundations of this textbook: a data science workflow, choosing the correct workflow flavour (inferential or predictive), and building your regression toolbox.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting Ready for Regression Cooking!</span>"
    ]
  },
  {
    "objectID": "book/01-intro.html#sec-ml-stats-dictionary",
    "href": "book/01-intro.html#sec-ml-stats-dictionary",
    "title": "1  Getting Ready for Regression Cooking!",
    "section": "",
    "text": "This document is intended to help students navigate the large amount of jargon, terminology, and acronyms encountered in the MDS program and beyond.\n\n\nThis section covers terms that have different meanings in different contexts, specifically statistics vs. machine learning (ML).\n\n\n\n\nHeads-up on terminology highlights!\n\n\nThroughout the book, following the ML-Stats dictionary, all statistical terms will be highlighted in blue whereas the machine learning terms will be highlighted in magenta. This color scheme helps readers move easily between disciplines. With practice, readers will comfortably use concepts from either field.\n\n\n\n\n\nIn supervised learning, it is the main variable of interest we are trying to learn or predict, or equivalently, in a statistical inference framework, the variable we are trying explain.\n\n\n\n\nEquivalent to:\n\n\nResponse variable, outcome, output or target.\n\n\n\n\n\nHeads-up on the use of terminology!\n\n\nThroughout this book, we will use specific terms interchangeably while explaining different regression methods. If confusion arises, readers should always check definitions and equivalences (or non-equivalences) in Appendix A.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting Ready for Regression Cooking!</span>"
    ]
  },
  {
    "objectID": "book/01-intro.html#sec-ds-workflow",
    "href": "book/01-intro.html#sec-ds-workflow",
    "title": "1  Getting Ready for Regression Cooking!",
    "section": "\n1.2 The Data Science Workflow",
    "text": "1.2 The Data Science Workflow\nUnderstanding the data science workflow is essential for mastering regression analysis. This workflow serves as a blueprint that guides us through each stage of our analysis, ensuring that we apply a systematic approach to solving our inquiries in a reproducible way. Each of the three pillars of this textbook—data science workflow, the right workflow flavor (inferential or predictive), and a regression toolbox—are deeply interconnected. Regardless of the regression model we explore, this general workflow provides a consistent framework that helps us navigate our data analysis with clarity and purpose. As shown in Figure 1.1, the data science workflow is composed of the following stages (each of which will be discussed in more detail in subsequent subsections):\n\n\nStudy design: Define the research question, objectives, and variables of interest to ensure the analysis is purpose-driven and aligned with the problem at hand.\n\nData collection and wrangling: Gather and clean data, addressing issues such as missing values, outliers, and inconsistencies to transform it into a usable format.\n\nExploratory data analysis: Explore the data through statistical summaries and visualizations to identify patterns, trends, and potential anomalies.\n\nData modelling: Apply statistical or machine learning models to uncover relationships between variables or make predictions based on the data.\n\nEstimation: Calculate model parameters to quantify relationships between variables and assess the accuracy and reliability of the model.\n\nGoodness of fit: Evaluate the model’s performance using metrics and diagnostic checks to determine how well it explains the data.\n\nResults: Interpret the model’s outputs to derive meaningful insights and provide answers to the original research question.\n\nStorytelling Communicate the findings through a clear, engaging narrative that is accessible to a non-technical audience.\n\nBy adhering to this workflow, we ensure that our regression analysis are not only systematic and thorough but also capable of producing results that are meaningful within the context of the problem we aim to solve.\n\n\n\n\n\n\nThe Importance of a Formal Structure in Regression Analysis\n\n\n\nFrom the earliest stages of learning data analysis, understanding the importance of a structured workflow is crucial. If we do not adhere to a predefined workflow, we risk misinterpreting the data, leading to incorrect conclusions that fail to address the core questions of our analysis. Such missteps can result in outcomes that are not only meaningless but potentially misleading when taken out of the problem’s context. Therefore, it is essential for aspiring data scientists to internalize this workflow from the very beginning of their education. A systematic approach ensures that each stage of the analysis is conducted with precision, ultimately producing reliable and contextually relevant results.\n\n\n\n\n\n\n\nFigure 1.1: Data science workflow for inferential and predictive inquiries in regression analysis and supervised learning, respectively. The workflow is structured in eight stages: study design, data collection and wrangling, exploratory data analysis, data modelling, estimation, goodness of fit, results, and storytelling.\n\n\n\n1.2.1 Study Design\nThe first stage of this workflow is centered around defining the main statistical inquiries we aim to address throughout the data analysis process. As a data scientist, your primary task is to translate these inquiries from the stakeholders into one of two categories: inferential or predictive. This classification determines the direction of your analysis and the methods you will use.\n\nInferential: The objective here is to explore and quantify relationships of association or causation between explanatory variables (regressors) and the response variable within the context of the problem at hand. For example, you may seek to determine whether a specific marketing campaign (regressor) significantly impacts sales revenue (response) and, if so, by how much.\nPredictive: In this case, the focus is on making accurate predictions about the response variable based on future observations of the regressors. Unlike inferential inquiries, where understanding the relationship between variables is key, the primary goal here is to maximize prediction accuracy. This approach is fundamental in machine learning. For instance, you might build a model to predict future sales revenue based on past marketing expenditures, without necessarily needing to understand the underlying relationship between the two.\n\nExample: Predicting Housing Prices\nTo illustrate the study design stage, let’s consider a simple example: predicting housing prices in a specific city.\n\nIf our goal is inferential, we might be interested in understanding the relationship between various factors (like square footage, number of bedrooms, and proximity to schools) and housing prices. Specifically, we would ask questions like, “How much does the number of bedrooms affect the price of a house, after accounting for other factors?”\nIf our goal is predictive, we would focus on creating a model that can accurately predict the price of a house based on its features, regardless of whether we fully understand how each factor contributes to the price.\n\nIn both cases, the study design stage involves clearly defining these objectives and determining the appropriate methods to address them. This stage sets the foundation for all subsequent steps in the data science workflow, as illustrated in Figure 1.2. Once the study design is established, the next stage is data collection and wrangling.\n\n\n\n\n\nFigure 1.2: Study design stage from the data science workflow in Figure 1.1. This stage is directly followed by data collection and wrangling.\n\n\n\n1.2.2 Data Collection and Wrangling\nOnce we have clearly defined our statistical questions, the next crucial step is to collect the data that will form the basis of our analysis. The way we collect this data is vital because it directly affects the accuracy and reliability of our results:\n\n\nFor inferential inquiries, we focus on understanding large groups or systems (populations) that we cannot fully observe. These populations are governed by characteristics (parameters) that we want to estimate. Because we can’t study every individual in the population, we collect a smaller, representative subset called a sample. The method we use to collect this sample—known as sampling—is crucial. A proper sampling method ensures that our sample reflects the larger population, allowing us to make accurate generalizations (inferences) about the entire group. After collecting the sample, it’s common practice to randomly split the data into training and test sets. This split allows us to build and validate our models, ensuring that the findings are robust and not overly tailored to the specific data at hand.\n\n\n\n\n\n\n\nA Quick Debrief on Sampling!\n\n\n\nAlthough this book does not cover sampling methods in detail, it’s important to know that the way you collect your sample can greatly influence your results. Depending on the problem, you might use different techniques:\n\n\nSimple Random Sampling: Every individual in the population has an equal chance of being selected.\n\nSystematic Sampling: You select individuals at regular intervals from a list of the population.\n\nStratified Sampling: You divide the population into subgroups (strata) and take a proportional sample from each subgroup.\n\nClustered Sampling: You divide the population into clusters and randomly select whole clusters for your sample.\nEtc.\n\nAs in the case of Regression Analysis, statistical sampling is a vast field, and we could spend a whole course on it. If you’re interested in learning more about these methods, Sampling: design and analysis by Lohr is a great resource.\n\n\n\n\nFor predictive inquiries, our goal is often to use existing data to make predictions about future events or outcomes. In these cases, we usually work with large datasets (databases) that have already been collected. Instead of focusing on whether the data represents a population (as in inferential inquiries), we focus on cleaning and preparing the data so that it can be used to train models that make accurate predictions. After wrangling the data, it is typically split into training, validation, and test sets. The training set is used to build the model, the validation set is used to tune model parameters, and the test set evaluates the model’s final performance on unseen data.\n\nExample: Collecting Data for Housing Price Predictions\nLet’s continue with our housing price prediction example to illustrate these concepts:\n\nInferential Approach: Suppose we want to understand how the number of bedrooms affects housing prices in a city. To do this, we would collect a sample of house sales that accurately represents the city’s entire housing market. For instance, we might use stratified sampling to ensure that we include houses from different neighborhoods in proportion to how common they are. After collecting the data, we would split it into training and test sets. The training set helps us build our model and estimate the relationship between variables, while the test set allows us to evaluate how well our findings generalize to new data.\nPredictive Approach: If our goal is to predict the selling price of a house based on its features (like size, number of bedrooms, and location), we would gather a large dataset of recent house sales. This data might come from a real estate database that tracks the details of each sale. Before we can use this data to train a model, we would clean it by filling in any missing information, converting data to a consistent format, and making sure all variables are ready for analysis. After preprocessing, we would split the data into training, validation, and test sets. The training set would be used to fit the model, the validation set to fine-tune it, and the test set to assess how well the model can predict prices for houses it hasn’t seen before.\n\nAs shown in Figure 1.3, the data collection and wrangling stage is fundamental to the workflow. It directly follows the study design and sets the stage for exploratory data analysis.\n\n\n\n\n\nFigure 1.3: Data collection and wrangling stage from the data science workflow in Figure 1.1. This stage is directly followed by exploratory data analysis and preceded by study design.\n\n\n\n1.2.3 Exploratory Data Analysis\nBefore diving into data modelling, it’s crucial to develop a deep understanding of the relationships between the variables in your training data. This is where the third stage of the data science workflow—Exploratory Data Analysis (EDA)—comes into play. EDA serves as a vital process that allows you to visualize and summarize your data, uncover patterns, detect anomalies, and test key assumptions that will inform your modelling decisions.\nThe first step in EDA is to classify your variables according to their types. This classification is essential because it guides your choice of analysis techniques and models. Specifically, you need to determine whether each variable is discrete or continuous, and whether it has any specific characteristics such as being bounded or unbounded.\n\n\nResponse Variable:\n\nDetermine if your response variable is discrete (e.g., binary, count-based, categorical) or continuous.\nIf it is continuous, consider whether it is bounded (e.g., percentages that range between 0 and 100) or unbounded (e.g., a variable like temperature that can take on a wide range of values).\n\n\n\nRegressors:\n\nFor each regressor, identify whether it is discrete or continuous.\nIf a regressor is discrete, classify it further as binary, count-based, or categorical.\nIf a regressor is continuous, determine whether it is bounded or unbounded.\n\n\n\nThis classification step ensures that you are prepared to choose the correct visualization and statistical methods for your analysis, as different types of variables often require different approaches.\nThis classification step ensures that you are prepared to choose the correct visualization and statistical methods for your analysis, as different types of variables often require different approaches.\nAfter classifying your variables, the next step is to create visualizations and calculate descriptive statistics using your training data. This involves coding plots that can reveal the underlying distribution of each variable and the relationships between them. For instance, you might create histograms to visualize distributions, scatter plots to explore relationships between continuous variables, and box plots to compare categorical variables against the response variable.\nAlongside these visualizations, it is important to calculate key descriptive statistics such as the mean, median, and standard deviation. These statistics provide a numerical summary of your data, offering insights into central tendency and variability. You might also use a correlation matrix to assess the strength of relationships between continuous variables.\nOnce you have generated these plots and statistics, they should be displayed in a clear and logical manner. The goal here is to interpret the data and draw preliminary conclusions about the relationships between variables. Presenting these findings effectively helps to uncover key insights and prepares you for the modelling stage.\nFinally, the insights gained from this exploratory analysis must be clearly articulated. This involves summarizing the key findings and considering their implications for the next stage of the workflow—data modelling. Observing patterns, correlations, and potential outliers in this stage will inform your modelling approach and ensure that it is grounded in a thorough and informed analysis.\nThis structured approach to EDA is visually summarized in Figure 1.4, illustrating the sequential steps from variable classification to the delivery of exploratory insights.\nExample: EDA for Housing Price Predictions\nTo illustrate the EDA process, let’s apply it to the example of predicting housing prices.\nWe start with variable classification:\n\nThe response variable is the sale price of a house, a continuous and unbounded variable.\nThe regressors include:\n\n\nNumber of bedrooms: Discrete, count-based.\n\nSquare footage: Continuous and unbounded.\n\nNeighborhood type: Discrete, categorical (e.g., urban, suburban, rural).\n\nProximity to schools: Continuous, potentially bounded by distance.\n\n\n\nOnce the variables are classified, we move on to coding plots and calculating descriptive statistics. Here are a couple of visualizations that can be helpful in this context:\n\nA histogram of sale prices helps visualize the distribution and spot any outliers.\nA scatter plot of square footage versus sale price shows the relationship, typically revealing a positive correlation.\n\nBox plots compare sale prices across different neighborhood types, highlighting any variations in median prices.\n\nDescriptive statistics like the mean and standard deviation provide a numerical summary, while a correlation matrix helps assess relationships between continuous variables like square footage and sale price.\n\nFinally, in displaying and interpreting results, these plots and statistics guide us in understanding the data:\n\nThe histogram might show most houses fall within a mid-range price.\nThe scatter plot could confirm that larger houses generally sell for more.\nBox plots may reveal that urban homes tend to have higher prices.\n\nThese exploratory insights help identify key predictors like square footage and neighborhood type, and highlight any outliers that may require further attention during modelling.\nBy following these steps, the EDA process in the housing price prediction example lays a solid foundation for effective modelling, ensuring that the key variables and their relationships are well understood.\n\n\n\n\n\nFigure 1.4: Exploratory data analysis stage from the data science workflow in Figure 1.1. This stage is directly followed by data modelling and preceded by data collection and wrangling.\n\n\n\n1.2.4 Data Modelling\n\n\n\n\n\nFigure 1.5: Data modelling stage from the data science workflow in Figure 1.1. This stage is directly preceded by exploratory data analysis. On the other hand, it is directly followed by estimation but indirectly with goodness of fit. If necessary, the goodness of fit stage could retake the process to data modelling.\n\n\n\n1.2.5 Estimation\n\n\n\n\n\nFigure 1.6: Estimation stage from the data science workflow in Figure 1.1. This stage is directly preceded by data modelling and followed by goodness of fit. If necessary, the goodness of fit stage could retake the process to data modelling and then to estimation.\n\n\n\n1.2.6 Goodness of Fit\n\n\n\n\n\nFigure 1.7: Goodness of fit stage from the data science workflow in Figure 1.1. This stage is directly preceded by estimation and followed by results. If necessary, the goodness of fit stage could retake the process to data modelling and then to estimation.\n\n\n\n1.2.7 Results\n\n\n\n\n\nFigure 1.8: Results stage from the data science workflow in Figure 1.1. This stage is directly followed by storytelling and preceded by goodness of fit.\n\n\n\n1.2.8 Storytelling\n\n\n\n\n\nFigure 1.9: Storytelling stage from the data science workflow in Figure 1.1. This stage preceded by results.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting Ready for Regression Cooking!</span>"
    ]
  },
  {
    "objectID": "book/01-intro.html#sec-regression-mindmap",
    "href": "book/01-intro.html#sec-regression-mindmap",
    "title": "1  Getting Ready for Regression Cooking!",
    "section": "\n1.3 Mind Map of Regression Analysis",
    "text": "1.3 Mind Map of Regression Analysis\nHaving defined the necessary statistical aspects to execute a proper supervised learning analysis, either inferential or predictive across its seven sequential phases, we must dig into the different approaches we might encounter in practice as regression models. The nature of our outcome of interest will dictate any given modelling approach to apply, depicted as clouds in Figure 1.10. Note these regression models can be split into two sets depending on whether the outcome of interest is continuous or discrete. Therefore, under a probabilistic view, identifying the nature of a given random variable is crucial in regression analysis.\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}\n        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(\n          (Exponential &lt;br/&gt;Outcome Y)\n          (Weibull &lt;br/&gt;Outcome Y)\n          (Lognormal &lt;br/&gt;Outcome Y)\n        )Chapter 7: &lt;br/&gt;Semiparametric &lt;br/&gt;Survival &lt;br/&gt;Regression(\n          (Cox Proportional &lt;br/&gt;Hazards Model)\n            (Hazard Function &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n      {{Binary &lt;br/&gt;Outcome Y}}\n        {{Ungrouped &lt;br/&gt;Data}}\n          )Chapter 8: &lt;br/&gt;Binary Logistic &lt;br/&gt;Regression(\n            (Bernoulli &lt;br/&gt;Outcome Y)\n        {{Grouped &lt;br/&gt;Data}}\n          )Chapter 9: &lt;br/&gt;Binomial Logistic &lt;br/&gt;Regression(\n            (Binomial &lt;br/&gt;Outcome Y)\n      {{Count &lt;br/&gt;Outcome Y}}\n        {{Equidispersed &lt;br/&gt;Data}}\n          )Chapter 10: &lt;br/&gt;Classical Poisson &lt;br/&gt;Regression(\n            (Poisson &lt;br/&gt;Outcome Y)\n        {{Overdispersed &lt;br/&gt;Data}}\n          )Chapter 11: &lt;br/&gt;Negative Binomial &lt;br/&gt;Regression(\n            (Negative Binomial &lt;br/&gt;Outcome Y)\n        {{Overdispersed or &lt;br/&gt;Underdispersed &lt;br/&gt;Data}}\n          )Chapter 13: &lt;br/&gt;Generalized &lt;br/&gt;Poisson &lt;br/&gt;Regression(\n            (Generalized &lt;br/&gt;Poisson &lt;br/&gt;Outcome Y)\n        {{Zero Inflated &lt;br/&gt;Data}}\n          )Chapter 12: &lt;br/&gt;Zero Inflated &lt;br/&gt;Poisson &lt;br/&gt;Regression(\n            (Zero Inflated &lt;br/&gt;Poisson &lt;br/&gt;Outcome Y)\n      {{Categorical &lt;br/&gt;Outcome Y}}\n        {{Nominal &lt;br/&gt;Outcome Y}}\n          )Chapter 14: &lt;br/&gt;Multinomial &lt;br/&gt;Logistic &lt;br/&gt;Regression(\n            (Multinomial &lt;br/&gt;Outcome Y)\n        {{Ordinal &lt;br/&gt;Outcome Y}}\n          )Chapter 15: &lt;br/&gt;Ordinal &lt;br/&gt;Logistic &lt;br/&gt;Regression(\n            (Logistic &lt;br/&gt;Distributed &lt;br/&gt;Cumulative Outcome &lt;br/&gt;Probability)\n\n\n\n\n\n\n\n\nFigure 1.10: Regression analysis mind map depicting all modelling techniques to be explored in this book. Depending on the type of outcome \\(Y\\), these techniques are split into two large zones: discrete and continuous.\n\n\nThat said, we will go beyond OLS regression and explore further regression techniques. In practice, these techniques have been developed in the statistical literature to address practical cases where the OLS modelling framework and assumptions are not suitable anymore. Thus, throughout this block, we will cover (at least) one new regression model per lecture.\nAs we can see in the clouds of Figure 1.10, there are 13 regression models: 8 belonging to discrete outcomes and 5 to continuous outcomes. Each of these models is contained in a chapter of this book, beginning with the most basic regression tool known as ordinary least-squares in Chapter 3. We must clarify that the current statistical literature is not restricted to these 13 regression models. The field of regression analysis is vast, and one might encounter more complex models to target certain specific inquiries. Nonetheless, I consider these models the fundamental regression approaches that any data scientist must be familiar with in everyday practice.\nEven though this book comprises 13 chapters, each depicting a different regression model, we have split these chapters into two major subsets: those with continuous outcomes and those with discrete outcomes.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Getting Ready for Regression Cooking!</span>"
    ]
  },
  {
    "objectID": "book/02-stats-review.html",
    "href": "book/02-stats-review.html",
    "title": "2  Basic Cuisine: A Review on Probability and Frequentist Statistical Inference",
    "section": "",
    "text": "2.1 Basics of Probability\nIn terms of regression analysis and its supervised learning counterpart (either on an inferential or predictive framework), probability can be viewed as the solid foundation on which more complex tools, including estimation and hypothesis testing, are built upon. Having said that, let us scaffold across all the necessary probabilistic concepts that will allow us to move forward into these more complex tools.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Cuisine: A Review on Probability and Frequentist Statistical Inference</span>"
    ]
  },
  {
    "objectID": "book/02-stats-review.html#sec-basics-prob",
    "href": "book/02-stats-review.html#sec-basics-prob",
    "title": "2  Basic Cuisine: A Review on Probability and Frequentist Statistical Inference",
    "section": "",
    "text": "2.1.1 First Insights\nTo start building up our solid probabilistic foundation, we assume our data is coming from a given population or system of interest. Moreover, the population or system is assumed to be governed by parameters which, as data scientists or researchers, they are of our best interest to study. That said, the terms population and parameter will pave the way to our first statistical definitions.\n\n\nDefinition of population\n\n\nIt is a whole collection of individuals or items that share distinctive attributes. As data scientists or researchers, we are interested in studying these attributes, which we assume are governed by parameters. In practice, we must be as specific as possible when defining our given population such that we would frame our entire data modelling process since its very early stages. Examples of a population could be the following:\n\nChildren between the ages of 5 and 10 years old in states of the American West Coast.\nCustomers of musical vinyl records in the Canadian provinces of British Columbia and Alberta.\nAvocado trees grown in the Mexican state of Michoacán.\nAdult giant pandas in the Southwestern Chinese province of Sichuan.\nMature açaí palm trees from the Brazilian Amazonian jungle.\n\n\n\nImage by Eak K. via Pixabay.\n\nNote that the term population could be exchanged for the term system, given that certain contexts do not particularly refer to individuals or items. Instead, these contexts could refer to processes whose attributes are also governed by parameters. Examples of a system could be the following:\n\nThe production of cellular phones from a given model in a set of manufacturing facilities.\nThe sale process in the Vancouver franchises of a well-known ice cream parlour.\nThe transit cycle during rush hours on weekdays in the twelve lines of Mexico City’s subway.\n\n\n\n\n\nDefinition of parameter\n\n\nIt is a characteristic (numerical or even non-numerical, such as a distinctive category) that summarizes the state of our population or system of interest. Examples of a population parameter can be described as follows:\n\nThe average weight of children between the ages of 5 and 10 years old in states of the American west coast (numerical).\nThe variability in the height of the mature açaí palm trees from the Brazilian Amazonian jungle (numerical).\nThe proportion of defective items in the production of cellular phones in a set of manufacturing facilities (numerical).\nThe average customer waiting time to get their order in the Vancouver franchises of a well-known ice cream parlour (numerical).\nThe most favourite pizza topping of vegetarian adults between the ages of 30 and 40 years old in Edmonton (non-numerical).\n\n\n\nImage by meineresterampe via Pixabay.\n\nNote the standard mathematical notation for population parameters are Greek letters (for more insights, you can check Appendix B). Moreover, in practice, these population parameter(s) of interest will be unknown to the data scientist or researcher. Instead, they would use formal statistical inference to estimate them.\n\n\nThe parameter definition points out a crucial fact in investigating any given population or system:\n\nOur parameter(s) of interest are usually unknown!\n\nGiven this fact, it would be pretty unfortunate and inconvenient if we eventually wanted to discover any significant insights about the population or system. Therefore, let us proceed to our so-called tasty example so we can dive into the need for statistical inference and why probability is our perfect ally in this parameter quest.\nImagine you are the owner of a large fleet of ice cream carts, around 900 to be exact. These ice cream carts operate across different parks in the following Canadian cities: Vancouver, Victoria, Edmonton, Calgary, Winnipeg, Ottawa, Toronto, and Montreal. In the past, to optimize operational costs, you decided to limit ice cream cones to only two items: vanilla and chocolate flavours, as in Figure 2.1.\n\n\n\n\n\nFigure 2.1: The two flavours of the ice cream cone you sell across all your ice cream carts: vanilla and chocolate. Image by tomekwalecki via Pixabay.\n\n\nNow, let us direct this whole case onto a more statistical and probabilistic field; suppose you have a well-defined overall population of interest for those above eight Canadian cities: children between 4 and 11 years old attending these parks during the Summer weekends. Of course, Summer time is coming this year, and you would like to know which ice cream cone flavour is the favourite one for this population (and by how much!). As a business owner, investigating ice cream flavour preferences would allow you to plan Summer restocks more carefully with your corresponding suppliers. Therefore, it would be essential to start collecting consumer data so the company can tackle this demand query.\nAlso, suppose there is a second query. For the sake of our case, we will call it a time query. As a critical component of demand planning, besides estimating which cone flavour is the most preferred one (and by how much!) for the above population of interest, the operations area is currently requiring a realistic estimation of the average waiting time from one customer to the next one in any given cart during Summer weekends. This average waiting time would allow the operations team to plan carefully how much stock each cart should have so there will not be any waste or shortage.\n\n\nImage by Icons8 Team via Unsplash.\n\nNote that the nature of the aforementioned time query is more related to a larger population. Therefore, we can define it as all our ice cream customers during the Summer weekends. Furthermore, this second definition would expand this query to our corresponding general ice cream customers, given the requirements of our operations team, and not just all the children between 4 and 11 years old attending the parks during Summer weekends. Consequently, it is crucial to note that the nature of our queries will dictate how we define our population and our subsequent data modelling and statistical inference.\nSummer time represents the most profitable season from a business perspective, thus solving these above two queries is a significant priority for your company. Hence, you decide to organize a meeting with your eight general managers (one per Canadian city). Finally, during the meeting with the general managers, it was decided to do the following:\n\nFor the demand query, a comprehensive market study will be run on the population of interest across the eight Canadian cities right before next Summer; suppose we are currently in Spring.\nFor the time query, since the operations team has not previously recorded any historical data (surprisingly!), all vendor staff from 900 carts will start collecting data on the waiting time in seconds between each customer this upcoming Summer.\n\nWhen discussing study requirements for the marketing firm who would be in charge of it for the demand query, Vancouver’s general manager dares to state the following:\n\nSince we’re already planning to collect consumer data on these cities, let’s mimic a census-type study to ensure we can have the MOST PRECISE results on their preferences.\n\nOn the other hand, when agreeing on the specific operations protocol to start recording waiting times for all the 900 vending carts this upcoming Summer, Ottawa’s general manager provides a comment for further statistical food for thought:\n\nThe operations protocol for recording waiting times in the 900 vending carts looks too cumbersome to implement straightforwardly this upcoming Summer. Why don’t we select A SMALLER SET of waiting times between two general customers across the 900 ice cream carts in the eight cities to have a more efficient process implementation that would allow us to optimize operational costs?\n\nBingo! Ottawa’s general manager just nailed the probabilistic way of making inference on our population parameter of interest for the time query. Indeed, their comment was primarily framed from a business perspective of optimizing operational costs. Still, this fact does not take away a crucial insight on which statistical inference is built: a random sample (as in its corresponding definition). As for Vancouver’s general manager, ironically, their statement is NOT PRECISE (from an inferential point of view)! Mimicking a census-type study might not be the most optimal decision for the demand query given the time constraint and the potential size of its target population.\n\n\nHeads-up on the use random sampling with probabilistic foundations!\n\n\nLet us clarify things from the start, especially from a statistical perspective:\n\nRealistically, there is no cheap and efficient way to conduct a census-type study for either of the two queries.\n\nWe must rely on probabilistic random sampling, selecting two small subsets of individuals from our two populations of interest. This approach allows us to save both financial and operational resources compared to conducting a complete census. However, random sampling requires us to use various probabilistic and inferential tools to manage and report the uncertainty associated with the estimation of the corresponding population parameters, which will help us answer our initial main queries.\n\n\nImage by manfredsteger via Pixabay.\n\nTherefore, having said all this, let us assume that in this ice cream case, the company decided to go ahead with random sampling to answer both queries.\n\n\nMoving on to one of the core topics in this chapter, we can state that probability is viewed as the language to decode random phenomena that occur in any given population or system of interest. In our example, we have two random phenomena:\n\nFor the demand query, a phenomenon can be represented by the preferred ice cream cone flavour of any randomly selected child between 4 and 11 years old attending the parks of the above eight Canadian cities during the Summer weekends.\nRegarding the time query, a phenomenon of this kind can be represented by any randomly recorded waiting time between two customers during a Summer weekend in any of the above eight Canadian cities across the 900 ice cream carts.\n\nNow, let us finally define what we mean by probability along with the inherent concept of sample space.\n\n\nDefinition of probability\n\n\nLet \\(A\\) be an event of interest in a random phenomenon of a population or system of interest, whose all possible outcomes belong to a given sample space \\(S\\). Generally, the probability for this event \\(A\\) happening can be mathematically depicted as \\(P(A)\\). Moreover, suppose we observe the random phenomenon \\(n\\) times such as we were running some class of experiment, then \\(P(A)\\) is defined as the following ratio:\n\\[\nP(A) = \\frac{\\text{Number of times event $A$ is observed}}{n},\n\\tag{2.1}\\]\nas the \\(n\\) times we observe the random phenomenon goes to infinity.\nEquation 2.1 will always put \\(P(A)\\) in the following numerical range:\n\\[\n0 \\leq P(A) \\leq 1.\n\\]\n\n\n\n\nDefinition of sample space\n\n\nLet \\(A\\) be an event of interest in a random phenomenon of a population or system of interest. The sample space \\(S\\) of event \\(A\\) denotes the set of all the possible random outcomes we might encounter every time we randomly observe \\(A\\) such as we were running some class of experiment.\nNote each of these outcomes has a determined probability associated with them. If we add up all these probabilities, the probability of the sample space \\(S\\) will be one, i.e.,\n\\[\nP(S) = 1.\n\\tag{2.2}\\]\n\n\n\n2.1.2 Schools of Statistical Thinking\nNote the above definition for the probability of an event \\(A\\) specifically highlights the following:\n\n… as the \\(n\\) times we observe the random phenomenon goes to infinity.\n\nThe “infinity” term is key when it comes to understanding the philosophy behind the frequentist school of statistical thinking in contrast to its Bayesian counterpart. In general, the frequentist way of practicing statistics in terms of probability and inference is the approach we usually learn in introductory courses, more specifically when it comes to hypothesis testing and confidence intervals which will be explored in Section 2.3. That said, the Bayesian approach is another way of practicing statistical inference. Its philosophy differs in what information is used to infer our population parameters of interest. Below, we briefly define both schools of thinking.\n\n\nDefinition of frequentist statistics\n\n\nThis statistical school of thinking heavily relies on the frequency of events to estimate specific parameters of interest in a population or system. This frequency of events is reflected in the repetition of \\(n\\) experiments involving a random phenomenon within this population or system.\nUnder the umbrella of this approach, we assume that our governing parameters are fixed. Note that, within the philosophy of this school of thinking, we can only make precise and accurate predictions as long as we repeat our \\(n\\) experiments as many times as possible, i.e.,\n\\[\nn \\rightarrow \\infty.\n\\]\n\n\n\n\nDefinition of Bayesian statistics\n\n\nThis statistical school of thinking also relies on the frequency of events to estimate specific parameters of interest in a population or system. Nevertheless, unlike frequentist statistics, Bayesian statisticians use prior knowledge on the population parameters to update their estimations on them along with the current evidence they can gather. This evidence is in the form of the repetition of \\(n\\) experiments involving a random phenomenon. All these ingredients allow Bayesian statisticians to make inference by conducting appropriate hypothesis testings, which are designed differently from their mainstream frequentist counterpart.\n\n\nThe unique known portrait of Reverend Thomas Bayes according to O’Donnell, T. (1936), even though Bellhouse (2004) argues it might not be a Bayes’ portrait.\n\nUnder the umbrella of this approach, we assume that our governing parameters are random; i.e., they have their own sample space and probabilities associated to their corresponding outcomes. The statistical process of inference is heavily backed up by probability theory mostly in the form of the Bayes’ rule (named after Reverend Thomas Bayes, an English statistician from the 18th century). This rule uses our current evidence along with our prior beliefs to deliver a posterior distribution of our random parameter(s) of interest.\n\n\nLet us put the definitions for these two schools of statistical thinking into a more concrete example. We can use the demand query from our ice cream case as a starting point. More concretely, we can dig more into a standalone population parameter such as the probability that a randomly selected child between 4 and 11 years old, attending the parks of the above eight Canadian cities during the Summer weekends, prefers the chocolate-flavoured ice cream cone over the vanilla one. Think about the following two hypothetical questions:\n\nFrom a frequentist point of view, what is the estimated probability of preferring chocolate over vanilla after randomly surveying \\(n = 100\\) children from our population of interest?\nUsing a Bayesian approach, suppose the marketing team has found ten prior market studies on similar children populations on their preferred ice cream flavour (between chocolate and vanilla). Therefore, along with our actual random survey of \\(n = 100\\) children from our population of interest, what is the posterior estimation of the probability of preferring chocolate over vanilla?\n\nBy comparing the above (a) and (b), we can see one characteristic in common when it comes to the estimation of the probability of preferring chocolate over vanilla: both frequentist and Bayesian approaches rely on the gathered evidence coming from the random survey of \\(n = 100\\) children from our population of interest. On the one hand, the frequentist approach solely relies on observed data to estimate this single probability of preferring chocolate over vanilla. On the other hand, the Bayesian approach uses the observed data in conjunction with the prior knowledge provided by the ten estimated probabilities to deliver a whole posterior distribution (i.e., the posterior estimation) of the probability of preferring chocolate over vanilla.\n\n\nHeads-up on the debate between frequentist and Bayesian statistics!\n\n\nEven though most of us began our statistical journey in a frequentist framework, we might be tempted to state that a Bayesian paradigm for parameter estimation and inference is better than a frequentist one since the former only takes into account the observed evidence without the prior knowledge on our parameters of interest.\n\n\nImage by Manfred Steger via Pixabay.\n\nIn the statistical community, there could be a fascinating debate between the pros and cons of each school of thinking. That said, it is crucial to state that no paradigm is considered wrong! Instead, using a pragmatic strategy of performing statistics according to our data science context is more convenient.\n\n\n\n\nTip on further Bayesian and frequentist insights!\n\n\nLet us check the following two examples (aside from our ice cream case) to illustrate the above pragmatic way of doing things:\n\nTake the production of cellular phones from a given model in a set of manufacturing facilities as the context. Hence, one might find a frequentist estimation of the proportion of defective items as a quicker and more efficient way to correct any given manufacturing process. That is, we will sample products from our finalized batches and check their status (defective or non-defective, our observed evidence) to deliver a proportion estimation of defective items.\nNow, take a physician’s context. It would not make a lot of sense to study the probability that a patient develops a certain disease by only using a frequentist approach, i.e., looking at the current symptoms which account for the observed evidence. In lieu, a Bayesian approach would be more suitable to study this probability which uses the observed evidence combined with the patient’s history (i.e., the prior knowledge) to deliver our posterior belief on the disease probability.\n\n\n\nHaving said all this, it is important to reiterate that the focus of this textbook is purely frequentist in regards to data modelling in regression analysis. If you would like to explore the fundamentals of the Bayesian paradigm; Johnson, Ott, and Dogucu (2022) have developed an amazing textbook on the basic probability theory behind this school of statistical thinking along with a whole variety regression techniques including the parameter estimation rationale.\n\n2.1.3 The Random Variables\nAs we continue our frequentist quest to review the probabilistic insights related to parameter estimation and statistical inference, we will focus on our ice cream case while providing a comprehensive array of definitions. Many of these definitions are inspired by the work of Casella and Berger (2024) and Soch et al. (2024).\nEach time we introduce a new probabilistic or statistical concept, we will apply it immediately to this ice cream case, allowing for hands-on practice that meets the learning objectives of this chapter. It is important to pay close attention to the definition and heads-up admonitions, as they are essential for fully understanding how these concepts apply to the ice cream case. On the other hand, the tip admonitions are designed to offer additional theoretical insights that may interest you, but they can be skipped if you prefer.\n\n\nTable 2.1: Table containing the corresponding insights to solve our demand and time queries.\n\n\n\n\n\n\n\n\n\nDemand Query\nTime Query\n\n\n\nStatement\nWe would like to know which ice cream flavour is the favourite one (either chocolate or vanilla) and by how much.\nWe would like to know the average waiting time from one customer to the next one in any given ice cream cart.\n\n\nPopulation of interest\n\nChildren between 4 and 11 years old attending different parks in Vancouver, Victoria, Edmonton, Calgary, Winnipeg, Ottawa, Toronto, and Montreal during Summer weekends.\n\nAll our general customer-to-customer waiting times in the different parks of Vancouver, Victoria, Edmonton, Calgary, Winnipeg, Ottawa, Toronto, and Montreal during Summer weekends across the 900 ice cream carts.\n\n\nParameter\n\nProportion of individuals from the population of interest who prefer the chocolate flavour versus the vanilla flavour.\n\nAverage waiting time from one customer to the next one.\n\n\n\n\n\n\nTable 2.1 presents the general statements and populations of interest derived from our two queries: demand and time. It is important to note that these general statements are based on the storytelling we initiated in Section 2.1.1. In practice, summarizing the overarching statistical problem is essential. This will enable us to translate the corresponding issue into a specific statement and population, from which we can define the parameters we aim to estimate later in our statistical process.\nNow, recall that in our initial meeting with the general managers, Ottawa’s general manager provided valuable statistical insights regarding the foundation of a random sample. For the time query, they suggested selecting a smaller set of waiting times between two general customers across the 900 ice cream carts. We already addressed this process as sampling, more specifically random sampling in technical language.\nSimilarly, we can apply this concept to the demand query by selecting a subgroup of children aged 4 to 11 who are visiting different parks in these eight cities. Then, we can ask them about their favorite ice cream flavour, specifically whether they prefer chocolate or vanilla. It is important to note that we are not conducting any census-type studies; instead, we are carrying out two studies that heavily rely on sampling to estimate population parameters.\n\n\nImage by Manfred Stege via Pixabay.\n\nFurthermore, we want to ensure that our two groups of observations—both children and waiting times—are representative of their respective populations. So, how can we achieve this? The baseline key is through what we call simple random sampling. This process involves the following per query:\n\nFor the demand query, let us assume there are \\(N_D\\) observations in our population of interest. In a simple random sampling scheme with replacement, our random sample will consist of \\(n_D\\) observations (noting that \\(n_D &lt;&lt; N_D\\)), each having the same probability of being selected for our estimation and inferential purposes, which is given by \\(\\frac{1}{N_D}\\).\nFor the time query, assume there are \\(N_T\\) observations in our population of interest. Again, in a simple random sampling scheme with replacement, our random sample will consist of \\(n_T\\) observations (noting that \\(n_T &lt;&lt; N_T\\)), each having the same probability of selection for estimation and inferential purposes, which is \\(\\frac{1}{N_T}\\).\n\n\n\nHeads-up on sampling with replacement!\n\n\nKeep in mind that sampling with replacement means you return any specific drawn observation back to the corresponding population before the next draw.\n\n\n\n\nTip of further sampling techniques!\n\n\nIf you want to explore additional sampling techniques besides simple random sampling, Section 1.2.2 provides further details and an external resource.\n\n\nWe can observe the concept of randomness reflected throughout the sampling schemes mentioned above. This aligns with what we referred to as random phenomena in both queries back in Section 2.1.1. Consequently, there should be a way to mathematically represent these phenomena, and the random variable is the starting point in this process.\n\n\nDefinition of random variable\n\n\nA random variable is a function where the input values correspond to real numbers assigned to events belonging to the sample space \\(S\\), and whose outcome is one of these real numbers after executing a given random experiment. For instance, a random variable (and its support, i.e., real numbers) is depicted with an uppercase such that\n\\[Y \\in \\mathbb{R}.\\]\n\n\nTo begin experimenting with random variables in this ice cream case, we need to define them clearly. It is important to be as clear as possible when defining random variables, and we should also remember to use uppercase letters as follows:\n\\[\n\\begin{align*}\nD_i &= \\text{A favourite ice cream flavour of a randomly surveyed $i$th child} \\\\\n& \\qquad \\text{between 4 and 11 years old attending the parks of} \\\\\n& \\qquad \\text{Vancouver, Victoria, Edmonton, Calgary,} \\\\\n& \\qquad \\text{Winnipeg, Ottawa, Toronto, and Montreal} \\\\\n& \\qquad \\text{during the Summer weekends} \\\\\n& \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\text{for $i = 1, \\dots, n_D.$}  \\\\\n\\\\\nT_j &= \\text{A randomly recorded $j$th waiting time in minutes between two} \\\\\n& \\qquad \\text{customers during a Summer weekend in any of the above} \\\\\n& \\qquad \\text{eight Canadian cities across the 900 ice cream carts} \\\\\n& \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\text{for $j = 1, \\dots, n_T.$}  \\\\\n\\end{align*}\n\\]\nNote that the demand query corresponds to the \\(i\\)th random variable \\(D_i\\), where the subindex \\(i\\) ranges from \\(1\\) to \\(n_D\\). The term \\(n_D\\) represents the sample size for this query and theoretically indicates the number of random variables we intend to observe from our population of interest during our sampling. On the other hand, for the time query, we have the \\(j\\)th random variable \\(T_j\\), with the subindex \\(j\\) ranging from \\(1\\) to \\(n_T\\). In the context of this query, \\(n_T\\) denotes the sample size and indicates how many random variables we plan to observe from our population of interest as part of our sampling.\nNow, \\(D_i\\) will require real numbers that correspond to potential outcomes derived from the specific demand sample space of ice cream flavour, which we can denote as \\(S_D\\). It is crucial to note that a given child from our population may prefer a flavour other than chocolate or vanilla—for example, strawberry, salted caramel, or pistachio. However, we are limited by our available flavour menu as a company. Therefore, we will restrict our survey question regarding these potential \\(n_D\\) surveyed children as follows:\n\\[\nd_i =\n\\begin{cases}\n1 \\qquad \\text{The surveyed child prefers chocolate.}\\\\\n0 \\qquad \\text{Otherwise.}\n\\end{cases}\n\\tag{2.3}\\]\nIn the modelling associated with Equation 2.3, an observed random variable \\(d_i\\) (thus, the lowercase) can only yield values of \\(1\\) if the surveyed child prefers chocolate and \\(0\\) otherwise. The term “otherwise” refers to any flavour other than chocolate, which, in our limited menu context, is vanilla!\nTo define the real numbers from a given waiting time sample space \\(S_T\\), associated with an observed random variable \\(t_j\\) (thus, the lowercase) measured in minutes, we need to establish a possible range for these waiting times. It would not make sense to have observed negative waiting times in this ice cream scenario; therefore, our lower bound for this range of potential values should be \\(0\\) minutes. However, we cannot set an upper limit on these waiting times since any ice cream vendor might need to wait for \\(1, 2, 3, \\ldots, 10, \\ldots, 20, \\ldots, 60, \\ldots\\) minutes for the next customer to arrive. In fact, it is possible to wait for a very long time, especially on a low sales day! Thus, the range of this observed random variable can be expressed as:\n\\[\nt_j \\in [0, \\infty),\n\\]\nwhere the \\(\\infty\\) symbol indicates no upper bound.\nAfter defining the possible values for our two random variables \\(D_i\\) and \\(T_j\\), we will now classify them correctly using further probabilistic definitions as shown below.\n\n\nDefinition of discrete random variable\n\n\nLet \\(Y\\) be a random variable whose support is \\(\\mathcal{Y}\\). If this support \\(\\mathcal{Y}\\) corresponds to a finite set or a countably infinite set of possible values, then \\(Y\\) is considered a discrete random variable.\nFor instance, we can encounter discrete random variables which could be classified as\n\n\nbinary (i.e., a finite set of two possible values),\n\ncategorical (either nominal or ordinal, which have a finite set of three or more possible values), or\n\ncounts (which might have a finite set or a countably infinite set of possible values as integers).\n\n\n\nImage by Pexels via Pixabay.\n\n\n\n\n\nDefinition of continuous random variable\n\n\nLet \\(Y\\) be a random variable whose support is \\(\\mathcal{Y}\\). If this support \\(\\mathcal{Y}\\) corresponds to an uncountably infinite set of possible values, then \\(Y\\) is considered a continuous random variable.\nNote a continuous random variable could be\n\n\ncompletely unbounded (i.e., its set of possible values goes from \\(-\\infty\\) to \\(\\infty\\) as in \\(-\\infty &lt; y &lt; \\infty\\)),\n\npositively unbounded (i.e., its set of possible values goes from \\(0\\) to \\(\\infty\\) as in \\(0 \\leq y &lt; \\infty\\)),\n\nnegatively unbounded (i.e., its set of possible values goes from \\(-\\infty\\) to \\(0\\) as in \\(-\\infty &lt; y \\leq 0\\)), or\n\nbounded between two values \\(a\\) and \\(b\\) (i.e., its set of possible values goes from \\(a\\) to \\(b\\) as in \\(a \\leq y \\leq b\\)).\n\n\n\nImage by arielrobin via Pixabay.\n\n\n\nTherefore, we can classify our two random variables as follows:\n\nFor the demand query, the support of \\(D_i\\) (denoted as \\(\\mathcal{D}\\)) is a countable finite set with two possible values: \\(d_i \\in \\{0, 1\\}\\), as noted by Equation 2.3. Therefore, \\(D_i\\) is categorized as a binary discrete random variable.\nFor the time query, the support of \\(T_j\\) (denoted as \\(\\mathcal{T}\\)) is positively unbounded. This results in an uncountably infinite set of values that \\(T_j\\) can take, including (but not limited to!) \\(0, \\dots, 0.01, \\ldots, 0.02, \\ldots, 0.00234, \\ldots, 1, \\ldots, 1.5576, \\ldots\\) minutes. Therefore, \\(T_j\\) is classified as a positively unbounded continuous random variable.\n\nSo far, we have successfully translated our two statistical queries into proper random variables, along with clear definitions and classifications derived from our problem statements, as well as the populations of interest, as noted in Table 2.1. However, we still need to find a way to include our parameters. The upcoming section will allow us to do that.\n\n2.1.4 The Wonders of Generative Modelling and Probability Distributions\nBefore exploring the wonders of generative models, let us introduce Table 2.2, an extension of Table 2.1 that now includes the elements discussed in Section 2.1.3.\n\n\nTable 2.2: Table containing the corresponding insights to solve our demand and time queries.\n\n\n\n\n\n\n\n\n\nDemand Query\nTime Query\n\n\n\nStatement\nWe would like to know which ice cream flavour is the favourite one (either chocolate or vanilla) and by how much.\nWe would like to know the average waiting time from one customer to the next one in any given ice cream cart.\n\n\nPopulation of interest\n\nChildren between 4 and 11 years old attending different parks in Vancouver, Victoria, Edmonton, Calgary, Winnipeg, Ottawa, Toronto, and Montreal during Summer weekends.\n\nAll our general customer-to-customer waiting times in the different parks of Vancouver, Victoria, Edmonton, Calgary, Winnipeg, Ottawa, Toronto, and Montreal during Summer weekends across the 900 ice cream carts.\n\n\nParameter\n\nProportion of individuals from the population of interest who prefer the chocolate flavour versus the vanilla flavour.\n\nAverage waiting time from one customer to the next one.\n\n\nRandom variable\n\n\\(D_i\\) for \\(i = 1, \\dots, n_D\\).\n\n\\(T_j\\) for \\(j = 1, \\dots, n_T\\).\n\n\nRandom variable definition\nA favourite ice cream flavour of a randomly surveyed \\(i\\)th child between 4 and 11 years old attending the parks of Vancouver, Victoria, Edmonton, Calgary, Winnipeg, Ottawa, Toronto, and Montreal during the Summer weekends.\nA randomly recorded \\(j\\)th waiting time in minutes between two customers during a Summer weekend across the 900 ice cream carts found in Vancouver, Victoria, Edmonton, Calgary, Winnipeg, Ottawa, Toronto, and Montreal.\n\n\nRandom variable type\nDiscrete and binary.\nContinuous and positively unbounded.\n\n\nRandom variable support\n\n\\(d_i \\in \\{ 0, 1\\}\\) as in Equation 2.3.\n\\(t_j \\in [0, \\infty).\\)\n\n\n\n\n\n\nHaving summarized all our probabilistic elements in Table 2.2, the parameters of interest must come into play for our data modelling game! Hence, the question is:\n\nIs there any feasible way to do so via the the foundations of random variables?\n\nThe answer lies in what we call a generative model, for which we have a whole toolbox corresponding to another important concept called probability distributions, as shown below.\n\n\nDefinition of generative model\n\n\nSuppose you observe some data \\(y\\) from a population or system of interest. Moreover, let us assume this population or system is governed by \\(k\\) parameters contained in the following vector:\n\\[\n\\boldsymbol{\\theta} = (\\theta_1, \\theta_2, \\cdots, \\theta_k)^T.\n\\]\nIf we state that the random variable \\(Y\\) follows certain probability distribution \\(\\mathcal{D}(\\cdot),\\) then we will have a generative model \\(m\\) such that\n\\[\nm: Y \\sim \\mathcal{D}(\\boldsymbol{\\theta}).\n\\]\n\n\nImage by Manfred Stege via Pixabay.\n\n\n\n\n\nDefinition of probability distribution\n\n\nWhen we set a random variable \\(Y\\), we also set a new set of \\(v\\) possible outcomes \\(\\mathcal{Y} = \\{ y_1, \\dots, y_v\\}\\) coming from the sample space \\(S\\). This new set of possible outcomes \\(\\mathcal{Y}\\) corresponds to the support of the random variable \\(Y\\) (i.e., all the possible values that could be taken on once we execute a given random experiment involving \\(Y\\)).\nThat said, let us suppose we have a sample space of \\(u\\) elements defined as\n\\[\nS = \\{ s_1, \\dots, s_u \\},\n\\]\nwhere each one of these elements has a probability assigned via a function \\(P_S(\\cdot)\\) such that\n\\[\nP(S) = \\sum_{i = 1}^u P_S(s_i) = 1.\n\\]\nwhich has to satisfy Equation 2.2.\nThen, the probability distribution of \\(Y\\), i.e., \\(P_Y(\\cdot)\\) assigns a probability to each observed value \\(Y = y_j\\) (with \\(j = 1, \\dots, v\\)) if and only if the outcome of the random experiment belongs to the sample space, i.e., \\(s_i \\in S\\) (for \\(i = 1, \\dots, u\\)) such that \\(Y(s_i) = y_j\\):\n\\[\nP_Y(Y = y_j) = P \\left( \\left\\{ s_i \\in S : Y(s_i) = y_j \\right\\} \\right).\n\\]\n\n\nSince we have two different queries, we will use two instances of generative models. It is worth noting that more complex modelling could refer to a single generative model. However, for the purposes of this review chapter, we will keep it simple with via two separate generative models.\nNow, let us introduce a specific notation for our discussion: the Greek alphabet. Greek letters are frequently used to statistically represent population parameters in modelling setups, estimation, and statistical inference. These letters will be quite useful for our parameters in this ice cream case!\n\n\nTip on the Greek alphabet in statistics!\n\n\nIn the early stages of learning statistical modelling, including concepts such as regression analysis, it is common to feel overwhelmed by unfamiliar letters and terminology. Whenever confusion arises in any of the main chapters of this book regarding these letters, we recommend referring to the Greek alphabet shared by Appendix B. It is important to note that frequentist statistical inference primarily uses lowercase letters. With consistent practice over time, you will likely memorize most of this alphabet!\n\n\nImage by meineresterampe via Pixabay.\n\n\n\nLet us retake the row corresponding to parameters in Table 2.2 and assign their corresponding Greek letters:\n\nFor the demand query, we are interested in the parameter \\(\\pi\\), which represents the proportion of individuals from the children population who prefer the chocolate flavour over the vanilla flavour. It is crucial to note that a proportion is always bounded between \\(0\\) and \\(1\\), similar to how probabilities function! For instance, a proportion of \\(0.2\\) would mean that \\(20\\%\\) of the children in our population prefer chocolate flavour over vanilla. This definition establishes our demand query parameter as follows:\n\n\\[\n\\pi \\in [0, 1].\n\\]\n\n\nHeads-up on the use of \\(\\pi\\)!\n\n\nIn this textbook, unless stated otherwise, the letter \\(\\pi\\) will denote a population parameter and not the mathematical constant \\(3.141592...\\)\n\n\n\nFor the time query, we are interested in the parameter \\(\\beta\\), which represents the average waiting time in minutes from one customer to the next one in our population of interest. Unlike the above \\(\\pi\\) parameter, \\(\\beta\\) is only positively unbounded given the definition of our random variable \\(T_j\\). Therefore, this definition establishes our time query parameter as follows:\n\n\\[\n\\beta \\in (0, \\infty).\n\\]\nHaving defined our parameters of interest with proper lowercase Greek letters, it is time to declare our corresponding generative models on a general basis. For the demand query, there will be a single parameter called \\(\\pi\\), where the randomly surveyed child \\(D_i\\) will follow the model \\(m_D\\) such that\n\\[\n\\begin{gather*}\nm_D : D_i \\sim \\mathcal{D}_D(\\pi) \\\\\n\\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\quad \\text{for $i = 1, \\dots, n_D.$}\n\\end{gather*}\n\\tag{2.4}\\]\nNow, for the time query, there will also be a single parameter called \\(\\beta\\). Thus, the randomly recorded waiting time \\(T_j\\) will follow the model \\(m_T\\) such that\n\\[\n\\begin{gather*}\nm_T : T_j \\sim \\mathcal{D}_T(\\beta) \\\\\n\\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\quad \\text{for $j = 1, \\dots, n_T.$}\n\\end{gather*}\n\\tag{2.5}\\]\nNonetheless, we might wonder the following:\n\nHow can we determine the corresponding distributions \\(\\mathcal{D}_D(\\pi)\\) and \\(\\mathcal{D}_T(\\beta)\\)?\n\nOf course the above definition of a probability distribution will come in handy to resolve this question. That said, given that we have two types of random variables (discrete and continuous), it is necessary to introduce two specific types of probability functions: probability mass function (PMF) and probability density function (PDF).\n\n\nDefinition of probability mass function (PMF)\n\n\nLet \\(Y\\) be a discrete random variable whose support is \\(\\mathcal{Y}\\). Moreover, suppose that \\(Y\\) has a probability distribution such that\n\\[\nP_Y(Y = y) : \\mathbb{R} \\rightarrow [0, 1]\n\\]\nwhere, for all \\(y \\notin \\mathcal{Y}\\), we have\n\\[\nP_Y(Y = y) = 0\n\\]\nand\n\\[\n\\sum_{y \\in \\mathcal{Y}} P_Y(Y = y) = 1.\n\\tag{2.6}\\] Then, \\(P_Y(Y = y)\\) is considered a PMF.\n\n\nAs we have discussed throughout this ice cream case, let us begin with the demand query. We have already defined the \\(i\\)th random variable \\(D_i\\) as discrete and binary. In statistical literature, certain random variables in common random processes can be modelled using what we call parametric families. We refer to these tools as parametric families because they are characterized by a specific set of parameters (in our case, each query has a single-element set, such as \\(\\pi\\) or \\(\\beta\\)).\nMoreover, we call them families since each member corresponds to a particular value of our parameter(s). For instance, in our demand query, a chosen member could be where \\(\\pi = 0.8\\) within the respective chosen parametric family to model our surveyed children. Other possible members could correspond to \\(\\pi = 0.2\\), \\(\\pi = 0.4\\) or \\(\\pi = 0.6\\). In fact, the number of members in our chosen parametric family is infinite in this demand query!\n\nTherefore, what parametric family can we choose for our demand query?\n\nThe question above introduces a new, valuable resource that is further elaborated upon in Appendix C. This resource outlines the various distributions that will be utilized in this textbook. In reality, the realm of parametric families—specifically, distributions—is quite extensive, and this material serves as only a brief overview of the many parametric families documented in statistical literature.\n\n\nTip on data modelling alternatives via different parametric families!\n\n\nAny data model is simply an abstraction of reality, and different parametric families can provide various alternatives for modelling. In practice, we often need to select a specific family based on our particular inquiries and the conditions of our data. This process requires time and experience to master. Furthermore, it is important to note that different families are often interconnected!\n\n\nImage by Manfred Stege via Pixabay.\n\nIf you wish to explore the world of univariate distribution families—which are used to model a single random variable—Leemis (n.d.) has created a comprehensive relational chart that covers 76 distinct probability distributions: 19 are discrete, and 57 are continuous. However, this chart does not encompass all the possible families that one might encounter in statistical literature (you can check another list at the end of this section).\n\n\nReferring back to our discussion about Appendix C, it is time to choose the most suitable parametric family for a discrete and a binary random variable, such as the \\(i\\)th random variable \\(D_i\\). A particular case we can examine is the Bernoulli distribution (also, commonly known as a Bernoulli trial). The Bernoulli distribution applies to a discrete random variable that can take one of two values: \\(0\\), which we refer to as a failure, and \\(1\\), identified as a success. This aligns with our previous definition from Equation 2.3:\n\\[\nd_i =\n\\begin{cases}\n1 \\qquad \\text{The surveyed child prefers chocolate.}\\\\\n0 \\qquad \\text{Otherwise.}\n\\end{cases}\n\\]\nThe equation above defines the chocolate preference of the \\(i\\)th surveyed child as a success, while another flavour—specifically vanilla in the context of our limited menu—is categorized as a failure. Thus, we can denote the support as \\(d_i \\in \\{0, 1\\}\\).\nWe need to define our population parameter for this demand query in the context of a Bernoulli trial, which is denoted by \\(\\pi \\in [0, 1]\\). This represents the proportion of children who prefer the chocolate flavour over the vanilla flavour. In a Bernoulli trial, this parameter refers to the probability of success. Lastly, we can specify our generative model accordingly:\n\\[\n\\begin{gather*}\nm_D : D_i \\sim \\text{Bern}(\\pi) \\\\\n\\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\quad \\text{for $i = 1, \\dots, n_D.$}\n\\end{gather*}\n\\]\nIt is time to start with formal equations! We need to define the PMF corresponding to the above generative model. The statistical literature assigns the following PMF for the a Bernoulli trial \\(D_i\\):\n\\[\nP_{D_i} \\left( D_i = d_i \\mid \\pi \\right) = \\pi^{d_i } (1 - \\pi)^{1 - d_i } \\quad \\text{for $d_i \\in \\{ 0, 1 \\}$.}\n\\tag{2.7}\\]\nA further question arises regarding whether Equation 2.7 satisfies the condition of the total probability of the sample space defined in the Equation 2.6 under the definition of a PMF. This condition states that a valid PMF should result in a total probability equal to one when we sum all the probabilities produced by this function over every possible value that the random variable can take.\nHence, we can state Equation 2.7 is a proper probability distribution (i.e., all the standalone probabilities over the support of \\(D_i\\) add up to one) given that:\n\nProof. \\[\n\\begin{align*}\n\\sum_{d_i = 0}^1 P_{D_i} \\left( D_i = d_i \\mid \\pi \\right) &=  \\sum_{d_i = 0}^1 \\pi^{d_i} (1 - \\pi)^{1 - d_i}  \\\\\n&= \\underbrace{\\pi^0}_{1} (1 - \\pi) + \\pi \\underbrace{(1 - \\pi)^{0}}_{1} \\\\\n&= (1 - \\pi) + \\pi \\\\\n&= 1. \\qquad \\qquad \\qquad \\qquad \\quad \\square\n\\end{align*}\n\\tag{2.8}\\]\n\nIndeed, this Bernoulli PMF is a proper probability distribution!\n\n\nThe probability distribution, obtained from Equation 2.8, is summarized in Table 2.3. Note that the chocolate preference has a probability equal to \\(\\pi\\), whereas the vanilla preference corresponds to the complement \\(1 - \\pi\\). This probability arrangement completely fulfils the corresponding probability condition of the sample space seen in Equation 2.6.\n\n\nTable 2.3: Probability distribution for the \\(i\\)th Bernoulli trial \\(D_i\\).\n\n\n\n\\(d_i\\)\n\\(P_{D_i} \\left( D_i = d_i \\mid \\pi \\right)\\)\n\n\n\n\\(0\\)\n\\(1 - \\pi\\)\n\n\n\\(1\\)\n\\(\\pi\\)\n\n\n\n\n\n\nTo proceed with the time query, we need to analyze the \\(j\\)th continuous random variable \\(T_j\\) and subsequently work with a PDF.\n\n\nDefinition of probability density function (PDF)\n\n\nLet \\(Y\\) be a continuous random variable whose support is \\(\\mathcal{Y}\\). Furthermore, consider a function \\(f_Y(y)\\) such that\n\\[\nf_Y(y) : \\mathbb{R} \\rightarrow \\mathbb{R}\n\\]\nwith\n\\[\nf_Y(y) \\geq 0.\n\\]\nThen, \\(f_Y(y)\\) is considered a PDF if the probability of \\(Y\\) taking on a value within the range represented by the subset \\(A \\subset \\mathcal{Y}\\) is equal to\n\\[\nP_Y(Y \\in A) = \\int_A f_Y(y) \\mathrm{d}y\n\\]\nwith\n\\[\n\\int_{\\mathcal{Y}} f_Y(y) \\mathrm{d}y = 1.\n\\tag{2.9}\\]\n\n\nTo begin our second analysis, let us examine the nature of the variable \\(T_j\\) represented as a continuous random variable. This variable is nonnegative, meaning it is positively unbounded, as it models a waiting time. We can interpret \\(T_j\\) as the waiting time until a specific event of interest occurs, such as when the next customer arrives at the ice cream cart. In statistical literature, this is commonly referred to as a survival time. Hence, we might wonder:\n\nWhat is the most suitable parametric family to model a survival time?\n\n\n\nImage by Manfred Stege via Pixabay.\n\nWell, in this case within our textbook and in general in statistical literature, there is more than one alternative to model a continuous and nonnegative survival time. Appendix C offers four possible ways:\n\n\nExponential. A random variable with a single parameter that can come in either of the following forms:\n\nAs a rate \\(\\lambda \\in (0, \\infty)\\), which generally defines the mean number of events of interest per time interval or space unit.\nAs a scale \\(\\beta \\in (0, \\infty)\\), which generally defines the mean time until the next event of interest occurs.\n\n\n\nWeibull. A random variable that is a generalization of the Exponential distribution. Note its distributional parameters are the scale continuous parameter \\(\\beta \\in (0, \\infty)\\) and shape continuous parameter \\(\\gamma \\in (0, \\infty)\\).\n\nGamma A random variable whose distributional parameters are the shape continuous parameter \\(\\eta \\in (0, \\infty)\\) and scale continuous parameter \\(\\theta \\in (0, \\infty)\\).\n\nLognormal. A random variable whose logarithmic transformation yields a Normal distribution. Its distributional parameters are the Normal location continuous parameter \\(\\mu \\in (-\\infty, \\infty)\\) and Normal scale continuous parameter \\(\\sigma^2 \\in (0, \\infty)\\).\n\nIn our context, as summarized in the corresponding generative model, it is in our best interest to select a probability distribution characterized by a single parameter. Therefore, the Exponential distribution is the most suitable choice for our current time query, particularly under the scale parametrization, since we aim to estimate the waiting time between two customers.\n\n\nHeads-up on survival analysis!\n\n\nAlthough our ice cream case can be straightforwardly modelled using an Exponential distribution for our time query, by using a single population parameter which indicates a mean waiting time between two customers, it is important to stress that other distributions, such as the Weibull, Gamma, or Lognormal, are also entirely valid options. In fact, utilizing these distributions, that involve more than just a standalone parameter, can enhance the flexibility of our data modelling!\n\n\nImage by toushirou_px via Pixabay.\n\nAdditionally, there is a specialized statistical field focused on modelling waiting times—specifically, the time until an event of interest occurs. These types of times are formally referred to as survival times, and the associated field is known as survival analysis. It is worth noting that regression analysis can be extended to this area, and Chapter 6 will provide a more in-depth exploration of various parametric models that involve the Exponential, Weibull, and Lognormal distributions.\n\n\nSince we are using an Exponential distribution, we need to establish our population parameter for this time query. As mentioned in Table 2.2, this parameter refers to the average (or mean) waiting time from one customer to the next. This corresponds to a scale parametrization, where the parameter \\(\\beta \\in (0, \\infty)\\) defines the mean time until the next event of interest occurs (in this case, the next customer!). Therefore, we can specify our generative model as follows:\n\\[\n\\begin{gather*}\nm_T : T_j \\sim \\text{Exponential}(\\beta) \\\\\n\\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\quad \\text{for $j = 1, \\dots, n_T.$}\n\\end{gather*}\n\\]\nSince \\(T_j\\) is a continuous random variable, we must define the PMF corresponding to the above generative model. The statistical literature assigns the following PDF for \\(T_j\\):\n\\[\nf_{T_j} \\left(t_j \\mid \\beta \\right) = \\frac{1}{\\beta} \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\quad \\text{for $t_j \\in [0, \\infty )$.}\n\\tag{2.10}\\]\nNow, we might wonder whether Equation 2.10 satisfies the condition of the total probability of the sample space defined in the Equation 2.9 under the definition of a PDF. This condition states that a valid PDF should result in a total probability equal to one when we integrate this function over all the support of \\(T_j\\).\nThus, we can state that Equation 2.10 is a proper probability distribution (i.e., Equation 2.10 integrates to one over the support of \\(T_j\\)) given that:\n\nProof. \\[\n\\begin{align*}\n\\int_{t_j = 0}^{t_j = \\infty} f_{T_j} \\left(t_j \\mid \\beta \\right) \\mathrm{d}y &= \\int_{t_j = 0}^{t_j = \\infty} \\frac{1}{\\beta} \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\mathrm{d}t_j \\\\\n&= \\frac{1}{\\beta} \\int_{t_j = 0}^{t_j = \\infty} \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\mathrm{d}t_j \\\\\n&= - \\frac{\\beta}{\\beta} \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\Bigg|_{t_j = 0}^{t_j = \\infty} \\\\\n&= - \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\Bigg|_{t_j = 0}^{t_j = \\infty} \\\\\n&= - \\left[ \\exp \\left( -\\infty \\right) - \\exp \\left( 0 \\right) \\right] \\\\\n&= - \\left( 0 - 1 \\right) \\\\\n&= 1. \\qquad \\qquad \\qquad \\qquad \\quad \\square\n\\end{align*}\n\\tag{2.11}\\]\n\nIndeed, the Exponential PDF, under a scale parametrization, is a proper probability distribution!\n\n\nUnlike our demand query, which features a table illustrating the PMF for \\(D_i \\in \\{ 0, 1 \\}\\) (see Table 2.3), it is not feasible to create a table for the PDF of \\(T_j \\in [0, \\infty)\\) because it represents an uncountably infinite set of possible values. However, we can plot the corresponding PDF using three specific members of the Exponential parametric family as examples. Figure 2.2 presents these three example members, with scale parameters values of \\(\\beta = 0.25, 0.5, 1\\) minutes, representing waiting times through their corresponding PDFs. Based on our findings in Equation 2.11, we know that the area under these three density plots equals one, indicating the total probability of the sample space. Additionally, it is important to note that as we increase the scale parameter, larger observed values \\(t_j\\) become more probable.\n\n\n\n\n\n\n\nFigure 2.2: Some members of the Exponential family with scale parametrization.\n\n\n\n\n\n2.1.5 Characterizing Probability Distributions\nBefore moving on into our distributional journey, let us update Table 2.2 with the specific probability distributions, and mathematical definitions of the parameters to estimate per query.\n\n\nTable 2.4: Table containing the corresponding insights to solve our demand and time queries.\n\n\n\n\n\n\n\n\n\nDemand Query\nTime Query\n\n\n\nStatement\nWe would like to know which ice cream flavour is the favourite one (either chocolate or vanilla) and by how much.\nWe would like to know the average waiting time from one customer to the next one in any given ice cream cart.\n\n\nPopulation of interest\n\nChildren between 4 and 11 years old attending different parks in Vancouver, Victoria, Edmonton, Calgary, Winnipeg, Ottawa, Toronto, and Montreal during Summer weekends.\n\nAll our general customer-to-customer waiting times in the different parks of Vancouver, Victoria, Edmonton, Calgary, Winnipeg, Ottawa, Toronto, and Montreal during Summer weekends across the 900 ice cream carts.\n\n\nParameter\n\nProportion of individuals from the population of interest who prefer the chocolate flavour versus the vanilla flavour.\n\nAverage waiting time in minutes from one customer to the next one.\n\n\nRandom variable\n\n\\(D_i\\) for \\(i = 1, \\dots, n_D\\).\n\n\\(T_j\\) for \\(j = 1, \\dots, n_T\\).\n\n\nRandom variable definition\nA favourite ice cream flavour of a randomly surveyed \\(i\\)th child between 4 and 11 years old attending the parks of Vancouver, Victoria, Edmonton, Calgary, Winnipeg, Ottawa, Toronto, and Montreal during the Summer weekends.\nA randomly recorded \\(j\\)th waiting time in minutes between two customers during a Summer weekend across the 900 ice cream carts found in Vancouver, Victoria, Edmonton, Calgary, Winnipeg, Ottawa, Toronto, and Montreal.\n\n\nRandom variable type\nDiscrete and binary.\nContinuous and positively unbounded.\n\n\nRandom variable support\n\n\\(d_i \\in \\{ 0, 1\\}\\) as in Equation 2.3.\n\\(t_j \\in [0, \\infty).\\)\n\n\nProbability distribution\n\\(D_i \\sim \\text{Bern}(\\pi)\\)\n\\(T_j \\sim \\text{Exponential}(\\beta)\\)\n\n\nMathematical definition of the parameter\n\\[\\pi\\]\n\\[\\beta\\]\n\n\n\n\n\n\nLet us proceed, then! We have been exploring the basics of random variables, as well as the importance of generative modelling and probability distributions in addressing different data inquiries. These concepts are fundamental to understanding the population parameter setup before we actually collect data and solve these inquiries to create effective storytelling. Therefore, before we delve into those stages, however, we need to identify and explain efficient ways to summarize probability distributions. This will help us make our storytelling compelling for a general audience, as we will discuss further.\n\n\nHeads-up on coding tabs!\n\n\nYou may be wondering:\n\nWhere do we begin with some R or Python code?\n\nIt is time to introduce our very first lines of code and provide some explanations about the coding approach in this book. As implied in the Preface, our goal is to make this book “bilingual,” meaning that all hands-on coding practices can be performed in either R or Python. Whenever we present a specific proof of concept or data modelling exercise, you will find two tabs: one for R and another for Python. We will first show the input code, followed by the output.\n\n\nImage by Manfred Stege via Pixabay.\n\nWith this format, you can choose your coding journey based on your language preferences and interests as you progress throughout the book.\n\n\nAlright! Moving forward with the code, we need to work with some simulated populations to create the corresponding proofs of concept in this section and the subsequent ones. Let us start with our demand query. We will consider a population size of \\(N_D = 2,000,000\\) children (whose characteristics are defined in Table 2.4). The code (in either R or Python) below assigns this value as N_D, along with a simulation seed to ensure our results are reproducible. Additionally, for the simulation purposes related to our generative modelling, we will assume that \\(65\\%\\) of these children prefer chocolate over vanilla (i.e., \\(\\pi = 0.65\\)).\n\n\nHeads-up on real and unknown parameters!\n\n\nAlthough we are assigning a value of \\(\\pi = 0.65\\) as our true population parameter in this query, we can never know the exact value in practice unless we conduct a full census. This is why we rely on probabilistic tools, via random sampling and statistical inference, to estimate this \\(\\pi\\) in frequentist statistics.\n\n\nLet us recall that we are assuming each child as a Bernoulli trial, where a success (denoted as 1) indicates that the child “prefers chocolate.” This also reflects the flavour mapping in the code. Furthermore, instead of using a Bernoulli random number generator, we are utilizing a Binomial random number generator. This is because the Binomial case with parameters \\(n = 1\\) and \\(\\pi\\) is equivalent to a Bernoulli trial with parameter \\(\\pi\\). Hence, consider the following Binomial case:\n\\[\nY \\sim \\text{Bin}(n = 1, \\pi),\n\\]\nwhose PMF is simplified as a Bernoulli given that\n\\[\n\\begin{align*}\nP_Y \\left( Y = y \\mid n = 1, \\pi \\right) &= {1 \\choose y} \\pi^y (1 - \\pi)^{1 - y} \\\\\n&= \\underbrace{\\frac{1!}{y!(1 - y)!}}_{\\text{$1$ for $y \\in \\{ 0, 1 \\}$}} \\pi^y (1 - \\pi)^{1 - y} \\\\\n&= \\pi^y (1 - \\pi)^{1 - y} \\\\\n& \\qquad \\qquad \\qquad \\qquad \\qquad \\text{for $y \\in \\{ 0, 1 \\}$.}\n\\end{align*}\n\\]\nThe final output of this quick simulation, which models a population of \\(N_D\\) children as Bernoulli trials with a probability of success \\(\\pi = 0.65\\), consists of a data frame containing \\(N_D = 2,000,000\\) rows, with each row representing a child and their preferred ice cream flavor: either chocolate or vanilla. It is worth noting that the outputs from both R and Python differ due to the fact that each language employs different pseudo-random number generators (even though we use the same seed).\n\n\nR Code\nPython Code\n\n\n\nset.seed(123)  # Seed for reproducibility\n\n# Population size\nN_D &lt;- 2000000\n\n# Simulate binary outcomes: 1 = chocolate, 0 = vanilla\nflavour_bin &lt;- rbinom(N_D, size = 1, prob = 0.65)\n\n# Map binary to flavour names\nflavours &lt;- ifelse(flavour_bin == 1, \"chocolate\", \"vanilla\")\n\n# Create data frame\nchildren_pop &lt;- data.frame(\n  children_ID = 1:N_D,\n  fav_flavour = flavours\n)\n\n# Showing the first 100 children of the population\nhead(children_pop, n = 100) \n\n\n# Importing libraries\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(123)   # Seed for reproducibility\n\n# Population size\nN_D = 2000000\n\n# Simulate binary outcomes: 1 = chocolate, 0 = vanilla\nflavour_bin = np.random.binomial(n = 1, p = 0.65, size = N_D)\n\n# Map binary to flavour names\nflavours = np.where(flavour_bin == 1, \"chocolate\", \"vanilla\")\n\n# Create data frame\nchildren_pop = pd.DataFrame({\n    \"children_ID\": np.arange(1, N_D + 1),\n    \"fav_flavour\": flavours\n})\n\n# Showing the first 100 children of the population\nprint(children_pop.head(100))\n\n\n\n\n\nR Output\nPython Output\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn our time query, we will simulate another population consisting of \\(N_T = 500,000\\) general customer-to-customer waiting times (as defined in Table 2.4). The code below assigns this population size to the variable N_T. We have already established that this class of data will be modelled using an Exponential distribution under a scale parameterization, where the parameter \\(\\beta\\) defines the mean waiting time between customers. For this query, we will assume that the population of waiting times has a true parameter value of \\(\\beta = 10\\) minutes. Therefore, the code below illustrates this generative modelling mechanism, which produces a data frame containing \\(N_T = 500,000\\) rows, with each row representing a specific waiting time in minutes.\n\n\nR Code\nPython Code\n\n\n\nset.seed(123)  # Seed for reproducibility\n\n# Population size\nN_T &lt;- 500000\n\n# In R, 'rate' is 1 / scale and rounding to two decimal places\nwaiting_times &lt;- round(rexp(N_T, rate = 1 / 10), 2)\n\n# Create data frame\nwaiting_pop &lt;- data.frame(\n  time_ID = 1:200,\n  waiting_time = waiting_times\n)\n\n# Showing the first 100 waiting times of the population\nhead(waiting_pop, n = 100)\n\n\nnp.random.seed(123)  # Seed for reproducibility\n\n# Population size\nN_T = 500000\n\n# Simulate waiting times\nwaiting_times = np.round(np.random.exponential(scale = 10, size = N_T), 2)\n\n# Create DataFrame\nwaiting_pop = pd.DataFrame({\n    \"time_ID\": np.arange(1, N_T + 1),\n    \"waiting_time\": waiting_times\n})\n\n# Showing the first 100 waiting times of the population\nprint(waiting_pop.head((100))\n\n\n\n\n\nR Output\nPython Output\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImagine that the data collection and analysis for the ice cream case have progressed into the future. You have a follow-up meeting with the eight general managers, one from each Canadian city, to discuss the statements related to both demand and time queries, as shown in Table 2.4 in relation to our populations of interest. Additionally, you have collected data from a sample of \\(n_D = 500\\) randomly surveyed children across these eight Canadian cities. Note that the corresponding R and Python sampling functions perform simple random sampling by default.\n\n\nR Code\nPython Code\n\n\n\nset.seed(123)  # Seed for reproducibility\n\n# Simple random sample of 500 children\nchildren_sample &lt;- children_pop[sample(1:nrow(children_pop), 500), ]\n\n# Showing the first 100 sampled children\nhead(children_sample, n = 100)\n\n\nnp.random.seed(123)  # Seed for reproducibility\n\n# Simple random sample of 500 rows\nchildren_sample = children_pop.sample(n = 500)\n\n# Showing the first 100 sampled children\nprint(children_sample.head(100))\n\n\n\n\n\nR Output\nPython Output\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlso, you have sampled data on \\(n_T = 200\\) randomly recorded waiting times between customers across our 900 ice cream carts in the same cities.\n\n\nR Code\nPython Code\n\n\n\nset.seed(123)  # Seed for reproducibility\n\n# Simple random sample of 200 waiting times\nwaiting_sample &lt;- waiting_pop[sample(1:nrow(waiting_pop), 200), ]\n\n# Showing the first 100 sampled waiting times\nhead(waiting_sample, n = 100)\n\n\nnp.random.seed(123)  # Seed for reproducibility\n\n# Simple random sample of 200 waiting times\nwaiting_sample = waiting_pop.sample(n = 500)\n\n# Showing the first 100 sampled waiting times\nprint(waiting_sample.head(100))\n\n\n\n\n\nR Output\nPython Output\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn terms of the executive meeting with the eight general managers, it would not be an efficient use of time to go individually over these \\(n_D = 500\\) and \\(n_T = 200\\) data points along with abstract mathematical concepts such as PMFs or PDFs, as well as probabilistic definitions of random variables and parameters represented by Greek letters. Instead, there should be a more straightforward and simple way to explain how these \\(n_D\\) and \\(n_T\\) observed random variables behaved during our data collection process. The key to addressing this complexity lies in understanding measures of central tendency and uncertainty.\n\n\nHeads-up on population and sample-based measures of central tendency and uncertainty!\n\n\nWhen learning about measures of central tendency and uncertainty, it is best to begin with those directly related to our population(s) of interest. These concepts provide valuable insights into how any given population behaves concerning typical values and spread. Subsequently, through sampled data, we can derive estimates for these population-based measures.\nIn this section, we will focus on the population measures, while Section 2.2 and Section 2.3 will examine the sample-based measures, which are simply the corresponding estimates. Of course, the latter measures will eventually be used in the upcoming executive meeting within the ice cream case. But, for now, let us immerse ourselves a bit into the theory behind the population side of things.\n\n\n\n\nImage by Manfred Stege via [Pixabay](https://pixabay.com/vectors/pixel-cells-lecture-lecturer-3976299/.\n\nOur first measure to explore is related to typical values found within any given population, specifically a measure of central tendency. We can think of this measure as representing “the most common value” we can expect when observing a certain number of random variables that are drawn from this particular population. Let us start with its formal definition.\n\n\nDefinition of measure of central tendency\n\n\nProbabilistically, a measure of central tendency is defined as a metric that identifies a central or typical value of a given probability distribution. In other words, a measure of central tendency refers to a central or typical value that a given random variable might take when we observe various realizations of this variable over a long period.\n\n\nImage by Manfred Stege via Pixabay.\n\n\n\nThere is more than one measure of central tendency in the statistical literature. However, for the regression models discussed in this book, we will focus on the expected value (see the definition below), which is commonly referred to as the average or mean. You will notice that this measure is closely related to the mainstream average we use in our everyday life.\n\n\nDefinition of expected value\n\n\nLet \\(Y\\) be a random variable whose support is \\(\\mathcal{Y}\\). In general, the expected value or mean \\(\\mathbb{E}(Y)\\) of this random variable is defined as a weighted average according to its corresponding probability distribution. In other words, this measure of central tendency \\(\\mathbb{E}(Y)\\) aims to find the middle value of this random variable by weighting all its possible values in its support \\(\\mathcal{Y}\\) as dictated by its probability distribution.\nGiven the above definition, when \\(Y\\) is a discrete random variable whose PMF is \\(P_Y(Y = y)\\), then its expected value is mathematically defined as\n\\[\n\\mathbb{E}(Y) = \\sum_{y \\in \\mathcal{Y}} y \\cdot P_Y(Y = y).\n\\tag{2.12}\\]\nWhen \\(Y\\) is a continuous random variable whose PDF is \\(f_Y(y)\\), its expected value is mathematically defined as\n\\[\n\\mathbb{E}(Y) = \\int_{\\mathcal{Y}} y \\cdot f_Y(y) \\mathrm{d}y.\n\\tag{2.13}\\]\n\n\nImage by Manfred Stege via Pixabay.\n\n\n\n\n\nTip on further measures of central tendency!\n\n\nIn addition to the expected value, there are other measures that will not be explored in this book such as:\n\n\nMode: For a discrete random variable, the mode is the outcome that corresponds to the highest probability in the PMF. In the case of a continuous random variable, the mode refers to the outcome at which the maximum value occurs in the corresponding PDF.\n\nMedian: This measure primarily relates to continuous random variables. The median is the outcome for which there is a probability of \\(0.5\\) for observing a value either greater or lesser than it.\n\n\n\nNote that the discrete random variable case in Equation 2.12 somehow resembles the mainstream average, which actually would assign an equal weight to each possible outcome of the random variable. On the other hand, for the above statistical definition, we use the corresponding PMF to assign these weights by possible outcome of the discrete random variable.\nLet us exemplify this by using our demand query. Recall that the \\(i\\)th discrete random variable (as in Table 2.4) \\(D_i\\) is distributed as follows:\n\\[\nD_i \\sim \\text{Bern}(\\pi),\n\\]\nwhose PMF is defined as\n\\[\nP_{D_i} \\left( D_i = d_i \\mid \\pi \\right) = \\pi^{d_i } (1 - \\pi)^{1 - d_i } \\quad \\text{for $d_i \\in \\{ 0, 1 \\}$.}\n\\]\nNow, by applying Equation 2.12, note we have the following result (which is in fact the formal proof of the expected value of Bernoulli trial!):\n\nProof. \\[\n\\begin{align*}\n\\mathbb{E}(D_i) &= \\sum_{d_i = 0}^1 d_i P_{D_i} \\left( D_i = d_i \\mid \\pi \\right) \\\\\n&= \\sum_{d_i = 0}^1 d_i \\left[ \\pi^{d_i} (1 - \\pi)^{1 - d_i} \\right] \\\\\n&= \\underbrace{(0) \\left[ \\pi^0 (1 - \\pi) \\right]}_{0} + (1) \\left[ \\pi (1 - \\pi)^{0} \\right] \\\\\n&= 0 + \\pi \\\\\n&= \\pi. \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\quad \\square\n\\end{align*}\n\\tag{2.14}\\]\n\nFor the specific case of a Bernoulli-type population, we have just found that the its expected value (from Equation 2.14) is equal to the corresponding parameter we aim to estimate, which is \\(\\pi\\). Then, you might wonder:\n\nIn practical terms for our ice cream company, how can I explain \\(\\mathbb{E}(D_i) = \\pi\\)?\n\nSuppose you sample a sufficiently large number of children (i.e., your sample size \\(n_D \\rightarrow \\infty\\)) from a Bernoulli-type population where \\(65\\%\\) of these children prefer chocolate over vanilla (i.e., \\(\\pi = 0.65\\)). Then, you will obtain the proportion of observed random variables \\(d_i\\) (for \\(i = 1, \\dots, n_D\\)) that correspond to \\(1\\) (as in Equation 2.3) which is merely a mainstream average. Theoretically speaking, according to our proof in Equation 2.14, this observed proportion should converge to the true population parameter \\(\\pi = 0.65\\).\nLet us now explore the expected value for a continuous random variable using our time query. Unlike the previous case depicted in Equation 2.12, the continuous counterpart in Equation 2.13 cannot utilize a summation. Instead, since we have an uncountably infinite set of possible values for a continuous random variable, we must use an integral. This integral involves the corresponding PDF, which weights all possible observed outcomes of the continuous random variable in conjunction with the differential.\nMoving along in this query, recall the \\(j\\)th continuous random variable (as in Table 2.4) \\(T_j\\) is distributed as follows:\n\\[\nT_j \\sim \\text{Exponential}(\\beta),\n\\]\nwhose PDF is defined as\n\\[\nf_{T_j} \\left(t_j \\mid \\beta \\right) = \\frac{1}{\\beta} \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\quad \\text{for $t_j \\in [0, \\infty )$.}\n\\]\nNow, by applying Equation 2.13, note we have the following result (which is the formal proof of the expected value of an Exponential-distributed random variable under a scale parametrization!):\n\nProof. \\[\n\\begin{align*}\n\\mathbb{E}(T_j) &= \\int_{t_j = 0}^{t_j = \\infty} t_j f_{T_j} \\left(t_j \\mid \\beta \\right) \\mathrm{d}t_j \\\\\n&= \\int_{t_j = 0}^{t_j = \\infty} \\frac{t_j}{\\beta} \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\mathrm{d}t_j \\\\\n&= \\frac{1}{\\beta} \\int_{t_j = 0}^{t_j = \\infty} t_j \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\mathrm{d}t_j. \\\\\n\\end{align*}\n\\tag{2.15}\\]\nEquation 2.15 cannot be solved straightforwardly, we need to use integration by parts as follows:\n\\[\n\\begin{equation}\n  \\begin{split}\n    u &= t_j \\\\\n    \\mathrm{d}u &= \\mathrm{d}t_j\n  \\end{split}\n\\qquad \\qquad\n  \\begin{split}\n    \\mathrm{d}v &= \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\mathrm{d}t_j \\\\\n    v &= -\\beta \\exp \\left( -\\frac{t_j}{\\beta} \\right),\n  \\end{split}\n\\end{equation}\n\\]\nwhich yields\n\\[\n\\begin{align*}\n\\mathbb{E}(T_j) &= \\frac{1}{\\beta} \\left[ u v \\Bigg|_{t_j = 0}^{t_j = \\infty} - \\int_{t_j = 0}^{t_j = \\infty} v \\mathrm{d}u \\right] \\\\\n&= \\frac{1}{\\beta} \\Bigg\\{ \\left[ -\\beta t_j \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\right] \\Bigg|_{t_j = 0}^{t_j = \\infty} + \\\\\n& \\qquad \\beta \\int_{t_j = 0}^{t_j = \\infty} \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\mathrm{d}t_j \\Bigg\\} \\\\\n&= \\frac{1}{\\beta} \\Bigg\\{ -\\beta \\Bigg[ \\underbrace{\\infty \\times \\exp(-\\infty)}_{0} - \\underbrace{0 \\times \\exp(0)}_{0} \\Bigg] - \\\\\n& \\qquad \\beta^2 \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\Bigg|_{t_j = 0}^{t_j = \\infty} \\Bigg\\} \\\\\n&= \\frac{1}{\\beta} \\left\\{ -\\beta (0) - \\beta^2 \\left[ \\exp \\left( -\\infty \\right) - \\exp \\left( 0 \\right) \\right] \\right\\} \\\\\n&= \\frac{1}{\\beta} \\left[ 0 - \\beta^2 (0 - 1) \\right] \\\\\n&= \\frac{\\beta^2}{\\beta} \\\\\n&= \\beta. \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\quad \\qquad \\qquad \\square\n\\end{align*}\n\\tag{2.16}\\]\n\nAgain, for the specific case of an Exponential-type population, we have just found that the its expected value (from Equation 2.16) is equal to the corresponding parameter we aim to estimate, which is \\(\\beta\\). This yields the following question:\n\nIn practical terms for our ice cream company, how can I explain \\(\\mathbb{E}(T_j) = \\beta\\)?\n\nImagine you sample a sufficiently large number of customer-to-customer waiting times (i.e., your sample size \\(n_T \\rightarrow \\infty\\)) from an Exponential-type population where the true average waiting time is \\(\\beta = 10\\) minutes. Then, you will obtain the mainstream average coming from these observed random variables \\(t_j\\) (for \\(j = 1, \\dots, n_T\\)). Theoretically speaking, according to our proof in Equation 2.16, this observed mainstream average should converge to the true population parameter \\(\\beta = 10\\).\n\n\nHeads-up on the so-called mainstream average!\n\n\nIn general, suppose that you obtain \\(n\\) realizations \\(y_k\\) (for \\(k = 1, \\dots, n\\)) of a given random variable \\(Y\\). The observed mainstream average is given by\n\\[\n\\bar{y} = \\frac{\\sum_{k = 1}^n y_k}{n}.\n\\tag{2.17}\\]\nFor the respective classes of observed random variables in the demand and time queries, Equation 2.17 can be applied to obtain estimates of the corresponding population parameters \\(\\pi\\) and \\(\\beta\\). The statistical rationale for using Equation 2.17 will be expanded in Section 2.2.\n\n\nWe have discussed measures of central tendency in detail, more specifically the mean, which represents typical values derived from observing a standalone random variable over a sufficiently large number of trials, denoted as \\(n\\). Interestingly, there is a useful probabilistic theorem that allows us to calculate expected values for general mathematical functions involving a standalone random variable. This theorem is crucial for obtaining another type of measure related to the spread of a random variable.\nAs we previously highlighted, you might choose to skip the tip admonition below; however, recall the theorem’s mathematical expressions for discrete random variables found in Equation 2.18 and for continuous random variables found in Equation 2.24, as they will be important for the upcoming discussions about our ice cream case.\n\n\nTip on the Law of the Unconscious Statistician!\n\n\nThe law of the unconscious statistician (LOTUS) is a particular theorem in probability theory that allows us to compute a wide variety of expected values. Let us properly define it for both discrete and continuous random variables.\n\nTheorem 2.1 Let \\(Y\\) be a discrete random variable whose support is \\(\\mathcal{Y}\\). The LOTUS indicates that the expected value of a general function \\(g(Y)\\) of this random variable \\(Y\\) can be obtained via \\(g(Y)\\) along with the corresponding PMF \\(P_Y(Y = y)\\). Hence, the expected value of \\(g(Y)\\) can be obtained as\n\\[\n\\mathbb{E}\\left[ g(Y) \\right] = \\sum_{y \\in \\mathcal{Y}} g(y) \\cdot P_Y(Y = y).\n\\tag{2.18}\\]\n\nProof. Let us explore the rationale provided by Soch et al. (2024). Thus, we will rename the general function \\(g(Y)\\) as another random variable called \\(Z\\) such that:\n\\[\nZ = g(Y).\n\\tag{2.19}\\]\nNote this function \\(g(Y)\\) can take on equal values \\(g(y_1), g(y_2), \\dots\\) coming from different observed values \\(y_1, y_2, \\dots\\); for example, if\n\\[\ng(y) = y^2\n\\]\nboth\n\\[\ny_1 = 2 \\quad \\text{and} \\quad y_2 = -2\n\\]\nyield\n\\[\ng(y_1) = g(y_2) = 4.\n\\]\nThe above Equation 2.19 is formally called a random variable transformation from the general function of random variable \\(Y\\), \\(g(Y)\\), to a new random variable \\(Z\\). Having said that, when we set up a transformation of this class, there will be a support mapping from this general function \\(g(Y)\\) to \\(Z\\). This will also yield a proper PMF,\n\\[\nP_Z(Z = z) : \\mathbb{R} \\rightarrow [0, 1] \\quad \\forall z \\in \\mathcal{Z},\n\\]\ngiven that \\(g(Y)\\) is a random variable-based function.\nTherefore, using the expected value definition for a discrete random variable as in Equation 2.12, we have the following for \\(Z\\):\n\\[\n\\mathbb{E}(Z) = \\sum_{z \\in \\mathcal{Z}} z \\cdot P_Z(Z = z).\n\\tag{2.20}\\]\nWithin the support \\(\\mathcal{Z}\\), suppose that \\(z_1, z_2, \\dots\\) are the possible different values of \\(Z\\) corresponding to function \\(g(Y)\\). Then, for the \\(i\\)th value \\(z_i\\) in this correspondence, let \\(I_i\\) be the collection of all \\(y_j\\) such that\n\\[\ng(y_j) = z_i.\n\\tag{2.21}\\]\nNow, let us tweak a bit the above expression from Equation 2.20 to include this setting:\n\\[\n\\begin{align*}\n\\mathbb{E}(Z) &= \\sum_{z \\in \\mathcal{Z}} z \\cdot P_Z(Z = z) \\\\\n&= \\sum_{i} z_i \\cdot P_{g(Y)}(Z = z_i) \\\\\n& \\qquad \\text{we subset the summation to all $z_i$ with $Z = g(Y)$}\\\\\n&= \\sum_{i} z_i \\sum_{j \\in I_i} P_Y(Y = y_j). \\\\\n\\end{align*}\n\\tag{2.22}\\]\nThe last line of Equation 2.22 maps the probabilities associated to all \\(z_i\\) in the corresponding PMF of \\(Z\\), \\(P_Z(\\cdot)\\) via the function \\(g(Y)\\), to the original PMF of \\(Y\\), \\(P_Y(\\cdot)\\), for all those \\(y_j\\) contained in the collection \\(I_i\\). Given that certain values \\(z_i\\) can be obtained with more than one value \\(y_j\\), such as in the above example when \\(g(y) = y^2\\) for \\(y_1 = 2\\) and \\(y_2 = -2\\), note we have a second summation of probabilities applied to the PMF of \\(Y\\).\nMoving along with Equation 2.22 in conjunction with Equation 2.21, we have that:\n\\[\n\\begin{align*}\n\\mathbb{E}(Z) &= \\sum_{i} z_i \\sum_{j \\in I_i} P_Y(Y = y_j) \\\\\n&= \\sum_{i} \\sum_{j \\in I_i} z_i \\cdot P_Y(Y = y_j) \\\\\n&= \\sum_{i} \\sum_{j \\in I_i} g(y_j) \\cdot P_Y(Y = y_j).\n\\end{align*}\n\\tag{2.23}\\]\nThe double summation in Equation 2.23 can be summarized into a single one, given neither of the factors on the right-hand side is subindexed by \\(i\\). Furthermore, this standalone summation can be applied to all \\(y \\in \\mathcal{Y}\\) while getting rid of the subindex \\(j\\) in the factors on the right-hand side:\n\\[\n\\begin{align*}\n\\mathbb{E}(Z) &= \\sum_{i} \\sum_{j \\in I_i} g(y_j) \\cdot P_Y(Y = y_j) \\\\\n&= \\sum_{y \\in \\mathcal{Y}} g(y) \\cdot P_Y(Y = y) \\\\\n&= \\mathbb{E}\\left[ g(Y) \\right].\n\\end{align*}\n\\]\nTherefore, we have:\n\\[\n\\mathbb{E}\\left[ g(Y) \\right] = \\sum_{y \\in \\mathcal{Y}} g(y) \\cdot P_Y(Y = y). \\quad \\square\n\\]\n\n\n\nTheorem 2.2 Let \\(Y\\) be a continuous random variable whose support is \\(\\mathcal{Y}\\). The LOTUS indicates that the expected value of a general function \\(g(Y)\\) of this random variable \\(Y\\) can be obtained via \\(g(Y)\\) along with the corresponding PDF \\(f_Y(y)\\). Thus, the expected value of \\(g(Y)\\) can be obtained as\n\\[\n\\mathbb{E}\\left[ g(Y) \\right] = \\int_{\\mathcal{Y}} g(y) \\cdot f_Y(y).\n\\tag{2.24}\\]\n\nProof. Let us explore the rationale provided by Soch et al. (2024). Hence, we will rename the general function \\(g(Y)\\) as another random variable called \\(Z\\) such that:\n\\[\nZ = g(Y).\n\\tag{2.25}\\]\nAs in the discrete LOTUS proof, the above Equation 2.25 is formally called a random variable transformation from the general function of random variable \\(Y,\\) \\(g(Y)\\), to a new random variable \\(Z\\). Therefore, when we set up a transformation of this class, there will be a support mapping from this general function \\(g(Y)\\) to \\(Z\\). This will also yield a proper PDF:\n\\[\nf_Z(z) : \\mathbb{R} \\rightarrow [0, 1] \\quad \\forall z \\in \\mathcal{Z},\n\\]\ngiven that \\(g(Y)\\) is a random variable-based function.\nNow, we will use the concept of the cumulative distribution function (CDF) for a continuous random variable \\(Z\\):\n\\[\n\\begin{align*}\nF_Z(z) &= P(Z \\leq z) \\\\\n&= P\\left[g(Y) \\leq z \\right] \\\\\n&= P\\left[Y \\leq g^{-1}(z) \\right] \\\\\n&= F_Y\\left[ g^{-1}(z) \\right].\n\\end{align*}\n\\tag{2.26}\\]\nA well-known Calculus result is the inverse function theorem. Assuming that\n\\[\nz = g(y)\n\\]\nis an invertible and differentiable function, then the inverse\n\\[\ny = g^{-1}(z)\n\\tag{2.27}\\]\nmust be differentiable as in:\n\\[\n\\frac{\\mathrm{d}}{\\mathrm{d}z} \\left[ g^{-1}(z) \\right] = \\frac{1}{g' \\left[ g^{-1}(z) \\right]}.\n\\tag{2.28}\\]\nNote that we differentiate Equation 2.27 as follows:\n\\[\n\\frac{\\mathrm{d}}{\\mathrm{d}z} y = \\frac{\\mathrm{d}}{\\mathrm{d}z} \\left[ g^{-1}(z) \\right].\n\\tag{2.29}\\]\nThen, plugging Equation 2.29 into Equation 2.28, we obtain:\n\\[\n\\begin{gather*}\n\\frac{\\mathrm{d}}{\\mathrm{d}z} y = \\frac{1}{g' \\left[ g^{-1}(z) \\right]} \\\\\n\\mathrm{d}y = \\frac{1}{g' \\left[ g^{-1}(z) \\right]} \\mathrm{d}z.\n\\end{gather*}\n\\tag{2.30}\\]\nThen, we use the property that relates the CDF \\(F_Z(z)\\) to the PDF \\(f_Z(z)\\):\n\\[\nf_Z(z) = \\frac{\\mathrm{d}}{\\mathrm{d}z} F_Z(z).\n\\]\nUsing Equation 2.26, we have:\n\\[\n\\begin{align*}\nf_Z(z) &= \\frac{\\mathrm{d}}{\\mathrm{d}z} F_Z(z) \\\\\n&= \\frac{\\mathrm{d}}{\\mathrm{d}z} F_Y\\left[ g^{-1}(z) \\right] \\\\\n&= f_Y\\left[ g^{-1}(z) \\right] \\frac{\\mathrm{d}}{\\mathrm{d}z} \\left[ g^{-1}(z) \\right].\n\\end{align*}\n\\]\nThen, via Equation 2.28, it follows that:\n\\[\nf_Z(z) = f_Y\\left[ g^{-1}(z) \\right] \\frac{1}{g' \\left[ g^{-1}(z) \\right]}.\n\\tag{2.31}\\]\nTherefore, using the expected value definition for a continuous random variable as in Equation 2.13, we have for \\(Z\\) that\n\\[\n\\mathbb{E}(Z) = \\int_{\\mathcal{Z}} z \\cdot f_Z(z) \\mathrm{d}z,\n\\]\nwhich yields via Equation 2.31:\n\\[\n\\mathbb{E}(Z) = \\int_{\\mathcal{Z}} z \\cdot f_Y \\left[ g^{-1}(z) \\right] \\frac{1}{g' \\left[ g^{-1}(z) \\right]} \\mathrm{d}z.\n\\]\nUsing Equation 2.27 and Equation 2.30, it follows that:\n\\[\n\\begin{align*}\n\\mathbb{E}(Z) &= \\int_{\\mathcal{Z}} z \\cdot f_Y(y) \\frac{1}{g' \\left[ g^{-1}(z) \\right]} \\mathrm{d}z \\\\\n&= \\int_{\\mathcal{Y}} g(y) \\cdot f_Y(y) \\mathrm{d}y.\n\\end{align*}\n\\]\nNote the last line in the above equation changes the integration limits to the support of \\(Y\\), given all terms end up depending on \\(y\\) on the right-hand side.\nFinally, given the random variable transformation from Equation 2.25, we have:\n\\[\n\\mathbb{E}\\left[ g(X) \\right] = \\int_{\\mathcal{Y}} g(y) \\cdot f_Y(y) \\mathrm{d}y. \\quad \\square\n\\]\n\n\n\n\nThe previous tip was quite theoretical! With that in mind, let us move on to the next stage where we will measure the spread of a random variable. This type of measure is formally known as a measure of uncertainty. We can think of this measure as a way to quantify the dispersion of any random variable from a specific population as we continue to observe it over a given number of trials. Let us begin with its formal definition.\n\n\nDefinition of measure of uncertainty\n\n\nProbabilistically, a measure of uncertainty refers to the spread of a given random variable when we observe its different realizations in the long term. Note a larger spread indicates more variability in these realizations. On the other hand, a smaller spread denotes less variability in these realizations.\n\n\nImage by Manfred Stege via Pixabay.\n\n\n\nSpecifically for this chapter, we will elaborate on the variance (and its derived measure called standard deviation) as a measure of uncertainty, given that it is commonly used across the different regression models in subsequent chapters. When it comes to exploratory data analysis, Chapter 3 will introduce an additional measure of this class called the interquartile range (IQR).\n\n\nDefinition of variance\n\n\nLet \\(Y\\) be a discrete or continuous random variable whose support is \\(\\mathcal{Y}\\) with a mean represented by \\(\\mathbb{E}(Y)\\). Then, the variance of \\(Y\\) is the mean of the squared deviation from the corresponding mean as follows:\n\\[\n\\text{Var}(Y) = \\mathbb{E}\\left\\{[ Y - \\mathbb{E}(Y)]^2 \\right\\}. \\\\\n\\tag{2.32}\\]\nNote the expression above is equivalent to:\n\\[\n\\text{Var}(Y) = \\mathbb{E} \\left( Y^2 \\right) - \\left[ \\mathbb{E}(Y) \\right]^2.\n\\tag{2.33}\\]\nFinally, to put the spread measurement on the same units of random variable \\(Y\\), the standard devation of \\(Y\\) is merely the square root of \\(\\text{Var}(Y)\\):\n\\[\n\\text{sd}(Y) = \\sqrt{\\text{Var}(Y)}.\n\\tag{2.34}\\]\n\n\nImage by Manfred Stege via Pixabay.\n\n\n\nSome of us might wonder why Equation 2.32 and Equation 2.33 are equivalent. Therefore, we provide the below tip as an optional clarification on this matter. Note the work of Casella and Berger (2024) inspires all these insights.\n\n\nTip on the two mathematical expressions of the variance!\n\n\nProving the equivalence of Equation 2.32 and Equation 2.33, requires the introduction of some further properties of the expected value of a random variable while using the LOTUS.\n\nTheorem 2.3 Let \\(Y\\) be a discrete or continuous random variable. Furthermore, let \\(a\\), \\(b\\), and \\(c\\) be constants. Thus, for any functions \\(g_1(y)\\) and \\(g_2(x)\\) whose means exist, we have that:\n\\[\n\\mathbb{E}\\left[ a g_1(Y) + b g_2(Y) + c \\right] = a \\mathbb{E}\\left[ g_1(Y) \\right] + b \\mathbb{E}\\left[ g_2(Y) \\right] + c.\n\\tag{2.35}\\]\nFirstly, let us prove Equation 2.35 for the discrete case.\n\nProof. Let \\(Y\\) be a discrete random variable whose support is \\(\\mathcal{Y}\\) and PMF is \\(P_Y(Y = y)\\). Let us apply the LOTUS as in Equation 2.18:\n\\[\n\\mathbb{E}\\left[ a g_1(Y) + b g_2(Y) + c \\right] = \\sum_{y \\in \\mathcal{Y}} \\left[ a g_1(y) + b g_2(y) + c \\right] \\cdot P_Y(Y = y).\n\\] We can distribute the summation across each addend as follows:\n\\[\n\\begin{align*}\n\\mathbb{E}\\left[ a g_1(Y) + b g_2(Y) + c \\right] &= \\sum_{y \\in \\mathcal{Y}} \\left[ a g_1(y) \\right] \\cdot P_Y(Y = y) + \\\\\n& \\qquad \\sum_{y \\in \\mathcal{Y}} \\left[ b g_2(y) \\right] \\cdot P_Y(Y = y) + \\\\\n& \\qquad \\sum_{y \\in \\mathcal{Y}} c \\cdot P_Y(Y = y).\n\\end{align*}\n\\]\nLet us take the constants out of the corresponding summations:\n\\[\n\\begin{align*}\n\\mathbb{E}\\left[ a g_1(Y) + b g_2(Y) + c \\right] &= a \\sum_{y \\in \\mathcal{Y}} g_1(y) \\cdot P_Y(Y = y) + \\\\\n& \\qquad b \\sum_{y \\in \\mathcal{Y}} g_2(y) \\cdot P_Y(Y = y) + \\\\\n& \\qquad c \\underbrace{\\sum_{y \\in \\mathcal{Y}} P_Y(Y = y)}_1 \\\\\n&= a \\underbrace{\\sum_{y \\in \\mathcal{Y}} g_1(y) \\cdot P_Y(Y = y)}_{\\mathbb{E} \\left[ g_1(Y) \\right]} + \\\\\n& \\qquad b \\underbrace{\\sum_{y \\in \\mathcal{Y}} g_2(y) \\cdot P_Y(Y = y)}_{\\mathbb{E} \\left[ g_2(Y) \\right]} + c.\n\\end{align*}\n\\]\nFor the first and second addends on the right-hand side in the above equation, let us apply the LOTUS again:\n\\[\n\\mathbb{E}\\left[ a g_1(Y) + b g_2(Y) + c \\right] = a \\mathbb{E} \\left[ g_1(Y) \\right] + b \\mathbb{E} \\left[ g_2(Y) \\right] + c. \\quad \\square\n\\]\n\nSecondly, let us prove Equation 2.35 for the continuous case.\n\nProof. Let \\(Y\\) be a continuous random variable whose support is \\(\\mathcal{Y}\\) and PDF is \\(f_Y(y)\\). Let us apply the LOTUS as in Equation 2.24:\n\\[\n\\mathbb{E}\\left[ a g_1(Y) + b g_2(Y) + c \\right] = \\int_{\\mathcal{Y}} \\left[ a g_1 (y) + b g_2(y) + c \\right] \\cdot f_Y(y) \\mathrm{d}y.\n\\]\nWe distribute the integral on the right-hand side of the above equation:\n\\[\n\\begin{align*}\n\\mathbb{E}\\left[ a g_1(Y) + b g_2(Y) + c \\right] &= \\int_{\\mathcal{Y}} \\left[ a g_1 (y) \\right] \\cdot f_Y(y) \\mathrm{d}y + \\\\\n& \\qquad \\int_{\\mathcal{Y}} \\left[ b g_2(y) \\right] \\cdot f_Y(y) \\mathrm{d}y + \\\\\n& \\qquad \\int_{\\mathcal{Y}} c \\cdot f_Y(y) \\mathrm{d}y.\n\\end{align*}\n\\]\nLet us take the constants out of the corresponding integrals:\n\\[\n\\begin{align*}\n\\mathbb{E}\\left[ a g_1(Y) + b g_2(Y) + c \\right] &= a \\int_{\\mathcal{Y}} g_1 (y) \\cdot f_Y(y) \\mathrm{d}y + \\\\\n& \\qquad b \\int_{\\mathcal{Y}} g_2(y) \\cdot f_Y(y) \\mathrm{d}y + \\\\\n& \\qquad c \\underbrace{\\int_{\\mathcal{Y}} f_Y(y) \\mathrm{d}y}_{1} \\\\\n&= a \\underbrace{\\int_{\\mathcal{Y}} g_1 (y) \\cdot f_Y(y) \\mathrm{d}y}_{\\mathbb{E} \\left[ g_1(Y) \\right]} + \\\\\n& \\qquad b \\underbrace{\\int_{\\mathcal{Y}} g_2(y) \\cdot f_Y(y) \\mathrm{d}y}_{\\mathbb{E} \\left[ g_2(Y) \\right]} + c.\n\\end{align*}\n\\]\nFor the first and second addends on the right-hand side in the above equation, let us apply the LOTUS again:\n\\[\n\\mathbb{E}\\left[ a g_1(Y) + b g_2(Y) + c \\right] = a \\mathbb{E} \\left[ g_1(Y) \\right] + b \\mathbb{E} \\left[ g_2(Y) \\right] + c. \\quad \\square\n\\]\n\n\nFinally, after applying some algebraic rearrangements and the expected value properties shown in Equation 2.35, Equation 2.32 and Equation 2.33 are equivalent as follows:\n\nProof. \\[\n\\begin{align*}\n\\text{Var}(Y) &= \\mathbb{E}\\left\\{[ Y - \\mathbb{E}(Y)]^2 \\right\\} \\\\\n&= \\mathbb{E} \\left\\{ Y^2 - 2Y \\mathbb{E}(Y) + \\left[ \\mathbb{E}(Y) \\right]^2 \\right\\} \\\\\n&= \\mathbb{E} \\left( Y^2 \\right) - \\mathbb{E} \\left[ 2Y \\mathbb{E}(Y) \\right] + \\mathbb{E} \\left[ \\mathbb{E}(Y) \\right]^2 \\\\\n& \\qquad \\text{distributing the expected value operator} \\\\\n&= \\mathbb{E} \\left( Y^2 \\right) - 2 \\mathbb{E} \\left[ Y \\mathbb{E}(Y) \\right] + \\mathbb{E} \\left[ \\mathbb{E}(Y) \\right]^2 \\\\\n& \\qquad \\text{since $2$ is a constant} \\\\\n&= \\mathbb{E} \\left( Y^2 \\right) - 2 \\mathbb{E}(Y) \\mathbb{E} \\left( Y \\right) + \\left[ \\mathbb{E}(Y) \\right]^2 \\\\\n& \\qquad \\text{since $\\mathbb{E}(Y)$ is a constant} \\\\\n&= \\mathbb{E} \\left( Y^2 \\right) - 2 \\left[ \\mathbb{E}(Y) \\right]^2 + \\left[ \\mathbb{E}(Y) \\right]^2 \\\\\n&= \\mathbb{E} \\left( Y^2 \\right) - \\left[ \\mathbb{E}(Y) \\right]^2.  \\qquad \\qquad \\qquad \\qquad \\qquad \\square\n\\end{align*}\n\\]\n\n\n\nIt is time to dig into the application of the variance as a measure of uncertainty for our ice cream case. We will start with the demand query. Let us remember that the \\(i\\)th discrete random variable (as in Table 2.4) \\(D_i\\) is distributed as follows:\n\\[\nD_i \\sim \\text{Bern}(\\pi),\n\\]\nwhose PMF is defined as\n\\[\nP_{D_i} \\left( D_i = d_i \\mid \\pi \\right) = \\pi^{d_i } (1 - \\pi)^{1 - d_i } \\quad \\text{for $d_i \\in \\{ 0, 1 \\}$.}\n\\]\nVia Equation 2.12, the LOTUS in Equation 2.18, and Equation 2.33, the variance of this Bernoulli-distributed random variable \\(D_i\\) can be found as follows:\n\nProof. \\[\n\\begin{align*}\n\\text{Var} (D_i) &= \\mathbb{E} \\left( D_i^2 \\right) - \\left[ \\mathbb{E}(D_i)\\right]^2 \\\\\n&= \\mathbb{E} \\left( D_i^2 \\right) - \\pi^2 \\qquad \\text{since $\\mathbb{E}(D_i) = \\pi$} \\\\\n&= \\sum_{d_i = 0}^1 d_i^2 P_{D_i} \\left( D_i = d_i \\mid \\pi \\right) - \\pi^2 \\qquad \\text{by LOTUS} \\\\\n&= \\left\\{ \\underbrace{(0^2) \\left[ \\pi^0 (1 - \\pi) \\right]}_{0} + \\underbrace{(1^2) \\left[ \\pi (1 - \\pi)^{0} \\right]}_{\\pi} \\right\\} - \\pi^2 \\\\\n&= (0 + \\pi) - \\pi^2 \\\\\n&= \\pi - \\pi^2 \\\\\n&= \\pi (1 - \\pi). \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\quad \\square\n\\end{align*}\n\\]\n\nTherefore, the standard deviation is given by:\n\\[\n\\text{sd}(D_i) = \\sqrt{\\pi (1 - \\pi)}.\n\\]\nSince the above standard deviation puts the variance on the same units of random variable \\(D_i\\), you might wonder:\n\nIn practical terms for our ice cream company, how can I explain \\(\\text{sd}(D_i) = \\sqrt{\\pi (1 - \\pi)}\\)?\n\nBefore discussing the specific case of a Bernoulli-type population where \\(65\\%\\) of children prefer chocolate over vanilla (i.e., a parameter \\(\\pi = 0.65\\)), let us first examine the general case for \\(\\pi \\in [0, 1]\\), as shown in Figure 2.3. In this plot, the range of \\(\\pi\\) is represented on the \\(x\\)-axis, while \\(\\text{sd}(D_i) = \\sqrt{\\pi (1 - \\pi)}\\) is shown on the \\(y\\)-axis. We will initially focus on three specific and increasing values of \\(\\pi\\), which are indicated by orange vertical dashed lines:\n\nWhen \\(\\pi = 0.5\\), it means that there is an equal chance of randomly obtaining either a success (i.e., a \\(1\\)) or a failure (i.e., a \\(0\\)). Note the standard deviation is given by \\(\\text{sd}(D_i) = \\sqrt{(0.5)(1 - 0.5)} = 0.5\\). Therefore, we state that the square root of the average squared distance from the mean is \\(0.5\\). Moreover, in Figure 2.3, this results in the largest spread of observed values (either \\(0\\) or \\(1\\)).\nWhen \\(\\pi = 0.7\\), the standard deviation is \\(\\text{sd}(D_i) = \\sqrt{(0.7)(1 - 0.7)} \\approx 0.46\\). Therefore, we state that the square root of the average squared distance from the mean is \\(0.46\\). In this case, there is a higher chance of randomly getting a success (i.e., a \\(1\\)) compared to a failure (i.e., a \\(0\\)). As a result, there is a smaller spread of observed values around the mean of \\(\\pi = 0.7\\), as most values in this population tend to be \\(1\\).\nWhen \\(\\pi = 0.9\\), the standard deviation is \\(\\text{sd}(D_i) = \\sqrt{(0.9)(1 - 0.9)} = 0.3\\). Here, the chance of obtaining a success (i.e., a \\(1\\)) is even higher than the chance of a failure (i.e., a \\(0\\)). Therefore, we state that the square root of the average squared distance from the mean is \\(0.3\\). This leads to an even smaller spread of observed values around the mean of \\(\\pi = 0.9\\), with most values in this population also being \\(1\\).\n\n\n\n\n\n\n\n\nFigure 2.3: Behaviour of the theoretical Bernoulli’s standard deviation over the range of its distributional parameter.\n\n\n\n\nLet us focus on our specific case where \\(\\pi = 0.65\\) in terms of the standard deviation, represented by the solid purple vertical line in Figure 2.3. Suppose you sample a sufficiently large number of children (i.e., your sample size \\(n_D \\rightarrow \\infty\\)) from a Bernoulli-type population where \\(65\\%\\) of these children prefer chocolate over vanilla. In this scenario, the standard deviation \\(\\text{sd}(D_i) = \\sqrt{(0.65)(1 - 0.65)} \\approx 0.48\\) indicates a slightly smaller spread compared to a population where there is an equal 50-50 chance of preferring chocolate over vanilla. Thus, when \\(\\pi = 0.65\\), the spread of values around the corresponding mean is slightly narrower since a slight majority leans towards preference for chocolate, which is represented by the value \\(1\\).\nTo address our time query, we can use a similar approach to obtain variance, but this time for a continuous random variable. Recall that the \\(j\\)th continuous random variable, denoted as \\(T_j\\), is distributed as follows:\n\\[\nT_j \\sim \\text{Exponential}(\\beta),\n\\]\nwhose PDF is defined as\n\\[\nf_{T_j} \\left(t_j \\mid \\beta \\right) = \\frac{1}{\\beta} \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\quad \\text{for $t_j \\in [0, \\infty )$.}\n\\]\nVia Equation 2.33 and the Equation 2.13 of a continuous expected value, the variance of this Exponential-distributed random variable \\(T_j\\) can be found as follows:\n\nProof. \\[\n\\begin{align*}\n\\text{Var} (T_j) &= \\mathbb{E} \\left( T_j^2 \\right) - \\left[ \\mathbb{E}(T_j)\\right]^2 \\\\\n&= \\mathbb{E} \\left( T_j^2 \\right) - \\beta^2 \\qquad \\text{since $\\mathbb{E}(T_j) = \\beta$}.\n\\end{align*}\n\\tag{2.36}\\]\nWe need to find \\(\\mathbb{E} \\left( T_j^2 \\right)\\) from Equation 2.36. Therefore, we make the following derivation via the LOTUS from Equation 2.24 when \\(g(T_j) = t_j^2\\):\n\\[\n\\begin{align*}\n\\mathbb{E} \\left( T_j^2 \\right) &= \\int_{t_j = 0}^{t_j = \\infty} t_j^2 f_{T_j} \\left(t_j \\mid \\beta \\right) \\mathrm{d}t_j \\\\\n&= \\int_{t_j = 0}^{t_j = \\infty} t_j^2 \\frac{1}{\\beta} \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\mathrm{d}t_j \\\\\n&= \\frac{1}{\\beta} \\int_{t_j = 0}^{t_j = \\infty} t_j^2 \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\mathrm{d}t_j. \\\\\n\\end{align*}\n\\tag{2.37}\\]\nEquation 2.37 cannot be solved straightforwardly, we need to use integration by parts as follows:\n\\[\n\\begin{equation}\n  \\begin{split}\n    u &= t_j^2 \\\\\n    \\mathrm{d}u &= 2t_j \\mathrm{d}t_j\n  \\end{split}\n\\qquad \\qquad\n  \\begin{split}\n    \\mathrm{d}v &= \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\mathrm{d}t_j \\\\\n    v &= -\\beta \\exp \\left( -\\frac{t_j}{\\beta} \\right),\n  \\end{split}\n\\end{equation}\n\\]\nwhich yields\n\\[\n\\begin{align*}\n\\mathbb{E} \\left( T_j^2 \\right) &= \\frac{1}{\\beta} \\left[ u v \\Bigg|_{t_j = 0}^{t_j = \\infty} - \\int_{t_j = 0}^{t_j = \\infty} v \\mathrm{d}u \\right] \\\\\n&= \\frac{1}{\\beta} \\Bigg\\{ \\left[ -\\beta t_j^2 \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\right] \\Bigg|_{t_j = 0}^{t_j = \\infty} + \\\\\n& \\qquad 2 \\beta \\int_{t_j = 0}^{t_j = \\infty} t_j \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\mathrm{d}t_j \\Bigg\\} \\\\\n&= \\frac{1}{\\beta} \\Bigg\\{ -\\beta \\Bigg[ \\underbrace{\\infty \\times \\exp(-\\infty)}_{0} - \\underbrace{0 \\times \\exp(0)}_{0} \\Bigg] + \\\\\n& \\qquad 2 \\beta \\int_{t_j = 0}^{t_j = \\infty} t_j \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\mathrm{d}t_j \\Bigg\\} \\\\\n&= \\frac{1}{\\beta} \\left\\{ -\\beta (0) + 2 \\beta \\int_{t_j = 0}^{t_j = \\infty} t_j \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\mathrm{d}t_j \\right\\} \\\\\n&= \\frac{1}{\\beta} \\left\\{ 0 + 2 \\beta \\int_{t_j = 0}^{t_j = \\infty} t_j \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\mathrm{d}t_j \\right\\} \\\\\n&= 2 \\int_{t_j = 0}^{t_j = \\infty} t_j \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\mathrm{d}t_j. \\\\\n\\end{align*}\n\\tag{2.38}\\]\nAgain, we need to apply integration by parts to solve Equation 2.38:\n\\[\n\\begin{equation}\n  \\begin{split}\n    u &= t_j \\\\\n    \\mathrm{d}u &= \\mathrm{d}t_j\n  \\end{split}\n\\qquad \\qquad\n  \\begin{split}\n    \\mathrm{d}v &= \\exp \\left( -\\frac{t_j}{\\beta} \\right)\\mathrm{d}t_j \\\\\n    v &= -\\beta \\exp \\left( -\\frac{t_j}{\\beta} \\right),\n  \\end{split}\n\\end{equation}\n\\]\nwhich yields\n\\[\n\\begin{align*}\n\\mathbb{E} \\left( T_j^2 \\right) &= 2 \\left[ u v \\Bigg|_{t_j = 0}^{t_j = \\infty} - \\int_{t_j = 0}^{t_j = \\infty} v \\mathrm{d}u \\right] \\\\\n&= 2 \\Bigg\\{ \\left[ -\\beta t_j \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\right] \\Bigg|_{t_j = 0}^{t_j = \\infty} + \\\\\n& \\qquad \\beta \\int_{t_j = 0}^{t_j = \\infty} \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\mathrm{d}t_j \\Bigg\\} \\\\\n&= 2 \\Bigg\\{ -\\beta \\Bigg[ \\underbrace{\\infty \\times \\exp(-\\infty)}_{0} - \\underbrace{0 \\times \\exp(0)}_{0} \\Bigg] - \\\\\n& \\qquad \\beta^2 \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\Bigg|_{t_j = 0}^{t_j = \\infty} \\Bigg\\} \\\\\n&= 2 \\left\\{ -\\beta (0) - \\beta^2 \\left[ \\exp \\left( -\\infty \\right) - \\exp \\left( 0 \\right) \\right] \\right\\} \\\\\n&= 2 \\left[ 0 - \\beta^2 (0 - 1) \\right] \\\\\n&= 2 \\beta^2.\n\\end{align*}\n\\tag{2.39}\\]\nFinally, we plug Equation 2.39 into Equation 2.36:\n\\[\n\\begin{align*}\n\\text{Var} (Y) &= \\mathbb{E} \\left( Y^2 \\right) - \\beta^2 \\\\\n&= 2 \\beta^2 - \\beta^2 \\\\\n&= \\beta^2. \\qquad \\qquad \\square\n\\end{align*}\n\\]\n\nHence, the standard deviation is given by:\n\\[\n\\text{sd}(T_j) = \\sqrt{\\beta^2} = \\beta.\n\\]\nSince the above standard deviation puts the variance on the same units of random variable \\(T_j\\), you might wonder:\n\nIn practical terms for our ice cream company, how can I explain \\(\\text{sd}(T_j) = \\beta\\)?\n\nLet us illustrate the behavior of the standard deviation within the context of the Exponential distribution, using a scale parameterization, through Figure 2.4. On the \\(x\\)-axis, we have the scale parameter \\(\\beta\\), which has a lower bound of \\(0\\) and an upper bound truncated at \\(50\\). Nonetheless, according to the definition of the Exponential distribution, recall that \\(\\beta\\) can range from \\(0\\) to \\(\\infty\\). Interestingly, both axes are measured in minutes, as the parameter definition of \\(\\beta\\) is expressed in the units of the Exponential random variable under this scale parametrization. Additionally, \\(\\text{sd}(T_j)\\) indicates the spread of the \\(T_j\\) in the same units. You can confirm these facts in Table 2.4.\n\n\n\n\n\n\n\nFigure 2.4: Behaviour of the theoretical Exponential’s standard deviation, under a scale parametrization, over a truncated range of its distributional parameter.\n\n\n\n\nFirstly, in Figure 2.4, it is important to emphasize that the relationship between the Exponential parameter \\(\\beta\\) and the standard deviation \\(\\text{sd}(T_j)\\) is linear. We have highlighted three specific cases as vertical lines:\n\nThe orange dotted line on the left indicates a small spread with \\(\\text{sd}(T_j) = 5\\) when \\(\\beta = 5\\). This signifies that the square root of the average squared distance from the mean is 5 minutes for the waiting times corresponding to this specific population.\nThe solid purple line represents our ice cream case, where \\(\\beta = 10\\), resulting in a larger spread with \\(\\text{sd}(T_j) = 10\\) compared to the case above. This means that the square root of the average squared distance from the mean is 10 minutes for the waiting times related to this specific population.\nThe orange dotted line on the right indicates the largest spread, compared to the two cases above, with \\(\\text{sd}(T_j) = 45\\) when \\(\\beta = 45\\). This means that the square root of the average squared distance from the mean is 45 minutes for the waiting times corresponding to this specific population.\n\n\n\nHeads-up on a further estimation technique for the variance!\n\n\nBefore concluding this section, it is important to note that, unlike the expected value case, we will not directly address how a sample-based tool similar to the mainstream average (i.e., Equation 2.17) can be used to estimate the variances for our demand and time queries. Instead, we will introduce a useful property related to the estimation parameter approach discussed in Section 2.2.\n\n\nImage by Manfred Stege via Pixabay.\n\n\n\n\n2.1.6 The Rationale in Random Sampling\nIn Section 2.1.1, we explained that random sampling allows us to save both financial and operational resources compared to conducting an entire census. This approach is particularly beneficial for estimating our population parameters for both demand and time queries. Furthermore, we highlighted that random sampling utilizes probabilistic and inferential tools to manage and report the uncertainty associated with these estimations. In this section, we will begin by examining those probabilistic tools.\nIt is important to note that random sampling is heavily based on the concept of random variables. However, mathematically expressing a set of random variables in a single expression requires the application of certain probabilistic concepts, specifically conditional probability and independence. While we will certainly need Bayes’ rule to connect these two concepts, we will not delve deeper into this rule in the subsequent chapters of this book. Therefore, let us begin with conditional probability.\n\n\nDefinition of conditional probability\n\n\nSuppose you have two events of interest, \\(A\\) and \\(B\\), in a random phenomenon of a population or system of interest. These two events belong to the sample space \\(S\\). Moreover, assume that the probability of event \\(B\\) is such that\n\\[\nP(B) &gt; 0,\n\\]\nwhich is considered the conditioning event.\nHence, the conditional probability of event \\(A\\) given event \\(B\\) is defined as\n\\[\nP(A | B) = \\frac{P(A \\cap B)}{P(B)},\n\\tag{2.40}\\]\nwhere \\(P(A \\cap B)\\) is read as the probability of the intersection of events \\(A\\) and \\(B\\).\n\n\nImage by Manfred Steger via Pixabay.\n\n\n\nHow can we think about the above concept in terms of our ice cream case? Well, let us consider the following in terms of our demand query. For the purpose of this explanation, imagine that we have a small population of \\(N_D = 20\\) children to sample from. We can define an event \\(B\\) as the selection of a specific child, referred to as child B, from this group of \\(N_D = 20\\) children. The probability of selecting child B can be calculated as follows:\n\\[\nP(B) = \\frac{1}{20}.\n\\]\nIf you choose to conduct random sampling without replacement, you will not return any sampled child back to the small population before the next draw. In this context, let us define event \\(A\\) as the selection of a second specific child, referred to as child A. When sampling without replacement, the probability of selecting child A (given you already sampled child B) is determined by calculating the conditional probability\n\\[\nP(A | B) = \\frac{1}{19}.\n\\]\nIn the above ratio, note we have updated the sample space to just 19 children given event \\(A\\) is conditioned on \\(B\\). Finally, how can we connect these two probabilities with the intersection \\(P(A \\cap B)\\) found in Equation 2.40? We can view this intersection as the probability of a sequence of two events:\n\nWe sample child B from our initial pool of \\(N_D = 20\\) children.\nThen, from the updated pool of \\(N_D - 1 = 19\\) children since we are sampling without replacement, we sample child A.\n\nProbabilistically, this sequence is expressed as follows:\n\\[\n\\begin{align*}\nP(A \\cap B) &= P(B \\cap A) \\\\\n&= P(B) \\times P(A | B) \\\\\n&= \\frac{1}{20} \\times \\frac{1}{19} = \\frac{1}{380}.\n\\end{align*}\n\\]\n\n\nTip on the rationale behind conditional probability!\n\n\nWe can delve into the rationale of Equation 2.40 by using a handy probabilistic concept called cardinality, which refers to the corresponding total number of possible outcomes in a random phenomenon belonging to any given event or sample space.\n\nProof. Let \\(|S|\\) be the cardinality corresponding to the sample space in a random phenomenon. Hence, as in Equation 2.2, we have that:\n\\[\nP(S) = \\frac{|S|}{|S|} = 1.\n\\]\nMoreover, suppose that \\(A\\) is the primary event of interest whose cardinality is represented by \\(|A|\\). Alternatively to Equation 2.1, the probability of \\(A\\) can be represented as\n\\[\nP(A) = \\frac{|A|}{|S|}.\n\\]\nOn the other hand, the cardinality of the conditioning event is\n\\[\nP(B) = \\frac{|B|}{|S|}.\n\\tag{2.41}\\]\nNow, let \\(|A \\cap B|\\) be the cardinality of the intersection between events \\(A\\) and \\(B\\). Its probability can be represented as:\n\\[\nP(A \\cap B) = \\frac{|A \\cap B|}{|B|}.\n\\tag{2.42}\\]\nAnalogous to Equation 2.41 and Equation 2.42, we can view the conditional probability \\(P(A | B)\\) as an updated probability of the primary event \\(A\\) restricted to the cardinality of the conditioning event \\(|B|\\). This places \\(|A \\cap B|\\) in the numerator and \\(|B|\\) in the denominator as follows:\n\\[\nP(A | B) = \\frac{|A \\cap B|}{|B|}.\n\\tag{2.43}\\]\nTherefore, we can play around with Equation 2.43 along with Equation 2.41 and Equation 2.42 as follows:\n\\[\n\\begin{align*}\nP(A | B) &= \\frac{|A \\cap B|}{|B|} \\\\\n&= \\frac{\\frac{|A \\cap B}{|S|}}{\\frac{|B|}{|S|}} \\qquad \\text{dividing numerator and denominator over $|S|$} \\\\\n&= \\frac{P(A \\cap B)}{P(B)}. \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\quad \\square\n\\end{align*}\n\\]\n\n\n\nTo connect the previous result regarding conditional probability with the concept of statistical independence, we need to utilize Bayes’ rule, which is another important result in probability theory. It is worth noting that this principle is a fundamental aspect of Bayesian statistics.\n\n\nDefinition of the Bayes’ rule\n\n\nSuppose you have two events of interest, \\(A\\) and \\(B\\), in a random phenomenon of a population or system of interest. From Equation 2.40, we can state the following expression for the conditional probability of \\(A\\) given \\(B\\):\n\\[\nP(A | B) = \\frac{P(A \\cap B)}{P(B)} \\quad \\text{if $P(B) &gt; 0$.}\n\\tag{2.44}\\]\nNote the conditional probability of \\(B\\) given \\(A\\) can be stated as:\n\\[\n\\begin{align*}\nP(B | A) &= \\frac{P(B \\cap A)}{P(A)} \\quad \\text{if $P(A) &gt; 0$} \\\\\n&= \\frac{P(A \\cap B)}{P(A)} \\quad \\text{since $P(B \\cap A) = P(A \\cap B)$.}\n\\end{align*}\n\\tag{2.45}\\]\nThen, we can manipulate Equation 2.45 as follows:\n\\[\nP(A \\cap B) = P(B | A) \\times P(A).\n\\]\nThe above result can be plugged into Equation 2.44:\n\\[\n\\begin{align*}\nP(A | B) &= \\frac{P(A \\cap B)}{P(B)} \\\\\n&= \\frac{P(B | A) \\times P(A)}{P(B)}.\n\\end{align*}\n\\tag{2.46}\\]\nEquation 2.46 is called the Bayes’ rule. We are basically flipping around conditional probabilities.\n\n\nEven though this textbook has a frequentist tone, let us quickly connect Equation 2.46 with the elements mentioned in the definition of Bayesian statistics:\n\\[\nP(A | B) = \\frac{P(B | A) \\times P(A)}{P(B)}.\n\\]\n\n\n\\(P(A | B)\\) is known as the posterior probability of observing a primary event \\(A\\) given the conditioning event \\(B\\), which is referred to as the current evidence.\n\n\\(P(B | A)\\) is the conditional probability of observing the current evidence represented by event \\(B\\) given that the primary event \\(A\\) has occurred.\n\n\\(P(A)\\) is called the prior probability of observing the primary event \\(A\\).\n\n\\(P(B)\\) represents the overall probability of observing the current evidence represented by event \\(B\\), without considering event \\(A\\).\n\nFinally, let us use all the above results to elaborate on what statistical independence is.\n\n\nDefinition of independence\n\n\nSuppose you have two events of interest, \\(A\\) and \\(B\\), in a random phenomenon of a population or system of interest. These two events are statistically independent if event \\(B\\) does not affect event \\(A\\) and vice versa. Therefore, the probability of their corresponding intersection is given by:\n\\[\nP(A \\cap B) = P(A) \\times P(B).\n\\tag{2.47}\\]\nLet us expand the above definition to a random variable framework:\n\nSuppose you have a set of \\(n\\) discrete random variables \\(Y_1, \\dots, Y_n\\) whose supports are \\(\\mathcal{Y_1}, \\dots, \\mathcal{Y_n}\\) with PMFs \\(P_{Y_1}(Y_1 = y_1), \\dots, P_{Y_n}(Y_n = y_n)\\) respectively. That said, the joint PMF of these \\(n\\) random variables is the multiplication of their corresponding standalone PMFs:\n\n\\[\n\\begin{align*}\nP_{Y_1, \\dots, Y_n}(Y_1 = y_1, \\dots, Y_n = y_n) &= \\prod_{i = 1}^n P_{Y_i}(Y_i = y_i) \\\\\n& \\qquad \\text{for all} \\\\\n& \\qquad \\quad y_i \\in \\mathcal{Y}_i, i = 1, \\dots, n.\n\\end{align*}\n\\tag{2.48}\\]\n\nSuppose you have a set of \\(n\\) continuous random variables \\(Y_1, \\dots, Y_n\\) whose supports are \\(\\mathcal{Y_1}, \\dots, \\mathcal{Y_n}\\) with PDFs \\(f_{Y_1}(y_1), \\dots, f_{Y_n}(y_n)\\) respectively. That said, the joint PDF of these \\(n\\) random variables is the multiplication of their corresponding standalone PDFs:\n\n\\[\n\\begin{align*}\nf_{Y_1, \\dots, Y_n}(y_1, \\dots, y_n) &= \\prod_{i = 1}^n f_{Y_i}(y_i) \\\\\n& \\qquad \\text{for all} \\\\\n& \\qquad \\quad y_i \\in \\mathcal{Y}_i, i = 1, \\dots, n.\n\\end{align*}\n\\tag{2.49}\\]\n\n\nLet us clarify Equation 2.47 using our ice cream case in relation to our demand query. We will revisit the scenario involving a small population consisting of \\(N_D = 20\\) children. We can define an event \\(B\\) as the selection of a specific child, referred to as child B, from these \\(N_D = 20\\) children. The probability of selecting child B can be calculated as follows:\n\\[\nP(B) = \\frac{1}{20}.\n\\]\nWhen conducting random sampling with replacement, each sampled child is returned to the population before the next draw. Let us define event \\(A\\) as the selection of a specific child, referred to as child A. In this type of sampling, event \\(B\\) does not influence event \\(A\\); in other words, \\(A\\) and \\(B\\) are statistically independent. Therefore, when sampling with replacement, the probability of selecting child A, given that you have already sampled child B, can be determined by calculating the conditional probability\n\\[\nP(A | B) = \\frac{1}{20}.\n\\]\nIn the above ratio, we do not need to update the sample space. We will still have 20 children available for sampling for event \\(A\\):\n\\[\nP(A) = P(A | B) = \\frac{1}{20}.\n\\]\nTherefore, we can connect the probabilities \\(P(A)\\) and \\(P(B)\\) with the intersection \\(P(A \\cap B)\\). Again, this intersection is the probability of a sequence of two events:\n\nWe sample child B from our initial pool of \\(N_D = 20\\) children.\nThen, using the same pool of \\(N_D = 20\\) children since we are sampling with replacement, we sample child A.\n\nProbabilistically, this sequence is expressed as follows:\n\\[\n\\begin{align*}\nP(A \\cap B) &= P(B \\cap A) \\\\\n&= P(B) \\times P(A | B) \\\\\n&= P(B) \\times P(A) \\\\\n&= \\frac{1}{20} \\times \\frac{1}{20} = \\frac{1}{400}.\n\\end{align*}\n\\]\nThis is Equation 2.47! The tip below theoretically delves further into this equation, but you can skip it if you prefer.\n\n\nTip on the rationale behind the rule of independent events!\n\n\nWe can delve into the rationale of Equation 2.47 by using the Bayes’ rule from Equation 2.46 along with the basic conditional probability formula from Equation 2.40.\n\nProof. Firstly, let us assume that a given event \\(B\\) does not affect event \\(A\\) which can be probabilistically represented as\n\\[\nP(A | B) = P(A).\n\\tag{2.50}\\]\nIf the statement in Equation 2.50 holds, by using the Bayes’ rule from Equation 2.46, we have the following manipulation for the below conditional probability formula:\n\\[\n\\begin{align*}\nP(B | A) &= \\frac{P(B \\cap A)}{P(A)} \\\\\n&= \\frac{P(A \\cap B)}{P(A)} \\qquad \\text{since $P(B \\cap A) = P(A \\cap B$)} \\\\\n&= \\frac{P(A | B) \\times P(B)}{P(A)} \\qquad \\text{by the Bayes' rule} \\\\\n&= \\frac{P(A) \\times P(B)}{P(A)} \\qquad \\text{since $P(A | B) = P(A)$} \\\\\n&= P(B).\n\\end{align*}\n\\]\nThen, again by using the Bayes’ rule, we obtain \\(P(B \\cap A)\\) as follows:\n\\[\n\\begin{align*}\nP(B \\cap A) &= P(B | A) \\times P(A) \\\\\n&= P(B) \\times P(A) \\qquad \\text{since $P(B | A) = P(B)$.}\n\\end{align*}\n\\]\nFinally, we have that:\n\\[\n\\begin{align*}\nP(A \\cap B) &= P(B \\cap A) \\\\\n&= P(B) \\times P(A) \\\\\n&= P(A) \\times P(B). \\qquad \\square\n\\end{align*}\n\\]\n\n\n\nIt is time to outline how our random sampling with replacement (as mentioned in Section 2.1.3) for both demand and time queries can be mathematically represented using random variables. This representation should also involve a crucial statistical concept such as the random sample. Ultimately, we aim to construct what is known as joint probability distributions, which can take the form of either PMF or PDF depending on the type of random variables we are dealing with.\nThe previously introduced ideas by Equation 2.48 and Equation 2.49 serve as the primary steps for our discrete (Bernoulli trials as discussed by Equation 2.7) and continuous (waiting times as demonstrated by Equation 2.10) random variables respectively. However, these probability distributions will require an extra tweak, as discussed below.\n\n\nDefinition of random sample\n\n\nA random sample is a collection of random variables \\(Y_1, \\dots, Y_n\\) of size \\(n\\) coming from a given population or system of interest. Note that the most elementary definition of a random sample assumes that these \\(n\\) random variables are mutually independent and identically distributed (which is abbreviated as iid).\nThe fact that these \\(n\\) random variables are identically distributed indicates that they have the same mathematical form for their corresponding PMFs or PDFs, depending on whether they are discrete or continuous respectively. Hence, under a generative modelling approach in a population or system of interest governed by \\(k\\) parameters contained in the vector\n\\[\n\\boldsymbol{\\theta} = (\\theta_1, \\theta_2, \\cdots, \\theta_k)^T,\n\\]\nwe can apply the iid property in an elementary random sample to obtain the following joint probability distributions:\n\nIn the case of \\(n\\) iid discrete random variables \\(Y_1, \\dots, Y_n\\) whose common standalone PMF is \\(P_Y(Y = y | \\boldsymbol{\\theta})\\) with support \\(\\mathcal{Y}\\), the joint PMF is mathematically expressed as\n\n\\[\n\\begin{align*}\nP_{Y_1, \\dots, Y_n}(Y_1 = y_1, \\dots, Y_n = y_n | \\boldsymbol{\\theta}) &= \\prod_{i = 1}^n P_Y(Y = y_i | \\boldsymbol{\\theta}) \\\\\n& \\quad \\text{for all} \\\\\n& \\quad \\quad y_i \\in \\mathcal{Y}, i = 1, \\dots, n.\n\\end{align*}\n\\tag{2.51}\\]\n\nIn the case of \\(n\\) iid continuous random variables \\(Y_1, \\dots, Y_n\\) whose common standalone PDF is \\(f_Y(y | \\boldsymbol{\\theta})\\) with support \\(\\mathcal{Y}\\), the joint PDF is mathematically expressed as\n\n\\[\n\\begin{align*}\nf_{Y_1, \\dots, Y_n}(y_1, \\dots, y_n | \\boldsymbol{\\theta}) &= \\prod_{i = 1}^n f_Y(y_i | \\boldsymbol{\\theta}) \\\\\n& \\quad \\text{for all} \\\\\n& \\quad \\quad y_i \\in \\mathcal{Y}, i = 1, \\dots, n.\n\\end{align*}\n\\tag{2.52}\\]\nUnlike Equation 2.48 and Equation 2.49, note that Equation 2.51 and Equation 2.52 do not indicate a subscript for \\(Y\\) in the corresponding probability distributions since we have identically distributed random variables. Furthermore, the joint distributions are conditioned on the population parameter vector \\(\\boldsymbol{\\theta}\\) which reflects our generative modelling approach.\n\n\nImage by Manfred Steger via Pixabay.\n\n\n\nAlright! We are ready to deliver our joint probability distributions for our ice cream case assuming sampling with replacement. Thus, in the demand query via a random sample under the iid property along with the standalone PMF for \\(D_i\\)\n\\[\nP_{D_i} \\left( D_i = d_i \\mid \\pi \\right) = \\pi^{d_i } (1 - \\pi)^{1 - d_i } \\quad \\text{for $d_i \\in \\{ 0, 1 \\}$},\n\\]\nour joint PMF is\n\\[\n\\begin{align*}\nP_{D_1, \\dots, D_{n_D}} \\left( D_1 = d_1, \\dots, D_{n_D} = d_{n_D} | \\pi \\right) &= \\prod_{i = 1}^{n_D} P_{D_i} \\left( D_i = d_i \\mid \\pi \\right) \\\\\n&= \\prod_{i = 1}^{n_D} P_D \\left( D = d_i \\mid \\pi \\right) \\\\\n& \\qquad \\qquad \\qquad \\quad \\quad \\text{iid} \\quad \\\\\n&= \\prod_{i = 1}^{n_D} \\pi^{d_i } (1 - \\pi)^{1 - d_i } \\\\\n& \\quad \\text{for all} \\\\\n& \\quad \\quad d_i \\in \\{ 0, 1 \\}, \\\\\n& \\qquad \\quad i = 1, \\dots, n_D.\n\\end{align*}\n\\tag{2.53}\\]\nIt is important to clarify that \\(n_D\\) refers to our sample size for this query. In contrast, our vector of population parameters consists of a single element: the probability of success \\(\\pi\\) (i.e., the proportion of children who prefer chocolate over vanilla from our population). Recall that, in practice, this parameter is unknown and we aim to estimate it via our \\(n_D\\) sampled data points. In the following section, we will see that these data points are contained in the data frame children_sample from Section 2.1.5.\nOn the other hand, our time query will demand a joint PDF. Again, this probability distribution will represent our random sample assuming sampling with replacement. Therefore, under the iid property along with the standalone PMF for \\(T_j\\)\n\\[\nf_{T_j} \\left(t_j \\mid \\beta \\right) = \\frac{1}{\\beta} \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\quad \\text{for $t_j \\in [0, \\infty )$},\n\\]\nour joint PDF is\n\\[\n\\begin{align*}\nf_{T_1, \\dots, T_{n_T}}(t_1, \\dots, t_{n_T} | \\beta) &= \\prod_{j = 1}^{n_T} f_{Y_j}(y_j | \\beta) \\\\\n&= \\prod_{j = 1}^{n_T} f_Y(y_j | \\beta) \\qquad \\text{iid} \\\\\n&= \\prod_{j = 1}^{n_T} \\frac{1}{\\beta} \\exp \\left( -\\frac{t_j}{\\beta} \\right) \\\\\n& \\quad \\text{for all} \\\\\n& \\quad \\quad t_j \\in [0, \\infty), \\\\\n& \\qquad \\quad j = 1, \\dots, n_T.\n\\end{align*}\n\\tag{2.54}\\]\nIn this query, \\(n_T\\) refers to our sample size of waiting times. Our vector of population parameters also consists of a single element: the average waiting time in minutes from one customer to the next, denoted as \\(\\beta\\). Again, in practice, this parameter is unknown, and our goal is to estimate it using the \\(n_T\\) sampled data points. As we will see in the upcoming section, these data points are contained in data frame waiting_sample from Section 2.1.5.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Cuisine: A Review on Probability and Frequentist Statistical Inference</span>"
    ]
  },
  {
    "objectID": "book/02-stats-review.html#sec-mle",
    "href": "book/02-stats-review.html#sec-mle",
    "title": "2  Basic Cuisine: A Review on Probability and Frequentist Statistical Inference",
    "section": "\n2.2 What is Maximum Likelihood Estimation?",
    "text": "2.2 What is Maximum Likelihood Estimation?\nOnce we have introduced all the necessary probabilistic concepts to address our demand and time queries from Table 2.4, it is time to explore an intriguing statistical concept: estimating our true population parameters using the sample data in children_sample and waiting_sample. Therefore, we will focus on maximum likelihood estimation (MLE) as a fundamental tool in this process, which will also be invoked in our subsequent regression-related chapters. MLE is closely connected to the probabilistic concepts we discussed in the previous section. As a result, we will partially transition from the probabilistic realm to the realm of inference since we are merely targeting estimation in this section.\n\n\nImage by Manfred Steger via Pixabay.\n\n\n2.2.1 Key Concepts\nMLE primarily relies on a random sample of \\(n\\) observations from the population or system of interest. In some cases, such as the ice cream example we have been discussing per query, we may only have one parameter to estimate. In this scenario, we will apply univariate MLE. Conversely, we may encounter situations, such as with regression models, that involve more than one parameter to estimate; this is referred to as multivariate MLE. Regardless of the case, MLE offers an effective method for finding estimators, which tend to behave well (asymptotically speaking, meaning when we gather a sufficiently large number of \\(n\\) data points).\n\n\nDefinition of estimator\n\n\nAn estimator is a mathematical rule involving the random variables \\(Y_1, \\dots, Y_n\\) from our random sample of size \\(n\\). As its name says, this rule allows us to estimate our population parameter of interest.\n\n\nIn statistical practice, finding reliable estimators can be quite challenging. However, MLE offers decent performance and is not a black box approach. The entire estimation process is transparent and well-structured, as we have elaborated throughout this chapter. For example, the sample mean\n\\[\n\\bar{Y} = \\frac{\\sum_{i = 1}^n Y_i}{n}\n\\tag{2.55}\\]\nis a primary case with a very intuitive answer to estimate any given parameter (more specifically, one related to a measure of central tendency). However, this primary case is supported by intriguing statistical modelling procedures in MLE, as we will explore further in this section. Note that Equation 2.55 is considered an estimator since its notation only involves random variables (i.e., uppercases). That said, let us explore an additional concept called the estimate.\n\n\nDefinition of estimate\n\n\nSuppose we have an observed random sample of size \\(n\\) with values \\(y_1, \\dots , y_n\\). Then, we apply a given estimator mathematical rule to these \\(n\\) observed values. Hence, this numerical computation is called an estimate of our population parameter of interest.\n\n\nIn simple terms, an estimate is the version of the estimator that is based on observed data. Therefore, an observed sample mean serves as an estimate, represented in this way using lowercase letters:\n\\[\n\\bar{y} = \\frac{\\sum_{i = 1}^n y_i}{n}.\n\\tag{2.56}\\]\nLet us recall the mainstream average from Equation 2.17 is considered an estimate. Now, moving along with our key concepts, it is time to have a crucial conversation on the difference between likelihood and probability.\n\n\nHeads-up on the statistical difference between probability and likelihood!\n\n\nUnlike everyday language, in statistics, probability and likelihood are not the same. In general, probability refers to the chance that some outcome of interest will happen for a particular random variable. Note a probability is always bounded between \\(0\\) and \\(1\\).\n\n\nImage by Manfred Steger via Pixabay.\n\nOn the other hand, given some observed data, a likelihood refers to how plausible a given distributional parameter is. Furthermore, a likelihood is not bounded between \\(0\\) and \\(1\\).\n\n\nLet us set aside our ice cream case and explore the difference between these two concepts using the Binomial distribution (whose specific theoretical insights can be found in Section D.2). This distribution models the number of successes in \\(n\\) independent Bernoulli trials, each sharing a common probability of success \\(\\pi\\) where \\(\\pi \\in [0, 1]\\). Let the random variable \\(Y\\) follow this Binomial distribution:\n\\[\nY \\sim \\text{Bin}(n, \\pi),\n\\]\nwhose PMF is\n\\[\n\\begin{align*}\nP_Y \\left( Y = y \\mid n, \\pi \\right) &= {n \\choose y} \\pi^y (1 - \\pi)^{n - y} \\\\\n& \\qquad \\qquad \\qquad \\text{for $y \\in \\{ 0, 1, \\dots, n \\}$.}\n\\end{align*}\n\\]\nTerm \\({n \\choose y}\\) represents the total number of combinations for \\(y\\) successes out of \\(n\\) trials:\n\\[\n{n \\choose y} = \\frac{n!}{y!(n - y)!}.\n\\]\nTo make our explanation more graphical, we will plot the PMFs of six Binomial random variables as in Figure 2.5.\n\n\n\n\n\n\n\nFigure 2.5: Probability mass functions of six Binomial distributions with the same number of trials and six different probabilities of success.\n\n\n\n\n\n2.2.2 Empirical Approach\n\n2.2.3 Analytical Approach\n\n\nR Code\nPython Code\n\n\n\npi_hat &lt;- round(mean(children_sample$fav_flavour == \"chocolate\"), 2)\npi_hat\n\n\npi_hat = round((children_sample[\"fav_flavour\"] == \"chocolate\").mean(), 2)\nprint(pi_hat)\n\n\n\n\n\nR Output\nPython Output\n\n\n\n\n\n[1] 0.68\n\n\n\n\n\n\n0.67\n\n\n\n\n\n\n\nR Code\nPython Code\n\n\n\nbeta_hat &lt;- round(mean(waiting_sample$waiting_time), 2)\nbeta_hat\n\n\nbeta_hat = round(waiting_sample[\"waiting_time\"].mean(), 2)\nprint(beta_hat)\n\n\n\n\n\nR Output\nPython Output\n\n\n\n\n\n[1] 10.63\n\n\n\n\n\n\n10.13",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Cuisine: A Review on Probability and Frequentist Statistical Inference</span>"
    ]
  },
  {
    "objectID": "book/02-stats-review.html#sec-basics-inf",
    "href": "book/02-stats-review.html#sec-basics-inf",
    "title": "2  Basic Cuisine: A Review on Probability and Frequentist Statistical Inference",
    "section": "\n2.3 Basics of Frequentist Statistical Inference",
    "text": "2.3 Basics of Frequentist Statistical Inference\n\n\n\n\n\nFigure 2.6: Results stage from the data science workflow in Figure 1.1. This stage is directly followed by storytelling and preceded by goodness of fit.\n\n\n\n\n\n\n\nFigure 2.7: A classical-based hypothesis testing workflow structured in four substages: general settings, hypotheses definitions, test flavour and components, and inferential conclusions.\n\n\n\n2.3.1 General Settings\n\n\n\n\n\nFigure 2.8: General settings substage from the classical-based hypothesis testing workflow in Figure 2.7. This substage is directly followed by the hypotheses definitions.\n\n\nBased on the work by Soch et al. (2024), let us check some key definitions.\n\n\nDefinition of hypothesis\n\n\nSuppose you observe some data \\(y\\) from some population(s) or system(s) of interest governed by \\(k\\) parameters contained in the following vector:\n\\[\n\\boldsymbol{\\theta} = (\\theta_1, \\theta_2, \\cdots, \\theta_k)^T.\n\\]\nMoreover, let us assume that random variable \\(Y\\) follows certain probability distribution \\(\\mathcal{D}(\\cdot)\\) in a generative model \\(m\\) as in\n\\[\nm: Y \\sim \\mathcal{D}(\\boldsymbol{\\theta}).\n\\]\nBeginning from the fact that \\(\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}\\) where \\(\\boldsymbol{\\Theta} \\in \\mathbb{R}^k\\), a statistical hypothesis is a general statement about some parameter vector \\(\\boldsymbol{\\theta}\\) in regards to specific values contained in vector \\(\\boldsymbol{\\Theta}^*\\) such that\n\\[\nH: \\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}^* \\quad \\text{where} \\quad \\boldsymbol{\\Theta}^* \\subset \\boldsymbol{\\Theta}.\n\\]\n\n\n\n\nDefinition of null hypothesis\n\n\nIn a hypothesis(s) testing, a null hypothesis is denoted by \\(H_0\\). The whole inferential process is designed to assess the strength of the evidence in favour or against this null hypothesis. In plain words, \\(H_0\\) is an inferential statement associated to the status quo in some population(s) or system(s) of interest, which might refer to no signal for the researcher in question.\nAgain, suppose random variable \\(Y\\) from some population(s) or system(s) of interest is governed by \\(k\\) parameters contained in the following vector:\n\\[\n\\boldsymbol{\\theta} = (\\theta_1, \\theta_2, \\cdots, \\theta_k)^T.\n\\]\nMoreover, we assume this observed data \\(y\\) follows certain probability distribution \\(\\mathcal{D}(\\cdot)\\) in a generative model \\(m\\) as in\n\\[\nm: y \\sim \\mathcal{D}(\\boldsymbol{\\theta}).\n\\]\nLet \\(\\boldsymbol{\\Theta}_0 \\subset \\boldsymbol{\\theta}\\) denote the status quo for the parameter(s) to be tested. Then, the null hypothesis is mathematically defined as\n\\[\nH_0: \\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}_0 \\quad \\text{where} \\quad \\boldsymbol{\\Theta}_0 \\subset \\boldsymbol{\\theta}.\n\\tag{2.57}\\]\n\n\n\n\nDefinition of alternative hypothesis\n\n\nIn a hypothesis testing, an alternative hypothesis is denoted by \\(H_1\\). This hypothesis corresponds to the complement (i.e., the opposite) of the null hypothesis \\(H_0\\). Since the whole inferential process is designed to assess the strength of the evidence in favour or against of \\(H_0\\), any inferential conclusion against \\(H_0\\) can be worded as “rejecting \\(H_0\\) in favour of \\(H_1\\).” In plain words, \\(H_1\\) is an inferential statement associated to a non-status quo in some population(s) or system(s) of interest, which might refer to actual signal for the researcher in question.\nLet us assume random variable \\(Y\\) from some population(s) or system(s) of interest is governed by \\(k\\) parameters contained in the following vector:\n\\[\n\\boldsymbol{\\theta} = (\\theta_1, \\theta_2, \\cdots, \\theta_k)^T.\n\\]\nMoreover, suppose this observed data \\(y\\) follows certain probability distribution \\(\\mathcal{D}(\\cdot)\\) in a generative model \\(m\\) as in\n\\[\nm: y \\sim \\mathcal{D}(\\boldsymbol{\\theta}).\n\\]\nLet \\(\\boldsymbol{\\Theta}_0^c \\subset \\boldsymbol{\\theta}\\) denote the non-status quo for the parameter(s) to be tested. Then, the alternative hypothesis is mathematically defined as\n\\[\nH_1: \\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}_0^c \\quad \\text{where} \\quad \\boldsymbol{\\Theta}_0^c \\subset \\boldsymbol{\\theta}.\n\\tag{2.58}\\]\n\n\n\n\nDefinition of hypothesis testing\n\n\nA hypothesis testing is the decision rule we have to apply between the null and alternative hypotheses, via our sample data, to fail to reject or reject the null hypothesis.\n\n\n\n\nDefinition of type I error (false positive)\n\n\nType I error is defined as incorrectly rejecting the null hypothesis \\(H_0\\) in favour of the alternative hypothesis \\(H_1\\) when, in fact, \\(H_0\\) is true. Analogously, this type of error is also called false positive .\n\n\n\n\nDefinition of type II error (false negative)\n\n\nType II error is defined as incorrectly failing to reject the null hypothesis \\(H_0\\) in favour of the alternative hypothesis \\(H_1\\) when, in fact, \\(H_0\\) is false. Analogously, this type of error is also called false negative . Table 2.5 summarizes the types of inferential conclusions in function on whether \\(H_0\\) is true or not.\n\n\nTable 2.5: Types of inferential conclusions in a frequentist hypothesis testing.\n\n\n\n\n\n\n\n\n\n\\(H_0\\) is true\n\\(H_0\\) is false\n\n\n\nReject \\(H_0\\)\nType I error (False positive)\nCorrect\n\n\nFail to reject \\(H_0\\)\nCorrect\nType II error (False negative)\n\n\n\n\n\n\n\n\n\n\nDefinition of significance level\n\n\nThe significance level \\(\\alpha\\) is defined as the conditional probability of rejecting the null hypothesis \\(H_0\\) given that \\(H_0\\) is true. This can be mathematically represented as\n\\[\nP \\left( \\text{Reject $H_0$} | \\text{$H_0$ is true} \\right) = \\alpha.\n\\]\nIn plain words, \\(\\alpha \\in [0, 1]\\) allows us to probabilistically control for type I error since we are dealing with random variables in our inferential process. The significance level can be thought as one of the main hypothesis testing and power analysis settings. The larger the significance level in our power analysis and hypothesis testing, the less prone we are to commit a type I error.\n\n\n\n\nDefinition of power\n\n\nThe statistical power of a test \\(1 -\\beta\\) is the complement of the conditional probability \\(\\beta\\) of failing to reject the null hypothesis \\(H_0\\) given that \\(H_0\\) is false, which is mathematically represented as\n\\[\nP \\left( \\text{Failing to reject $H_0$} | \\text{$H_0$ is false} \\right) = \\beta;\n\\]\nyielding\n\\[\n\\text{Power} = 1 - \\beta.\n\\]\nIn plain words, \\(1 - \\beta \\in [0, 1]\\) is the probabilistic ability of our hypothesis testing to detect any signal in our inferential process, if there is any. The larger the power in our power analysis, the less prone we are to commit a type II error.\n\n\n\n\nDefinition of power analysis\n\n\nPower analysis is a set of statistical tools used to compute the minimum required sample size \\(n\\) for any given inferential study. These tools require the significance level, power, and effect size (i.e., the magnitude of the signal) the researcher aims to detect via their inferential study. This analysis seeks to determine whether observed results are likely due to chance or represent a true and meaningful effect.\n\n\nImage by Manfred Steger via Pixabay.\n\n\n\n\n2.3.2 Hypotheses Definitions\n\n\n\n\n\nFigure 2.9: Hypotheses definitions substage from the classical-based hypothesis testing workflow in Figure 2.7. This substage is directly preceded by general settings and followed by test flavour and components.\n\n\n\n2.3.3 Test Flavour and Components\n\n\n\n\n\nFigure 2.10: Test flavour and components substage from the classical-based hypothesis testing workflow in Figure 2.7. This substage is directly preceded by hypotheses definitions and followed by inferential conclusions.\n\n\n\n\nDefinition of observed effect\n\n\nAn observed effect is the difference between the estimate provided the observed random sample (of size \\(n\\), as in \\(y_1, \\dots, y_n\\)) to the hypothesized value(s) of the population parameter(s) depicted in the statistical hypotheses.\n\n\n\n\nDefinition of standard error\n\n\nThe standard error allows us to quantify the extent to which an estimate coming from an observed random sample (of size \\(n\\), as in \\(y_1, \\dots, y_n\\)) may deviate from the expected value under the assumption that the null hypothesis is true.\nIt plays a critical role in determining whether an observed effect is likely attributable to random variation or represents a statistically significant finding. In the absence of the standard error, it would not be possible to rigorously assess the reliability or precision of an estimate.\n\n\nImage by Manfred Steger via Pixabay.\n\n\n\n\n\nDefinition of test statistic\n\n\nThe test statistic is a function of the random sample of size \\(n\\), i.e., it is in the function of the random variables \\(Y_1, \\dots, Y_n\\). Therefore, the test statistic will also be a random variable, whose observed value will describe how closely the probability distribution from which the random sample comes from matches the probability distribution of the null hypothesis \\(H_0\\).\nMore specifically, once we have obtained the observed effect and standard error from our observed random sample, we can compute the corresponding observed test statistic. This test statistic computation will be placed on the corresponding \\(x\\)-axis of the probability distribution of \\(H_0\\) so we can reject or fail to reject it accordingly.\n\n\nImage by Manfred Steger via Pixabay.\n\n\n\n\n2.3.4 Inferential Conclusions\n\n\n\n\n\nFigure 2.11: Inferential conclusions substage from the classical-based hypothesis testing workflow in Figure 2.7. This substage is directly preceded by rest flavour and components and followed by the corresponding delivery significance conclusion within the results stage of the data science workflow as shown in Figure 2.6.\n\n\n\n\nDefinition of critical value\n\n\nThe critical value of a hypothesis testing defines the region for which we might reject \\(H_0\\) in favour of \\(H_1\\). This critical value is in the function of the significance level \\(\\alpha\\) and test flavour. It is located on the corresponding \\(x\\)-axis of the probability distribution of \\(H_0\\). Hence, this value acts as a threshold to decide either of the following:\n\nIf the observed test statistic exceeds a given critical value, then we have enough statistical evidence to reject \\(H_0\\) in favour of \\(H_1\\).\nIf the observed test statistic does not exceed a given critical value, then we have enough statistical evidence to fail to reject \\(H_0\\).\n\n\n\n\n\nDefinition of \\(p\\)-value\n\n\nA \\(p\\)-value refers to the probability of obtaining a test statistic just as extreme or more extreme than the observed test statistic coming from our observed random sample of size \\(n\\). This \\(p\\)-value is obtained via the probability distribution of \\(H_0\\) and the observed test statistic.\nAlternatively to a critical value, we can reject or fail to reject the null hypothesis \\(H_0\\) using this \\(p\\)-value as follows:\n\nIf the \\(p\\)-value associated to the observed test statistic exceeds a given significance level \\(\\alpha\\), then we have enough statistical evidence to reject \\(H_0\\) in favour of \\(H_1\\).\nIf the \\(p\\)-value associated to the observed test statistic does not exceed a given significance level \\(\\alpha\\), then we have enough statistical evidence to fail to reject \\(H_0\\).\n\n\n\n\n\nDefinition of confidence interval\n\n\nA confidence interval provides an estimated range of values within which the true population parameter is likely to fall, based on the sample data. It reflects the degree of uncertainty associated with the obtained estimate. For instance, a 95% confidence interval means that if the study were repeated many times using different random samples from the same population or system of interest, approximately 95% of the resulting intervals would contain the true parameter.\n\n\nImage by Manfred Steger via Pixabay.\n\n\n\n\n\n\n\nBellhouse, D. R. 2004. “The Reverend Thomas Bayes, FRS: A Biography to Celebrate the Tercentenary of His Birth.” Statistical Science 19 (1): 3–43. https://doi.org/10.1214/088342304000000189.\n\n\nCasella, G., and R. Berger. 2024. Statistical Inference. Chapman & Hall/CRC Texts in Statistical Science. CRC Press. https://www.taylorfrancis.com/books/mono/10.1201/9781003456285/statistical-inference-roger-berger-george-casella.\n\n\nJohnson, A. A., M. Q. Ott, and M. Dogucu. 2022. Bayes Rules!: An Introduction to Applied Bayesian Modeling. Chapman & Hall/CRC Texts in Statistical Science. CRC Press. https://www.bayesrulesbook.com/.\n\n\nLeemis, Larry. n.d. “Univariate Distribution Relationship Chart.” https://www.math.wm.edu/~leemis/chart/UDR/UDR.html.\n\n\nO’Donnell, T. 1936. History of Life Insurance in Its Formative Years. Compiled from Approved Sources by T. O’Donnell. Chicago.\n\n\nSoch, Joram, The Book of Statistical Proofs, Maja, Pietro Monticone, Thomas J. Faulkenberry, Alex Kipnis, Kenneth Petrykowski, et al. 2024. “StatProofBook/StatProofBook.github.io: StatProofBook 2023.” Zenodo. https://doi.org/10.5281/zenodo.10495684.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Basic Cuisine: A Review on Probability and Frequentist Statistical Inference</span>"
    ]
  },
  {
    "objectID": "book/03-ols.html",
    "href": "book/03-ols.html",
    "title": "3  Zestylicious Ordinary Least-squares Regression",
    "section": "",
    "text": "3.1 Introduction\nWhen looking at data, we often want to know how different factors affect each other. For instance, if you have data on student finances, you might ask:\nOnce you have this financial data, the next step is to analyze it to find answers. One straightforward method for doing this is through regression analysis, and the simplest form is called Ordinary Least Squares (OLS).",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Zestylicious Ordinary Least-squares Regression</span>"
    ]
  },
  {
    "objectID": "book/03-ols.html#introduction",
    "href": "book/03-ols.html#introduction",
    "title": "3  Zestylicious Ordinary Least-squares Regression",
    "section": "",
    "text": "How does having a job affect a student’s leftover money at the end of the month?\nWhat impact does receiving a monthly allowance have on their net savings?",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Zestylicious Ordinary Least-squares Regression</span>"
    ]
  },
  {
    "objectID": "book/03-ols.html#what-is-ordinary-least-squares-ols",
    "href": "book/03-ols.html#what-is-ordinary-least-squares-ols",
    "title": "3  Zestylicious Ordinary Least-squares Regression",
    "section": "\n3.2 What is Ordinary Least Squares (OLS)?",
    "text": "3.2 What is Ordinary Least Squares (OLS)?\nOrdinary Least Squares (OLS) is a fundamental method in regression analysis for estimating the relationship between a dependent variable and one or more independent variables. In simple terms, OLS is like drawing the best straight line through a scatterplot of data points. Imagine you plotted students’ net savings on a graph, and each point represents a student’s financial outcome. OLS finds the line that best follows the trend of these points by minimizing the overall distance (error) between what the line predicts and what the actual data shows.\nOLS is widely used because it is:\n\n\nSimple: Easy to understand and compute.\n\nClear: Provides straightforward numbers (coefficients) that tell you how much each factor influences the outcome.\n\nVersatile: Applicable in many fields, from economics to social sciences, to help make informed decisions.\n\nIn this chapter, we will break down how OLS works in plain language, explore its underlying assumptions, and discuss its practical applications and limitations. This will give you a solid foundation in regression analysis, paving the way for more advanced techniques later on.",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Zestylicious Ordinary Least-squares Regression</span>"
    ]
  },
  {
    "objectID": "book/03-ols.html#the-best-line",
    "href": "book/03-ols.html#the-best-line",
    "title": "3  Zestylicious Ordinary Least-squares Regression",
    "section": "\n3.3 The “Best Line”",
    "text": "3.3 The “Best Line”\nWhen using Ordinary Least Squares (OLS) to fit a regression line, our goal is to find the line that best represents the relationship between our dependent variable \\(Y\\) and independent variable \\(X\\). But what does “best” mean?\nImagine you have a scatter plot of data points. Now, consider drawing two different lines through this plot. Each one of these lines represent a set of predictions. They also represent a way to represent the relationship between the dependent variable \\(Y\\) and independent variable \\(X\\)\n\n\nLine A (Blue): A line that follows the general trend of the data very well.\n\nLine B (Red): A line that doesn’t capture the trend as accurately.\n\n\n\nR Code\nPython Code\n\n\n\n# Sample data\nset.seed(42)\nX &lt;- c(1000, 1200, 1500, 1800, 2000)\nY &lt;- c(200, 230, 250, 290, 310)\n\n# Create a data frame\ndf &lt;- data.frame(Size = X, Price = Y)\n\n# Fit the correct OLS model\ncorrect_model &lt;- lm(Price ~ Size, data = df)\n\n# Create predictions for the two lines\ndf$Predicted_Correct &lt;- predict(correct_model, newdata = df)\ndf$Predicted_Wrong &lt;- 110 + 0.08 * df$Size  # Adjusted manually\n\n# Reshape data for ggplot (to add legend)\ndf_long &lt;- data.frame(\n  Size = rep(df$Size, 2),\n  Price = c(df$Predicted_Correct, df$Predicted_Wrong),\n  Line = rep(c(\"Line A (Best Fit)\", \"Line B (Worse Fit)\"), each = nrow(df))\n)\n\n# Store the plot with a legend\nlibrary(ggplot2)\nplot &lt;- ggplot() +\n  geom_point(data = df, aes(x = Size, y = Price), size = 3, color = \"black\") +\n  geom_line(data = df_long, aes(x = Size, y = Price, color = Line), linewidth = 1.2) +\n  scale_color_manual(values = c(\"Line A (Best Fit)\" = \"blue\", \"Line B (Worse Fit)\" = \"red\")) +\n  labs(title = \"Comparing Regression Line Fits\",\n       x = \"House Size (sq ft)\",\n       y = \"House Price (in $1000s)\",\n       color = \"Regression Line\") +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5, face = \"bold\"),\n        legend.position = \"bottom\")\n\nplot\n\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\n\n# Sample data\nnp.random.seed(42)\nX = np.array([1000, 1200, 1500, 1800, 2000])\nY = np.array([200, 230, 250, 290, 310])\ndf = pd.DataFrame({'Size': X, 'Price': Y})\n\n# Fit the correct OLS model\nX_sm = sm.add_constant(df['Size'])\nmodel = sm.OLS(df['Price'], X_sm).fit()\ndf['Predicted_Correct'] = model.predict(X_sm)\n\n# Manually add the incorrect line\ndf['Predicted_Wrong'] = 110 + 0.08 * df['Size']\n\n# Reshape for plotting\ndf_long = pd.concat([\n    df[['Size', 'Predicted_Correct']].rename(columns={'Predicted_Correct': 'Price'}).assign(Line='Line A (Best Fit)'),\n    df[['Size', 'Predicted_Wrong']].rename(columns={'Predicted_Wrong': 'Price'}).assign(Line='Line B (Worse Fit)')\n])\n\n# Plot\nfig, ax = plt.subplots(figsize=(6, 4))\nax.scatter(df['Size'], df['Price'], color='black', label='Actual Data')\nfor label, group in df_long.groupby('Line'):\n    ax.plot(group['Size'], group['Price'], label=label)\nax.set_title(\"Comparing Regression Line Fits\", fontsize=14, fontweight='bold')\nax.set_xlabel(\"House Size (sq ft)\")\nax.set_ylabel(\"House Price (in $1000s)\")\nax.legend(title=\"Regression Line\", loc='lower right')\nplt.grid(True)\nplt.show()\n\n\n\n\n\nR Output\nPython Output\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3.3.1 Understanding Residuals\nFor each data point, the residual is the vertical distance between the actual \\(Y\\) value and the predicted \\(Y\\) value (denoted \\(\\hat{Y}\\)) on the line. In simple terms, it tells us how far off our prediction is for each point given the same \\(X\\) value. If a line fits well, these residuals will be small, meaning our predictions of the \\(Y\\) variable are close to the actual value.\nOLS quantifies how well a line fits the data by calculating the Sum of Squared Errors (SSE). The SSE is obtained by:\n\nComputing the residual for each data point.\nSquaring each residual (this ensures that errors do not cancel each other out).\nSumming all these squared values.\n\n\\[\nSSE=\\sum_{i=1}^{n} (Y_i - \\hat{Y}_i)^2\n\\]\nA lower SSE indicates a line that is closer to the actual data points. OLS chooses the best line by finding the one with the smallest SSE.\n\n3.3.2 Quantifying the Fit with SSE\nWe can compare the two lines by computing their SSE. The code below calculates and prints the SSE for each line:\n\n\nR Code\nPython Code\n\n\n\n# Calculate the Sum of Squared Errors for the correct model (Blue)\nsse_correct &lt;- sum((df$Price - df$Predicted_Correct)^2)\n\n# Calculate the Sum of Squared Errors for the manually adjusted model (Red)\nsse_wrong &lt;- sum((df$Price - df$Predicted_Wrong)^2)\n\n# Print the SSEs for each line\ncat(\"SSE for Best-Fit Line (Blue line):\", sse_correct, \"\\n\")\ncat(\"SSE for Worse-Fit Line (Red line):\", sse_wrong, \"\\n\")\n\n\n# Calculate the Sum of Squared Errors for the correct model (Blue)\nsse_correct = np.sum((df['Price'] - df['Predicted_Correct']) ** 2)\n\n# Calculate the Sum of Squared Errors for the manually adjusted model (Red)\nsse_wrong = np.sum((df['Price'] - df['Predicted_Wrong']) ** 2)\n\n# Print the SSEs for each line\nprint(f\"SSE for Best-Fit Line (Blue line): {sse_correct}\")\nprint(f\"SSE for Worse-Fit Line (Red line): {sse_wrong}\")\n\n\n\n\n\nR Output\nPython Output\n\n\n\n\n\nSSE for Best-Fit Line (Blue line): 83.23529 \n\n\nSSE for Worse-Fit Line (Red line): 3972 \n\n\n\n\n\n\nSSE for Best-Fit Line (Blue line): 83.23529411764711\n\n\nSSE for Worse-Fit Line (Red line): 3972.0\n\n\n\n\n\nWhen you run this code, you’ll observe that the blue line (Line A) has a much lower SSE compared to the red line (Line B). This tells us that the blue line is a better fit for the data because its predictions are, on average, closer to the actual values.\nIn summary, OLS selects the “best line” by minimizing the sum of squared errors, ensuring that the total error between predicted and actual values is as small as possible.\n\n3.3.3 Why Squared Errors?\nWhen measuring how far off our predictions are, errors can be positive (if our prediction is too low) or negative (if it’s too high). If we simply added these errors together, they could cancel each other out, hiding the true size of the mistakes. By squaring each error, we convert all numbers to positive values so that every mistake counts.\nIn addition, squaring makes big errors count a lot more than small ones. This means that a large mistake will have a much bigger impact on the overall error, encouraging the model to reduce those large errors and improve its overall accuracy.\n\n3.3.4 The Mathematical Formulation of the OLS Model\nNow that we understand how OLS finds the best-fitting line by minimizing the differences between the actual and predicted values, let’s look at the math behind it.\nIn a simple linear regression with one predictor, we express the relationship between the outcome \\(Y\\) and the predictor \\(X\\) using the following equation. Note that OLS fits a straight line to the data, which is why the equation takes the familiar form of a straight line:\n\\[\nY=\\beta_0+\\beta_1X+\\epsilon\n\\]\nHere’s what each part of the equation means:\n\n\n\\(Y\\) is the dependent variable or the outcome we want to predict.\n\n\\(X\\) is the independent variable or the predictor that we believe influences \\(Y\\).\n\n\\(\\beta_0\\) is the intercept. It represents the predicted value of \\(Y\\) when \\(X=0\\).\n\n\\(\\beta_1\\) is the slope. It tells us how much \\(Y\\) is expected to change for each one-unit increase in \\(X\\).\n\n\\(\\epsilon\\) is the error term. It captures the random variation in \\(Y\\) that cannot be explained by \\(X\\).\n\nThis equation provides a clear mathematical framework for understanding how changes in \\(X\\) are expected to affect \\(Y\\), while also accounting for random variation. In the upcoming section, we will explore our toy dataset to showcase this equation and OLS in action.",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Zestylicious Ordinary Least-squares Regression</span>"
    ]
  },
  {
    "objectID": "book/03-ols.html#case-study-understanding-financial-behaviors",
    "href": "book/03-ols.html#case-study-understanding-financial-behaviors",
    "title": "3  Zestylicious Ordinary Least-squares Regression",
    "section": "\n3.4 Case Study: Understanding Financial Behaviors",
    "text": "3.4 Case Study: Understanding Financial Behaviors\nTo demonstrate Ordinary Least Squares (OLS) in action, we will walk through a case study using a toy dataset. This case study will help us understand the financial behaviors of students and identify the factors that influence their Net_Money, the amount of money left over at the end of each month. We will approach this case study using the data science workflow described in a previous chapter, ensuring a structured approach to problem-solving and model building.\n\n3.4.1 The Dataset\nOur dataset captures various aspects of students’ financial lives. Each row represents a student, and the columns describe different characteristics. Below is a breakdown of the variables:\n\n\n\n\n\n\nVariable Name\nDescription\n\n\n\nHas_Job\nWhether the student has a job (0 = No, 1 = Yes).\n\n\nYear_of_Study\nThe student’s current year of study (e.g., 1st year, 2nd year, etc.).\n\n\nFinancially_Dependent\nWhether the student is financially dependent on someone else (0 = No, 1 = Yes).\n\n\nMonthly_Allowance\nThe amount of financial support the student receives each month.\n\n\nCooks_at_Home\nWhether the student prepares their own meals (0 = No, 1 = Yes).\n\n\nLiving_Situation\nThe student’s living arrangement (e.g., living with family, in a shared apartment, etc.).\n\n\nHousing_Type\nThe type of housing the student lives in (e.g., rented, owned, dormitory).\n\n\nGoes_Out_Spends_Money\nHow frequently the student goes out and spends money (1 = rarely, 5 = very often).\n\n\nDrinks_Alcohol\nWhether the student drinks alcohol (0 = No, 1 = Yes).\n\n\nNet_Money\nThe amount of money the student has left at the end of the month after income and expenses.\n\n\nMonthly_Earnings\nThe student’s earnings from any part-time jobs or other income sources.\n\n\n\nHere’s a sample of the dataset:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHas_Job\nYear_of_Study\nFinancially_Dependent\nMonthly_Allowance\nCooks_at_Home\nLiving_Situation\nHousing_Type\nGoes_Out_Spends_Money\nDrinks_Alcohol\nNet_Money\nMonthly_Earnings\n\n\n\n0\n1\n0\n658.99\n0\n3\n1\n6\n0\n529.34\n0.00\n\n\n1\n3\n0\n592.55\n0\n3\n2\n3\n1\n992.72\n941.92\n\n\n1\n4\n1\n602.54\n0\n2\n2\n2\n1\n557.30\n876.57\n\n\n\n\nThis dataset provides a structured way to analyze the financial habits of students and determine which factors contribute most to their financial stability.\n\n3.4.2 The Problem We’re Trying to Solve\nOur goal in this case study is to understand which factors impact a student’s net money. Specifically, we aim to identify which characteristics, such as having a job, monthly earnings, or financial support, explain why some students have more money left over at the end of the month than others.\nThe key question we want to answer is:\n\nWhich factors have the biggest influence on a student’s net money?\n\nBy applying OLS to this dataset, we can:\n\nMeasure how much each factor contributes to variations in net money. For example, we can determine the increase in net money associated with a one-unit increase in monthly earnings.\nIdentify whether each factor has a positive or negative effect on net money.\nUnderstand the unique contribution of each variable while accounting for the influence of others. This helps us isolate the effect of, say, having a job from that of receiving financial support.\nPredict a student’s net money based on their characteristics. These insights could help institutions design targeted financial literacy programs or interventions to improve financial stability.\nEvaluate the overall performance of our model using statistical measures such as R-squared and p-values. This not only confirms the significance of our findings but also guides improvements in future analyses.\n\nIn summary, using OLS in this case study allows us to break down complex financial behaviors into understandable components. This powerful tool provides clear, actionable insights into which factors are most important, paving the way for more informed decisions and targeted interventions.\n\n3.4.3 Study Design\nNow that we’ve introduced our case study and dataset, it’s time to follow the data science workflow step by step. The first step is to define the main statistical inquiries we want to address. As mentioned earlier, our key question is:\n\nWhich factors have the biggest influence on a student’s net money?\n\nTo answer this question, we will adopt an inferential analysis approach rather than a predictive analysis approach. Let’s quickly review the difference between these two methods:\nInferential vs. Predictive Analysis\n\n\nInferential Analysis explores and quantifies the relationships between explanatory variables (e.g., student characteristics) and the response variable (Net_Money). For example, we might ask: Does having a part-time job significantly affect a student’s net money, and by how much? The goal here is to understand these effects and assess their statistical significance.\n\nPredictive Analysis focuses on accurately forecasting the response variable using new data. In this case, the question could be: Can we predict a student’s net money based on factors like monthly earnings, living situation, and spending habits? The emphasis is on building a model that produces reliable predictions, even if it doesn’t fully explain the underlying relationships.\n\n3.4.4 Applying Study Design to Our Case Study\nFor our case study, we are interested in understanding how factors such as Has_Job, Monthly_Earnings, and Spending_Habits affect a student’s Net_Money. This leads us to adopt an inferential approach. We aim to answer questions like:\n\nDoes having a part-time job lead to significantly higher net money?\nHow much do a student’s monthly earnings influence their financial situation?\nDo spending habits, like going out frequently, decrease a student’s net money?\n\nUsing OLS, we will estimate the impact of each factor and determine whether these effects are statistically significant. This inferential analysis will help us understand which variables have the greatest influence on students’ financial outcomes.\nIf our goal were instead to predict a student’s future Net Money based on their characteristics, we would adopt a predictive approach. Although our focus here is on inference, it’s important to recognize that OLS is versatile and can be applied in both contexts.",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Zestylicious Ordinary Least-squares Regression</span>"
    ]
  },
  {
    "objectID": "book/03-ols.html#data-collection-and-wrangling",
    "href": "book/03-ols.html#data-collection-and-wrangling",
    "title": "3  Zestylicious Ordinary Least-squares Regression",
    "section": "\n3.5 Data Collection and Wrangling",
    "text": "3.5 Data Collection and Wrangling\nWith the statistical questions clearly defined, the next step is to ensure that the data is appropriately prepared for analysis. Although we already have the dataset, it is valuable to consider how this data could have been collected to better understand its context and potential limitations.\n\n3.5.1 Data Collection\nFor a study like ours, data on students’ financial behaviors could have been collected through various methods:\n\n\nSurveys: Students might have been asked about their employment status, earnings, and spending habits through structured questionnaires. While surveys can capture self-reported financial behaviors, they may suffer from recall bias or social desirability bias.\n\nAdministrative Data: Universities or employers may maintain records on student income and employment, providing a more objective source of financial information. However, access to such data may be limited due to privacy regulations.\n\nFinancial Tracking Apps: Digital financial management tools can offer detailed, real-time data on student income and spending patterns. While these apps provide high granularity, they may introduce selection bias, as only students who use such apps would be represented in the dataset.\n\nRegardless of the data collection method, each approach presents challenges, such as missing data, reporting errors, or sample biases. Addressing these issues is a critical aspect of data wrangling.\n\n3.5.2 Data Wrangling\nNow that our dataset is ready, the next step is to clean and organize it so that it’s in the best possible shape for analysis using OLS. Data wrangling involves several steps that ensure our data is accurate, consistent, and ready for modeling. Here are some key tasks:\nHandling Missing Data\nThe first task is to ensure data integrity by checking for missing values. Missing data can occur for various reasons, such as unrecorded responses or errors in data entry. When we find missing values—for example, if some students don’t have recorded earnings or net money—we must decide how to handle these gaps. Common strategies include:\n\n\nRemoving incomplete records: If the amount of missing data is minimal or missingness is random.\n\nImputing missing values: Using logical estimates or averages if missingness follows a systematic pattern.\n\nIn our toy dataset, there are no missing values, as confirmed by:\n\n\nR Code\nPython Code\n\n\n\n\ncolSums(is.na(data))\n\n              Has_Job         Year_of_Study Financially_Dependent \n                    0                     0                     0 \n    Monthly_Allowance         Cooks_at_Home      Living_Situation \n                    0                     0                     0 \n         Housing_Type Goes_Out_Spends_Money        Drinks_Alcohol \n                    0                     0                     0 \n            Net_Money      Monthly_Earnings \n                    0                     0 \n\n\n\n\n\n# Count missing values in each column\ndata.isna().sum()\n\nHas_Job                  0\nYear_of_Study            0\nFinancially_Dependent    0\nMonthly_Allowance        0\nCooks_at_Home            0\nLiving_Situation         0\nHousing_Type             0\nGoes_Out_Spends_Money    0\nDrinks_Alcohol           0\nNet_Money                0\nMonthly_Earnings         0\ndtype: int64\n\n\n\n\n\nEncoding Categorical Variables\nFor regression analysis, we need to convert categorical variables into numerical representations. In R, binary variables like Has_Job and Drinks_Alcohol should be transformed into factors so that the model correctly interprets them as categorical data rather than continuous numbers. For example:\n\n\nR Code\nPython Code\n\n\n\n\n# Convert binary categorical variables to factors\ndata &lt;- data |&gt;\n  mutate(Has_Job = as.factor(Has_Job),\n         Drinks_Alcohol = as.factor(Drinks_Alcohol),\n         Financially_Dependent = as.factor(Financially_Dependent),\n         Cooks_at_Home = as.factor(Cooks_at_Home))\n\n\n\n\n# Convert binary columns to categorical dtype\ncols_to_convert = [\"Has_Job\", \"Drinks_Alcohol\", \"Financially_Dependent\", \"Cooks_at_Home\"]\ndata[cols_to_convert] = data[cols_to_convert].astype(\"category\")\n\n\n\n\nDetecting and Handling Outliers\nOutliers in continuous variables like Monthly_Earnings and Net_Money can distort the regression analysis by skewing results. We use the Interquartile Range (IQR) method to identify these extreme values. Specifically, any observation falling below 1.5 times the IQR below the first quartile (Q1) or above 1.5 times the IQR above the third quartile (Q3) is flagged as an outlier. These outliers are then treated as missing values and removed:\n\n\nR Code\nPython Code\n\n\n\n\n# Using IQR method to filter out extreme values in continuous variables\nremove_outliers &lt;- function(x) {\n  Q1 &lt;- quantile(x, 0.25, na.rm = TRUE)\n  Q3 &lt;- quantile(x, 0.75, na.rm = TRUE)\n  IQR &lt;- Q3 - Q1\n  x[x &lt; (Q1 - 1.5 * IQR) | x &gt; (Q3 + 1.5 * IQR)] &lt;- NA\n  return(x)\n}\n\ndata &lt;- data |&gt;\n  mutate(across(c(Monthly_Earnings, Net_Money), remove_outliers))\n\n# Remove rows with newly introduced NAs due to outlier handling\ndata &lt;- na.omit(data)\n\n\n\n\n# Define the IQR outlier-removal function\ndef remove_outliers(series):\n    Q1 = series.quantile(0.25)\n    Q3 = series.quantile(0.75)\n    IQR = Q3 - Q1\n    return series.where((series &gt;= Q1 - 1.5 * IQR) & (series &lt;= Q3 + 1.5 * IQR))\n\n# Apply to specific continuous columns\ndata[\"Monthly_Earnings\"] = remove_outliers(data[\"Monthly_Earnings\"])\ndata[\"Net_Money\"] = remove_outliers(data[\"Net_Money\"])\n\n# Drop rows with any newly introduced NAs (from outliers)\ndata = data.dropna()\n\n\n\n\nSplitting the Data for Model Training\nTo ensure that our OLS model generalizes well to unseen data, we split the dataset into training and testing subsets. The training set is used to estimate the model parameters, and the testing set is used to evaluate the model’s performance. This split is typically done in an 80/20 ratio, as shown below:\n\n\nR Code\nPython Code\n\n\n\n\n# Splitting the dataset by row order: first 80% for training, last 20% for testing\nn &lt;- nrow(data)\nsplit_index &lt;- floor(0.8 * n)\ntrain_data &lt;- data[1:split_index, ]\ntest_data &lt;- data[(split_index + 1):n, ]\n\n\n\n\n# Splitting the dataset by row order: first 80% for training, last 20% for testing\nn = len(data)\nsplit_index = int(0.8 * n)\ntrain_data = data.iloc[:split_index]\ntest_data = data.iloc[split_index:]\n\n\n\n\nAlthough random sampling is generally preferred, since it helps ensure the training and testing sets are representative of the overall dataset, we deliberately split the data by row index here to produce consistent results across R and Python. This allows for reproducible comparisons between implementations in both languages.\nBy following these steps, checking for missing values, encoding categorical variables, handling outliers, and splitting the data, we ensure that our dataset is clean, well-organized, and ready for regression analysis using OLS.\nIt’s important to note, however, that these are just a few of the many techniques available during the data wrangling stage. Depending on the dataset and the specific goals of your analysis, you might also consider additional strategies such as feature scaling, normalization, advanced feature engineering, handling duplicate records, or addressing imbalanced data. Each of these techniques comes with its own set of solutions, and the optimal approach will depend on the unique challenges and objectives of your case.",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Zestylicious Ordinary Least-squares Regression</span>"
    ]
  },
  {
    "objectID": "book/03-ols.html#exploratory-data-analysis-eda",
    "href": "book/03-ols.html#exploratory-data-analysis-eda",
    "title": "3  Zestylicious Ordinary Least-squares Regression",
    "section": "\n3.6 Exploratory Data Analysis (EDA)",
    "text": "3.6 Exploratory Data Analysis (EDA)\nBefore diving into data modeling, it is crucial to develop a deep understanding of the relationships between variables in the dataset. This stage, known as Exploratory Data Analysis (EDA), helps us visualize and summarize the data, uncover patterns, detect anomalies, and test key assumptions that will inform our modeling decisions.\n\n3.6.1 Classifying Variables\nThe first step in EDA is to classify variables according to their types. This classification guides the selection of appropriate visualization techniques and modeling strategies. In our toy dataset, we categorize variables as follows:\n\n\nNet_Money serves as the response variable, representing a continuous outcome constrained by realistic income and expenses.\n\nThe regressors include a mix of binary, categorical, ordinal, and continuous variables.\n\nBinary variables, such as Has_Job and Drinks_Alcohol, take on only two values and need to be encoded for modeling.\nCategorical variables, like Living_Situation and Housing_Type, represent qualitative distinctions between different student groups.\nSome predictors, like Year_of_Study and Goes_Out_Spends_Money, follow an ordinal structure, meaning they have a meaningful ranking but no consistent numerical spacing.\nFinally, Monthly_Allowance and Monthly_Earnings are continuous variables, requiring attention to their distributions and potential outliers.\n\nBy classifying variables correctly at the outset, we ensure that they are analyzed and interpreted appropriately throughout the modeling process.\n\n3.6.2 Visualizing Variable Distributions\nOnce variables are classified, the next step is to explore their distributions. Understanding how variables are distributed is crucial for identifying potential issues such as skewness, outliers, or missing values. We employ different visualizations depending on the variable type:\nContinuous Variables\nWe begin by examining continuous variables, which are best visualized using histograms and boxplots.\nHistograms\nHistograms display the frequency distribution of a continuous variable. They allow us to assess the overall shape, central tendency, and spread of the data. For example, the histogram of Net_Money helps us determine if the variable follows a roughly normal distribution or if it is skewed. A normal distribution often appears bell-shaped, while skewness can indicate that the data might benefit from transformations (like logarithmic transformations) to meet the assumptions of regression analysis. In our case, the histogram below shows that Net_Money appears roughly normal.\n\n\nR Code\nPython Code\n\n\n\n\n# Histogram of Net_Money\nhist(train_data$Net_Money, \n     main = \"Distribution of Net Money\", \n     xlab = \"Net Money\", \n     col = \"blue\", \n     border = \"white\")\n\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\n# Histogram of Net_Money\nplt.hist(train_data[\"Net_Money\"].dropna(), bins=8, color=\"blue\", edgecolor=\"white\")\nplt.title(\"Distribution of Net Money\")\nplt.xlabel(\"Net Money\")\nplt.ylabel(\"Frequency\")\nplt.show()\n\n\n\n\n\n\n\n\n\n\nBoxplots\nBoxplots provide a concise summary of a variable’s distribution by displaying its quartiles and highlighting potential outliers. Outliers are typically defined as data points that fall below \\(Q1 - 1.5 * IQR\\) or above \\(Q3 + 1.5 * IQR\\). The boxplot below visualizesNet_Money and helps us quickly assess if there are any extreme values that might skew the analysis. In this case, the boxplot suggests that there are no significant outliers according to the IQR method (the method commonly used by ggplot to identify outliers).\n\n\nR Code\nPython Code\n\n\n\n\n# Boxplot of Net Money\nboxplot(train_data$Net_Money, \n        main = \"Boxplot of Net Money\", \n        ylab = \"Net Money\", \n        col = \"lightblue\")\n\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(4, 6))\nax.boxplot(train_data[\"Net_Money\"].dropna(), patch_artist=True,\n           boxprops=dict(facecolor=\"lightblue\"));\nax.set_title(\"Boxplot of Net Money\")\nax.set_ylabel(\"Net Money\")\nax.set_xticks([1])\nax.set_xticklabels([\"\"])\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nBy visualizing the distribution of Net_Money with these plots, we gain valuable insights into its behavior. This understanding not only informs whether transformations are needed but also prepares us for deeper analysis as we move forward with regression modeling.\nCategorical and Ordinal Variables\nCategorical variables require a different approach from continuous ones because they represent distinct groups rather than numerical values. For these variables, bar charts are very effective. They display the frequency of each category, helping us understand the distribution of qualitative attributes.\nFor example, consider the variable Living_Situation. The bar chart below shows how many students fall into each category. From the chart, we can see that category 1 is more heavily represented, while categories 2 and 3 have roughly similar counts. This insight can be critical—if a category is underrepresented, you might need to consider grouping it with similar categories or applying techniques such as one-hot encoding to ensure that each category contributes appropriately to the model.\n\n\nR Code\nPython Code\n\n\n\n\n# Bar plot of Living Situation\nbarplot(table(train_data$Living_Situation), \n        main = \"Living Situation Distribution\", \n        xlab = \"Living Situation\", \n        ylab = \"Frequency\", \n        col = \"purple\")\n\n\n\n\n\n\n\n\n\n\n# Count occurrences of each category\nliving_counts = train_data[\"Living_Situation\"].value_counts()\n\n# Bar plot of Living Situation\nplt.bar(living_counts.index, living_counts.values, color=\"purple\")\nplt.title(\"Living Situation Distribution\")\nplt.xlabel(\"Living Situation\")\nplt.ylabel(\"Frequency\")\nplt.xticks(rotation=45)  # Optional: rotate labels if they overlap\n\n(array([0. , 0.5, 1. , 1.5, 2. , 2.5, 3. , 3.5, 4. ]), [Text(0.0, 0, '0.0'), Text(0.5, 0, '0.5'), Text(1.0, 0, '1.0'), Text(1.5, 0, '1.5'), Text(2.0, 0, '2.0'), Text(2.5, 0, '2.5'), Text(3.0, 0, '3.0'), Text(3.5, 0, '3.5'), Text(4.0, 0, '4.0')])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nFor ordinal variables (which have a natural order but not a fixed numerical interval), you might still use bar charts to show the ranking or frequency of each level. Additionally, understanding these distributions can help you decide whether to treat them as categorical variables or convert them into numeric scores for analysis.\nExploring Relationships Between Variables\nBeyond examining individual variables, it is crucial to explore how they interact with one another, especially the predictors and the response variable. Understanding these relationships helps identify which predictors might be influential in the model and whether any issues, like multicollinearity, could affect regression estimates.\nCorrelation Matrices\nFor continuous variables, correlation matrices provide a numerical summary of how strongly pairs of variables are related. High correlations between predictors might signal multicollinearity, which can distort model estimates. For demonstration, consider the correlation matrix computed for Net_Money, Monthly_Allowance, and Monthly_Earnings:\n\n\nR Code\nPython Code\n\n\n\n\n# Correlation matrix\ncor_matrix &lt;- cor(train_data[, c(\"Net_Money\", \"Monthly_Allowance\", \"Monthly_Earnings\")], use = \"complete.obs\")\nprint(cor_matrix)\n\n                  Net_Money Monthly_Allowance Monthly_Earnings\nNet_Money         1.0000000         0.2975895        0.7525736\nMonthly_Allowance 0.2975895         1.0000000       -0.0319396\nMonthly_Earnings  0.7525736        -0.0319396        1.0000000\n\n\n\n\n\n# Select relevant columns and drop rows with missing values\ncor_matrix = train_data[[\"Net_Money\", \"Monthly_Allowance\", \"Monthly_Earnings\"]].corr(method=\"pearson\")\nprint(cor_matrix)\n\n                   Net_Money  Monthly_Allowance  Monthly_Earnings\nNet_Money           1.000000            0.29759          0.752574\nMonthly_Allowance   0.297590            1.00000         -0.031940\nMonthly_Earnings    0.752574           -0.03194          1.000000\n\n\n\n\n\nIn the output, we observe a strong positive correlation (corr = 0.757) between Monthly_Earnings and Net_Money. This result is intuitive. Higher earnings typically lead to more money left at the end of the month, resulting in a higher Net_Money.\nScatterplots\nScatter plots visually depict the relationship between two continuous variables. For example, plotting Monthly_Allowance against Net_Money helps us assess whether students with higher allowances tend to have higher or lower net savings. In the scatter plot below, a slightly positive trend is visible. However, the points are quite scattered, indicating that while there may be a relationship, it is not overwhelmingly strong. Such visual insights might prompt further investigation, perhaps considering polynomial transformations or interaction terms if nonlinearity is suspected.\n\n\nR Code\nPython Code\n\n\n\n\n# Scatter plot of Monthly Allowance vs. Net Money\nplot(train_data$Monthly_Allowance, train_data$Net_Money, \n     main = \"Net Money vs. Monthly Allowance\", \n     xlab = \"Monthly Allowance\", \n     ylab = \"Net Money\", \n     col = \"blue\", \n     pch = 19)\nabline(lm(Net_Money ~ Monthly_Allowance, data = train_data), col = \"red\", lwd = 2)\n\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Scatter plot with regression line\nplt.figure(figsize=(6, 4))\nsns.regplot(\n    data=train_data,\n    x=\"Monthly_Allowance\",\n    y=\"Net_Money\",\n    scatter_kws={\"color\": \"blue\", \"s\": 40},  # s = point size\n    line_kws={\"color\": \"red\", \"linewidth\": 2}\n)\nplt.title(\"Net Money vs. Monthly Allowance\")\nplt.xlabel(\"Monthly Allowance\")\nplt.ylabel(\"Net Money\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nBoxplots for Categorical Variables\nFor categorical predictors, boxplots are an excellent tool to compare the distribution of the response variable across different groups. For instance, examining how Net_Money varies by Living_Situation can reveal whether students in different living arrangements experience different financial outcomes. In the boxplot below, the distributions of Net_Money across categories of Living_Situation appear quite similar. This similarity may suggest that Living_Situation has little impact on Net_Money in our dataset.\n\n\nR Code\nPython Code\n\n\n\n\n# Boxplot of Net Money by Living Situation\nboxplot(Net_Money ~ Living_Situation, \n        data = train_data, \n        main = \"Net Money by Living Situation\", \n        xlab = \"Living Situation\", \n        ylab = \"Net Money\", \n        col = \"lightgreen\")\n\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Boxplot of Net Money by Living Situation\nplt.figure(figsize=(6, 4))\nsns.boxplot(\n    data=train_data,\n    x=\"Living_Situation\",\n    y=\"Net_Money\",\n    color=\"lightgreen\"\n)\nplt.title(\"Net Money by Living Situation\")\nplt.xlabel(\"Living Situation\")\nplt.ylabel(\"Net Money\")\nplt.xticks(rotation=45)  # Optional: rotate if labels overlap\n\n([0, 1, 2], [Text(0, 0, '1.0'), Text(1, 0, '2.0'), Text(2, 0, '3.0')])\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nSummary Statistics\nIn addition to visual exploration, descriptive statistics provide a numerical summary of the dataset that is especially useful for beginners. Summary statistics give you a snapshot of the central tendency and spread of your data, helping you quickly grasp its overall characteristics.\nFor instance, if you notice that the mean of Monthly_Earning is significantly higher than its median, it might suggest that a few high values (or outliers) are skewing the data.\n\n\nR Code\nPython Code\n\n\n\n\n# Summary statistics for numerical variables\nsummary(train_data[, c(\"Net_Money\", \"Monthly_Allowance\", \"Monthly_Earnings\")])\n\n   Net_Money        Monthly_Allowance Monthly_Earnings\n Min.   :-1719.38   Min.   :  51.33   Min.   :   0.0  \n 1st Qu.: -387.69   1st Qu.: 399.83   1st Qu.:   0.0  \n Median :   66.15   Median : 494.10   Median : 348.0  \n Mean   :  117.76   Mean   : 497.44   Mean   : 500.5  \n 3rd Qu.:  589.36   3rd Qu.: 592.96   3rd Qu.: 998.4  \n Max.   : 1932.42   Max.   :1088.94   Max.   :1839.9  \n\n\n\n\n\n# Summary statistics for numerical variables\ntrain_data[[\"Net_Money\", \"Monthly_Allowance\", \"Monthly_Earnings\"]].describe()\n\n         Net_Money  Monthly_Allowance  Monthly_Earnings\ncount   797.000000         797.000000        797.000000\nmean    117.758595         497.442424        500.451432\nstd     675.877166         147.209448        536.948133\nmin   -1719.378062          51.329604          0.000000\n25%    -387.687620         399.833067          0.000000\n50%      66.145622         494.103907        347.994676\n75%     589.360845         592.956717        998.419667\nmax    1932.416524        1088.935656       1839.947244\n\n\n\n\n\n\n3.6.3 Key Takeaways from EDA\nConducting Exploratory Data Analysis (EDA) allows us to gain an initial understanding of the data and its underlying patterns before moving on to model building. Through EDA, we identify the types of variables present, examine their distributions, and uncover potential issues such as skewness, outliers, or multicollinearity. This process helps to highlight which variables might be strong predictors and which may require additional transformation or treatment. For instance, a strong correlation between two variables, like Monthly_Earnings and Net_Money, signals that earnings are likely a key driver of net savings. At the same time, observing differences in distributions or spotting similar patterns across groups in boxplots can inform us about the impact of categorical factors like Living_Situation.\nIt is important to remember that the insights gained from EDA are preliminary and primarily serve to inform further analysis. When we explore relationships between only two variables, we might overlook the influence of other factors, which could lead to misleading conclusions if taken in isolation. EDA is a crucial step for forming initial hypotheses and guiding decisions regarding data transformations, feature engineering, and the overall modeling strategy. With this foundation, we are better prepared to build a robust Ordinary Least Squares (OLS) regression model on data that has been carefully examined and understood.",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Zestylicious Ordinary Least-squares Regression</span>"
    ]
  },
  {
    "objectID": "book/03-ols.html#data-modelling",
    "href": "book/03-ols.html#data-modelling",
    "title": "3  Zestylicious Ordinary Least-squares Regression",
    "section": "\n3.7 Data Modelling",
    "text": "3.7 Data Modelling\nAfter conducting Exploratory Data Analysis (EDA), we transition to the modeling stage, where we apply a structured approach to uncover relationships between variables and predict outcomes. In this section, we focus on Ordinary Least Squares (OLS) regression, a widely used statistical technique for modeling linear relationships.\nOLS aims to estimate the effect of multiple predictors on an outcome variable by minimizing the sum of squared differences between observed and predicted values. This approach helps quantify financial behaviors, allowing us to interpret the impact of various factors on students’ net financial balance.\n\n3.7.1 Choosing a Suitable Regression Model\nThe choice of regression model depends on the patterns identified in EDA and the objectives of our analysis. Regression techniques vary in complexity, with some handling simple linear relationships and others accounting for more nuanced effects. Below are common approaches:\n\n\nSimple Linear Regression models the relationship between a single predictor and the response variable. This approach is suitable when we suspect a dominant factor driving financial balance.\n\nMultiple Linear Regression extends simple regression by incorporating multiple predictors, allowing us to account for various financial influences simultaneously.\n\nPolynomial Regression captures non-linear relationships by introducing polynomial terms of predictors, useful when relationships observed in scatter plots are curved rather than strictly linear.\n\nLog-Linear Models transform skewed distributions to improve interpretability and meet regression assumptions.\n\nRegularized Regression (Ridge and Lasso) applies penalties to regression coefficients to handle multicollinearity and enhance model generalization by reducing overfitting.\n\nGiven that our goal is to examine how multiple factors-such as income, expenses, and living arrangements—affect students’ financial balance, we select Multiple Linear Regression via OLS. This method allows us to quantify the influence of each predictor while controlling for confounding effects.\n\n3.7.2 Defining Modeling Parameters\nOnce we select OLS regression, we define the key modeling components: the response variable (dependent variable) and the predictor variables (independent variables).\nResponse Variable (Y):\nThe response variable, also known as the dependent variable, represents the financial outcome we aim to explain:\n\n\nNet_Money: The dependent variable representing financial balance.\nPredictor Variables (X):\nEach predictor variable is chosen based on its theoretical and statistical relevance in explaining financial behavior:\n\n\nHas_Job (Binary) – Indicates whether the student has a job (1 = Yes, 0 = No).\n\nFinancially_Dependent (Binary) – Identifies students who rely on external financial support.\n\nYear_of_Study (Ordinal) – Represents academic seniority (higher values indicate later years).\n\nGoes_Out_Spends_Money (Ordinal) – Measures spending behavior on a scale from 1 to 6.\n\nDrinks_Alcohol (Binary) – Identifies whether a student consumes alcohol, which may impact discretionary spending.\n\nMonthly_Allowance (Continuous) – Represents financial support received from family or scholarships.\n\nMonthly_Earnings (Continuous) – Reflects the student’s personal income from work.\n\nLiving_Situation (Categorical) – Encodes different living arrangements (e.g., dormitory, shared apartment, living with family).\n\nHousing_Type (Categorical) – Further distinguishes between different types of housing situations.\n\nCooks_at_Home (Binary) – Indicates whether the student regularly prepares meals at home.\n\nThese predictors capture a mix of economic, behavioral, and lifestyle factors, providing a comprehensive view of the drivers of student financial balance.\n\n3.7.3 Setting Up the Modeling Equation\nWith all predictors defined, the OLS regression equation models the relationship between Net_Money and the predictor variables:\n\n\\[\n\\begin{align*}\n\\text{Net\\_Money} &= \\beta_0 \\\\\n&\\quad + \\beta_1 \\times \\text{Has\\_Job} \\\\\n&\\quad + \\beta_2 \\times \\text{Financially\\_Dependent} \\\\\n&\\quad + \\beta_3 \\times \\text{Year\\_of\\_Study} \\\\\n&\\quad + \\beta_4 \\times \\text{Goes\\_Out\\_Spends\\_Money} \\\\\n&\\quad + \\beta_5 \\times \\text{Drinks\\_Alcohol} \\\\\n&\\quad + \\beta_6 \\times \\text{Monthly\\_Allowance} \\\\\n&\\quad + \\beta_7 \\times \\text{Monthly\\_Earnings} \\\\\n&\\quad + \\beta_8 \\times \\text{Living\\_Situation} \\\\\n&\\quad + \\beta_9 \\times \\text{Housing\\_Type} \\\\\n&\\quad + \\beta_{10} \\times \\text{Cooks\\_at\\_Home} \\\\\n&\\quad + \\epsilon\n\\end{align*}\n\\]\n\nwhere:\n\n\n\\(\\beta_0\\) represents the intercept, or the baseline Net_Money when all predictors are set to zero.\n\n\\(\\beta_1, \\beta_2, ..., \\beta_{10}\\) are the regression coefficients, quantifying the impact of each predictor on financial balance.\n\n\\(\\epsilon\\) is the error term, accounting for unexplained variability and random noise.\n\nEach coefficient provides insight into how Net_Money changes when a specific predictor increases by one unit, holding all other factors constant. For example:\n\n\n\\(\\beta_5\\) (Drinks_Alcohol) measures the financial impact of alcohol consumption, which may reflect higher discretionary spending.\n\n\\(\\beta_6\\) (Monthly_Allowance) quantifies the increase in Net_Money per additional dollar of allowance.\n\n\\(\\beta_10\\) (Cooks_at_Home) indicates how much more (or less) financially stable students are when they cook at home instead of eating out.\n\nIf significant interaction effects exist—such as students who live independently having a different financial impact from increased earnings compared to those living with family—we can extend the model by adding interaction terms.",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Zestylicious Ordinary Least-squares Regression</span>"
    ]
  },
  {
    "objectID": "book/03-ols.html#estimation",
    "href": "book/03-ols.html#estimation",
    "title": "3  Zestylicious Ordinary Least-squares Regression",
    "section": "\n3.8 Estimation",
    "text": "3.8 Estimation\nWith the data modeling stage completed, we now move to estimation, where we fit the Ordinary Least Squares (OLS) regression model to the data and obtain numerical estimates for the regression coefficients. These estimates quantify how much each predictor contributes to the response variable, allowing us to measure their individual effects on Net Money.\nThe goal of estimation is to determine the best-fitting regression line by minimizing the sum of squared residuals—the differences between the observed and predicted values. This step provides a mathematical basis for analyzing financial behaviors in students.\n\n3.8.1 Fitting the Model\nTo estimate the regression coefficients, we fit the OLS model to the training data using Python (statsmodels) or R (lm). The model is trained using least squares estimation, which finds the coefficients that minimize the total squared error between observed values and predictions.\nIn R, we can fit the regression model using the lm() function:\n\n\nR Code\nPython Code\n\n\n\n\n# Load necessary library\nlibrary(stats)\n\n# Fit the OLS model\nols_model &lt;- lm(Net_Money ~ Has_Job + Financially_Dependent + Year_of_Study + Goes_Out_Spends_Money + Drinks_Alcohol + Monthly_Allowance + Monthly_Earnings + Living_Situation + Housing_Type + Cooks_at_Home, data = train_data)\n\n# Display summary of model results\nsummary(ols_model)\n\n\nCall:\nlm(formula = Net_Money ~ Has_Job + Financially_Dependent + Year_of_Study + \n    Goes_Out_Spends_Money + Drinks_Alcohol + Monthly_Allowance + \n    Monthly_Earnings + Living_Situation + Housing_Type + Cooks_at_Home, \n    data = train_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-752.76 -142.00    9.64  154.20  679.52 \n\nCoefficients:\n                         Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            -647.24459   48.05092 -13.470  &lt; 2e-16 ***\nHas_Job1                 91.24439   39.55815   2.307   0.0213 *  \nFinancially_Dependent1 -488.10094   15.87713 -30.742  &lt; 2e-16 ***\nYear_of_Study          -100.14255    6.94097 -14.428  &lt; 2e-16 ***\nGoes_Out_Spends_Money   -47.85370    4.10987 -11.644  &lt; 2e-16 ***\nDrinks_Alcohol1        -139.96472   16.10396  -8.691  &lt; 2e-16 ***\nMonthly_Allowance         1.51624    0.05361  28.283  &lt; 2e-16 ***\nMonthly_Earnings          0.92083    0.03686  24.981  &lt; 2e-16 ***\nLiving_Situation        107.91555    9.57487  11.271  &lt; 2e-16 ***\nHousing_Type             57.77879    9.89696   5.838 7.72e-09 ***\nCooks_at_Home1          -86.39027   16.22054  -5.326 1.31e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 221.7 on 786 degrees of freedom\nMultiple R-squared:  0.8937,    Adjusted R-squared:  0.8924 \nF-statistic:   661 on 10 and 786 DF,  p-value: &lt; 2.2e-16\n\n\n\n\n\nimport statsmodels.formula.api as smf\n\n# Fit the OLS model using a formula\nols_model = smf.ols(\n    formula=\"Net_Money ~ Has_Job + Financially_Dependent + Year_of_Study + Goes_Out_Spends_Money + Drinks_Alcohol + Monthly_Allowance + Monthly_Earnings + Living_Situation + Housing_Type + Cooks_at_Home\",\n    data=train_data\n).fit()\n\n# Display summary of model results\nprint(ols_model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:              Net_Money   R-squared:                       0.894\nModel:                            OLS   Adj. R-squared:                  0.892\nMethod:                 Least Squares   F-statistic:                     661.0\nDate:                Wed, 02 Jul 2025   Prob (F-statistic):               0.00\nTime:                        02:36:32   Log-Likelihood:                -5430.3\nNo. Observations:                 797   AIC:                         1.088e+04\nDf Residuals:                     786   BIC:                         1.093e+04\nDf Model:                          10                                         \nCovariance Type:            nonrobust                                         \n================================================================================================\n                                   coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------------------------\nIntercept                     -647.2446     48.051    -13.470      0.000    -741.568    -552.921\nHas_Job[T.1.0]                  91.2444     39.558      2.307      0.021      13.592     168.897\nFinancially_Dependent[T.1.0]  -488.1009     15.877    -30.742      0.000    -519.268    -456.934\nDrinks_Alcohol[T.1.0]         -139.9647     16.104     -8.691      0.000    -171.577    -108.353\nCooks_at_Home[T.1.0]           -86.3903     16.221     -5.326      0.000    -118.231     -54.550\nYear_of_Study                 -100.1425      6.941    -14.428      0.000    -113.768     -86.518\nGoes_Out_Spends_Money          -47.8537      4.110    -11.644      0.000     -55.921     -39.786\nMonthly_Allowance                1.5162      0.054     28.283      0.000       1.411       1.621\nMonthly_Earnings                 0.9208      0.037     24.981      0.000       0.848       0.993\nLiving_Situation               107.9155      9.575     11.271      0.000      89.120     126.711\nHousing_Type                    57.7788      9.897      5.838      0.000      38.351      77.206\n==============================================================================\nOmnibus:                        4.197   Durbin-Watson:                   1.944\nProb(Omnibus):                  0.123   Jarque-Bera (JB):                4.115\nSkew:                          -0.138   Prob(JB):                        0.128\nKurtosis:                       3.218   Cond. No.                     5.14e+03\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The condition number is large, 5.14e+03. This might indicate that there are\nstrong multicollinearity or other numerical problems.\n\n\n\n\n\n\n3.8.2 Interpreting the Coefficients\nAfter fitting the model, we examine the estimated coefficients to understand their impact. Each coefficient obtained from the OLS regression represents the expected change in Net_Money for a one-unit increase in the corresponding predictor, holding all other variables constant. The estimated regression equation can be expressed as:\n\n\\[\n\\begin{align*}\n\\text{Net\\_Money} &= -647.24 \\\\\n&\\quad + 91.24 \\times \\text{Has\\_Job} \\\\\n&\\quad - 488.10 \\times \\text{Financially\\_Dependent} \\\\\n&\\quad - 100.14 \\times \\text{Year\\_of\\_Study} \\\\\n&\\quad - 47.85 \\times \\text{Goes\\_Out\\_Spends\\_Money} \\\\\n&\\quad - 139.96 \\times \\text{Drinks\\_Alcohol} \\\\\n&\\quad + 1.52 \\times \\text{Monthly\\_Allowance} \\\\\n&\\quad + 0.92 \\times \\text{Monthly\\_Earnings} \\\\\n&\\quad + 107.92 \\times \\text{Living\\_Situation} \\\\\n&\\quad + 57.78 \\times \\text{Housing\\_Type} \\\\\n&\\quad - 86.39 \\times \\text{Cooks\\_at\\_Home} \\\\\n&\\quad + \\epsilon\n\\end{align*}\n\\]\n\nFor example:\n\nThe intercept (\\(\\beta_0 = -647.24\\)) represents the expected financial balance for a student in the reference group—i.e., a student who has no job, is not financially dependent, does not go out to spend money or drink alcohol, receives no allowance or earnings, and is in the baseline category for all categorical variables.\nA 1 dollar increase in Monthly_Allowance (\\(\\beta\\) = 1.52$) is associated with a $1.52 increase in Net_Money, suggesting that students with larger allowances tend to have a higher financial balance, all else being equal.\n\nThese estimates provide an initial understanding of the direction and magnitude of relationships between predictors and financial balance. However, before drawing conclusions, we need to validate model assumptions and evaluate the statistical significance of each coefficient.",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Zestylicious Ordinary Least-squares Regression</span>"
    ]
  },
  {
    "objectID": "book/03-ols.html#goodness-of-fit",
    "href": "book/03-ols.html#goodness-of-fit",
    "title": "3  Zestylicious Ordinary Least-squares Regression",
    "section": "\n3.9 Goodness of Fit",
    "text": "3.9 Goodness of Fit\nAfter estimating the regression coefficients, the next step is to assess how well the model fits the data and whether it satisfies the assumptions of Ordinary Least Squares (OLS) regression. This evaluation ensures that the model is not only statistically valid but also generalizes well to unseen data. A well-fitting model should explain a substantial proportion of variation in the response variable while adhering to key statistical assumptions. If these assumptions are violated, model estimates may be biased, leading to misleading conclusions.\n\n3.9.1 Checking Model Assumptions\nOLS regression is built on several fundamental assumptions:\n\nlinearity\nindependence of errors\nhomoscedasticity\nnormality of residuals\n\nIf these assumptions hold, OLS provides unbiased, efficient, and consistent estimates. We assess each assumption through diagnostic plots and statistical tests.\nLinearity\nA core assumption of OLS is that the relationship between each predictor and the response variable is linear. If this assumption is violated, the model may systematically under- or overestimate Net_Money, leading to biased predictions. The Residuals vs. Fitted values plot is a common diagnostic tool for checking linearity. In a well-specified linear model, residuals should be randomly scattered around zero, without any discernible patterns. If the residuals exhibit a U-shaped or curved pattern, this suggests a non-linear relationship, indicating that transformations such as logarithmic, square root, or polynomial terms may be necessary.\nTo visualize linearity, we plot the residuals against the fitted values:\n\n\nR Code\nPython Code\n\n\n\n\n# Residuals vs Fitted plot (R)\nplot(ols_model$fitted.values, residuals(ols_model), \n     main = \"Residuals vs Fitted\", xlab = \"Fitted Values\", ylab = \"Residuals\")\nabline(h = 0, col = \"red\")\n\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\n# Extract fitted values and residuals\nfitted_vals = ols_model.fittedvalues\nresiduals = ols_model.resid\n\n# Plot Residuals vs Fitted\nplt.figure(figsize=(6, 4))\nplt.scatter(fitted_vals, residuals, alpha=0.7)\nplt.axhline(y=0, color='red', linestyle='--')\nplt.title(\"Residuals vs Fitted\")\nplt.xlabel(\"Fitted Values\")\nplt.ylabel(\"Residuals\")\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nIf the residual plot displays a clear trend, polynomial regression or feature engineering may be required to better capture the underlying data structure. However, in this case, the residuals appear to be randomly scattered around the horizontal axis, with no obvious patterns such as curves or systematic structure. This suggests that the linearity assumption of the OLS model holds reasonably well in this case. Therefore, no immediate transformation or addition of nonlinear terms is necessary to capture the relationship between predictors and the response variable.\nIndependence of Errors\nThe residuals, or errors, in an OLS model should be independent of one another. This assumption is particularly relevant in time-series or sequential data, where errors from one observation might influence subsequent observations, leading to autocorrelation. If the errors are correlated, the estimated standard errors will be biased, making hypothesis testing unreliable.\nThe Durbin-Watson test is commonly used to detect autocorrelation. This test produces a statistic that ranges between 0 and 4, where values close to 2 indicate no significant autocorrelation, while values near 0 or 4 suggest positive or negative correlation in the residuals.\n\n\nR Code\nPython Code\n\n\n\n\ndwtest(ols_model)\n\n\n    Durbin-Watson test\n\ndata:  ols_model\nDW = 1.9437, p-value = 0.2133\nalternative hypothesis: true autocorrelation is greater than 0\n\n\n\n\n\nfrom statsmodels.stats.stattools import durbin_watson\n\n# Durbin-Watson test for autocorrelation of residuals\ndw_stat = durbin_watson(ols_model.resid)\n\nprint(f\"Durbin-Watson statistic: {dw_stat:.3f}\")\n\nDurbin-Watson statistic: 1.944\n\n\n\n\n\nBased on the Durbin-Watson test, the test statistic is 1.9437 with a p-value of 0.2133. Since the statistic is close to 2 and the p-value is not statistically significant, we do not find evidence of autocorrelation in the residuals. This suggests that the assumption of independence of errors holds for this model.\nIf the test suggests autocorrelation, a possible solution is to use time-series regression models such as Autoregressive Integrated Moving Average (ARIMA) or introduce lagged predictors to account for dependencies in the data.\nHomoscedasticity (Constant Variance of Errors)\nOLS regression assumes that the variance of residuals remains constant across all fitted values. If this assumption is violated, the model exhibits heteroscedasticity, where the spread of residuals increases or decreases systematically. This can result in inefficient coefficient estimates, making some predictors appear statistically significant when they are not.\nTo check for heteroscedasticity, we plot residuals against the fitted values and conduct a Breusch-Pagan test, which formally tests whether residual variance is constant.\n\n\nR Code\nPython Code\n\n\n\n\nbptest(ols_model)  # Uses all regressors, like Python\n\n\n    studentized Breusch-Pagan test\n\ndata:  ols_model\nBP = 14.381, df = 10, p-value = 0.1563\n\n\n\n\n\nfrom statsmodels.stats.diagnostic import het_breuschpagan\n\n# Extract residuals and design matrix from the fitted model\nresiduals = ols_model.resid\nexog = ols_model.model.exog  # independent variables (with intercept)\n\n# Perform Breusch-Pagan test\nbp_test = het_breuschpagan(residuals, exog)\n\n# Unpack results\nbp_stat, bp_pvalue, _, _ = bp_test\n\nprint(f\"Breusch-Pagan test statistic: {bp_stat:.3f}\")\n\nBreusch-Pagan test statistic: 14.381\n\nprint(f\"P-value: {bp_pvalue:.4f}\")\n\nP-value: 0.1563\n\n\n\n\n\nSince the p-value (0.1563) is greater than the conventional threshold of 0.05, we fail to reject the null hypothesis of constant variance. This indicates no significant evidence of heteroscedasticity, and thus the assumption of homoscedasticity appears to hold for this model.\nIf heteroscedasticity is detected, solutions include applying weighted least squares (WLS) regression, transforming the dependent variable (e.g., using a log transformation), or computing robust standard errors to correct for variance instability.\nNormality of Residuals\nFor valid hypothesis testing and confidence interval estimation, OLS assumes that residuals follow a normal distribution. If residuals deviate significantly from normality, statistical inference may be unreliable, particularly for small sample sizes.\nA Q-Q plot (Quantile-Quantile plot) is used to assess normality. If residuals are normally distributed, the points should lie along the reference line.\n\n\nR Code\nPython Code\n\n\n\n\nqqnorm(residuals(ols_model))\nqqline(residuals(ols_model), col = \"red\")\n\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\n\n# Extract residuals from the model\nresiduals = ols_model.resid\n\n# Q-Q plot of residuals\nplt.figure(figsize=(6, 4))\n\n&lt;Figure size 600x400 with 0 Axes&gt;\n\n_ = stats.probplot(residuals, dist=\"norm\", plot=plt)  # Suppress output by assigning to _\nplt.title(\"Q-Q Plot of Residuals\")\n\nText(0.5, 1.0, 'Q-Q Plot of Residuals')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nThe Q-Q plot shows that the residuals closely follow the 45-degree reference line, indicating that the residuals are approximately normally distributed. While there are some mild deviations at the tails, these are minimal and do not suggest serious violations of the normality assumption.\nIf the plot reveals heavy tails or skewness, potential solutions include applying log or Box-Cox transformations to normalize the distribution. In cases where normality is severely violated, using a non-parametric model or bootstrapping confidence intervals may be appropriate.\n\n3.9.2 Evaluating Model Fit\nA good model should explain a large proportion of variance in the response variable.\nR-Squared\nBeyond checking assumptions, it is essential to assess how well the model explains variability in the response variable. One of the most commonly used metrics is R-Squared (\\(R^2\\)), which measures the proportion of variance in Net_Money that is explained by the predictors. An \\(R^2\\) value close to 1 indicates a strong model fit, whereas a low value suggests that important predictors may be missing or that the model is poorly specified.\nWe can retrieve the R-squared and Adjusted R-squared values from the model summary:\n\n\nR Code\nPython Code\n\n\n\n\nsummary(ols_model)$r.squared  # R-squared value\n\n[1] 0.8937252\n\nsummary(ols_model)$adj.r.squared  # Adjusted R-squared\n\n[1] 0.8923731\n\n\n\n\n\n# R-squared\nr_squared = ols_model.rsquared\n\n# Adjusted R-squared\nadj_r_squared = ols_model.rsquared_adj\n\n# Print values\nprint(f\"R-squared: {r_squared:.4f}\")\n\nR-squared: 0.8937\n\nprint(f\"Adjusted R-squared: {adj_r_squared:.4f}\")\n\nAdjusted R-squared: 0.8924\n\n\n\n\n\nIn this model, the R-squared is 0.894 and the adjusted R-squared is 0.892, indicating that around 89% of the variance in Net_Money is explained by the model.\nHowever, while \\(R^2\\) provides insight into model fit, it has limitations. Adding more predictors will always increase \\(R^2\\), even if those predictors have little explanatory power. That’s why Adjusted R-squared is often preferred, as it adjusts for the number of predictors and only increases when a new variable meaningfully improves the model.\nFinally, a high \\(R^2\\) should not be interpreted as evidence of causation, nor does it guarantee the model is free from issues like omitted variable bias or multicollinearity. Always complement goodness-of-fit metrics with residual diagnostics and statistical inference to ensure model reliability.\nIdentifying Outliers and Influential Points\nOutliers and influential observations can distort regression estimates, making it crucial to detect and address them appropriately. One way to identify extreme residuals is through residual plots, where large deviations from zero may indicate problematic data points.\n\n\nR Code\nPython Code\n\n\n\n\nplot(residuals(ols_model), main = \"Residual Plot\", ylab = \"Residuals\")\nabline(h = 0, col = \"red\")\n\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\n\n# Extract residuals\nresiduals = ols_model.resid\n\n# Residual plot (residuals vs observation index)\nplt.figure(figsize=(6, 4))\n\n&lt;Figure size 600x400 with 0 Axes&gt;\n\nplt.plot(residuals, marker='o', linestyle='none', alpha=0.7)\n\n[&lt;matplotlib.lines.Line2D object at 0x14c17d710&gt;]\n\nplt.axhline(y=0, color='red', linestyle='--')\n\n&lt;matplotlib.lines.Line2D object at 0x14c5e1390&gt;\n\nplt.title(\"Residual Plot\")\n\nText(0.5, 1.0, 'Residual Plot')\n\nplt.xlabel(\"Observation Index\")\n\nText(0.5, 0, 'Observation Index')\n\nplt.ylabel(\"Residuals\")\n\nText(0, 0.5, 'Residuals')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nIn the residual plot above, the residuals appear to be evenly and randomly scattered around zero, with no clear pattern or extreme values. This suggests that there are no obvious outliers or highly influential observations in the dataset. The model residuals behave as expected, reinforcing the assumption that the data points do not exert undue influence on the regression fit.\nAnother important diagnostic tool is Cook’s Distance, which measures the influence of each observation on the regression results. Data points with Cook’s Distance values greater than 0.5 may significantly impact model estimates.\n\n\nR Code\nPython Code\n\n\n\n\ncook_values &lt;- cooks.distance(ols_model)\nplot(cook_values, type = \"h\", main = \"Cook's Distance\")\n\n\n\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\n\n# Get Cook's distance values\ninfluence = ols_model.get_influence()\ncooks_d = influence.cooks_distance[0]  # Values\n\n# Plot Cook's distance\nfig, ax = plt.subplots(figsize=(6, 4))\nmarkerline, stemlines, baseline = ax.stem(cooks_d, markerfmt=\",\")\nax.set_title(\"Cook's Distance\")\n\nText(0.5, 1.0, \"Cook's Distance\")\n\nax.set_xlabel(\"Observation Index\")\n\nText(0.5, 0, 'Observation Index')\n\nax.set_ylabel(\"Cook's Distance\")\n\nText(0, 0.5, \"Cook's Distance\")\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nIn the plot above, all observations have Cook’s Distance values well below the 0.5 threshold. This indicates that no individual data point has an undue influence on the model’s estimates.\nIf influential points are identified, the next steps involve investigating data quality, testing robust regression techniques, or applying Winsorization, which involves replacing extreme values with more moderate ones to reduce their impact.",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Zestylicious Ordinary Least-squares Regression</span>"
    ]
  },
  {
    "objectID": "book/03-ols.html#results",
    "href": "book/03-ols.html#results",
    "title": "3  Zestylicious Ordinary Least-squares Regression",
    "section": "\n3.10 Results",
    "text": "3.10 Results\nAfter validating the goodness of fit, we now assess how well the model performs in both predictive analysis and inferential analysis. This step involves using the trained model to generate predictions on unseen data and evaluating how well it generalizes beyond the training set. Additionally, we analyze the estimated regression coefficients to draw meaningful conclusions about student financial behaviors.\n\n3.10.1 Predictive Analysis\nA key objective of regression modeling is to generate reliable predictions. To assess how well our model generalizes, we apply it to the test dataset—a portion of the original data that was not used for model training. If the model’s predictions align closely with actual outcomes, we can conclude that it has strong predictive power.\nIn R, we use the predict() function to apply the trained OLS model to the test set. In Python, we use the predict() method from the statsmodels library after ensuring the test data is properly formatted.\n\n\nR Code\nPython Code\n\n\n\n\n# Generate predictions on the test set\ny_pred &lt;- predict(ols_model, newdata=test_data)\n\n\n\n\nimport statsmodels.api as sm\n\n# Prepare the test data: add constant term to match training\nX_test = test_data[[\n    \"Has_Job\", \"Financially_Dependent\", \"Year_of_Study\",\n    \"Goes_Out_Spends_Money\", \"Drinks_Alcohol\", \"Monthly_Allowance\",\n    \"Monthly_Earnings\", \"Living_Situation\", \"Housing_Type\", \"Cooks_at_Home\"\n]]\nX_test = sm.add_constant(X_test)  # Add intercept term\n\n# Generate predictions\ny_pred = ols_model.predict(X_test)\n\n\n\n\nOnce predictions are generated, we evaluate their accuracy using common regression error metrics.\nPerformance Metrics\nModel accuracy is assessed using four standard error metrics:\n\n\nMean Absolute Error (MAE) measures the average absolute differences between predicted and actual values. A lower MAE indicates better model accuracy.\n\nMean Squared Error (MSE) calculates the average squared differences between predicted and actual values, penalizing larger errors more heavily.\n\nRoot Mean Squared Error (RMSE) is the square root of MSE, making it easier to interpret since it retains the same units as the dependent variable (Net_Money).\n\nR-squared (\\(R^2\\)) quantifies the proportion of variance in Net_Money explained by the model. A higher \\(R^2\\) value indicates better model performance.\n\nThese metrics can be computed as follows:\n\n\nR Code\nPython Code\n\n\n\n\n# Extract response variable from test data\ny_test &lt;- test_data$Net_Money\n\n# Calculate metrics in R\nmae &lt;- mean(abs(y_test - y_pred))\nmse &lt;- mean((y_test - y_pred)^2)\nrmse &lt;- sqrt(mse)\nr2 &lt;- summary(ols_model)$r.squared\n\ncat(sprintf(\"MAE: %.2f, MSE: %.2f, RMSE: %.2f, R-squared: %.2f\", mae, mse, rmse, r2))\n\nMAE: 175.48, MSE: 45299.10, RMSE: 212.84, R-squared: 0.89\n\n\n\n\n\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nimport numpy as np\n\n# Extract the true values\ny_test = test_data[\"Net_Money\"]\n\n# Calculate metrics\nmae = mean_absolute_error(y_test, y_pred)\nmse = mean_squared_error(y_test, y_pred)\nrmse = np.sqrt(mse)\nr2 = r2_score(y_test, y_pred)\n\n# Print results\nprint(f\"MAE: {mae:.2f}, MSE: {mse:.2f}, RMSE: {rmse:.2f}, R-squared: {r2:.2f}\")\n\nMAE: 175.48, MSE: 45299.10, RMSE: 212.84, R-squared: 0.91\n\n\n\n\n\nIf the RMSE is significantly larger than the MAE, it suggests that the model is highly sensitive to large prediction errors, meaning that certain extreme values are having a disproportionate impact on the model’s performance. Similarly, a low R-squared value may indicate that important predictors are missing from the model or that the relationship is more complex than a simple linear pattern can capture.\nIn this case, the model’s performance metrics are encouraging. With a MAE of 175.48, the model’s predictions deviate from actual values by about $175 on average. The RMSE of 212.84, which is not drastically higher than the MAE, suggests that large errors are present but not excessively dominant. An R-squared value of 0.89 confirms that the model explains a substantial portion of the variance in Net_Money, indicating strong predictive performance and a solid overall model fit.\n\n3.10.2 Inferential Analysis\nBeyond prediction, OLS regression allows us to interpret the estimated coefficients to uncover patterns in students’ financial behaviors. Each coefficient represents the expected change in Net_Money for a one-unit increase in the corresponding predictor, assuming all other variables remain constant.\nInsights from Regression Coefficients\nHere are a few insights that we can extract from the regression model result:\n\nFinancial dependency is one of the strongest negative predictors of financial balance. Students who rely on others—such as parents or guardians—for financial support tend to have $488.10 less in Net_Money. This may be due to having limited personal income, reduced autonomy in managing expenses, or tighter financial constraints imposed by dependency on external sources.\nSpending habits, particularly related to social activities, also play a crucial role. Students who report going out and spending money more frequently experience a $47.85 decrease in Net_Money for each unit increase in this behavior. This result aligns with expectations: frequent socializing often involves discretionary expenses such as dining out or entertainment, which can erode savings or disposable income over time.\nAnother lifestyle factor, alcohol consumption, is associated with a $139.96 drop in Net_Money. This relatively large effect suggests that students who drink alcohol regularly may also engage in broader spending behaviors linked to nightlife or entertainment, significantly impacting their overall financial standing. It also highlights alcohol as a strong proxy for costly social habits.\nFinally, the student’s living situation is associated with financial advantage. Certain types of living arrangements correspond to an increase of $107.92 in Net_Money. This may reflect the financial benefits of shared housing, university-subsidized residences, or lower-cost arrangements. Choosing a cost-effective living setup appears to have a notable influence on students’ financial outcomes.\n\nThese findings suggest that students can improve their financial position through a combination of employment, controlled social spending, and strategic housing choices. Conversely, financial dependency and certain lifestyle habits like frequent alcohol use and going out may contribute to lower net balances. These insights can inform both personal budgeting decisions and institutional support strategies for student financial wellness.",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Zestylicious Ordinary Least-squares Regression</span>"
    ]
  },
  {
    "objectID": "book/03-ols.html#storytelling",
    "href": "book/03-ols.html#storytelling",
    "title": "3  Zestylicious Ordinary Least-squares Regression",
    "section": "\n3.11 Storytelling",
    "text": "3.11 Storytelling\nThe final step in our data science workflow is storytelling, where we translate our analytical findings into actionable insights. This stage ensures that our results are clearly understood by both technical and non-technical audiences. Effective storytelling involves summarizing insights, using visuals for clarity, and making data-driven recommendations.\n\n\nFun fact!\n\n\nZestylicious! That mouth-puckering, lemon-squirted, totally tangy kick!\n\n\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n\n\n\n\n\n\n\n\nFigure 3.2",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Zestylicious Ordinary Least-squares Regression</span>"
    ]
  },
  {
    "objectID": "book/04-gamma.html",
    "href": "book/04-gamma.html",
    "title": "4  Smoketastic Gamma Regression",
    "section": "",
    "text": "Fun fact!\n\n\nSmoketastic! For foods that seem to have been grilled by a campfire enthusiast.\n\n\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n\n\n\n\n\n\n\n\nFigure 4.1",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Smoketastic Gamma Regression</span>"
    ]
  },
  {
    "objectID": "book/05-beta.html",
    "href": "book/05-beta.html",
    "title": "5  Soup-erb Beta Regression",
    "section": "",
    "text": "Fun fact!\n\n\nSoup-erb! Soup that’s so heartwarming it feels like a cozy hug.\n\n\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n\n\n\n\n\n\n\n\nFigure 5.1",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Soup-erb Beta Regression</span>"
    ]
  },
  {
    "objectID": "book/06-parametric-survival.html",
    "href": "book/06-parametric-survival.html",
    "title": "6  Crunchified Parametric Survival Regression",
    "section": "",
    "text": "Fun fact!\n\n\nCrunchified! Extra crunchy, borderline noisy; could probably shatter glass.\n\n\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}\n        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(\n          (Exponential &lt;br/&gt;Outcome Y)\n          (Weibull &lt;br/&gt;Outcome Y)\n          (Lognormal &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n\n\n\n\n\n\n\n\nFigure 6.1\n\n\n\n\nDefinition of cumulative distribution function\n\n\nLet \\(Y\\) be a random variable either discrete or continuous. Its cumulative distribution function (CDF) \\(F_Y(y)  : \\mathbb{R} \\rightarrow [0, 1]\\) refers to the probability that \\(Y\\) is less or equal than an observed value \\(y\\):\n\\[\nF_Y(y) = P(Y \\leq y).\n\\tag{6.1}\\]\nThen, we have the following by type of random variable:\n\nWhen \\(Y\\) is discrete, whose support is \\(\\mathcal{Y}\\), suppose it has a PMF \\(P_Y(Y = y)\\). Then, the CDF is mathematically represented as:\n\n\\[\nF_Y(y) = \\sum_{\\substack{t \\in \\mathcal{Y} \\\\ t \\leq y}} P_Y(Y = t).\n\\tag{6.2}\\]\n\nWhen \\(Y\\) is continuous, whose support is \\(\\mathcal{Y}\\), suppose it has a PDF \\(f_Y(y)\\). Then, the CDF is mathematically represented as:\n\n\\[\nF_Y(y) = \\int_{-\\infty}^y f_Y(t) \\mathrm{d}t.\n\\tag{6.3}\\]\nNote that in Equation 6.2 and Equation 6.3, we use the auxiliary variable \\(t\\) since we do not compute the summation or integral over the observed \\(y\\) given its role on either the PMF or PDF. Therefore, we use this auxiliary variable \\(t\\).\n\n\n\n\nHeads-up on the properties of the cumulative distribution function!\n\n\nIt is important to clarify that a valid CDF \\(F_Y(y)\\) fulfils the following properties:\n\n\n\\(F_Y(y)\\) must never be a decreasing function.\nGiven that \\(F_Y(y)  : \\mathbb{R} \\rightarrow [0, 1]\\), it must never evaluate to be \\(&lt; 0\\) or \\(&gt; 1\\). The output of a CDF is a cumulative probability, hence the previous bounds.\nWhen \\(y \\rightarrow -\\infty\\), if follows that \\(F_Y(y) \\rightarrow 0\\).\nWhen \\(y \\rightarrow \\infty\\), if follows that \\(F_Y(y) \\rightarrow 1\\).\n\nNow, in the case of a CDF corresponding to a continuous random variable \\(Y\\), there is an additional handy property that relates the CDF \\(F_Y(y)\\) to the PDF \\(f_Y(y)\\):\n\\[\nf_Y(y) = \\frac{\\mathrm{d}}{\\mathrm{d}y} F_Y(y).\n\\tag{6.4}\\]\nEquation 6.4 indicates that the PDF of \\(Y\\) can be obtained by taking the first derivative of the CDF with respect to \\(y\\).",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Crunchified Parametric Survival Regression</span>"
    ]
  },
  {
    "objectID": "book/07-semiparametric-survival.html",
    "href": "book/07-semiparametric-survival.html",
    "title": "7  Butteryfied Semiparametric Survival Regression",
    "section": "",
    "text": "Fun fact!\n\n\nButteryfied! So rich and buttery it practically slides off the plate.\n\n\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}\n        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(\n          (Exponential &lt;br/&gt;Outcome Y)\n          (Weibull &lt;br/&gt;Outcome Y)\n          (Lognormal &lt;br/&gt;Outcome Y)\n        )Chapter 7: &lt;br/&gt;Semiparametric &lt;br/&gt;Survival &lt;br/&gt;Regression(\n          (Cox Proportional &lt;br/&gt;Hazards Model)\n            (Hazard Function &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n\n\n\n\n\n\n\n\nFigure 7.1",
    "crumbs": [
      "Continuous Cuisine",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Butteryfied Semiparametric Survival Regression</span>"
    ]
  },
  {
    "objectID": "book/08-binary-logistic.html",
    "href": "book/08-binary-logistic.html",
    "title": "8  Sauce-sational Binary Logistic Regression",
    "section": "",
    "text": "Fun fact!\n\n\nSauce-sational! When the sauce is so good, it’s basically soup.\n\n\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}\n        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(\n          (Exponential &lt;br/&gt;Outcome Y)\n          (Weibull &lt;br/&gt;Outcome Y)\n          (Lognormal &lt;br/&gt;Outcome Y)\n        )Chapter 7: &lt;br/&gt;Semiparametric &lt;br/&gt;Survival &lt;br/&gt;Regression(\n          (Cox Proportional &lt;br/&gt;Hazards Model)\n            (Hazard Function &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n      {{Binary &lt;br/&gt;Outcome Y}}\n        {{Ungrouped &lt;br/&gt;Data}}\n          )Chapter 8: &lt;br/&gt;Binary Logistic &lt;br/&gt;Regression(\n            (Bernoulli &lt;br/&gt;Outcome Y)\n\n\n\n\n\n\n\n\nFigure 8.1",
    "crumbs": [
      "Discrete Cuisine",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Sauce-sational Binary Logistic Regression</span>"
    ]
  },
  {
    "objectID": "book/09-binomial-logistic.html",
    "href": "book/09-binomial-logistic.html",
    "title": "9  Cheesified Binomial Logistic Regression",
    "section": "",
    "text": "Fun fact!\n\n\nCheesified! Oozing with cheese in every crevice; a cheese lover’s paradise.\n\n\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma &lt;br/&gt;Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}\n        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(\n          (Exponential &lt;br/&gt;Outcome Y)\n          (Weibull &lt;br/&gt;Outcome Y)\n          (Lognormal &lt;br/&gt;Outcome Y)\n        )Chapter 7: &lt;br/&gt;Semiparametric &lt;br/&gt;Survival &lt;br/&gt;Regression(\n          (Cox Proportional &lt;br/&gt;Hazards Model)\n            (Hazard Function &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n      {{Binary &lt;br/&gt;Outcome Y}}\n        {{Ungrouped &lt;br/&gt;Data}}\n          )Chapter 8: &lt;br/&gt;Binary Logistic &lt;br/&gt;Regression(\n            (Bernoulli &lt;br/&gt;Outcome Y)\n        {{Grouped &lt;br/&gt;Data}}\n          )Chapter 9: &lt;br/&gt;Binomial Logistic &lt;br/&gt;Regression(\n            (Binomial &lt;br/&gt;Outcome Y)\n\n\n\n\n\n\n\n\nFigure 9.1",
    "crumbs": [
      "Discrete Cuisine",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Cheesified Binomial Logistic Regression</span>"
    ]
  },
  {
    "objectID": "book/10-classical-poisson.html",
    "href": "book/10-classical-poisson.html",
    "title": "10  Bubblarious Classical Poisson Regression",
    "section": "",
    "text": "Fun fact!\n\n\nBubblarious! For all the boba, fizzy drinks, and seltzers that go pop!\n\n\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}\n        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(\n          (Exponential &lt;br/&gt;Outcome Y)\n          (Weibull &lt;br/&gt;Outcome Y)\n          (Lognormal &lt;br/&gt;Outcome Y)\n        )Chapter 7: &lt;br/&gt;Semiparametric &lt;br/&gt;Survival &lt;br/&gt;Regression(\n          (Cox Proportional &lt;br/&gt;Hazards Model)\n            (Hazard Function &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n      {{Binary &lt;br/&gt;Outcome Y}}\n        {{Ungrouped &lt;br/&gt;Data}}\n          )Chapter 8: &lt;br/&gt;Binary Logistic &lt;br/&gt;Regression(\n            (Bernoulli &lt;br/&gt;Outcome Y)\n        {{Grouped &lt;br/&gt;Data}}\n          )Chapter 9: &lt;br/&gt;Binomial Logistic &lt;br/&gt;Regression(\n            (Binomial &lt;br/&gt;Outcome Y)\n      {{Count &lt;br/&gt;Outcome Y}}\n        {{Equidispersed &lt;br/&gt;Data}}\n          )Chapter 10: &lt;br/&gt;Classical Poisson &lt;br/&gt;Regression(\n            (Poisson &lt;br/&gt;Outcome Y)\n\n\n\n\n\n\n\n\nFigure 10.1",
    "crumbs": [
      "Discrete Cuisine",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Bubblarious Classical Poisson Regression</span>"
    ]
  },
  {
    "objectID": "book/11-negative-binomial.html",
    "href": "book/11-negative-binomial.html",
    "title": "11  Umami-zing Negative Binomial Regression",
    "section": "",
    "text": "Fun fact!\n\n\nUmami-zing! Savory to the point where you start craving a second plate… and a third.\n\n\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}\n        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(\n          (Exponential &lt;br/&gt;Outcome Y)\n          (Weibull &lt;br/&gt;Outcome Y)\n          (Lognormal &lt;br/&gt;Outcome Y)\n        )Chapter 7: &lt;br/&gt;Semiparametric &lt;br/&gt;Survival &lt;br/&gt;Regression(\n          (Cox Proportional &lt;br/&gt;Hazards Model)\n            (Hazard Function &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n      {{Binary &lt;br/&gt;Outcome Y}}\n        {{Ungrouped &lt;br/&gt;Data}}\n          )Chapter 8: &lt;br/&gt;Binary Logistic &lt;br/&gt;Regression(\n            (Bernoulli &lt;br/&gt;Outcome Y)\n        {{Grouped &lt;br/&gt;Data}}\n          )Chapter 9: &lt;br/&gt;Binomial Logistic &lt;br/&gt;Regression(\n            (Binomial &lt;br/&gt;Outcome Y)\n      {{Count &lt;br/&gt;Outcome Y}}\n        {{Equidispersed &lt;br/&gt;Data}}\n          )Chapter 10: &lt;br/&gt;Classical Poisson &lt;br/&gt;Regression(\n            (Poisson &lt;br/&gt;Outcome Y)\n        {{Overdispersed &lt;br/&gt;Data}}\n          )Chapter 11: &lt;br/&gt;Negative Binomial &lt;br/&gt;Regression(\n            (Negative Binomial &lt;br/&gt;Outcome Y)\n\n\n\n\n\n\n\n\nFigure 11.1",
    "crumbs": [
      "Discrete Cuisine",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Umami-zing Negative Binomial Regression</span>"
    ]
  },
  {
    "objectID": "book/12-zero-inflated-poisson.html",
    "href": "book/12-zero-inflated-poisson.html",
    "title": "12  Spicetacular Zero-Inflated Poisson Regression",
    "section": "",
    "text": "Fun fact!\n\n\nSpicetacular! The kind of spicy that requires a fire extinguisher at the ready.\n\n\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}\n        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(\n          (Exponential &lt;br/&gt;Outcome Y)\n          (Weibull &lt;br/&gt;Outcome Y)\n          (Lognormal &lt;br/&gt;Outcome Y)\n        )Chapter 7: &lt;br/&gt;Semiparametric &lt;br/&gt;Survival &lt;br/&gt;Regression(\n          (Cox Proportional &lt;br/&gt;Hazards Model)\n            (Hazard Function &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n      {{Binary &lt;br/&gt;Outcome Y}}\n        {{Ungrouped &lt;br/&gt;Data}}\n          )Chapter 8: &lt;br/&gt;Binary Logistic &lt;br/&gt;Regression(\n            (Bernoulli &lt;br/&gt;Outcome Y)\n        {{Grouped &lt;br/&gt;Data}}\n          )Chapter 9: &lt;br/&gt;Binomial Logistic &lt;br/&gt;Regression(\n            (Binomial &lt;br/&gt;Outcome Y)\n      {{Count &lt;br/&gt;Outcome Y}}\n        {{Equidispersed &lt;br/&gt;Data}}\n          )Chapter 10: &lt;br/&gt;Classical Poisson &lt;br/&gt;Regression(\n            (Poisson &lt;br/&gt;Outcome Y)\n        {{Overdispersed &lt;br/&gt;Data}}\n          )Chapter 11: &lt;br/&gt;Negative Binomial &lt;br/&gt;Regression(\n            (Negative Binomial &lt;br/&gt;Outcome Y)\n        {{Overdispersed or &lt;br/&gt;Underdispersed &lt;br/&gt;Data}}\n        {{Zero Inflated &lt;br/&gt;Data}}\n          )Chapter 12: &lt;br/&gt;Zero Inflated Poisson &lt;br/&gt;Regression(\n            (Zero Inflated &lt;br/&gt;Poisson &lt;br/&gt;Outcome Y)\n\n\n\n\n\n\n\n\nFigure 12.1",
    "crumbs": [
      "Discrete Cuisine",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Spicetacular Zero-Inflated Poisson Regression</span>"
    ]
  },
  {
    "objectID": "book/13-generalized-poisson.html",
    "href": "book/13-generalized-poisson.html",
    "title": "13  Herbalicious Generalized Poisson Regression",
    "section": "",
    "text": "Fun fact!\n\n\nHerbalicious! Loaded with herbs and greens; like chewing through a botanical garden.\n\n\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: &lt;br/&gt;Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}\n        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(\n          (Exponential &lt;br/&gt;Outcome Y)\n          (Weibull &lt;br/&gt;Outcome Y)\n          (Lognormal &lt;br/&gt;Outcome Y)\n        )Chapter 7: &lt;br/&gt;Semiparametric &lt;br/&gt;Survival &lt;br/&gt;Regression(\n          (Cox Proportional &lt;br/&gt;Hazards Model)\n            (Hazard Function &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n      {{Binary &lt;br/&gt;Outcome Y}}\n        {{Ungrouped &lt;br/&gt;Data}}\n          )Chapter 8: &lt;br/&gt;Binary Logistic &lt;br/&gt;Regression(\n            (Bernoulli &lt;br/&gt;Outcome Y)\n        {{Grouped &lt;br/&gt;Data}}\n          )Chapter 9: &lt;br/&gt;Binomial Logistic &lt;br/&gt;Regression(\n            (Binomial &lt;br/&gt;Outcome Y)\n      {{Count &lt;br/&gt;Outcome Y}}\n        {{Equidispersed &lt;br/&gt;Data}}\n          )Chapter 10: &lt;br/&gt;Classical Poisson &lt;br/&gt;Regression(\n            (Poisson &lt;br/&gt;Outcome Y)\n        {{Overdispersed &lt;br/&gt;Data}}\n          )Chapter 11: &lt;br/&gt;Negative Binomial &lt;br/&gt;Regression(\n            (Negative Binomial &lt;br/&gt;Outcome Y)\n        {{Zero Inflated &lt;br/&gt;Data}}\n          )Chapter 12: &lt;br/&gt;Zero Inflated &lt;br/&gt;Poisson &lt;br/&gt;Regression(\n            (Zero Inflated &lt;br/&gt;Poisson &lt;br/&gt;Outcome Y)\n        {{Overdispersed or &lt;br/&gt;Underdispersed &lt;br/&gt;Data}}\n          )Chapter 13: &lt;br/&gt;Generalized &lt;br/&gt;Poisson &lt;br/&gt;Regression(\n            (Generalized &lt;br/&gt;Poisson &lt;br/&gt;Outcome Y)\n\n\n\n\n\n\n\n\nFigure 13.1",
    "crumbs": [
      "Discrete Cuisine",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Herbalicious Generalized Poisson Regression</span>"
    ]
  },
  {
    "objectID": "book/14-multinomial-logistic.html",
    "href": "book/14-multinomial-logistic.html",
    "title": "14  Picklified Multinomial Logistic Regression",
    "section": "",
    "text": "Fun fact!\n\n\nPicklified! When everything, even dessert, tastes a bit pickled!\n\n\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}\n        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(\n          (Exponential &lt;br/&gt;Outcome Y)\n          (Weibull &lt;br/&gt;Outcome Y)\n          (Lognormal &lt;br/&gt;Outcome Y)\n        )Chapter 7: &lt;br/&gt;Semiparametric &lt;br/&gt;Survival &lt;br/&gt;Regression(\n          (Cox Proportional &lt;br/&gt;Hazards Model)\n            (Hazard Function &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n      {{Binary &lt;br/&gt;Outcome Y}}\n        {{Ungrouped &lt;br/&gt;Data}}\n          )Chapter 8: &lt;br/&gt;Binary Logistic &lt;br/&gt;Regression(\n            (Bernoulli &lt;br/&gt;Outcome Y)\n        {{Grouped &lt;br/&gt;Data}}\n          )Chapter 9: &lt;br/&gt;Binomial Logistic &lt;br/&gt;Regression(\n            (Binomial &lt;br/&gt;Outcome Y)\n      {{Count &lt;br/&gt;Outcome Y}}\n        {{Equidispersed &lt;br/&gt;Data}}\n          )Chapter 10: &lt;br/&gt;Classical Poisson &lt;br/&gt;Regression(\n            (Poisson &lt;br/&gt;Outcome Y)\n        {{Overdispersed &lt;br/&gt;Data}}\n          )Chapter 11: &lt;br/&gt;Negative Binomial &lt;br/&gt;Regression(\n            (Negative Binomial &lt;br/&gt;Outcome Y)\n        {{Zero Inflated &lt;br/&gt;Data}}\n          )Chapter 12: &lt;br/&gt;Zero Inflated &lt;br/&gt;Poisson &lt;br/&gt;Regression(\n            (Zero Inflated &lt;br/&gt;Poisson &lt;br/&gt;Outcome Y)\n        {{Overdispersed or &lt;br/&gt;Underdispersed &lt;br/&gt;Data}}\n          )Chapter 13: &lt;br/&gt;Generalized &lt;br/&gt;Poisson &lt;br/&gt;Regression(\n            (Generalized &lt;br/&gt;Poisson &lt;br/&gt;Outcome Y)\n      {{Categorical &lt;br/&gt;Outcome Y}}\n        {{Nominal &lt;br/&gt;Outcome Y}}\n          )Chapter 14: &lt;br/&gt;Multinomial &lt;br/&gt;Logistic &lt;br/&gt;Regression(\n            (Multinomial &lt;br/&gt;Outcome Y)\n\n\n\n\n\n\n\n\nFigure 14.1",
    "crumbs": [
      "Discrete Cuisine",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Picklified Multinomial Logistic Regression</span>"
    ]
  },
  {
    "objectID": "book/15-ordinal-logistic.html",
    "href": "book/15-ordinal-logistic.html",
    "title": "15  Tang-tastic Ordinal Logistic Regression",
    "section": "",
    "text": "Fun fact!\n\n\nTang-tastic! So tangy it could wake you up better than coffee.\n\n\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}\n        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(\n          (Exponential &lt;br/&gt;Outcome Y)\n          (Weibull &lt;br/&gt;Outcome Y)\n          (Lognormal &lt;br/&gt;Outcome Y)\n        )Chapter 7: &lt;br/&gt;Semiparametric &lt;br/&gt;Survival &lt;br/&gt;Regression(\n          (Cox Proportional &lt;br/&gt;Hazards Model)\n            (Hazard Function &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n      {{Binary &lt;br/&gt;Outcome Y}}\n        {{Ungrouped &lt;br/&gt;Data}}\n          )Chapter 8: &lt;br/&gt;Binary Logistic &lt;br/&gt;Regression(\n            (Bernoulli &lt;br/&gt;Outcome Y)\n        {{Grouped &lt;br/&gt;Data}}\n          )Chapter 9: &lt;br/&gt;Binomial Logistic &lt;br/&gt;Regression(\n            (Binomial &lt;br/&gt;Outcome Y)\n      {{Count &lt;br/&gt;Outcome Y}}\n        {{Equidispersed &lt;br/&gt;Data}}\n          )Chapter 10: &lt;br/&gt;Classical Poisson &lt;br/&gt;Regression(\n            (Poisson &lt;br/&gt;Outcome Y)\n        {{Overdispersed &lt;br/&gt;Data}}\n          )Chapter 11: &lt;br/&gt;Negative Binomial &lt;br/&gt;Regression(\n            (Negative Binomial &lt;br/&gt;Outcome Y)\n        {{Overdispersed or &lt;br/&gt;Underdispersed &lt;br/&gt;Data}}\n          )Chapter 13: &lt;br/&gt;Generalized &lt;br/&gt;Poisson &lt;br/&gt;Regression(\n            (Generalized &lt;br/&gt;Poisson &lt;br/&gt;Outcome Y)\n        {{Zero Inflated &lt;br/&gt;Data}}\n          )Chapter 12: &lt;br/&gt;Zero Inflated &lt;br/&gt;Poisson &lt;br/&gt;Regression(\n            (Zero Inflated &lt;br/&gt;Poisson &lt;br/&gt;Outcome Y)\n      {{Categorical &lt;br/&gt;Outcome Y}}\n        {{Nominal &lt;br/&gt;Outcome Y}}\n          )Chapter 14: &lt;br/&gt;Multinomial &lt;br/&gt;Logistic &lt;br/&gt;Regression(\n            (Multinomial &lt;br/&gt;Outcome Y)\n        {{Ordinal &lt;br/&gt;Outcome Y}}\n          )Chapter 15: &lt;br/&gt;Ordinal &lt;br/&gt;Logistic &lt;br/&gt;Regression(\n            (Logistic &lt;br/&gt;Distributed &lt;br/&gt;Cumulative Outcome &lt;br/&gt;Probability)\n\n\n\n\n\n\n\n\nFigure 15.1",
    "crumbs": [
      "Discrete Cuisine",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Tang-tastic Ordinal Logistic Regression</span>"
    ]
  },
  {
    "objectID": "book/references.html",
    "href": "book/references.html",
    "title": "References",
    "section": "",
    "text": "Bellhouse, D. R. 2004. “The Reverend Thomas\nBayes, FRS: A Biography to Celebrate the Tercentenary of His\nBirth.” Statistical Science 19 (1): 3–43. https://doi.org/10.1214/088342304000000189.\n\n\nCasella, G., and R. Berger. 2024. Statistical Inference.\nChapman & Hall/CRC Texts in Statistical Science. CRC Press. https://www.taylorfrancis.com/books/mono/10.1201/9781003456285/statistical-inference-roger-berger-george-casella.\n\n\nConsul, P. C., and G. C. Jain. 1973. “A Generalization of the\nPoisson Distribution.” Technometrics 15 (4): 791–99. http://www.jstor.org/stable/1267389.\n\n\nEarlom, Richard. 1793. “Brook Taylor - National Portrait\nGallery.” NPG D6930; Brook Taylor - Portrait - National\nPortrait Gallery. National Portrait Gallery. https://www.npg.org.uk/collections/search/portrait/mw40921/Brook-Taylor.\n\n\nGelbart, Michael. 2017. “Data Science Terminology.” UBC\nMDS. Master of Data Science at the University of British Columbia.\nhttps://ubc-mds.github.io/resources_pages/terminology/.\n\n\nGregory, James. 1668. Vera circuli et\nhyperbolae quadratura cui accedit geometria pars vniuersalis inseruiens\nquantitatum curuarum transmutationi & mensurae. Authore Iacobo\nGregorio Abredonensi. Padua, Italy: Patavii: typis heredum\nPauli Frambotti bibliop. https://archive.org/details/ita-bnc-mag-00001357-001/page/n10/mode/2up.\n\n\nHarding, Edward. 1798. Portrait of Colin MacLaurin.\nCourtesy of the Smithsonian Libraries and Archives. https://library.si.edu/image-gallery/72863.\n\n\nJohnson, A. A., M. Q. Ott, and M. Dogucu. 2022. Bayes Rules!: An\nIntroduction to Applied Bayesian Modeling. Chapman & Hall/CRC\nTexts in Statistical Science. CRC Press. https://www.bayesrulesbook.com/.\n\n\nLeemis, Larry. n.d. “Univariate\nDistribution Relationship\nChart.” https://www.math.wm.edu/~leemis/chart/UDR/UDR.html.\n\n\nMaclaurin, Colin. 1742. A Treatise of Fluxions. Edinburgh,\nScotland: Printed for the Author by T.W.; T. Ruddimans. https://archive.org/details/treatiseonfluxio02macl/page/n5/mode/2up.\n\n\nO’Donnell, T. 1936. History of Life Insurance\nin Its Formative Years. Compiled from Approved Sources by T.\nO’Donnell. Chicago.\n\n\nR Core Team. 2024. “R: A Language and Environment for Statistical\nComputing.” Vienna, Austria: R Foundation for Statistical\nComputing. https://www.R-project.org/.\n\n\nScotland, National Galleries of. n.d. Professor James Gregory, 1638\n- 1675 (1). Mathematician. Professor James Gregory, 1638 - 1675\n(1). Mathematician | National Galleries. https://www.nationalgalleries.org/art-and-artists/31132/professor-james-gregory-1638-1675-mathematician.\n\n\nSoch, Joram, The Book of Statistical Proofs, Maja, Pietro Monticone,\nThomas J. Faulkenberry, Alex Kipnis, Kenneth Petrykowski, et al. 2024.\n“StatProofBook/StatProofBook.github.io:\nStatProofBook 2023.” Zenodo. https://doi.org/10.5281/zenodo.10495684.\n\n\nTaylor, Brook. 1715. Methodus incrementorum\ndirecta & inversa. Auctore Brook Taylor, LL. D. & Regiae\nSocietatis Secretario. London, England: Typis Pearsonianis\nProstant apud Gul. Innys ad Insignia Principis in Coemeterio Paulino\nMDCCXV. https://archive.org/details/bim_eighteenth-century_methodus-incrementorum-d_taylor-brook_1717.\n\n\nThe Pandas Development Team. 2024. “Pandas-Dev/Pandas:\nPandas.” Zenodo. https://doi.org/10.5281/zenodo.3509134.\n\n\nVan Rossum, Guido, and Fred L. Drake. 2009. Python 3 Reference\nManual. Scotts Valley, CA: CreateSpace.\n\n\nWeisstein, Eric W. n.d.a. “Gamma Function.” From\nMathWorld–A Wolfram Web Resource. https://mathworld.wolfram.com/GammaFunction.html.\n\n\n———. n.d.b. “Taylor Series.” From MathWorld–A Wolfram\nWeb Resource. https://mathworld.wolfram.com/TaylorSeries.html.\n\n\nWickham, Hadley, Mara Averick, Jennifer Bryan, Winston Chang, Lucy\nD’Agostino McGowan, Romain François, Garrett Grolemund, et al. 2019.\n“Welcome to the tidyverse.”\nJournal of Open Source Software 4 (43): 1686. https://doi.org/10.21105/joss.01686.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "book/A-dictionary.html",
    "href": "book/A-dictionary.html",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "",
    "text": "A",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#a",
    "href": "book/A-dictionary.html#a",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "",
    "text": "Alternative hypothesis\nIn a hypothesis testing, an alternative hypothesis is denoted by \\(H_1\\). This hypothesis corresponds to the complement (i.e., the opposite) of the null hypothesis \\(H_0\\). Since the whole inferential process is designed to assess the strength of the evidence in favour or against of \\(H_0\\), any inferential conclusion against \\(H_0\\) can be worded as “rejecting \\(H_0\\) in favour of \\(H_1\\).” In plain words, \\(H_1\\) is an inferential statement associated to a non-status quo in some population(s) or system(s) of interest, which might refer to actual signal for the researcher in question.\nLet us assume random variable \\(Y\\) from some population(s) or system(s) of interest is governed by \\(k\\) parameters contained in the following vector:\n\\[\n\\boldsymbol{\\theta} = (\\theta_1, \\theta_2, \\cdots, \\theta_k)^T.\n\\]\nMoreover, suppose this observed data \\(y\\) follows certain probability distribution \\(\\mathcal{D}(\\cdot)\\) in a generative model \\(m\\) as in\n\\[\nm: y \\sim \\mathcal{D}(\\boldsymbol{\\theta}).\n\\]\nLet \\(\\boldsymbol{\\Theta}_0^c \\subset \\boldsymbol{\\theta}\\) denote the non-status quo for the parameter(s) to be tested. Then, the alternative hypothesis is mathematically defined as\n\\[\nH_1: \\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}_0^c \\quad \\text{where} \\quad \\boldsymbol{\\Theta}_0^c \\subset \\boldsymbol{\\theta}.\n\\]\nAttribute\n\n\nEquivalent to:\n\n\nCovariate, exogeneous variable, explanatory variable, feature, independent variable, input, predictor or regressor.\n\n\nAverage\nLet \\(Y\\) be a random variable whose support is \\(\\mathcal{Y}\\). In general, the expected value or mean \\(\\mathbb{E}(Y)\\) of this random variable is defined as a weighted average according to its corresponding probability distribution. In other words, this measure of central tendency \\(\\mathbb{E}(Y)\\) aims to find the middle value of this random variable by weighting all its possible values in its support \\(\\mathcal{Y}\\) as dictated by its probability distribution.\nGiven the above definition, when \\(Y\\) is a discrete random variable whose probability mass function (PMF) is \\(P_Y(Y = y)\\), then its weighted average is mathematically defined as\n\\[\n\\mathbb{E}(Y) = \\sum_{y \\in \\mathcal{Y}} y \\cdot P_Y(Y = y).\n\\]\nWhen \\(Y\\) is a continuous random variable whose probability density function (PDF) is \\(f_Y(y)\\), its weighted average is mathematically defined as\n\\[\n\\mathbb{E}(Y) = \\int_{\\mathcal{Y}} y \\cdot f_Y(y) \\mathrm{d}y.\n\\]\n\n\nEquivalent to:\n\n\nExpected value or mean.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#b",
    "href": "book/A-dictionary.html#b",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "B",
    "text": "B\nBayesian statistics\nThis statistical school of thinking also relies on the frequency of events to estimate specific parameters of interest in a population or system. Nevertheless, unlike frequentist statistics, Bayesian statisticians use prior knowledge on the population parameters to update their estimations on them along with the current evidence they can gather. This evidence is in the form of the repetition of \\(n\\) experiments involving a random phenomenon. All these ingredients allow Bayesian statisticians to make inference by conducting appropriate hypothesis testings, which are designed differently from their mainstream frequentist counterpart.\nUnder the umbrella of this approach, we assume that our governing parameters are random; i.e., they have their own sample space and probabilities associated to their corresponding outcomes. The statistical process of inference is heavily backed up by probability theory mostly in the form of the Bayes’ rule (named after Reverend Thomas Bayes, an English statistician from the 18th century). This rule uses our current evidence along with our prior beliefs to deliver a posterior distribution of our random parameter(s) of interest.\nBayes’ rule\nSuppose you have two events of interest, \\(A\\) and \\(B\\), in a random phenomenon of a population or system of interest. From Equation A.4, we can state the following expression for the conditional probability of \\(A\\) given \\(B\\):\n\\[\nP(A | B) = \\frac{P(A \\cap B)}{P(B)} \\quad \\text{if $P(B) &gt; 0$.}\n\\tag{A.1}\\]\nNote the conditional probability of \\(B\\) given \\(A\\) can be stated as:\n\\[\n\\begin{align*}\nP(B | A) &= \\frac{P(B \\cap A)}{P(A)} \\quad \\text{if $P(A) &gt; 0$} \\\\\n&= \\frac{P(A \\cap B)}{P(A)} \\quad \\text{since $P(B \\cap A) = P(A \\cap B)$.}\n\\end{align*}\n\\tag{A.2}\\]\nThen, we can manipulate Equation A.2 as follows:\n\\[\nP(A \\cap B) = P(B | A) \\times P(A).\n\\]\nThe above result can be plugged into Equation A.1:\n\\[\n\\begin{align*}\nP(A | B) &= \\frac{P(A \\cap B)}{P(B)} \\\\\n&= \\frac{P(B | A) \\times P(A)}{P(B)}.\n\\end{align*}\n\\tag{A.3}\\]\nEquation A.3 is called the Bayes’ rule. We are basically flipping around conditional probabilities.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#c",
    "href": "book/A-dictionary.html#c",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "C",
    "text": "C\nCritical value\nThe critical value of a hypothesis testing defines the region for which we might reject \\(H_0\\) in favour of \\(H_1\\). This critical value is in the function of the significance level \\(\\alpha\\) and test flavour. It is located on the corresponding \\(x\\)-axis of the probability distribution of \\(H_0\\). Hence, this value acts as a threshold to decide either of the following:\n\nIf the observed test statistic exceeds a given critical value, then we have enough statistical evidence to reject \\(H_0\\) in favour of \\(H_1\\).\nIf the observed test statistic does not exceed a given critical value, then we have enough statistical evidence to fail to reject \\(H_0\\).\nConditional probability\nSuppose you have two events of interest, \\(A\\) and \\(B\\), in a random phenomenon, in a population or system of interest. These two events belong to the sample space \\(S\\). Moreover, assume that the probability of event \\(B\\) is such that\n\\[\nP(B) &gt; 0,\n\\]\nwhich is considered the conditioning event.\nHence, the conditional probability event \\(A\\) given event \\(B\\) is defined as\n\\[\nP(A | B) = \\frac{P(A \\cap B)}{P(B)},\n\\tag{A.4}\\]\nwhere \\(P(A \\cap B)\\) is read as the probability of the intersection of events \\(A\\) and \\(B\\).\nConfidence interval\nA confidence interval provides an estimated range of values within which the true population parameter is likely to fall, based on the sample data. It reflects the degree of uncertainty associated with the obtained estimate.\nFor instance, a 95% confidence interval means that if the study were repeated many times using different random samples from the same population or system of interest, approximately 95% of the resulting intervals would contain the true parameter.\nContinuous random variable\nLet \\(Y\\) be a random variable whose support is \\(\\mathcal{Y}\\). If this support \\(\\mathcal{Y}\\) corresponds to an uncountably infinite set of possible values, then \\(Y\\) is considered a continuous random variable.\nNote a continuous random variable could be\n\n\ncompletely unbounded (i.e., its set of possible values goes from \\(-\\infty\\) to \\(\\infty\\) as in \\(-\\infty &lt; y &lt; \\infty\\)),\n\npositively unbounded (i.e., its set of possible values goes from \\(0\\) to \\(\\infty\\) as in \\(0 \\leq y &lt; \\infty\\)),\n\nnegatively unbounded (i.e., its set of possible values goes from \\(-\\infty\\) to \\(0\\) as in \\(-\\infty &lt; y \\leq 0\\)), or\n\nbounded between two values \\(a\\) and \\(b\\) (i.e., its set of possible values goes from \\(a\\) to \\(b\\) as in \\(a \\leq y \\leq b\\)).\nCovariate\n\n\nEquivalent to:\n\n\nAttribute, exogeneous variable, explanatory variable, feature, independent variable, input, predictor or regressor.\n\n\nCumulative distribution function\nLet \\(Y\\) be a random variable either discrete or continuous. Its cumulative distribution function (CDF) \\(F_Y(y)  : \\mathbb{R} \\rightarrow [0, 1]\\) refers to the probability that \\(Y\\) is less or equal than an observed value \\(y\\):\n\\[\nF_Y(y) = P(Y \\leq y).\n\\]\nThen, we have the following by type of random variable:\n\nWhen \\(Y\\) is discrete, whose support is \\(\\mathcal{Y}\\), suppose it has a probability mass function (PMF) \\(P_Y(Y = y)\\). Then, the CDF is mathematically represented as:\n\n\\[\nF_Y(y) = \\sum_{\\substack{t \\in \\mathcal{Y} \\\\ t \\leq y}} P_Y(Y = t).\n\\tag{A.5}\\]\n\nWhen \\(Y\\) is continuous, whose support is \\(\\mathcal{Y}\\), suppose it has a probability density function (PDF) \\(f_Y(y)\\). Then, the CDF is mathematically represented as:\n\n\\[\nF_Y(y) = \\int_{-\\infty}^y f_Y(t) \\mathrm{d}t.\n\\tag{A.6}\\]\nNote that in Equation A.5 and Equation A.6, we use the auxiliary variable \\(t\\) since we do not compute the summation or integral over the observed \\(y\\) given its role on either the PMF or PDF. Therefore, we use this auxiliary variable \\(t\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#d",
    "href": "book/A-dictionary.html#d",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "D",
    "text": "D\nDependent variable\nIn supervised learning, it is the main variable of interest we are trying to learn or predict, or equivalently, the variable we are trying explain in a statistical inference framework.\n\n\nEquivalent to:\n\n\nEndogeneous variable, response variable, outcome, output or target.\n\n\nDiscrete random variable\nLet \\(Y\\) be a random variable whose support is \\(\\mathcal{Y}\\). If this support \\(\\mathcal{Y}\\) corresponds to a finite set or a countably infinite set of possible values, then \\(Y\\) is considered a discrete random variable.\nFor instance, we can encounter discrete random variables which could be classified as\n\n\nbinary (i.e., a finite set of two possible values),\n\ncategorical (either nominal or ordinal, which have a finite set of three or more possible values), or\n\ncounts (which might have a finite set or a countably infinite set of possible values as integers).\nDispersion",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#e",
    "href": "book/A-dictionary.html#e",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "E",
    "text": "E\nEndogeneous variable\n\n\nEquivalent to:\n\n\nDependent variable, outcome, output, response variable or target.\n\n\nEquidispersion\nEstimate\nSuppose we have an observed random sample of size \\(n\\) with values \\(y_1, \\dots , y_n\\). Then, we apply a given estimator mathematical rule to these \\(n\\) observed values. Hence, this numerical computation is called an estimate of our population parameter of interest.\nEstimator\nAn estimator is a mathematical rule involving the random variables \\(Y_1, \\dots, Y_n\\) from our random sample of size \\(n\\). As its name says, this rule allows us to estimate our population parameter of interest.\nExpected value\nLet \\(Y\\) be a random variable whose support is \\(\\mathcal{Y}\\). In general, the expected value or mean \\(\\mathbb{E}(Y)\\) of this random variable is defined as a weighted average according to its corresponding probability distribution. In other words, this measure of central tendency \\(\\mathbb{E}(Y)\\) aims to find the middle value of this random variable by weighting all its possible values in its support \\(\\mathcal{Y}\\) as dictated by its probability distribution.\nGiven the above definition, when \\(Y\\) is a discrete random variable whose probability mass function (PMF) is \\(P_Y(Y = y)\\), then its expected value is mathematically defined as\n\\[\n\\mathbb{E}(Y) = \\sum_{y \\in \\mathcal{Y}} y \\cdot P_Y(Y = y).\n\\tag{A.7}\\]\nWhen \\(Y\\) is a continuous random variable whose probability density function (PDF) is \\(f_Y(y)\\), its expected value is mathematically defined as\n\\[\n\\mathbb{E}(Y) = \\int_{\\mathcal{Y}} y \\cdot f_Y(y) \\mathrm{d}y.\n\\tag{A.8}\\]\n\n\nEquivalent to:\n\n\nAverage or mean.\n\n\nExogeneous variable\n\n\nEquivalent to:\n\n\nAttribute, covariate, explanatory variable, feature, independent variable, input, predictor or regressor.\n\n\nExplanatory variable\n\n\nEquivalent to:\n\n\nAttribute, covariate, exogeneous variable, feature, independent variable, input, predictor or regressor.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#f",
    "href": "book/A-dictionary.html#f",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "F",
    "text": "F\nFalse negative\nA false negative is defined as incorrectly failing to reject the null hypothesis \\(H_0\\) in favour of the alternative hypothesis \\(H_1\\) when, in fact, \\(H_0\\) is false.\n\n\nEquivalent to:\n\n\nType II error.\n\n\nFalse positive\nA false positive is defined as incorrectly rejecting the null hypothesis \\(H_0\\) in favour of the alternative hypothesis \\(H_1\\) when, in fact, \\(H_0\\) is true. Table A.1 summarizes the types of inferential conclusions in function on whether \\(H_0\\) is true or not.\n\n\nTable A.1: Types of inferential conclusions in a frequentist hypothesis testing.\n\n\n\n\n\n\n\n\n\n\\(H_0\\) is true\n\\(H_0\\) is false\n\n\n\nReject \\(H_0\\)\nType I error (False positive)\nCorrect\n\n\nFail to reject \\(H_0\\)\nCorrect\nType II error (False negative)\n\n\n\n\n\n\n\n\nEquivalent to:\n\n\nType I error.\n\n\nFeature\n\n\nEquivalent to:\n\n\nAttribute, covariate, exogeneous variable, explanatory variable, independent variable, input, predictor or regressor.\n\n\nFrequentist statistics\nThis statistical school of thinking heavily relies on the frequency of events to estimate specific parameters of interest in a population or system. This frequency of events is reflected in the repetition of \\(n\\) experiments involving a random phenomenon within this population or system.\nUnder the umbrella of this approach, we assume that our governing parameters are fixed. Note that, within the philosophy of this school of thinking, we can only make precise and accurate predictions as long as we repeat our \\(n\\) experiments as many times as possible, i.e.,\n\\[\nn \\rightarrow \\infty.\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#g",
    "href": "book/A-dictionary.html#g",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "G",
    "text": "G\nGeneralized linear model\nGenerative model\nSuppose you observe some data \\(y\\) from a population or system of interest. Moreover, let us assume this population or system is governed by \\(k\\) parameters contained in the following vector:\n\\[\n\\boldsymbol{\\theta} = (\\theta_1, \\theta_2, \\cdots, \\theta_k)^T.\n\\]\nIf we state that the random variable \\(Y\\) follows certain probability distribution \\(\\mathcal{D}(\\cdot)\\), then we will have a generative model \\(m\\) such that\n\\[\nm: Y \\sim \\mathcal{D}(\\boldsymbol{\\theta}).\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#h",
    "href": "book/A-dictionary.html#h",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "H",
    "text": "H\nHypothesis\nSuppose you observe some data \\(y\\) from some population(s) or system(s) of interest governed by \\(k\\) parameters contained in the following vector:\n\\[\n\\boldsymbol{\\theta} = (\\theta_1, \\theta_2, \\cdots, \\theta_k)^T.\n\\]\nMoreover, let us assume that random variable \\(Y\\) follows certain probability distribution \\(\\mathcal{D}(\\cdot)\\) in a generative model \\(m\\) as in\n\\[\nm: Y \\sim \\mathcal{D}(\\boldsymbol{\\theta}).\n\\]\nBeginning from the fact that \\(\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}\\) where \\(\\boldsymbol{\\Theta} \\in \\mathbb{R}^k\\), a statistical hypothesis is a general statement about some parameter vector \\(\\boldsymbol{\\theta}\\) in regards to specific values contained in vector \\(\\boldsymbol{\\Theta}^*\\) such that\n\\[\nH: \\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}^* \\quad \\text{where} \\quad \\boldsymbol{\\Theta}^* \\subset \\boldsymbol{\\Theta}.\n\\]\nHypothesis testing\nA hypothesis testing is the decision rule we have to apply between the null and alternative hypotheses, via our sample data, to fail to reject or reject the null hypothesis.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#i",
    "href": "book/A-dictionary.html#i",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "I",
    "text": "I\nIndependence\nSuppose you have two events of interest, \\(A\\) and \\(B\\), in a random phenomenon of a population or system of interest. These two events are statistically independent if event \\(B\\) does not affect event \\(A\\) and vice versa. Therefore, the probability of their corresponding intersection is given by:\n\\[\nP(A \\cap B) = P(A) \\times P(B).\n\\]\nLet us expand the above definition to a random variable framework:\n\nSuppose you have a set of \\(n\\) discrete random variables \\(Y_1, \\dots, Y_n\\) whose supports are \\(\\mathcal{Y_1}, \\dots, \\mathcal{Y_n}\\) with probability mass functions (PMFs) \\(P_{Y_1}(Y_1 = y_1), \\dots, P_{Y_n}(Y_n = y_n)\\) respectively. That said, the joint PMF of these \\(n\\) random variables is the multiplication of their corresponding standalone PMFs:\n\n\\[\n\\begin{align*}\nP_{Y_1, \\dots, Y_n}(Y_1 = y_1, \\dots, Y_n = y_n) &= \\prod_{i = 1}^n P_{Y_i}(Y_i = y_i) \\\\\n& \\qquad \\text{for all} \\\\\n& \\qquad \\quad y_i \\in \\mathcal{Y}_i, i = 1, \\dots, n.\n\\end{align*}\n\\tag{A.9}\\]\n\nSuppose you have a set of \\(n\\) continuous random variables \\(Y_1, \\dots, Y_n\\) whose supports are \\(\\mathcal{Y_1}, \\dots, \\mathcal{Y_n}\\) with probability density functions (PDFs) \\(f_{Y_1}(y_1), \\dots, f_{Y_n}(y_n)\\) respectively. That said, the joint PDF of these \\(n\\) random variables is the multiplication of their corresponding standalone PDFs:\n\n\\[\n\\begin{align*}\nf_{Y_1, \\dots, Y_n}(y_1, \\dots, y_n) &= \\prod_{i = 1}^n f_{Y_i}(y_i) \\\\\n& \\qquad \\text{for all} \\\\\n& \\qquad \\quad y_i \\in \\mathcal{Y}_i, i = 1, \\dots, n.\n\\end{align*}\n\\tag{A.10}\\]\nIndependent variable\n\n\nEquivalent to:\n\n\nAttribute, covariate, exogeneous variable, explanatory variable, feature, input, predictor or regressor.\n\n\nInput\n\n\nEquivalent to:\n\n\nAttribute, covariate, exogeneous variable, explanatory variable, feature, independent variable, predictor or regressor.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#m",
    "href": "book/A-dictionary.html#m",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "M",
    "text": "M\nMean\nLet \\(Y\\) be a random variable whose support is \\(\\mathcal{Y}\\). In general, the expected value or mean \\(\\mathbb{E}(Y)\\) of this random variable is defined as a weighted average according to its corresponding probability distribution. In other words, this measure of central tendency \\(\\mathbb{E}(Y)\\) aims to find the middle value of this random variable by weighting all its possible values in its support \\(\\mathcal{Y}\\) as dictated by its probability distribution.\nGiven the above definition, when \\(Y\\) is a discrete random variable whose probability mass function (PMF) is \\(P_Y(Y = y)\\), then its mean is mathematically defined as\n\\[\n\\mathbb{E}(Y) = \\sum_{y \\in \\mathcal{Y}} y \\cdot P_Y(Y = y).\n\\]\nWhen \\(Y\\) is a continuous random variable whose probability density function (PDF) is \\(f_Y(y)\\), its mean is mathematically defined as\n\\[\n\\mathbb{E}(Y) = \\int_{\\mathcal{Y}} y \\cdot f_Y(y) \\mathrm{d}y.\n\\]\n\n\nEquivalent to:\n\n\nAverage or expected value.\n\n\nMeasure of central tendency\nProbabilistically, a measure of central tendency is defined as a metric that identifies a central or typical value of a given probability distribution. In other words, a measure of central tendency refers to a central or typical value that a given random variable might take when we observe various realizations of this variable over a long period.\nMeasure of uncertainty\nProbabilistically, a measure of uncertainty refers to the spread of a given random variable when we observe its different realizations in the long term. Note a larger spread indicates more variability in these realizations. On the other hand, a smaller spread denotes less variability in these realizations.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#n",
    "href": "book/A-dictionary.html#n",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "N",
    "text": "N\nNull hypothesis\nIn a hypothesis(s) testing, a null hypothesis is denoted by \\(H_0\\). The whole inferential process is designed to assess the strength of the evidence in favour or against this null hypothesis. In plain words, \\(H_0\\) is an inferential statement associated to the status quo in some population(s) or system(s) of interest, which might refer to no signal for the researcher in question.\nAgain, suppose random variable \\(Y\\) from some population(s) or system(s) of interest is governed by \\(k\\) parameters contained in the following vector:\n\\[\n\\boldsymbol{\\theta} = (\\theta_1, \\theta_2, \\cdots, \\theta_k)^T.\n\\]\nMoreover, we assume this observed data \\(y\\) follows certain probability distribution \\(\\mathcal{D}(\\cdot)\\) in a generative model \\(m\\) as in\n\\[\nm: y \\sim \\mathcal{D}(\\boldsymbol{\\theta}).\n\\]\nLet \\(\\boldsymbol{\\Theta}_0 \\subset \\boldsymbol{\\theta}\\) denote the status quo for the parameter(s) to be tested. Then, the null hypothesis is mathematically defined as\n\\[\nH_0: \\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}_0 \\quad \\text{where} \\quad \\boldsymbol{\\Theta}_0 \\subset \\boldsymbol{\\theta}.\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#o",
    "href": "book/A-dictionary.html#o",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "O",
    "text": "O\nObserved effect\nAn observed effect is the difference between the estimate provided the observed random sample (of size \\(n\\), as in \\(y_1, \\dots, y_n\\)) to the hypothesized value(s) of the population parameter(s) depicted in the statistical hypotheses.\nOutcome\nIn supervised learning, it is the main variable of interest we are trying to learn or predict, or equivalently, the variable we are trying explain in a statistical inference framework.\n\n\nEquivalent to:\n\n\nDependent variable, endogeneous variable, response variable, output or target.\n\n\nOutput\nIn supervised learning, it is the main variable of interest we are trying to learn or predict, or equivalently, the variable we are trying explain in a statistical inference framework.\n\n\nEquivalent to:\n\n\nDependent variable, endogeneous variable, response variable, outcome or target.\n\n\nOverdispersion",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#p",
    "href": "book/A-dictionary.html#p",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "P",
    "text": "P\nParameter\nIt is a characteristic (numerical or even non-numerical, such as a distinctive category) that summarizes the state of our population or system of interest.\nNote the standard mathematical notation for population parameters are Greek letters (for more insights, you can check Appendix B). Moreover, in practice, these population parameter(s) of interest will be unknown to the data scientist or researcher. Instead, they would use formal statistical inference to estimate them.\nPopulation\nIt is a whole collection of individuals or items that share distinctive attributes. As data scientists or researchers, we are interested in studying these attributes, which we assume are governed by parameters. In practice, we must be as specific as possible when defining our given population such that we would frame our entire data modelling process since its very early stages.\nNote that the term population could be exchanged for the term system, given that certain contexts do not specifically refer to individuals or items. Instead, these contexts could refer to processes whose attributes are also governed by parameters.\nPower\nThe statistical power of a test \\(1 -\\beta\\) is the complement of the conditional probability \\(\\beta\\) of failing to reject the null hypothesis \\(H_0\\) given that \\(H_0\\) is false, which is mathematically represented as\n\\[\nP \\left( \\text{Failing to reject $H_0$} | \\text{$H_0$ is false} \\right) = \\beta;\n\\]\nyielding\n\\[\n\\text{Power} = 1 - \\beta.\n\\]\nIn plain words, \\(1 - \\beta \\in [0, 1]\\) is the probabilistic ability of our hypothesis testing to detect any signal in our inferential process, if there is any. The larger the power in our power analysis, the less prone we are to commit a type II error.\n\n\nEquivalent to:\n\n\nTrue positive rate.\n\n\nPower analysis\nThe power analysis is a set of statistical tools used to compute the minimum required sample size \\(n\\) for any given inferential study. These tools require the significance level, power, and effect size (i.e., the magnitude of the signal) the researcher aims to detect via their inferential study. This analysis seeks to determine whether observed results are likely due to chance or represent a true and meaningful effect.\nPredictor\n\n\nEquivalent to:\n\n\nAttribute, covariate, exogeneous variable, explanatory variable, feature, independent variable, input or regressor.\n\n\nProbability\nLet \\(A\\) be an event of interest in a random phenomenon, in a population or system of interest, whose all possible outcomes belong to a given sample space \\(S\\). Generally, the probability for this event \\(A\\) happening can be mathematically depicted as \\(P(A)\\). Moreover, suppose we observe the random phenomenon \\(n\\) times such as we were running some class of experiment, then \\(P(A)\\) is defined as the following ratio:\n\\[\nP(A) = \\frac{\\text{Number of times event $A$ is observed}}{n},\n\\tag{A.11}\\]\nas the \\(n\\) times we observe the random phenomenon goes to infinity.\nEquation A.11 will always put \\(P(A)\\) in the following numerical range:\n\\[\n0 \\leq P(A) \\leq 1.\n\\]\nProbability distribution\nWhen we set a random variable \\(Y\\), we also set a new set of \\(v\\) possible outcomes \\(\\mathcal{Y} = \\{ y_1, \\dots, y_v\\}\\) coming from the sample space \\(S\\). This new set of possible outcomes \\(\\mathcal{Y}\\) corresponds to the support of the random variable \\(Y\\) (i.e., all the possible values that could be taken on once we execute a given random experiment involving \\(Y\\)).\nThat said, let us suppose we have a sample space of \\(u\\) elements defined as\n\\[\nS = \\{ s_1, \\dots, s_u \\},\n\\]\nwhere each one of these elements has a probability assigned via a function \\(P_S(\\cdot)\\) such that\n\\[\nP(S) = \\sum_{i = 1}^u P_S(s_i) = 1.\n\\]\nwhich has to satisfy Equation A.14.\nThen, the probability distribution of \\(Y\\), i.e., \\(P_Y(\\cdot)\\) assigns a probability to each observed value \\(Y = y_j\\) (with \\(j = 1, \\dots, v\\)) if and only if the outcome of the random experiment belongs to the sample space, i.e., \\(s_i \\in S\\) (for \\(i = 1, \\dots, u\\)) such that \\(Y(s_i) = y_j\\):\n\\[\nP_Y(Y = y_j) = P \\left( \\left\\{ s_i \\in S : Y(s_i) = y_j \\right\\} \\right).\n\\]\nProbability density function\nLet \\(Y\\) be a continuous random variable whose support is \\(\\mathcal{Y}\\). Furthermore, consider a function \\(f_Y(y)\\) such that\n\\[\nf_Y(y) : \\mathbb{R} \\rightarrow \\mathbb{R}\n\\]\nwith\n\\[\nf_Y(y) \\geq 0.\n\\]\nThen, \\(f_Y(y)\\) is considered a probability density function (PDF) if the probability of \\(Y\\) taking on a value within the range represented by the subset \\(A \\subset \\mathcal{Y}\\) is equal to\n\\[\nP_Y(Y \\in A) = \\int_A f_Y(y) \\mathrm{d}y\n\\]\nwith\n\\[\n\\int_{\\mathcal{Y}} f_Y(y) \\mathrm{d}y = 1.\n\\]\nProbability mass function\nLet \\(Y\\) be a discrete random variable whose support is \\(\\mathcal{Y}\\). Moreover, suppose that \\(Y\\) has a probability distribution such that\n\\[\nP_Y(Y = y) : \\mathbb{R} \\rightarrow [0, 1]\n\\]\nwhere, for all \\(y \\notin \\mathcal{Y}\\), we have\n\\[\nP_Y(Y = y) = 0\n\\]\nand\n\\[\n\\sum_{y \\in \\mathcal{Y}} P_Y(Y = y) = 1.\n\\] Then, \\(P_Y(Y = y)\\) is considered a probability mass function (PMF).\n\\(p\\)-value\nA \\(p\\)-value refers to the probability of obtaining a test statistic just as extreme or more extreme than the observed test statistic coming from our observed random sample of size \\(n\\). This \\(p\\)-value is obtained via the probability distribution of \\(H_0\\) and the observed test statistic.\nAlternatively to a critical value, we can reject or fail to reject the null hypothesis \\(H_0\\) using this \\(p\\)-value as follows:\n\nIf the \\(p\\)-value associated to the observed test statistic exceeds a given significance level \\(\\alpha\\), then we have enough statistical evidence to reject \\(H_0\\) in favour of \\(H_1\\).\nIf the \\(p\\)-value associated to the observed test statistic does not exceed a given significance level \\(\\alpha\\), then we have enough statistical evidence to fail to reject \\(H_0\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#r",
    "href": "book/A-dictionary.html#r",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "R",
    "text": "R\nRandom Sample\nA random sample is a collection of random variables \\(Y_1, \\dots, Y_n\\) of size \\(n\\) coming from a given population or system of interest. Note that the most elementary definition of a random sample assumes that these \\(n\\) random variables are mutually independent and identically distributed (which is abbreviated as iid).\nThe fact that these \\(n\\) random variables are identically distributed indicates that they have the same mathematical form for their corresponding probability mass functions (PMFs) or probability density function (PDFs), depending on whether they are discrete or continuous respectively. Hence, under a generative modelling approach in a population or system of interest governed by \\(k\\) parameters contained in the vector\n\\[\n\\boldsymbol{\\theta} = (\\theta_1, \\theta_2, \\cdots, \\theta_k)^T,\n\\]\nwe can apply the iid property in an elementary random sample to obtain the following joint probability distributions:\n\nIn the case of \\(n\\) iid discrete random variables \\(Y_1, \\dots, Y_n\\) whose common standalone PMF is \\(P_Y(Y = y | \\boldsymbol{\\theta})\\) with support \\(\\mathcal{Y}\\), the joint PMF is mathematically expressed as\n\n\\[\n\\begin{align*}\nP_{Y_1, \\dots, Y_n}(Y_1 = y_1, \\dots, Y_n = y_n | \\boldsymbol{\\theta}) &= \\prod_{i = 1}^n P_Y(Y = y_i | \\boldsymbol{\\theta}) \\\\\n& \\qquad \\text{for all} \\\\\n& \\qquad \\quad y_i \\in \\mathcal{Y}, i = 1, \\dots, n.\n\\end{align*}\n\\tag{A.12}\\]\n\nIn the case of \\(n\\) iid continuous random variables \\(Y_1, \\dots, Y_n\\) whose common standalone PDF is \\(f_Y(y | \\boldsymbol{\\theta})\\) with support \\(\\mathcal{Y}\\), the joint PDF is mathematically expressed as\n\n\\[\n\\begin{align*}\nf_{Y_1, \\dots, Y_n}(y_1, \\dots, y_n | \\boldsymbol{\\theta}) &= \\prod_{i = 1}^n f_Y(y_i | \\boldsymbol{\\theta}) \\\\\n& \\qquad \\text{for all} \\\\\n& \\qquad \\quad y_i \\in \\mathcal{Y}, i = 1, \\dots, n.\n\\end{align*}\n\\tag{A.13}\\]\nUnlike Equation A.9 and Equation A.10, note that Equation A.12 and Equation A.13 do not indicate a subscript for \\(Y\\) in the corresponding probability distributions since we have identically distributed random variables. Furthermore, the joint distributions are conditioned on the population parameter vector \\(\\boldsymbol{\\theta}\\) which reflects our generative modelling approach.\n\n\nSomewhat equivalent to:\n\n\nTraining dataset.\n\n\nRandom variable\nA random variable is a function where the input values correspond to real numbers assigned to events belonging to the sample space \\(S\\), and whose outcome is one of these real numbers after executing a given random experiment. For instance, a random variable (and its support, i.e., real numbers) is depicted with an uppercase such that\n\\[Y \\in \\mathbb{R}.\\]\nRegression analysis\nRegressor\n\n\nEquivalent to:\n\n\nAttribute, covariate, exogeneous variable, explanatory variable, feature, independent variable, input or predictor.\n\n\nResponse variable\nIn supervised learning, it is the main variable of interest we are trying to learn or predict, or equivalently, the variable we are trying explain in a statistical inference framework.\n\n\nEquivalent to:\n\n\nDependent variable, endogeneous variable, outcome, output or target.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#s",
    "href": "book/A-dictionary.html#s",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "S",
    "text": "S\nSample space\nLet \\(A\\) be an event of interest in a random phenomenon in a population or system of interest. The sample space \\(S\\) of event \\(A\\) denotes the set of all the possible random outcomes we might encounter every time we randomly observe \\(A\\) such as we were running some class of experiment.\nNote each of these outcomes has a determined probability associated with them. If we add up all these probabilities, the probability of the sample \\(S\\) will be one, i.e.,\n\\[\nP(S) = 1.\n\\tag{A.14}\\]\nSignificance level\nThe significance level \\(\\alpha\\) is defined as the conditional probability of rejecting the null hypothesis \\(H_0\\) given that \\(H_0\\) is true. This can be mathematically represented as\n\\[\nP \\left( \\text{Reject $H_0$} | \\text{$H_0$ is true} \\right) = \\alpha.\n\\]\nIn plain words, \\(\\alpha \\in [0, 1]\\) allows us to probabilistically control for type I error since we are dealing with random variables in our inferential process. The significance level can be thought as one of the main hypothesis testing and power analysis settings.\nStandard error\nThe standard error allows us to quantify the extent to which an estimate coming from an observed random sample (of size \\(n\\), as in \\(y_1, \\dots, y_n\\)) may deviate from the expected value under the assumption that the null hypothesis is true.\nIt plays a critical role in determining whether an observed effect is likely attributable to random variation or represents a statistically significant finding. In the absence of the standard error, it would not be possible to rigorously assess the reliability or precision of an estimate.\nSupervised learning\nSurvival analysis",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#t",
    "href": "book/A-dictionary.html#t",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "T",
    "text": "T\nTarget\nIn supervised learning, it is the main variable of interest we are trying to learn or predict, or equivalently, the variable we are trying explain in a statistical inference framework.\n\n\nEquivalent to:\n\n\nDependent variable, endogeneous variable, response variable, outcome or output.\n\n\nTest statistic\nThe test statistic is a function of the random sample of size \\(n\\), i.e., it is in the function of the random variables \\(Y_1, \\dots, Y_n\\). Therefore, the test statistic will also be a random variable, whose observed value will describe how closely the probability distribution from which the random sample comes from matches the probability distribution of the null hypothesis \\(H_0\\).\nMore specifically, once we have obtained the observed effect and standard error from our observed random sample, we can compute the corresponding observed test statistic. This test statistic computation will be placed on the corresponding \\(x\\)-axis of the probability distribution of \\(H_0\\) so we can reject or fail to reject it accordingly.\nTraining dataset\n\n\nSomewhat equivalent to:\n\n\nRandom sample.\n\n\nTrue positive rate\nThe statistical true positive rate of a test \\(1 -\\beta\\) is the complement of the conditional probability \\(\\beta\\) of failing to reject the null hypothesis \\(H_0\\) given that \\(H_0\\) is false, which is mathematically represented as\n\\[\nP \\left( \\text{Failing to reject $H_0$} | \\text{$H_0$ is false} \\right) = \\beta;\n\\]\nyielding\n\\[\n\\text{Power} = 1 - \\beta.\n\\]\nIn plain words, \\(1 - \\beta \\in [0, 1]\\) is the probabilistic ability of our hypothesis testing to detect any signal in our inferential process, if there is any. The larger the true positive rate in our power analysis, the less prone we are to commit a type II error.\n\n\nEquivalent to:\n\n\nPower.\n\n\nType I error\nType I error is defined as incorrectly rejecting the null hypothesis \\(H_0\\) in favour of the alternative hypothesis \\(H_1\\) when, in fact, \\(H_0\\) is true.\n\n\nEquivalent to:\n\n\nFalse positive.\n\n\nType II error\nType II error is defined as incorrectly failing to reject the null hypothesis \\(H_0\\) in favour of the alternative hypothesis \\(H_1\\) when, in fact, \\(H_0\\) is false. Table A.2 summarizes the types of inferential conclusions in function on whether \\(H_0\\) is true or not.\n\n\nTable A.2: Types of inferential conclusions in a frequentist hypothesis testing.\n\n\n\n\n\n\n\n\n\n\\(H_0\\) is true\n\\(H_0\\) is false\n\n\n\nReject \\(H_0\\)\nType I error (False positive)\nCorrect\n\n\nFail to reject \\(H_0\\)\nCorrect\nType II error (False negative)\n\n\n\n\n\n\n\n\nEquivalent to:\n\n\nFalse negative.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#u",
    "href": "book/A-dictionary.html#u",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "U",
    "text": "U\nUnderdispersion",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/A-dictionary.html#v",
    "href": "book/A-dictionary.html#v",
    "title": "Appendix A — The Fusionified ML-Stats Dictionary",
    "section": "V",
    "text": "V\nVariance\nLet \\(Y\\) be a discrete or continuous random variable whose support is \\(\\mathcal{Y}\\) with a mean represented by \\(\\mathbb{E}(Y)\\). Then, the variance of \\(Y\\) is the mean of the squared deviation from the corresponding mean as follows:\n\\[\n\\text{Var}(Y) = \\mathbb{E}\\left\\{[ Y - \\mathbb{E}(Y)]^2 \\right\\}. \\\\\n\\]\nNote the expression above is equivalent to:\n\\[\n\\text{Var}(Y) = \\mathbb{E}(Y^2) - \\left[ \\mathbb{E}(Y) \\right]^2.\n\\] Finally, to put the spread measurement on the same units of random variable \\(Y\\), the standard devation of \\(Y\\) is merely the square root of \\(\\text{Var}(Y)\\):\n\\[\n\\text{sd}(Y) = \\sqrt{\\text{Var}(Y)}.\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>The Fusionified ML-Stats Dictionary</span>"
    ]
  },
  {
    "objectID": "book/B-greek-alphabet.html",
    "href": "book/B-greek-alphabet.html",
    "title": "Appendix B — The Snazzalicious Greek Alphabet",
    "section": "",
    "text": "Fun fact!\n\n\nSnazzalicious! Food that’s dressed up, fancy, and begging for a photo.\n\n\nStatistical notation can be pretty particular and different from usual mathematical notation. One of these particularities is the constant use of Greek letters to denote unknown population parameters in modelling setup, estimation, and statistical inference. In that spirit, throughout this book, we use diverse Greek letters to denote our regression parameters across each of the outlined models in every chapter.\n\n\nImage by meineresterampe via Pixabay.\n\nDuring early learning stages of regression modelling, we may feel overwhelmed by these new letters, which could be unfamiliar. Therefore, whenever confusion arises in any of the main chapters in this book regarding the names of these letters, we recommend checking out the Greek alphabet from Table B.1. Note that frequentist statistical inference mostly uses lowercase letters. With practice over time, you would likely end up memorizing most of this alphabet.\n\n\nTable B.1: Greek alphabet composed of 24 letters, from left to right you can find the name of letter along with its corresponding uppercase and lowercase forms.\n\n\n\nName\nUppercase\nLowercase\n\n\n\nAlpha\n\\(\\text{A}\\)\n\\(\\alpha\\)\n\n\nBeta\n\\(\\text{B}\\)\n\\(\\beta\\)\n\n\nGamma\n\\(\\Gamma\\)\n\\(\\gamma\\)\n\n\nDelta\n\\(\\Delta\\)\n\\(\\delta\\)\n\n\nEpsilon\n\\(\\text{E}\\)\n\\(\\epsilon\\)\n\n\nZeta\n\\(\\text{Z}\\)\n\\(\\zeta\\)\n\n\nEta\n\\(\\text{H}\\)\n\\(\\eta\\)\n\n\nTheta\n\\(\\Theta\\)\n\\(\\theta\\)\n\n\nIota\n\\(\\text{I}\\)\n\\(\\iota\\)\n\n\nKappa\n\\(\\text{K}\\)\n\\(\\kappa\\)\n\n\nLambda\n\\(\\Lambda\\)\n\\(\\lambda\\)\n\n\nMu\n\\(\\text{M}\\)\n\\(\\mu\\)\n\n\nNu\n\\(\\text{N}\\)\n\\(\\nu\\)\n\n\nXi\n\\(\\Xi\\)\n\\(\\xi\\)\n\n\nO\n\\(\\text{O}\\)\n\\(\\text{o}\\)\n\n\nPi\n\\(\\Pi\\)\n\\(\\pi\\)\n\n\nRho\n\\(\\text{P}\\)\n\\(\\rho\\)\n\n\nSigma\n\\(\\Sigma\\)\n\\(\\sigma\\)\n\n\nTau\n\\(\\text{T}\\)\n\\(\\tau\\)\n\n\nUpsilon\n\\(\\Upsilon\\)\n\\(\\upsilon\\)\n\n\nPhi\n\\(\\Phi\\)\n\\(\\phi\\)\n\n\nChi\n\\(\\text{X}\\)\n\\(\\chi\\)\n\n\nPsi\n\\(\\Psi\\)\n\\(\\psi\\)\n\n\nOmega\n\\(\\Omega\\)\n\\(\\omega\\)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>The Snazzalicious Greek Alphabet</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html",
    "href": "book/C-distributional-mind-map.html",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "",
    "text": "D Discrete Random Variables\nLet us recall what a discrete random variable is. This type of variable is defined to take on a set of countable possible values. In other words, these values belong to a finite set. Figure C.1 delves into the following specific probability distributions:\nTable D.1 outlines the parameter(s), support, mean, and variance for each discrete probability distribution utilized to model the target \\(Y\\) in a specific regression tool explained in this book.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#sec-bernoulli-distribution",
    "href": "book/C-distributional-mind-map.html#sec-bernoulli-distribution",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nD.1 Bernoulli",
    "text": "D.1 Bernoulli\nLet \\(Y\\) be a discrete random variable that is part of a random process or system. \\(Y\\) can only take on the following values:\n\\[\ny =\n\\begin{cases}\n1 \\; \\; \\; \\; \\text{if there is a success},\\\\\n0 \\; \\; \\; \\; \\mbox{otherwise}.\n\\end{cases}\n\\tag{D.1}\\]\nNote that the support of \\(Y\\) in Equation D.1 makes it binary with these outcomes: \\(1\\) for success and \\(0\\) for failure. Then, \\(Y\\) is said to have a Bernoulli distribution with parameter \\(\\pi\\):\n\\[\nY \\sim \\text{Bern}(\\pi).\n\\]\n\nD.1.1 Probability Mass Function\nThe PMF of \\(Y\\) is the following:\n\\[\nP_Y \\left( Y = y \\mid \\pi \\right) = \\pi^y (1 - \\pi)^{1 - y} \\quad \\text{for $y \\in \\{ 0, 1 \\}$.}\n\\tag{D.2}\\]\nParameter \\(\\pi \\in [0, 1]\\) refers to the probability of success. We can verify Equation D.2 is a proper probability distribution (i.e., all the standalone probabilities over the support of \\(Y\\) add up to one) given that:\n\nProof. \\[\n\\begin{align*}\n\\sum_{y = 0}^1 P_Y \\left( Y = y \\mid \\pi \\right) &=  \\sum_{y = 0}^1 \\pi^y (1 - \\pi)^{1 - y}  \\\\\n&= \\underbrace{\\pi^0}_{1} (1 - \\pi) + \\pi \\underbrace{(1 - \\pi)^{0}}_{1} \\\\\n&= (1 - \\pi) + \\pi \\\\\n&= 1. \\qquad \\qquad \\qquad \\qquad \\quad \\square\n\\end{align*}\n\\]\n\nIndeed, the Bernoulli PMF is a proper probability distribution!\n\n\n\nD.1.2 Expected Value\nVia Equation C.3, the expected value or mean of a Bernoulli-distributed random variable \\(Y\\) can be found as follows:\n\nProof. \\[\n\\begin{align*}\n\\mathbb{E}(Y) &= \\sum_{y = 0}^1 y P_Y \\left( Y = y \\mid \\pi \\right) \\\\\n&= \\sum_{y = 0}^1 y \\left[ \\pi^y (1 - \\pi)^{1 - y} \\right] \\\\\n&= \\underbrace{(0) \\left[ \\pi^0 (1 - \\pi) \\right]}_{0} + (1) \\left[ \\pi (1 - \\pi)^{0} \\right] \\\\\n&= 0 + \\pi \\\\\n&= \\pi. \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\quad \\square\n\\end{align*}\n\\]\n\n\nD.1.3 Variance\nVia Equation C.5 and the Equation C.3 of a discrete expected value, the variance of a Bernoulli-distributed random variable \\(Y\\) can be found as follows:\n\nProof. \\[\n\\begin{align*}\n\\text{Var} (Y) &= \\mathbb{E} \\left( Y^2 \\right) - \\left[ \\mathbb{E}(Y)\\right]^2 \\\\\n&= \\mathbb{E} \\left( Y^2 \\right) - \\pi^2 \\qquad \\text{since $\\mathbb{E}(Y) = \\pi$} \\\\\n&= \\sum_{y = 0}^1 y^2 P_Y \\left( Y = y \\mid \\pi \\right) - \\pi^2 \\qquad \\text{by LOTUS} \\\\\n&= \\left\\{ \\underbrace{(0^2) \\left[ \\pi^0 (1 - \\pi) \\right]}_{0} + \\underbrace{(1^2) \\left[ \\pi (1 - \\pi)^{0} \\right]}_{\\pi} \\right\\} - \\pi^2 \\\\\n&= (0 + \\pi) - \\pi^2 \\\\\n&= \\pi - \\pi^2 \\\\\n&= \\pi (1 - \\pi). \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\quad \\square\n\\end{align*}\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#sec-binomial-distribution",
    "href": "book/C-distributional-mind-map.html#sec-binomial-distribution",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nD.2 Binomial",
    "text": "D.2 Binomial\nSuppose you execute \\(n\\) independent Bernoulli trials, each one with a probability of success \\(\\pi\\). Let \\(Y\\) be the number of successes obtained within these \\(n\\) Bernoulli trials. Then, \\(Y\\) is said to have a Binomial distribution with parameters \\(n\\) and \\(\\pi\\):\n\\[\nY \\sim \\text{Bin}(n, \\pi).\n\\]\n\nD.2.1 Probability Mass Function\nThe PMF of \\(Y\\) is the following:\n\\[\n\\begin{align*}\nP_Y \\left( Y = y \\mid n, \\pi \\right) &= {n \\choose y} \\pi^y (1 - \\pi)^{n - y} \\\\\n& \\qquad \\qquad \\qquad \\text{for $y \\in \\{ 0, 1, \\dots, n \\}$.}\n\\end{align*}\n\\tag{D.3}\\]\nParameter \\(\\pi \\in [0, 1]\\) refers to the probability of success of each Bernoulli trial and \\(n \\in \\mathbb{N}\\) to the number of trials. On the other hand, the term \\({n \\choose y}\\) indicates the total number of possible combinations for \\(y\\) successes out of our \\(n\\) trials:\n\\[\n{n \\choose y} = \\frac{n!}{y!(n - y)!}.\n\\tag{D.4}\\]\n\nHow can we verify that Equation D.3 is a proper PMF (i.e., all the standalone probabilities over the support of \\(Y\\) add up to one)?\n\nTo elaborate on this, we need to use a handy mathematical result called the binomial theorem.\n\nTheorem D.1 (Binomial Theorem) This theorem is associated to the Pascal’s identity, and it defines the pattern of coefficients in the expansion of a polynomial in the form \\((u + v)^m\\). More specifically, the binomial theorem indicates that if \\(m\\) is a non-negative integer, then the polynomial \\((u + v)^m\\) can be expanded via the following series:\n\\[\n\\begin{align*}\n(u + v)^m &= u^m + {m \\choose 1} u^{m - 1} v + {m \\choose 2} u^{m - 2} v^2 + \\dots + \\\\\n& \\qquad {m \\choose r} u^{m - r} v^r + \\dots + \\\\\n& \\qquad {m \\choose m - 1} u v^{m - 1} + v^m \\\\\n&= \\underbrace{{m \\choose 0}}_1 u^m + {m \\choose 1} u^{m - 1} v + {m \\choose 2} u^{m - 2} v^2 + \\dots + \\\\\n& \\qquad {m \\choose r} u^{m - r} v^r + \\dots + \\\\\n& \\qquad {m \\choose m - 1} u v^{m - 1} + \\underbrace{{m \\choose m}}_1 v^m \\\\\n&= \\sum_{i = 0}^m {m \\choose i} u^{m - i} v^i.\n\\end{align*}\n\\tag{D.5}\\]\n\n\n\nTip on the binomial theorem and Pascal’s identity\n\n\nLet us dig into the proof of the binomial theorem from Equation D.5. This proof will require another important result called the Pascal’s identity. This identity states that for any integers \\(m\\) and \\(k\\), with \\(k \\in \\{ 1, \\dots, m \\}\\), it follows that:\n\nProof. \\[\n\\begin{align*}\n{m \\choose k - 1} + {m \\choose k} &= \\left[ \\frac{m!}{(k - 1)! (m - k + 1)!} \\right] \\\\\n& \\qquad + \\left[ \\frac{m!}{k! (m - k)!} \\right] \\\\\n&= m! \\biggl\\{ \\left[ \\frac{1}{(k - 1)! (m - k + 1)!} \\right] + \\\\\n& \\qquad \\left[ \\frac{1}{k! (m - k)!} \\right] \\biggl\\} \\\\\n&= m! \\Biggl\\{ \\Biggr[ \\frac{k}{\\underbrace{k (k - 1)!}_{k!} (m - k + 1)!} \\Biggr] + \\\\\n& \\qquad \\Biggr[ \\frac{m - k + 1}{k! \\underbrace{(m - k + 1)(m - k)!}_{(m - k + 1)!}} \\Biggr] \\Biggl\\}  \\\\\n&= m! \\left[ \\frac{k + m - k + 1}{k! (m - k + 1)!} \\right] \\\\\n&= m! \\left[ \\frac{m + 1}{k! (m - k + 1)!} \\right] \\\\\n&= \\frac{(m + 1)!}{k! (m + 1 - k)!} \\\\\n&= {m + 1 \\choose k }. \\qquad \\qquad \\qquad \\qquad \\square\n\\end{align*}\n\\tag{D.6}\\]\n\n\nProof. Now, we will use mathematical induction to prove the binomial theorem from Equation D.5. Firstly, on the left-hand side of the theorem, note that when \\(m = 0\\) we have:\n\\[\n(u + v)^0 = 1.\n\\]\nNow, when \\(m = 0\\), for the right-hand side of this equation, we have that\n\\[\n\\sum_{i = 0}^m {m \\choose i} u^{m - i} v^i  = \\sum_{i = 0}^0 {0 \\choose i} u^i v^{i} = {0 \\choose 0} u^0 v^0 = 1.\n\\]\nHence, the binomial theorem holds when \\(m = 0\\). This is what we call the base case in mathematical induction.\nThat said, let us proceed with the inductive hypothesis. We aim to prove that the binomial theorem\n\\[\n\\begin{align*}\n(u + v)^j &= u^j + {j \\choose 1} u^{j - 1} v + {j \\choose 2} u^{j - 2} v^2 + \\dots + \\\\\n& \\qquad {j \\choose r} u^{j - r} v^r + \\dots + \\\\\n& \\qquad {j \\choose j - 1} u v^{j - 1} + v^j \\\\\n&= \\underbrace{{j \\choose 0}}_1 u^j + {j \\choose 1} u^{j - 1} v + {j \\choose 2} u^{j - 2} v^2 + \\dots + \\\\\n& \\qquad {j \\choose r} u^{j - r} v^r + \\dots + \\\\\n& \\qquad {j \\choose j - 1} u v^{j - 1} + \\underbrace{{j \\choose j}}_1 v^j \\\\\n&= \\sum_{i = 0}^j {j \\choose i} u^{j - i} v^i\n\\end{align*}\n\\tag{D.7}\\]\nholds when integer \\(j \\geq 1\\). This is our inductive hypothesis.\nThen, we pave the way to the inductive step. Let us consider the following expansion:\n\\[\n\\begin{align*}\n(u + v)^{j + 1} &= (u + v) (u + v)^j \\\\\n&= (u + v) \\times \\\\\n& \\qquad \\bigg[ u^j + {j \\choose 1} u^{j - 1} v + {j \\choose 2} u^{j - 2} v^2 + \\dots + \\\\\n& \\qquad {j \\choose r} u^{j - r} v^r + \\dots + {j \\choose j - 1} u v^{j - 1} + v^j \\bigg] \\\\\n&= \\bigg[u^{j + 1} + {j \\choose 1} u^j v + {j \\choose 2} u^{j - 1} v^2 + \\dots + \\\\\n& \\qquad {j \\choose r} u^{j - r + 1} v^r + \\dots + \\\\\n& \\qquad {j \\choose j - 1} u^2 v^{j - 1} + u v^j \\bigg] + \\\\\n& \\qquad \\bigg[ u^j v + {j \\choose 1} u^{j - 1} v^2 + {j \\choose 2} u^{j - 2} v^3 + \\dots + \\\\\n& \\qquad {j \\choose r} u^{j - r} v^{r + 1} + \\dots + \\\\\n& \\qquad {j \\choose j - 1} u v^j + {j \\choose j} v^{j + 1} \\bigg] \\\\\n&= u^{j + 1} + \\left[ {j \\choose 0} + {j \\choose 1} \\right] u^j v + \\\\\n& \\qquad \\left[ {j \\choose 1} + {j \\choose 2} \\right] u^{j - 1} v^2 + \\dots + \\\\\n& \\qquad \\left[ {j \\choose r - 1} + {j \\choose r} \\right] u^{j - r + 1} v^r + \\dots + \\\\\n& \\qquad \\left[ {j \\choose j - 1} + {j \\choose j} \\right] u v^j + v^{j + 1}.\n\\end{align*}\n\\tag{D.8}\\]\nLet us plug in the Pascal’s identity from Equation D.6 into Equation D.8:\n\\[\n\\begin{align*}\n(u + v)^{j + 1} &= u^{j + 1} + {j + 1 \\choose 1} u^j v + \\\\\n& \\qquad {j + 1 \\choose 2} u^{j - 1} v^2 + \\dots + \\\\\n& \\qquad {j + 1 \\choose r} u^{j - r + 1} v^r + \\dots + \\\\\n& \\qquad {j + 1 \\choose j} u v^j + v^{j + 1} \\\\\n&= \\underbrace{{j + 1 \\choose 0}}_1 u^{j + 1} + {j + 1 \\choose 1} u^j v + \\\\\n& \\qquad {j + 1 \\choose 2} u^{j - 1} v^2 + \\dots + \\\\\n& \\qquad {j + 1 \\choose r} u^{j - r + 1} v^r + \\dots + \\\\\n& \\qquad {j + 1 \\choose j} u v^j + \\underbrace{{j + 1 \\choose j + 1}}_1 v^{j + 1} \\\\\n&= \\sum_{i = 0}^{j + 1} {j + 1 \\choose i} u^{j + 1 - i} v^i. \\qquad \\quad \\square\n\\end{align*}\n\\tag{D.9}\\]\nNote that the result for \\(j\\) in Equation D.7 also holds for \\(j + 1\\) in Equation D.9. Therefore, by induction, the binomial theorem from Equation D.5 is true for all positive integers \\(m\\).\n\n\n\nAfter the above fruitful digression on the binomial theorem, let us use it to show that our Binomial PMF in Equation D.3 actually adds up to one all over the support of the random variable:\n\nProof. \\[\n\\begin{align*}\n\\sum_{y = 0}^n P_Y \\left( Y = y \\mid n, \\pi \\right) &= \\sum_{y = 0}^n {n \\choose y} \\pi^y (1 - \\pi)^{n - y} \\\\\n&= \\sum_{y = 0}^n {n \\choose y} (1 - \\pi)^{n - y} \\pi^y \\\\\n& \\quad \\qquad \\text{rearranging factors.}\n\\end{align*}\n\\]\nNow, by using the binomial theorem in Equation D.5, let:\n\\[\n\\begin{gather*}\nm  = n\\\\\ni = y \\\\\nu = 1 - \\pi \\\\\nv = \\pi.\n\\end{gather*}\n\\]\nThe above arrangement yields the following result:\n\\[\n\\begin{align*}\n\\sum_{y = 0}^n P_Y \\left( Y = y \\mid n, \\pi \\right) &= (1 - \\pi + \\pi)^n \\\\\n&= 1^n = 1. \\qquad \\square\n\\end{align*}\n\\tag{D.10}\\]\n\nIndeed, the Binomial PMF is a proper probability distribution!\n\n\n\nD.2.2 Expected Value\nVia Equation C.3, the expected value or mean of a Binomial-distributed random variable \\(Y\\) can be found as follows:\n\nProof. \\[\n\\begin{align*}\n\\mathbb{E}(Y) &= \\sum_{y = 0}^n y P_Y \\left( Y = y \\mid n, \\pi \\right) \\\\\n&= \\sum_{y = 1}^n y P_Y \\left( Y = y \\mid n, \\pi \\right) \\\\\n& \\quad \\qquad \\text{for $y = 0$, the addend is equal to zero} \\\\\n&= \\sum_{y = 1}^n y \\left[ {n \\choose y} \\pi^y (1 - \\pi)^{n - y} \\right] \\\\\n&= \\sum_{y = 1}^n y \\left[ \\frac{n!}{y! (n - y)!} \\pi^y (1 - \\pi)^{n - y} \\right] \\\\\n&= \\sum_{y = 1}^n \\left[ \\frac{y n!}{y (y - 1)!(n - y)!} \\pi^y (1 - \\pi)^{n - y} \\right] \\\\\n& \\quad \\qquad \\text{in the denominator, $y! = y (y - 1)!$}\\\\\n&= \\sum_{y = 1}^n \\left[ \\frac{n (n - 1)!}{(y - 1)!(n - y)!} \\pi^y (1 - \\pi)^{n - y} \\right] \\\\\n& \\quad \\qquad \\text{in the numerator, $n! = n (n - 1)!$} \\\\\n&= \\sum_{y = 1}^n \\left[ \\frac{n (n - 1)!}{(y - 1)!(n - y)!} \\pi^{y + 1 - 1} (1 - \\pi)^{n - y} \\right] \\\\\n& \\quad \\qquad \\text{note $\\pi^y = \\pi^{y + 1 - 1}$} \\\\\n&= n \\sum_{y = 1}^n \\left[ \\frac{(n - 1)!}{(y - 1)!(n - y)!} \\pi \\pi^{y - 1} (1 - \\pi)^{n - y} \\right] \\\\\n& \\quad \\qquad \\text{rearranging terms} \\\\\n&= n \\pi \\sum_{y = 1}^n \\left[ \\frac{(n - 1)!}{(y - 1)!(n - y)!} \\pi^{y - 1} (1 - \\pi)^{n - y} \\right].\n\\end{align*}\n\\tag{D.11}\\]\nNow, let us make the following variable rearrangement:\n\\[\n\\begin{gather*}\nm = n - 1 \\\\\nz = y - 1 \\\\\nm - z = n - y.\n\\end{gather*}\n\\]\nGoing back to Equation D.11, and applying our above variable rearrangement within the summation, we have:\n\\[\n\\begin{align*}\n\\mathbb{E}(Y) &= n \\pi \\sum_{z = 0}^m \\left[ \\frac{m!}{z!(m - z)!} \\pi^{z} (1 - \\pi)^{m - z} \\right] \\\\\n&= n \\pi \\sum_{z = 0}^m \\left[ {m \\choose z}\\pi^{z} (1 - \\pi)^{m - z} \\right].\n\\end{align*}\n\\tag{D.12}\\]\nNote that, in the summation of Equation D.12, we encounter the PMF of a random variable \\(Z\\) as follows:\n\\[\nZ \\sim \\text{Bin}(m, \\pi).\n\\]\nSince the summation, where this Binomial PMF of \\(Z\\) is depicted, goes from \\(z = 0\\) to \\(m\\), we can apply our result from Equation D.10:\n\\[\n\\begin{align*}\n\\mathbb{E}(Y) &= n \\pi \\underbrace{\\sum_{z = 0}^m \\left[ {m \\choose z}\\pi^{z} (1 - \\pi)^{m - z} \\right]}_{1} \\\\\n&= n \\pi. \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\quad \\square\n\\end{align*}\n\\]\n\n\nD.2.3 Variance\nVia Equation C.5 and the Equation C.3 of a discrete expected value, the variance of a Binomial-distributed random variable \\(Y\\) can be found as follows:\n\nProof. \\[\n\\begin{align*}\n\\text{Var} (Y) &= \\mathbb{E} \\left( Y^2 \\right) - \\left[ \\mathbb{E}(Y)\\right]^2 \\\\\n&= \\mathbb{E} \\left( Y^2 \\right) - (n \\pi)^2 \\qquad \\text{since $\\mathbb{E}(Y) = n \\pi$.}\n\\end{align*}\n\\tag{D.13}\\]\nUnlike the Bernoulli random variable, finding \\(\\mathbb{E} \\left( Y^2 \\right)\\) is not quite straightforward. We need to play around with the below expected value expression as follows:\n\\[\n\\begin{align*}\n\\mathbb{E} \\left( Y^2 \\right) &= \\mathbb{E} \\left[ Y (Y - 1) \\right] + \\mathbb{E}(Y) \\\\\n&= \\mathbb{E} \\left[ Y (Y - 1) \\right] + n \\pi \\qquad \\text{since $\\mathbb{E}(Y) = n \\pi$.}\n\\end{align*}\n\\tag{D.14}\\]\nNow, to find \\(\\mathbb{E} \\left[ Y (Y - 1) \\right]\\), we make the following derivation via the LOTUS from Equation C.1 when \\(g(Y) = y (y - 1)\\):\n\\[\n\\begin{align*}\n\\mathbb{E} \\left[ Y (Y - 1) \\right] &= \\sum_{y = 0}^n y (y - 1) P_Y \\left( Y = y \\mid n, \\pi \\right) \\\\\n&= \\sum_{y = 2}^n y (y - 1) P_Y \\left( Y = y \\mid n, \\pi \\right) \\\\\n& \\quad \\qquad \\text{for $y = \\{0, 1\\}$,} \\\\\n& \\quad \\qquad \\text{the addends are equal to zero} \\\\\n&= \\sum_{y = 2}^n y (y - 1) \\left[ {n \\choose y} \\pi^y (1 - \\pi)^{n - y} \\right] \\\\\n&= \\sum_{y = 2}^n y (y - 1) \\left[ \\frac{n!}{y! (n - y)!} \\pi^y (1 - \\pi)^{n - y} \\right] \\\\\n&= \\sum_{y = 2}^n \\left[ \\frac{y (y - 1) n!}{y (y - 1) (y - 2)! (n - y)!} \\pi^y (1 - \\pi)^{n - y} \\right] \\\\\n& \\quad \\qquad \\text{in the denominator, $y! = y (y - 1) (y - 2)!$} \\\\\n&= \\sum_{y = 2}^n \\left[ \\frac{n (n - 1) (n - 2)!}{(y - 2)! (n - y)!} \\pi^y (1 - \\pi)^{n - y} \\right] \\\\\n& \\quad \\qquad \\text{in the numerator, $n! = n (n - 1) (n - 2)!$} \\\\\n&= \\sum_{y = 2}^n \\left[ \\frac{n (n - 1) (n - 2)!}{(y - 2)! (n - y)!} \\pi^{y + 2 - 2} (1 - \\pi)^{n - y} \\right] \\\\\n& \\quad \\qquad \\text{note $\\pi^y = \\pi^{y + 2 - 2}$} \\\\\n&= n (n - 1) \\times \\\\\n& \\qquad \\sum_{y = 2}^n \\left[ \\frac{(n - 2)!}{(y - 2)! (n - y)!} \\pi^2 \\pi^{y - 2} (1 - \\pi)^{n - y} \\right] \\\\\n& \\qquad \\qquad \\text{rearranging terms} \\\\\n&= n (n - 1) \\pi^2 \\times \\\\\n& \\qquad \\sum_{y = 2}^n \\left[ \\frac{(n - 2)!}{(y - 2)! (n - y)!} \\pi^{y - 2} (1 - \\pi)^{n - y} \\right] \\\\\n& \\qquad \\qquad \\text{rearranging terms.}\n\\end{align*}\n\\tag{D.15}\\]\nThen, we make the following variable rearrangement:\n\\[\n\\begin{gather*}\nm = n - 2 \\\\\nz = y - 2 \\\\\nm - z = n - y.\n\\end{gather*}\n\\]\nGoing back to Equation D.15, and applying our above variable rearrangement within the summation, we have:\n\\[\n\\begin{align*}\n\\mathbb{E} \\left[ Y (Y - 1) \\right] &= n (n - 1) \\pi^2 \\sum_{z = 0}^m \\left[ \\frac{m!}{z! (m - z)!} \\pi^{z} (1 - \\pi)^{m - z} \\right] \\\\\n&= n (n - 1) \\pi^2 \\sum_{z = 0}^m \\left[ {m \\choose z} \\pi^{z} (1 - \\pi)^{m - z} \\right].\n\\end{align*}\n\\tag{D.16}\\]\nNote that, in the summation of Equation D.16, we encounter the PMF of a random variable \\(Z\\) as follows:\n\\[\nZ \\sim \\text{Bin}(m, \\pi).\n\\]\nSince the summation, where this Binomial PMF of \\(Z\\) is depicted, goes from \\(z = 0\\) to \\(m,\\) we can apply our result from Equation D.10:\n\\[\n\\begin{align*}\n\\mathbb{E} \\left[ Y (Y - 1) \\right] &= n (n - 1) \\pi^2 \\underbrace{\\sum_{z = 0}^m \\left[ {m \\choose z} \\pi^{z} (1 - \\pi)^{m - z} \\right]}_{1} \\\\\n&= n (n - 1) \\pi^2.\n\\end{align*}\n\\]\nLet us go back to Equation D.14 and plug in the above result:\n\\[\n\\begin{align*}\n\\mathbb{E} \\left( Y^2 \\right) &= \\mathbb{E} \\left[ Y (Y - 1) \\right] + n \\pi \\\\\n&= n (n - 1) \\pi^2 + n \\pi. \\\\\n\\end{align*}\n\\]\nFinally, we plug in \\(\\mathbb{E} \\left( Y^2 \\right)\\) in Equation D.13:\n\\[\n\\begin{align*}\n\\text{Var} (Y) &= \\mathbb{E} \\left( Y^2 \\right) - (n \\pi)^2 \\\\\n&= n (n - 1) \\pi^2 + n \\pi - n^2 \\pi^2 \\\\\n&= n^2 \\pi^2 - n \\pi^2 + n \\pi - n^2 \\pi^2 \\\\\n&= n \\pi - n \\pi^2 \\\\\n&= n \\pi (1 - \\pi). \\qquad \\qquad \\qquad \\square\n\\end{align*}\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#sec-negative-binomial-distribution",
    "href": "book/C-distributional-mind-map.html#sec-negative-binomial-distribution",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nD.3 Negative Binomial",
    "text": "D.3 Negative Binomial\nSuppose you execute a series of independent Bernoulli trials, each one with a probability of success \\(\\pi\\). Let \\(Y\\) be the number of failures in this series of Bernoulli trials you obtain before experiencing \\(k\\) successes. Therefore, \\(Y\\) is said to have a Negative Binomial distribution with parameters \\(k\\) and \\(\\pi\\):\n\\[\nY \\sim \\text{NegBin}(k, \\pi).\n\\]\n\nD.3.1 Probability Mass Function\nThe PMF of \\(Y\\) is the following:\n\\[\n\\begin{align*}\nP_Y \\left( Y = y \\mid k, \\pi \\right) &= {k + y - 1 \\choose y} \\pi^k (1 - \\pi)^y \\\\\n& \\qquad \\qquad \\qquad \\quad \\text{for $y \\in \\{ 0, 1, \\dots \\}$.}\n\\end{align*}\n\\tag{D.17}\\]\nParameter \\(\\pi \\in [0, 1]\\) refers to the probability of success of each Bernoulli trial, whereas \\(k\\) refers to the number of successes.\n\n\nTip on an alternative Negative Binomial PMF!\n\n\nThere is an alternative parametrization to define a Negative Binomial distribution in which we have a random variable \\(Z\\) defined as the total number of Bernoulli trials (i.e., \\(k\\) successes plus the \\(Y\\) failures depicted in Equation D.17):\n\\[\nZ = Y + k.\n\\]\nThis alternative parametrization of the Negative Binomial distribution yields the following PMF:\n\\[\n\\begin{align*}\nP_Z \\left( Z = z \\mid k, \\pi \\right) &= {z - 1 \\choose k - 1} \\pi^k (1 - \\pi)^{z - k} \\\\\n& \\qquad \\qquad \\qquad \\text{for $z \\in \\{ k, k + 1, \\dots \\}$.}\n\\end{align*}\n\\]\nNevertheless, we will not dig into this version of the Negative Binomial distribution since Chapter 11 delves into a modelling estimation via a joint PMF of the training set involving Equation D.17.\n\n\n\nHow can we verify that Equation D.17 is a proper PMF (i.e., all the standalone probabilities over the support of \\(Y\\) add up to one)?\n\n\nProof. Let us manipulate the factor involving the number of combinations corresponding to how many different possible subsets of size \\(y\\) can be made from the larger set of size \\(k + y - 1\\):\n\\[\n\\begin{align*}\n{k + y - 1 \\choose y} &= \\frac{(k + y - 1)!}{(k + y - 1 - y)! y !} \\\\\n&= \\frac{(k + y - 1)!}{(k - 1)! y!} \\\\\n&= \\frac{(k + y - 1) (k + y - 2) \\cdots (k + 1) (k) (k - 1)!}{(k - 1)! y!} \\\\\n&= \\frac{(\\overbrace{k + y - 1) (k + y - 2) \\cdots (k + 1) k}^{\\text{we have $y$ factors}}}{y!} \\\\\n&= (- 1)^y \\frac{\\overbrace{(-k - y + 1) (-k - y + 2) \\cdots (-k - 1) (-k)}^{\\text{multiplying each factor times $-1$}}}{y!} \\\\\n&= (- 1)^y \\frac{\\overbrace{(-k) (-k - 1) \\cdots (-k - y + 2) (-k - y + 1)}^{\\text{rearranging factors}}}{y!} \\\\\n&= (- 1)^y \\frac{(-k) (-k - 1) \\cdots (-k - y + 2) (-k - y + 1)}{y!} \\times \\\\\n& \\qquad \\frac{(-k - y) (-k - y - 1) \\cdots (1)}{(-k - y) (-k - y - 1) \\cdots (1)} \\\\\n&= (- 1)^y \\frac{(-k) (-k - 1) \\cdots (-k - y + 2) (-k - y + 1)}{y!} \\times \\\\\n& \\qquad \\frac{(-k - y) (-k - y - 1) \\cdots (1)}{(-k - y)!}.\n\\end{align*}\n\\]\nIn the equation above, note that there are still several factors in the numerator, which can be summarized using a factorial as follows:\n\\[\n\\begin{align*}\n(-k)! &= (-k) (-k - 1) \\cdots (-k - y + 2) (-k - y + 1) \\times \\\\\n& \\quad \\qquad (-k - y) (-k - y - 1) \\cdots (1).\n\\end{align*}\n\\]\nTherefore:\n\\[\n\\begin{align*}\n{k + y - 1 \\choose y} &= (- 1)^y \\frac{(-k)!}{(-k - y)! y!}\\\\\n&= (- 1)^y {-k \\choose y}.\n\\end{align*}\n\\]\nNow, let us begin with the summation involving the Negative Binomial PMF depicted in Equation D.17 from \\(0\\) to \\(\\infty\\):\n\\[\n\\begin{align*}\n\\sum_{y = 0}^{\\infty} P_Y \\left( Y = y \\mid k, \\pi \\right) &= \\sum_{y = 0}^{\\infty} {k + y - 1 \\choose y} \\pi^k (1 - \\pi)^y \\\\\n&= \\sum_{y = 0}^{\\infty} (- 1)^y {-k \\choose y} \\pi^k (1 - \\pi)^y \\\\\n&= \\pi^k \\sum_{y = 0}^{\\infty} (- 1)^y {-k \\choose y} (1 - \\pi)^y \\\\\n&= \\pi^k \\sum_{y = 0}^{\\infty} {-k \\choose y} (-1 + \\pi)^y.\n\\end{align*}\n\\tag{D.18}\\]\nOn the right-hand side of Equation D.18 we will add the following factor:\n\\[\n(1)^{-k - y} = 1.\n\\]\nThus:\n\\[\n\\begin{align*}\n\\sum_{y = 0}^{\\infty} P_Y \\left( Y = y \\mid k, \\pi \\right) &= \\pi^k \\sum_{y = 0}^{\\infty} {-k \\choose y} (1)^{-k - y} (-1 + \\pi)^y.\n\\end{align*}\n\\tag{D.19}\\]\nNow, by using the binomial theorem in Equation D.5, let:\n\\[\n\\begin{gather*}\nm  = -k\\\\\ni = y \\\\\nu = 1 \\\\\nv = -1 + \\pi.\n\\end{gather*}\n\\]\nThe above arrangement yields the following result in Equation D.19:\n\\[\n\\begin{align*}\n\\sum_{y = 0}^{\\infty} P_Y \\left( Y = y \\mid k, \\pi \\right) &=  \\pi^k (1 - 1 + \\pi)^{-k} \\\\\n&= \\pi^k (\\pi) ^{-k} \\\\\n&= \\pi^0 \\\\\n&= 1. \\qquad \\qquad \\qquad \\square\n\\end{align*}\n\\tag{D.20}\\]\n\nIndeed, the Negative Binomial PMF is a proper probability distribution!\n\n\n\nD.3.2 Expected Value\nVia Equation C.3, the expected value or mean of a Negative Binomial-distributed random variable \\(Y\\) can be found as follows:\n\nProof. \\[\n\\begin{align*}\n\\mathbb{E}(Y) &= \\sum_{y = 0}^{\\infty} y P_Y \\left( Y = y \\mid k, \\pi \\right) \\\\\n&= \\sum_{y = 1}^{\\infty} y P_Y \\left( Y = y \\mid k, \\pi \\right) \\\\\n& \\quad \\qquad \\text{for $y = 0$, the addend is equal to zero} \\\\\n&= \\sum_{y = 1}^{\\infty} y \\left[ {k + y - 1 \\choose y} \\pi^k (1 - \\pi)^y \\right] \\\\\n&= \\sum_{y = 1}^{\\infty} y \\left[ \\frac{(k + y - 1)!}{y! (k + y - 1 - y)!} \\pi^k (1 - \\pi)^y \\right] \\\\\n&= \\sum_{y = 1}^{\\infty} y \\left[ \\frac{(k + y - 1)!}{y! (k - 1)!} \\pi^k (1 - \\pi)^y \\right] \\\\\n&= \\sum_{y = 1}^{\\infty} y \\Bigg[ \\frac{(k + y - 1)!}{y (y - 1)! \\underbrace{\\left( \\frac{k!}{k} \\right)}_{(k - 1)!}} \\pi^k (1 - \\pi)^y \\Bigg] \\\\\n&= \\sum_{y = 1}^{\\infty} k \\left[ \\frac{(k + y - 1)!}{k! (y - 1)!} \\pi^k (1 - \\pi)^y \\right] \\\\\n&= k \\sum_{y = 1}^{\\infty} \\left[ {k + y - 1 \\choose y - 1} \\pi^k (1 - \\pi)^y \\right] \\\\\n&= k \\sum_{y = 1}^{\\infty} \\left[ {k + y - 1 \\choose y - 1} \\pi^{k + 1 - 1} (1 - \\pi)^{y + 1 - 1} \\right] \\\\\n& \\quad \\qquad \\text{note $\\pi^k = \\pi^{k + 1 - 1}$ and $(1 - \\pi)^y = (1 - \\pi)^{y + 1 - 1}$} \\\\\n&= \\frac{k (1 - \\pi)}{\\pi} \\sum_{y = 1}^{\\infty} \\left[ {k + y - 1 \\choose y - 1} \\pi^{k + 1} (1 - \\pi)^{y - 1} \\right].\n\\end{align*}\n\\tag{D.21}\\]\nNow, let us make the following variable rearrangement:\n\\[\n\\begin{gather*}\nm = k + 1 \\\\\nz = y - 1 \\\\\nm + z - 1  = k + y - 1.\n\\end{gather*}\n\\]\nGoing back to Equation D.21, and applying our above variable rearrangement within the summation, we have:\n\\[\n\\mathbb{E}(Y) = \\frac{k (1 - \\pi)}{\\pi} \\sum_{z = 0}^{\\infty} \\left[ {m + z - 1 \\choose z} \\pi^{m} (1 - \\pi)^{z} \\right].\n\\tag{D.22}\\]\nNote that, in the summation of Equation D.22, we encounter the PMF of a random variable \\(Z\\) as follows:\n\\[\nZ \\sim \\text{NegBin}(m, \\pi).\n\\]\nSince the summation, where this Negative Binomial PMF of \\(Z\\) is depicted, goes from \\(z = 0\\) to \\(\\infty\\), we can apply our result from Equation D.20:\n\\[\n\\begin{align*}\n\\mathbb{E}(Y) &= \\frac{k (1 - \\pi)}{\\pi} \\underbrace{\\sum_{z = 0}^m \\left[ {m + z - 1 \\choose z} \\pi^{m} (1 - \\pi)^{z} \\right]}_{1} \\\\\n&= \\frac{k (1 - \\pi)}{\\pi}. \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\quad \\square\n\\end{align*}\n\\]\n\n\nD.3.3 Variance\nVia Equation C.5 and the Equation C.3 of a discrete expected value, the variance of a Negative Binomial-distributed random variable \\(Y\\) can be found as follows:\n\nProof. \\[\n\\begin{align*}\n\\text{Var} (Y) &= \\mathbb{E} \\left( Y^2 \\right) - \\left[ \\mathbb{E}(Y)\\right]^2 \\\\\n&= \\mathbb{E} \\left( Y^2 \\right) - \\left[ \\frac{k (1 - \\pi)}{\\pi} \\right]^2 \\quad \\text{since $\\mathbb{E}(Y) = \\frac{k (1 - \\pi)}{\\pi}$.}\n\\end{align*}\n\\tag{D.23}\\]\nNow, we need to play around with the below expected value expression as follows:\n\\[\n\\begin{align*}\n\\mathbb{E} \\left( Y^2 \\right) &= \\mathbb{E} \\left[ Y (Y - 1) \\right] + \\mathbb{E}(Y) \\\\\n&= \\mathbb{E} \\left[ Y (Y - 1) \\right] + \\frac{k (1 - \\pi)}{\\pi}.\n\\end{align*}\n\\tag{D.24}\\]\nTo find \\(\\mathbb{E} \\left[ Y (Y - 1) \\right]\\), we make the following derivation via the LOTUS from Equation C.1 when \\(g(Y) = y (y - 1)\\):\n\\[\n\\begin{align*}\n\\mathbb{E} \\left[ Y (Y - 1) \\right] &= \\sum_{y = 0}^{\\infty} y (y - 1) P_Y \\left( Y = y \\mid k, \\pi \\right) \\\\\n&= \\sum_{y = 2}^{\\infty} y (y - 1) P_Y \\left( Y = y \\mid k, \\pi \\right) \\\\\n& \\quad \\qquad \\text{for $y = \\{0, 1\\}$,} \\\\\n& \\quad \\qquad \\text{the addends are equal to zero} \\\\\n&= \\sum_{y = 2}^{\\infty} y (y - 1) \\left[ {k + y - 1 \\choose y} \\pi^k (1 - \\pi)^y \\right] \\\\\n&= \\sum_{y = 2}^{\\infty} y (y - 1) \\left[ \\frac{(k + y - 1)!}{y! (k + y - 1 - y)!} \\pi^k (1 - \\pi)^y \\right] \\\\\n&= \\sum_{y = 2}^{\\infty} y (y - 1) \\left[ \\frac{(k + y - 1)!}{y! (k - 1)!} \\pi^k (1 - \\pi)^y \\right] \\\\\n&= \\sum_{y = 2}^{\\infty} \\frac{y (y - 1)}{y (y - 1)} \\left[ \\frac{(k + y - 1)!}{(y - 2)! (k - 1)!} \\pi^k (1 - \\pi)^y \\right] \\\\\n& \\quad \\qquad \\text{in the denominator, $y! = y (y - 1) (y - 2)!$} \\\\\n&= \\sum_{y = 2}^{\\infty} \\Bigg[ \\frac{(k + y - 1)!}{(y - 2)! \\underbrace{\\frac{(k + 1)!}{k (k + 1)}}_{(k - 1)!}} \\pi^k (1 - \\pi)^y \\Bigg] \\\\\n&= \\sum_{y = 2}^{\\infty} \\left[ k (k + 1) \\frac{(k + y - 1)!}{(k + 1)! (y - 2)!} \\pi^k (1 - \\pi)^y \\right] \\\\\n&= k (k + 1) \\sum_{y = 2}^{\\infty} \\left[ {k + y - 1 \\choose y - 2} \\pi^k (1 - \\pi)^y \\right] \\\\\n&= k (k + 1) \\sum_{y = 2}^{\\infty} \\left[ {k + y - 1 \\choose y - 2} \\pi^{k + 2 - 2} (1 - \\pi)^{y + 2 - 2} \\right] \\\\\n& \\quad \\qquad \\text{note $\\pi^k = \\pi^{k + 2 - 2}$ and} \\\\\n& \\quad \\qquad (1 - \\pi)^y = (1 - \\pi)^{y + 2 - 2} \\\\\n&= \\frac{k (k + 1) ( 1 - \\pi)^2}{\\pi^2} \\times \\\\\n& \\qquad \\sum_{y = 2}^{\\infty} \\left[ {k + y - 1 \\choose y - 2} \\pi^{k + 2} (1 - \\pi)^{y - 2} \\right].\n\\end{align*}\n\\tag{D.25}\\]\nThen, we make the following variable rearrangement:\n\\[\n\\begin{gather*}\nm = k + 2\\\\\nz = y - 2 \\\\\nm + z - 1  = k + y - 1.\n\\end{gather*}\n\\]\nGoing back to Equation D.25, and applying our above variable rearrangement within the summation, we have:\n\\[\n\\begin{align*}\n\\mathbb{E} \\left[ Y (Y - 1) \\right] &= \\frac{k (k + 1) ( 1 - \\pi)^2}{\\pi^2} \\times \\\\\n& \\qquad \\sum_{y = 2}^{\\infty} \\left[ {m + z - 1 \\choose z} \\pi^m (1 - \\pi)^z \\right].\n\\end{align*}\n\\tag{D.26}\\]\nNote that, in the summation of Equation D.26, we encounter the PMF of a random variable \\(Z\\) as follows:\n\\[\nZ \\sim \\text{NegBin}(m, \\pi).\n\\]\nSince the summation, where this Binomial PMF of \\(Z\\) is depicted, goes from \\(z = 0\\) to \\(\\infty\\), we can apply our result from Equation D.20:\n\\[\n\\begin{align*}\n\\mathbb{E} \\left[ Y (Y - 1) \\right] &= \\frac{k (k + 1) ( 1 - \\pi)^2}{\\pi^2} \\times \\\\\n& \\qquad \\underbrace{\\sum_{y = 2}^{\\infty} \\left[ {m + z - 1 \\choose z} \\pi^m (1 - \\pi)^z \\right]}_{1} \\\\\n&= \\frac{k (k + 1) ( 1 - \\pi)^2}{\\pi^2}.\n\\end{align*}\n\\]\nLet us go back to Equation D.24 and plug in the above result:\n\\[\n\\begin{align*}\n\\mathbb{E} \\left( Y^2 \\right) &= \\mathbb{E} \\left[ Y (Y - 1) \\right] + \\frac{k ( 1 - \\pi)}{\\pi} \\\\\n&= \\frac{k (k + 1) ( 1 - \\pi)^2}{\\pi^2} + \\frac{k ( 1 - \\pi)}{\\pi}.\n\\end{align*}\n\\]\nFinally, we plug in \\(\\mathbb{E} \\left( Y^2 \\right)\\) in Equation D.23:\n\\[\n\\begin{align*}\n\\text{Var} (Y) &= \\mathbb{E} \\left( Y^2 \\right) - \\left[ \\frac{k (1 - \\pi)}{\\pi} \\right]^2 \\\\\n&= \\frac{k (k + 1) ( 1 - \\pi)^2}{\\pi^2} + \\frac{k ( 1 - \\pi)}{\\pi} - \\left[ \\frac{k (1 - \\pi)}{\\pi} \\right]^2 \\\\\n&= \\frac{k (1 - \\pi)}{\\pi} \\left[ \\frac{(k + 1) (1 - \\pi)}{\\pi} + 1 - \\frac{k (1 - \\pi)}{\\pi} \\right] \\\\\n&= \\frac{k (1 - \\pi)}{\\pi} \\left[ \\frac{(k + 1) (1 - \\pi) + \\pi - k (1 - \\pi)}{\\pi} \\right] \\\\\n&= \\frac{k (1 - \\pi)}{\\pi} \\left( \\frac{k - k \\pi + 1 - \\pi + \\pi - k + k \\pi}{\\pi} \\right) \\\\\n&= \\frac{k (1 - \\pi)}{\\pi} \\left( \\frac{1}{\\pi} \\right) \\\\\n&= \\frac{k (1 - \\pi)}{\\pi^2}. \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\quad \\square\n\\end{align*}\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#sec-classical-poisson-distribution",
    "href": "book/C-distributional-mind-map.html#sec-classical-poisson-distribution",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nD.4 Classical Poisson",
    "text": "D.4 Classical Poisson\nSuppose you observe the count of events happening in a fixed interval of time or space. Let \\(Y\\) be the number of counts considered of integer type. Then, \\(Y\\) is said to have a classical Poisson distribution with a continuous parameter \\(\\lambda\\):\n\\[\nY \\sim \\text{Pois}(\\lambda).\n\\]\n\nD.4.1 Probability Mass Function\nThe PMF of this count-type \\(Y\\) is the following:\n\\[\nP_Y \\left( Y = y \\mid \\lambda \\right) = \\frac{\\lambda^y \\exp{(-\\lambda)}}{y!} \\quad \\text{for $y \\in \\{ 0, 1, 2, \\dots\\}$,}\n\\tag{D.27}\\]\nwhere \\(\\exp{(\\cdot)}\\) depicts the base \\(e\\) (i.e., Euler’s number, \\(e = 2.71828...\\)) and \\(y!\\) is the factorial\n\\[\ny! = y \\times (y - 1) \\times (y - 2) \\times (y - 3) \\times \\cdots \\times 3 \\times 2 \\times 1.  \n\\]\nwith\n\\[\n0! = 1.\n\\]\nThe continuous parameter \\(\\lambda \\in (0, \\infty)\\) represents the average rate at which these events happen (i.e., events per area unit or events per time unit). Curiously, even though the random variable \\(Y\\) is considered discrete in this case, \\(\\lambda\\) is modelled as continuous!\n\nHow can we verify that Equation D.27 is a proper PMF (i.e., all the standalone probabilities over the support of \\(Y\\) add up to one)?\n\nTo elaborate on this, we need to use some mathematical tools called the Taylor series expansions and a derived result called Maclaurin series expansions.\n\n\nHeads-up on the Taylor and Maclaurin series expansions!\n\n\nIn mathematics, there are helpful tools known as Taylor series expansions, which were officially published by English mathematician Brook Taylor in Methodus Incrementorum Directa & Inversa (Taylor 1715).\n\n\nPortrait of mathematician Brook Taylor (Earlom 1793).\n\nHowever, it is essential to note that Scottish mathematician James Gregory introduced the notion of these series expansions in his work Vera Circuli et Hyperbolae Quadratura (Gregory 1668).\n\n\nPortrait of mathematician James Gregory (Scotland, n.d.).\n\nThese series approximate complex mathematical functions through an infinite sum of polynomial terms. For example, in machine learning, the Taylor series expansions can be utilized in gradient-based optimization methods. Specifically, Newton’s method uses these expansions to find roots of equations that cannot be solved analytically, which is common in maximum likelihood-based parameter estimation for the varied regression models discussed throughout this book. Moreover, we can find these series in different engineering and scientific fields such as physics.\nSuppose we have real function \\(f(u)\\) around a point \\(u = a\\), then the one-dimensional infinite Taylor series expansion is given by the expression\n\\[\n\\begin{align*}\nf(u) &= f(a) + f'(a) (u - a) + \\frac{f''(a)}{2!} (u - a)^2 + \\\\\n& \\qquad \\frac{f^{(3)}(a)}{3!} (u - a)^3 + \\frac{f^{(4)}(a)}{4!} (u - a)^4 + \\\\\n& \\qquad \\frac{f^{(5)}(a)}{5!} (u - a)^5 + \\cdots \\\\\n&= \\sum_{j = 0}^{\\infty} \\frac{f^{(j)}(a)}{j!} (u - a)^j.\n\\end{align*}\n\\tag{D.28}\\]\nA complete mathematical derivation of Equation D.28 can be found in Weisstein (n.d.b). Moving along, specifically in the last line of this equation which shows an infinite summation, note the following:\n\n\n\\(f^{(j)}(a)\\) indicates the \\(j\\)th order derivative of \\(f(u)\\) and evaluated at point \\(a\\).\n\n\\(j!\\) implicates the factorial of \\(j\\) such that\n\n\\[\nj! = j \\times (j - 1) \\times (j - 2) \\times (j - 3) \\times \\cdots \\times 3 \\times 2 \\times 1.\n\\]\nwith\n\\[\n0! = 1.\n\\]\nIf we go even further with Equation D.28, we have a specific case when \\(a = 0\\) called the Maclaurin series expansions. This case was introduced by the Scottish mathematician Colin Maclaurin in his work A Treatise of Fluxions (Maclaurin 1742).\n\n\nPortrait of mathematician Colin Maclaurin (Harding 1798).\n\nHence, in a Mclaurin series, Equation D.28 becomes:\n\\[\n\\begin{align*}\nf(u) &= f(0) + f'(0) (u) + \\frac{f''(0)}{2!} u^2 + \\\\\n& \\qquad \\frac{f^{(3)}(0)}{3!} u^3 + \\frac{f^{(4)}(0)}{4!} u^4 + \\\\\n& \\qquad \\frac{f^{(5)}(0)}{5!} u^5 + \\cdots \\\\\n&= \\sum_{j = 0}^{\\infty} \\frac{f^{(j)}(0)}{j!} u^j.\n\\end{align*}\n\\tag{D.29}\\]\nDifferent statistical proofs make use of Taylor series expansions as well as the Mclaurin series, and the Poisson distribution is not an exception at all!\n\n\nThe above Mclaurin series in Equation D.29 will help us to show that our Poisson PMF in Equation D.27 actually adds up to one all over the support of the random variable:\n\nProof. \\[\n\\begin{align*}\n\\sum_{y = 0}^{\\infty} P_Y \\left( Y = y \\mid \\lambda \\right) &= \\sum_{y = 0}^{\\infty} \\frac{\\lambda^y \\exp{(-\\lambda)}}{y!} \\\\\n&= \\exp{(-\\lambda)} \\sum_{y = 0}^{\\infty} \\frac{\\lambda^y}{y!} \\\\\n& \\quad \\qquad \\text{factoring out $\\exp{(-\\lambda)}$,} \\\\\n& \\quad \\qquad \\text{since it does not depend on $y$.}\n\\end{align*}\n\\tag{D.30}\\]\nNow, we will focus on the above summation\n\\[\n\\sum_{y = 0}^{\\infty} \\frac{\\lambda^y}{y!}\n\\] and use the Mclaurin series from Equation D.29 by letting\n\\[\nf(u) = \\exp(u).\n\\tag{D.31}\\]\nWe know that all derivatives of the above function are equal\n\\[\nf'(u) = f''(u) = f^{(3)}(u) = f^{(4)}(u) = f^{(5)}(u) = \\cdots = \\exp{(u)},\n\\] which allows us to conclude that the \\(j\\)th derivative is\n\\[\nf^{(j)}(u) = \\exp(u).\n\\]\nThis \\(j\\)th derivative evaluated at \\(u = 0\\) becomes\n\\[\nf^{(j)}(0) = \\exp(0) = 1.\n\\]\nTherefore, the Mclaurin series for Equation D.31 is the following:\n\\[\n\\begin{align*}\nf(u) &= \\exp(u) \\\\\n&= \\sum_{j = 0}^{\\infty} \\frac{\\exp(0)}{j!} u^j \\\\\n&= \\sum_{j = 0}^{\\infty} \\frac{u^j }{j!}.\n\\end{align*}\n\\tag{D.32}\\]\nThat said, using Equation D.32, let:\n\\[\n\\begin{gather*}\n\\lambda = u \\\\\ny = j.\n\\end{gather*}\n\\]\nThus, we have the following:\n\\[\n\\sum_{y = 0}^{\\infty} \\frac{\\lambda^y}{y!} = \\exp{(\\lambda)}.\n\\]\nFinally, going back to Equation D.30:\n\\[\n\\begin{align*}\n\\sum_{y = 0}^{\\infty} P_Y \\left( Y = y \\mid \\lambda \\right) &= \\exp{(-\\lambda)} \\overbrace{\\sum_{y = 0}^{\\infty} \\frac{\\lambda^y}{y!}}^{\\exp{(\\lambda)}} \\\\\n&= \\exp{(-\\lambda)} \\times \\exp{(\\lambda)} \\\\\n&= \\exp{(-\\lambda + \\lambda)} \\\\\n&= \\exp{(0)} \\\\\n&= 1. \\qquad \\qquad \\qquad \\qquad \\square\n\\end{align*}\n\\tag{D.33}\\]\n\nIndeed, the Poisson PMF is a proper probability distribution!\n\n\n\nD.4.2 Expected Value\nVia Equation C.3, the expected value or mean of a Poisson-distributed random variable \\(Y\\) can be found as follows:\n\nProof. \\[\n\\begin{align*}\n\\mathbb{E}(Y) &= \\sum_{y = 0}^{\\infty} y P_Y \\left( Y = y \\mid \\lambda \\right) \\\\\n&= \\sum_{y = 1}^{\\infty} y P_Y \\left( Y = y \\mid \\lambda \\right) \\\\\n& \\quad \\qquad \\text{for $y = 0$, the addend is equal to zero} \\\\\n&= \\sum_{y = 1}^{\\infty} y \\left[ \\frac{\\lambda^y \\exp{(-\\lambda)}}{y!} \\right] \\\\\n&= \\exp{(-\\lambda)} \\sum_{y = 1}^{\\infty} \\frac{y \\lambda^y}{y!} \\\\\n& \\quad \\qquad \\text{factoring out $\\exp{(-\\lambda)}$,} \\\\\n& \\quad \\qquad \\text{since it does not depend on $y$} \\\\\n&= \\exp{(-\\lambda)} \\sum_{y = 1}^{\\infty} \\frac{y \\lambda^y}{y (y - 1)!} \\\\\n& \\quad \\qquad \\text{in the denominator, $y! = y (y - 1)!$}\\\\\n&= \\exp{(-\\lambda)} \\sum_{y = 1}^{\\infty} \\frac{\\lambda^y}{(y - 1)!} \\\\\n&= \\exp{(-\\lambda)} \\sum_{y = 1}^{\\infty} \\frac{\\lambda^{y + 1 - 1}}{(y - 1)!} \\\\\n& \\quad \\qquad \\text{note $\\lambda^y = \\lambda^{y + 1 - 1}$} \\\\\n&= \\exp{(-\\lambda)} \\sum_{y = 1}^{\\infty} \\frac{\\lambda \\lambda^{y - 1}}{(y - 1)!} \\\\\n& \\quad \\qquad \\text{rearranging terms} \\\\\n&= \\lambda \\exp{(-\\lambda)} \\sum_{y = 1}^{\\infty} \\frac{\\lambda^{y - 1}}{(y - 1)!} \\\\\n& \\quad \\qquad \\text{factoring out $\\lambda$,} \\\\\n& \\quad \\qquad \\text{since it does not depend on $y$.}\n\\end{align*}\n\\tag{D.34}\\]\nThen, let us make the following variable rearrangement:\n\\[\nz = y - 1.\n\\]\nGoing back to Equation D.34, and applying our above variable rearrangement within the summation, we have:\n\\[\n\\mathbb{E}(Y) = \\lambda \\exp{(-\\lambda)} \\sum_{z = 0}^{\\infty} \\frac{\\lambda^z}{z!}\n\\tag{D.35}\\]\nUsing Equation D.32, let:\n\\[\n\\begin{gather*}\n\\lambda = u \\\\\nz = j.\n\\end{gather*}\n\\]\nHence, we have the following:\n\\[\n\\sum_{z = 0}^{\\infty} \\frac{\\lambda^z}{z!} = \\exp{(\\lambda)}.\n\\]\nFinally, going back to Equation D.35:\n\\[\n\\begin{align*}\n\\mathbb{E}(Y) &= \\lambda \\exp{(-\\lambda)} \\overbrace{\\sum_{z = 0}^{\\infty} \\frac{\\lambda^z}{z!}}^{\\exp{(\\lambda)}} \\\\\n&= \\lambda \\exp{(-\\lambda)} \\times \\exp{(\\lambda)} \\\\\n&= \\lambda \\exp{(-\\lambda + \\lambda)} \\\\\n&= \\lambda \\exp{(0)} \\\\\n&= \\lambda. \\qquad \\qquad \\qquad \\qquad \\square\n\\end{align*}\n\\]\n\n\nD.4.3 Variance\nVia Equation C.5 and the Equation C.3 of a discrete expected value, the variance of a Poisson-distributed random variable \\(Y\\) can be found as follows:\n\nProof. \\[\n\\begin{align*}\n\\text{Var} (Y) &= \\mathbb{E} \\left( Y^2 \\right) - \\left[ \\mathbb{E}(Y)\\right]^2 \\\\\n&= \\mathbb{E} \\left( Y^2 \\right) - \\lambda^2 \\qquad \\text{since $\\mathbb{E}(Y) = \\lambda$.}\n\\end{align*}\n\\tag{D.36}\\]\nNow, we need to play around with the below expected value expression as follows:\n\\[\n\\begin{align*}\n\\mathbb{E} \\left( Y^2 \\right) &= \\mathbb{E} \\left[ Y (Y - 1) \\right] + \\mathbb{E}(Y) \\\\\n&= \\mathbb{E} \\left[ Y (Y - 1) \\right] + \\lambda \\qquad \\text{since $\\mathbb{E}(Y) = \\lambda$.}\n\\end{align*}\n\\tag{D.37}\\]\nNow, to find \\(\\mathbb{E} \\left[ Y (Y - 1) \\right]\\), we make the following derivation via the LOTUS from Equation C.1 when \\(g(Y) = y (y - 1)\\):\n\\[\n\\begin{align*}\n\\mathbb{E} \\left[ Y (Y - 1) \\right] &= \\sum_{y = 0}^{\\infty} y (y - 1) P_Y \\left( Y = y \\mid \\lambda \\right) \\\\\n&= \\sum_{y = 2}^{\\infty} y (y - 1) P_Y \\left( Y = y \\mid \\lambda \\right) \\\\\n& \\quad \\qquad \\text{for $y = \\{0, 1\\}$,} \\\\\n& \\quad \\qquad \\text{the addends are equal to zero} \\\\\n&= \\sum_{y = 2}^{\\infty} y (y - 1) \\left[ \\frac{\\lambda^y \\exp{(-\\lambda)}}{y!} \\right] \\\\\n&= \\exp{(-\\lambda)} \\sum_{y = 2}^{\\infty} \\left[ \\frac{y (y - 1) \\lambda^y}{y!} \\right] \\\\\n& \\quad \\qquad \\text{factoring out $\\exp{(-\\lambda)}$,} \\\\\n& \\quad \\qquad \\text{since it does not depend on $y$} \\\\\n&= \\exp{(-\\lambda)} \\sum_{y = 2}^{\\infty} \\left[ \\frac{y (y - 1) \\lambda^y}{y (y - 1) (y - 2)!} \\right] \\\\\n& \\quad \\qquad \\text{in the denominator, $y! = y (y - 1) (y - 2)!$} \\\\\n&= \\exp{(-\\lambda)} \\sum_{y = 2}^{\\infty} \\frac{\\lambda^y}{(y - 2)!} \\\\\n&= \\exp{(-\\lambda)} \\sum_{y = 2}^{\\infty} \\frac{\\lambda^{y + 2 - 2}}{(y - 2)!} \\\\\n& \\quad \\qquad \\text{note $\\lambda^y = \\lambda^{y + 2 - 2} $} \\\\\n&= \\lambda^2 \\exp{(-\\lambda)} \\sum_{y = 2}^{\\infty} \\frac{\\lambda^{y - 2}}{(y - 2)!} \\\\\n& \\quad \\qquad \\text{factoring out $\\lambda^2$,} \\\\\n& \\quad \\qquad \\text{since it does not depend on $y$.} \\\\\n\\end{align*}\n\\tag{D.38}\\]\nThen, we make the following variable rearrangement:\n\\[\nz = y - 2.\n\\]\nGoing back to Equation D.38, and applying our above variable rearrangement within the summation, we have:\n\\[\n\\mathbb{E} \\left[ Y (Y - 1) \\right] = \\lambda^2 \\exp{(-\\lambda)} \\sum_{z = 0}^{\\infty} \\frac{\\lambda^z}{z!}.\n\\tag{D.39}\\]\nUsing Equation D.32, let:\n\\[\n\\begin{gather*}\n\\lambda = u \\\\\nz = j.\n\\end{gather*}\n\\]\nThus, we have the following:\n\\[\n\\sum_{z = 0}^{\\infty} \\frac{\\lambda^z}{z!} = \\exp{(\\lambda)}.\n\\]\nGoing back to Equation D.39:\n\\[\n\\begin{align*}\n\\mathbb{E} \\left[ Y (Y - 1) \\right] &= \\lambda^2 \\exp{(-\\lambda)} \\overbrace{\\sum_{z = 0}^{\\infty} \\frac{\\lambda^z}{z!}}^{\\exp{(\\lambda)}} \\\\\n&= \\lambda^2 \\exp{(-\\lambda)} \\times \\exp{\\lambda} \\\\\n&= \\lambda^2 \\exp{(-\\lambda + \\lambda)} \\\\\n&= \\lambda^2 \\exp{(0)} \\\\\n&= \\lambda^2.\n\\end{align*}\n\\tag{D.40}\\]\nLet us retake Equation D.37 and plug in the above result:\n\\[\n\\begin{align*}\n\\mathbb{E} \\left( Y^2 \\right) &= \\mathbb{E} \\left[ Y (Y - 1) \\right] + \\lambda \\\\\n&= \\lambda^2 + \\lambda. \\\\\n\\end{align*}\n\\]\nFinally, we plug in \\(\\mathbb{E} \\left( Y^2 \\right)\\) in Equation D.36:\n\\[\n\\begin{align*}\n\\text{Var} (Y) &= \\mathbb{E} \\left( Y^2 \\right) - \\lambda^2 \\\\\n&= \\lambda^2 + \\lambda - \\lambda^2 \\\\\n&= \\lambda. \\qquad \\qquad \\square\n\\end{align*}\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#sec-generalized-poisson-distribution",
    "href": "book/C-distributional-mind-map.html#sec-generalized-poisson-distribution",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nD.5 Generalized Poisson",
    "text": "D.5 Generalized Poisson\nThe generalized Poisson (GP) distribution is viewed as the general Poisson case. It was introduced by Consul and Jain (1973). Suppose you observe the count of events happening in a fixed interval of time or space. Let \\(Y\\) be the number of counts considered of integer type. Then, \\(Y\\) is said to have a GP distribution with continuous parameters \\(\\lambda\\) and \\(\\theta\\):\n\\[\nY \\sim \\text{GP}(\\lambda, \\theta).\n\\]\n\nD.5.1 Probability Mass Function\nThe PMF of this count-type \\(Y\\) is the following:\n\\[\n\\begin{align*}\nP_Y \\left( Y = y \\mid \\lambda, \\theta \\right) &= \\frac{\\lambda (\\lambda + y \\theta)^{y - 1} \\exp{\\left[ -(\\lambda + y \\theta) \\right]}}{y!} \\\\\n& \\qquad \\qquad \\qquad \\text{for $y \\in \\{ 0, 1, 2, \\dots\\}$,}\n\\end{align*}\n\\tag{D.41}\\]\nwhere \\(\\exp{(\\cdot)}\\) depicts the base \\(e\\) (i.e., Euler’s number, \\(e = 2.71828...\\)) and \\(y!\\) is the factorial\n\\[\ny! = y \\times (y - 1) \\times (y - 2) \\times (y - 3) \\times \\cdots \\times 3 \\times 2 \\times 1.  \n\\]\nwith\n\\[\n0! = 1.\n\\]\nThe continuous parameter \\(\\lambda \\in (0, \\infty)\\) represents the average rate at which these events happen (i.e., events per area unit or events per time unit). As in the case of the classical Poisson case, even though the GP random variable \\(Y\\) is considered discrete, \\(\\lambda\\) is modelled as continuous!\nOn the other hand, the continuous and bounded parameter \\(\\theta \\in (-1, 1)\\) controls for dispersion present in the GP random variable Y as follows:\n\nWhen \\(0 &lt; \\theta &lt; 1\\), the GP \\(Y\\) shows overdispersion which implies that \\[\\text{Var}(Y) &gt; \\mathbb{E}(Y).\\]\nWhen \\(-1 &lt; \\theta &lt; 0\\), the GP \\(Y\\) shows underdispersion which implies that \\[\\text{Var}(Y) &lt; \\mathbb{E}(Y).\\]\nWhen \\(\\theta = 0\\), the PMF of the GP \\(Y\\) in Equation D.41 becomes the classical Poisson PMF from Equation D.27: \\[\n\\begin{align*}\nP_Y \\left( Y = y \\mid \\lambda, \\theta = 0 \\right) &= \\frac{\\lambda (\\lambda + y \\theta)^{y - 1} \\exp{\\left[ -(\\lambda + y \\theta) \\right]}}{y!} \\\\\n&= \\frac{\\lambda (\\lambda)^{y - 1} \\exp{\\left( -\\lambda \\right)}}{y!} \\qquad \\text{setting $\\theta = 0$} \\\\\n&= \\frac{\\lambda^y \\exp{\\left( -\\lambda \\right)}}{y!} \\\\\n& \\qquad \\qquad \\qquad \\text{for $y \\in \\{ 0, 1, 2, \\dots\\}$.}\n\\end{align*}\n\\]\n\n\n\nHeads-up on equidispersion in a generalized Poisson random variable!\n\n\nIn a GP-distributed \\(Y\\), when \\(\\theta = 0\\) in its corresponding PMF, we have equidispersion which implies \\[\n\\mathbb{E}(Y \\mid \\theta = 0) = \\frac{\\lambda}{1 - \\theta} = \\lambda\n\\] \\[\n\\text{Var}(Y \\mid \\theta = 0) = \\frac{\\lambda}{(1 - \\theta)^2} = \\lambda\n\\] \\[\n\\mathbb{E}(Y \\mid \\theta = 0) = \\text{Var}(Y).\n\\]\n\n\n\nHow can we verify that Equation D.41 is a proper PMF (i.e., all the standalone probabilities over the support of \\(Y\\) add up to one)?\n\n\nD.5.2 Expected Value\n\nD.5.3 Variance",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#sec-zero-inflated-poisson-distribution",
    "href": "book/C-distributional-mind-map.html#sec-zero-inflated-poisson-distribution",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nD.6 Zero-inflated Poisson",
    "text": "D.6 Zero-inflated Poisson",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#sec-multinomial-distribution",
    "href": "book/C-distributional-mind-map.html#sec-multinomial-distribution",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nD.7 Multinomial",
    "text": "D.7 Multinomial",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#sec-weibull-distribution",
    "href": "book/C-distributional-mind-map.html#sec-weibull-distribution",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nE.1 Weibull",
    "text": "E.1 Weibull\nSuppose you observe the waiting times for some event of interest to happen (i.e., survival times). Let random variable \\(Y\\) be considered continuous and nonnegative. Then, \\(Y\\) is said to have a Weibull distribution with the following scale continuous parameter \\(\\beta\\) and shape continuous parameter \\(\\gamma\\):\n\\[\nY \\sim \\text{Weibull}(\\beta, \\gamma).\n\\]\n\nE.1.1 Probability Density Function\nThe PDF of \\(Y\\) is the following:\n\\[\nf_Y \\left(y \\mid \\beta, \\gamma \\right) = \\frac{\\gamma}{\\beta} \\left( \\frac{y}{\\beta} \\right)^{\\gamma - 1} \\exp{\\left[ -\\left( \\frac{y}{\\beta} \\right)^{\\gamma} \\right]} \\quad \\text{for $y \\in [0, \\infty )$.}\n\\tag{E.1}\\]\nParameters \\(\\beta \\in (0, \\infty)\\) and \\(\\gamma \\in (0, \\infty)\\) refer to the random process’ scale and shape, respectively. Figure E.1 shows nine members of the Weibull parametric family, i.e., nine different PDFs with all possible pairwise combinations for three different scale parameters \\(\\beta = 0.5, 1, 2\\) and shape parameters \\(\\gamma = 1.5, 3, 6\\). We can highlight the following:\n\nRegardless of the shape parameter \\(\\gamma\\), as we increase the scale parameter \\(\\beta\\), note that there is more spread in the corresponding distributions.\nRegardless of the scale parameter \\(\\beta\\), as we increase the shape parameter \\(\\gamma\\), note the peak of the distribution moves more to the right.\n\n\n\n\n\n\n\n\nFigure E.1: Some members of the Weibull parametric family.\n\n\n\n\n\n\nHeads-up on the Weibull and Exponential distributions in survival analysis!\n\n\nThe Weibull distribution extends its Exponential counterpart (as in Section E.3) by allowing the event rate (or hazard) to change over time, rather than staying constant. This makes it especially useful in survival analysis and reliability studies, where capturing how the risk of an event evolves is critical.\nAs a side note, the Weibull and Exponential PDFs are mathematically related. When \\(\\gamma = 1\\) in Equation E.1, the Weibull PDF is equal to the Exponential PDF under the scale parametrization as in Equation E.11:\n\\[\n\\begin{align*}\nf_Y \\left(y \\mid \\beta, \\gamma = 1 \\right) &= \\frac{\\gamma}{\\beta} \\left( \\frac{y}{\\beta} \\right)^{\\gamma - 1} \\exp{\\left[ -\\left( \\frac{y}{\\beta} \\right)^{\\gamma} \\right]} \\\\\n&= \\frac{1}{\\beta} \\underbrace{\\left( \\frac{y}{\\beta} \\right)^0}_{1} \\exp{\\left( -\\frac{y}{\\beta} \\right)} \\\\\n&= \\frac{1}{\\beta} \\exp{\\left( -\\frac{y}{\\beta} \\right)} \\quad \\text{for $y \\in [0, \\infty )$}.\n\\end{align*}\n\\]\n\n\n\nHow can we verify that Equation E.1 is a proper PDF (i.e., Equation E.1 integrates to one over the support of \\(Y\\))?\n\n\nProof. \\[\n\\begin{align*}\n\\int_{y = 0}^{y = \\infty} f_Y \\left(y \\mid \\beta, \\gamma \\right) \\mathrm{d}y &= \\int_{y = 0}^{y = \\infty} \\frac{\\gamma}{\\beta} \\left( \\frac{y}{\\beta} \\right)^{\\gamma - 1} \\exp{\\left[ -\\left( \\frac{y}{\\beta} \\right)^{\\gamma} \\right]} \\mathrm{d}y.\n\\end{align*}\n\\tag{E.2}\\]\nNow, let us make the variable substitution:\n\\[\n\\begin{gather*}\nu = \\left( \\frac{y}{\\beta} \\right)^{\\gamma} \\\\\ny = \\beta u^{\\frac{1}{\\gamma}} \\\\\n\\mathrm{d}y = \\frac{\\beta}{\\gamma} u^{\\frac{1}{\\gamma} - 1} \\mathrm{d}u.\n\\end{gather*}\n\\]\nThe above rearrangemet yields the following in Equation E.2:\n\\[\n\\begin{align*}\n\\int_{y = 0}^{y = \\infty} f_Y \\left(y \\mid \\beta, \\gamma \\right) \\mathrm{d}y &= \\int_{u = 0}^{u = \\infty} \\frac{\\gamma}{\\beta} \\left( \\frac{\\beta u^{\\frac{1}{\\gamma}}}{\\beta} \\right)^{\\gamma - 1} \\exp{\\left( -u \\right)} \\frac{\\beta}{\\gamma} u^{\\frac{1}{\\gamma} - 1} \\mathrm{d}u \\\\\n&= \\int_{u = 0}^{u = \\infty} \\left( u^{\\frac{1}{\\gamma}} \\right)^{\\gamma - 1} \\exp{\\left( -u \\right)} u^{\\frac{1}{\\gamma} - 1} \\mathrm{d}u \\\\\n&= \\int_{u = 0}^{u = \\infty} u^{\\frac{\\gamma - 1}{\\gamma}} \\exp{\\left( -u \\right)} u^{\\frac{1}{\\gamma} - 1} \\mathrm{d}u \\\\\n&= \\int_{u = 0}^{u = \\infty} u^{\\frac{\\gamma - 1}{\\gamma} + \\frac{1}{\\gamma} - 1} \\exp{\\left( -u \\right)} \\mathrm{d}u \\\\\n&= \\int_{u = 0}^{u = \\infty} u^{1 - \\frac{1}{\\gamma} + \\frac{1}{\\gamma} - 1} \\exp{\\left( -u \\right)} \\mathrm{d}u \\\\\n&= \\int_{u = 0}^{u = \\infty} u^0 \\exp{\\left( -u \\right)} \\mathrm{d}u \\\\\n&= \\int_{u = 0}^{u = \\infty} \\exp{\\left( -u \\right)} \\mathrm{d}u \\\\\n&= -\\exp{\\left( -u \\right)} \\Bigg|_{u = 0}^{u = \\infty} \\\\\n&= - \\left[ \\exp \\left( -\\infty \\right) - \\exp \\left( 0 \\right) \\right] \\\\\n&= - \\left( 0 - 1 \\right) \\\\\n&= 1. \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\square\n\\end{align*}\n\\]\n\nIndeed, the Weibull PDF is a proper probability distribution!\n\n\n\nE.1.2 Expected Value\nVia Equation C.4, the expected value or mean of a Weibull-distributed random variable \\(Y\\) can be found as follows:\n\nProof. \\[\n\\begin{align*}\n\\mathbb{E}(Y) &= \\int_{y = 0}^{y = \\infty} y f_Y \\left(y \\mid \\beta, \\gamma \\right) \\mathrm{d}y \\\\\n&= \\int_{y = 0}^{y = \\infty} y \\frac{\\gamma}{\\beta} \\left( \\frac{y}{\\beta} \\right)^{\\gamma - 1} \\exp{\\left[ -\\left( \\frac{y}{\\beta} \\right)^{\\gamma} \\right]} \\mathrm{d}y \\\\\n&= \\frac{\\gamma}{\\beta} \\int_{y = 0}^{y = \\infty} y \\left( \\frac{y}{\\beta} \\right)^{\\gamma - 1} \\exp{\\left[ -\\left( \\frac{y}{\\beta} \\right)^{\\gamma} \\right]} \\mathrm{d}y \\\\\n&= \\frac{\\gamma}{\\beta} \\int_{y = 0}^{y = \\infty} y \\frac{y^{\\gamma - 1}}{\\beta^{\\gamma - 1}} \\exp{\\left[ -\\left( \\frac{y}{\\beta} \\right)^{\\gamma} \\right]} \\mathrm{d}y \\\\\n&= \\frac{\\gamma}{\\beta} \\int_{y = 0}^{y = \\infty} \\frac{y^{\\gamma}}{\\beta^{\\gamma - 1}} \\exp{\\left[ -\\left( \\frac{y}{\\beta} \\right)^{\\gamma} \\right]} \\mathrm{d}y \\\\\n&= \\frac{\\gamma}{\\beta^{\\gamma}} \\int_{y = 0}^{y = \\infty} y^{\\gamma} \\exp{\\left[ -\\left( \\frac{y}{\\beta} \\right)^{\\gamma} \\right]} \\mathrm{d}y.\n\\end{align*}\n\\tag{E.3}\\]\nThen, we make the following variable substitution:\n\\[\n\\begin{gather*}\nu = \\left( \\frac{y}{\\beta} \\right)^{\\gamma} \\\\\ny = \\beta u^{\\frac{1}{\\gamma}} \\\\\n\\mathrm{d}y = \\frac{\\beta}{\\gamma} u^{\\frac{1}{\\gamma} - 1} \\mathrm{d}u.\n\\end{gather*}\n\\]\nThe above rearrangemet yields the following in Equation E.3:\n\\[\n\\begin{align*}\n\\mathbb{E}(Y) &= \\frac{\\gamma}{\\beta^{\\gamma}} \\int_{u = 0}^{u = \\infty} \\left( \\beta u^{\\frac{1}{\\gamma}} \\right)^{\\gamma} \\exp{\\left( -u \\right)} \\frac{\\beta}{\\gamma} u^{\\frac{1}{\\gamma} - 1} \\mathrm{d}u \\\\\n&= \\frac{\\gamma}{\\beta^{\\gamma}} \\int_{u = 0}^{u = \\infty} \\beta^{\\gamma} u \\exp{\\left( -u \\right)} \\frac{\\beta}{\\gamma} u^{\\frac{1}{\\gamma} - 1} \\mathrm{d}u \\\\\n&= \\frac{\\gamma \\beta^{\\gamma} \\beta}{\\beta^{\\gamma} \\gamma} \\int_{u = 0}^{u = \\infty} u \\exp{\\left( -u \\right)} u^{\\frac{1}{\\gamma} - 1} \\mathrm{d}u \\\\\n&= \\beta \\int_{u = 0}^{u = \\infty} u^{\\frac{1}{\\gamma}} \\exp{\\left( -u \\right)} \\mathrm{d}u \\\\\n&= \\beta \\int_{u = 0}^{u = \\infty} u^{\\left( \\frac{1}{\\gamma} + 1 \\right) - 1} \\exp{\\left( -u \\right)} \\mathrm{d}u \\\\\n& \\quad \\qquad \\text{note $\\frac{1}{\\gamma} = \\left( \\frac{1}{\\gamma} + 1 \\right) - 1$.}\n\\end{align*}\n\\tag{E.4}\\]\nThe integral on the right-hand side of Equation E.4 corresponds to the so-called Gamma function as described below.\n\n\nHeads-up on the Gamma function!\n\n\nThe Gamma function is a mathematical generalization of the factorial function, but applied to non-integer numbers. In many different probability distributions, this function appears as a normalizing constant. Moreover, it also appears as part of the expressions of expected values and variances.\nThat said, for a variable \\(z\\) in general, we can represent the Gamma function via the following integral:\n\\[\n\\Gamma(z) = \\int_{t = 0}^{t = \\infty} t^{z - 1} \\exp{\\left( -t \\right)} \\mathrm{d}t.\n\\tag{E.5}\\]\nWeisstein (n.d.a) provides further insights on this Gamma function along with some useful properties.\n\n\nThus, via the Gamma function from Equation E.5, we set the following:\n\\[\n\\begin{gather*}\nt = u \\\\\nz = \\frac{1}{\\gamma} + 1,\n\\end{gather*}\n\\]\nwhich yields\n\\[\n\\Gamma \\left( \\frac{1}{\\gamma} + 1 \\right) = \\int_{u = 0}^{u = \\infty} u^{\\left( \\frac{1}{\\gamma} + 1 \\right) - 1} \\exp{\\left( -u \\right)} \\mathrm{d}u.\n\\]\nMoving along with Equation E.4, we have:\n\\[\n\\begin{align*}\n\\mathbb{E}(Y) &= \\beta \\int_{u = 0}^{u = \\infty} u^{\\left( \\frac{1}{\\gamma} + 1 \\right) - 1} \\exp{\\left( -u \\right)} \\mathrm{d}u \\\\\n&= \\beta \\Gamma \\left( \\frac{1}{\\gamma} + 1 \\right). \\qquad \\qquad \\qquad \\quad \\square\n\\end{align*}\n\\]\n\n\nE.1.3 Variance\nVia Equation C.5 and the Equation C.4 of a continuous expected value, the variance of a Weibull-distributed random variable \\(Y\\) can be found as follows:\n\nProof. \\[\n\\begin{align*}\n\\text{Var} (Y) &= \\mathbb{E} \\left( Y^2 \\right) - \\left[ \\mathbb{E}(Y)\\right]^2 \\\\\n&= \\mathbb{E} \\left( Y^2 \\right) - \\beta^2 \\Gamma^2 \\left( \\frac{1}{\\gamma} + 1 \\right) \\\\\n& \\quad \\qquad \\text{since $\\mathbb{E}(Y) = \\beta \\Gamma \\left( \\frac{1}{\\gamma} + 1 \\right)$}.\n\\end{align*}\n\\tag{E.6}\\]\nNow, we need to find \\(\\mathbb{E} \\left( Y^2 \\right)\\) from Equation E.6. Thus, we make the following derivation via the LOTUS from Equation C.2 when \\(g(Y) = y^2\\):\n\\[\n\\begin{align*}\n\\mathbb{E} \\left( Y^2 \\right) &= \\int_{y = 0}^{y = \\infty} y^2 f_Y \\left(y \\mid \\beta, \\gamma \\right) \\mathrm{d}y \\\\\n&= \\int_{y = 0}^{y = \\infty} y^2 \\frac{\\gamma}{\\beta} \\left( \\frac{y}{\\beta} \\right)^{\\gamma - 1} \\exp{\\left[ -\\left( \\frac{y}{\\beta} \\right)^{\\gamma} \\right]} \\mathrm{d}y \\\\\n&= \\frac{\\gamma}{\\beta} \\int_{y = 0}^{y = \\infty} y^2 \\left( \\frac{y}{\\beta} \\right)^{\\gamma - 1} \\exp{\\left[ -\\left( \\frac{y}{\\beta} \\right)^{\\gamma} \\right]} \\mathrm{d}y \\\\\n&= \\frac{\\gamma}{\\beta} \\int_{y = 0}^{y = \\infty} y^2 \\frac{y^{\\gamma - 1}}{\\beta^{\\gamma - 1}} \\exp{\\left[ -\\left( \\frac{y}{\\beta} \\right)^{\\gamma} \\right]} \\mathrm{d}y \\\\\n&= \\frac{\\gamma}{\\beta^{\\gamma}} \\int_{y = 0}^{y = \\infty} y^{\\gamma + 1} \\exp{\\left[ -\\left( \\frac{y}{\\beta} \\right)^{\\gamma} \\right]} \\mathrm{d}y.\n\\end{align*}\n\\tag{E.7}\\]\nThen, we make the following variable substitution:\n\\[\n\\begin{gather*}\nu = \\left( \\frac{y}{\\beta} \\right)^{\\gamma} \\\\\ny = \\beta u^{\\frac{1}{\\gamma}} \\\\\n\\mathrm{d}y = \\frac{\\beta}{\\gamma} u^{\\frac{1}{\\gamma} - 1} \\mathrm{d}u.\n\\end{gather*}\n\\]\nThe above rearrangemet yields the following in Equation E.7:\n\\[\n\\begin{align*}\n\\mathbb{E} \\left( Y^2 \\right) &= \\frac{\\gamma}{\\beta^{\\gamma}} \\int_{u = 0}^{u = \\infty} \\left( \\beta u^{\\frac{1}{\\gamma}} \\right)^{\\gamma + 1} \\exp{\\left( -u \\right)} \\frac{\\beta}{\\gamma} u^{\\frac{1}{\\gamma} - 1} \\mathrm{d}u \\\\\n&= \\frac{\\gamma}{\\beta^{\\gamma}} \\int_{u = 0}^{u = \\infty} \\beta^{\\gamma + 1} u^{1 + \\frac{1}{\\gamma}} \\exp{\\left( -u \\right)} \\frac{\\beta}{\\gamma} u^{\\frac{1}{\\gamma} - 1} \\mathrm{d}u \\\\\n&= \\frac{\\gamma \\beta^{\\gamma + 1} \\beta}{\\beta^{\\gamma} \\gamma} \\int_{u = 0}^{u = \\infty} u^{1 + \\frac{1}{\\gamma}} \\exp{\\left( -u \\right)} u^{\\frac{1}{\\gamma} - 1} \\mathrm{d}u \\\\\n&= \\beta^2 \\int_{u = 0}^{u = \\infty} u^{1 + \\frac{1}{\\gamma} + \\frac{1}{\\gamma} - 1} \\exp{\\left( -u \\right)} \\mathrm{d}u \\\\\n&= \\beta^2 \\int_{u = 0}^{u = \\infty} u^{\\left( \\frac{2}{\\gamma} + 1 \\right) - 1} \\exp{\\left( -u \\right)} \\mathrm{d}u.\n\\end{align*}\n\\tag{E.8}\\]\nHence, via the Gamma function from Equation E.5, we set the following:\n\\[\n\\begin{gather*}\nt = u \\\\\nz = \\frac{2}{\\gamma} + 1,\n\\end{gather*}\n\\]\nwhich yields\n\\[\n\\Gamma \\left( \\frac{2}{\\gamma} + 1 \\right) = \\int_{u = 0}^{u = \\infty} u^{\\left( \\frac{2}{\\gamma} + 1 \\right) - 1} \\exp{\\left( -u \\right)} \\mathrm{d}u.\n\\]\nMoving along with Equation E.8, we have:\n\\[\n\\begin{align*}\n\\mathbb{E} \\left( Y^2 \\right) &= \\beta^2 \\int_{u = 0}^{u = \\infty} u^{\\left( \\frac{2}{\\gamma} + 1 \\right) - 1} \\exp{\\left( -u \\right)} \\mathrm{d}u \\\\\n&= \\beta^2 \\Gamma \\left( \\frac{2}{\\gamma} + 1 \\right).\n\\end{align*}\n\\tag{E.9}\\]\nFinally, we plug Equation E.9 into Equation E.6:\n\\[\n\\begin{align*}\n\\text{Var} (Y) &= \\mathbb{E}\\left( Y^2 \\right) - \\beta^2 \\Gamma^2 \\left( \\frac{1}{\\gamma} + 1 \\right) \\\\\n&= \\beta^2 \\Gamma \\left( \\frac{2}{\\gamma} + 1 \\right) - \\beta^2 \\Gamma^2 \\left( \\frac{1}{\\gamma} + 1 \\right) \\\\\n&= \\beta^2 \\left[  \\Gamma \\left( \\frac{2}{\\gamma} + 1 \\right) - \\Gamma^2 \\left( \\frac{1}{\\gamma} + 1 \\right) \\right]. \\qquad \\qquad \\square\n\\end{align*}\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#sec-lognormal-distribution",
    "href": "book/C-distributional-mind-map.html#sec-lognormal-distribution",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nE.2 Lognormal",
    "text": "E.2 Lognormal",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#sec-exponential-distribution",
    "href": "book/C-distributional-mind-map.html#sec-exponential-distribution",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nE.3 Exponential",
    "text": "E.3 Exponential\nSuppose you observe the waiting times for some event of interest to happen (i.e., survival times). Let random variable \\(Y\\) be considered continuous and nonnegative. Then, \\(Y\\) is said to have an Exponential distribution with the following rate continuous parameter \\(\\lambda\\):\n\\[\nY \\sim \\text{Exponential}(\\lambda).\n\\]\nWe can also model \\(Y\\) with the following scale continuous parameter \\(\\beta\\):\n\\[\nY \\sim \\text{Exponential}(\\beta).\n\\]\n\nE.3.1 Probability Density Functions\nGiven the two above parametrizations of the Exponential distribution, there are two possible PDFs as discussed below.\nRate Parametrization\nThe PDF of \\(Y\\) is the following:\n\\[\nf_Y \\left(y \\mid \\lambda \\right) = \\lambda \\exp \\left( -\\lambda y \\right) \\quad \\text{for $y \\in [0, \\infty )$.}\n\\tag{E.10}\\]\nParameter \\(\\lambda \\in (0, \\infty)\\) refers to the random process’ rate. Figure E.2 shows three members of the Exponential parametric family, i.e., three different PDFs with different rate parameters \\(\\lambda = 0.25, 0.5, 1\\). As we increase the rate parameter, note that smaller observed values \\(y\\) get more probable.\n\n\n\n\n\n\n\nFigure E.2: Some members of the Exponential parametric family with rate parametrization.\n\n\n\n\n\nHow can we verify that Equation E.10 is a proper PDF (i.e., Equation E.10 integrates to one over the support of \\(Y\\))?\n\n\nProof. \\[\n\\begin{align*}\n\\int_{y = 0}^{y = \\infty} f_Y \\left(y \\mid \\lambda \\right) \\mathrm{d}y &= \\int_{y = 0}^{y = \\infty} \\lambda \\exp \\left( -\\lambda y \\right) \\mathrm{d}y \\\\\n&= \\lambda \\int_{y = 0}^{y = \\infty} \\exp \\left( -\\lambda y \\right) \\mathrm{d}y \\\\\n&= - \\frac{\\lambda}{\\lambda} \\exp \\left( -\\lambda y \\right) \\Bigg|_{y = 0}^{y = \\infty} \\\\\n&= - \\exp \\left( -\\lambda y \\right) \\Bigg|_{y = 0}^{y = \\infty} \\\\\n&= - \\left[ \\exp \\left( -\\infty \\right) - \\exp \\left( 0 \\right) \\right] \\\\\n&= - \\left( 0 - 1 \\right) \\\\\n&= 1. \\qquad \\qquad \\qquad \\qquad \\quad \\square\n\\end{align*}\n\\]\n\nIndeed, the Exponential PDF, under a rate parametrization, is a proper probability distribution!\n\n\nScale Parametrization\nThe PDF of \\(Y\\) is the following:\n\\[\nf_Y \\left(y \\mid \\beta \\right) = \\frac{1}{\\beta} \\exp \\left( -\\frac{y}{\\beta} \\right) \\quad \\text{for $y \\in [0, \\infty )$.}\n\\tag{E.11}\\]\nParameter \\(\\beta \\in (0, \\infty)\\) refers to the random process’ scale. Figure E.3 shows three members of the Exponential parametric family, i.e., three different PDFs with different scale parameters \\(\\beta = 0.25, 0.5, 1\\). As we increase the scale parameter, note that larger observed values \\(y\\) get more probable.\n\n\n\n\n\n\n\nFigure E.3: Some members of the Exponential parametric family with scale parametrization.\n\n\n\n\n\nHow can we verify that Equation E.11 is a proper PDF (i.e., Equation E.11 integrates to one over the support of \\(Y\\))?\n\n\nProof. \\[\n\\begin{align*}\n\\int_{y = 0}^{y = \\infty} f_Y \\left(y \\mid \\beta \\right) \\mathrm{d}y &= \\int_{y = 0}^{y = \\infty} \\frac{1}{\\beta} \\exp \\left( -\\frac{y}{\\beta} \\right) \\mathrm{d}y \\\\\n&= \\frac{1}{\\beta} \\int_{y = 0}^{y = \\infty} \\exp \\left( -\\frac{y}{\\beta} \\right) \\mathrm{d}y \\\\\n&= - \\frac{\\beta}{\\beta} \\exp \\left( -\\frac{y}{\\beta} \\right) \\Bigg|_{y = 0}^{y = \\infty} \\\\\n&= - \\exp \\left( -\\frac{y}{\\beta} \\right) \\Bigg|_{y = 0}^{y = \\infty} \\\\\n&= - \\left[ \\exp \\left( -\\infty \\right) - \\exp \\left( 0 \\right) \\right] \\\\\n&= - \\left( 0 - 1 \\right) \\\\\n&= 1. \\qquad \\qquad \\qquad \\qquad \\quad \\square\n\\end{align*}\n\\]\n\nIndeed, the Exponential PDF, under a scale parametrization, is a proper probability distribution!\n\n\n\nE.3.2 Expected Value\nAgain, given the two above parametrizations of the Exponential distribution, there are two possible mathematical expressions for the expected value as discussed below.\nRate Parametrization\nVia Equation C.4, the expected value or mean of an Exponential-distributed random variable \\(Y\\) can be found as follows:\n\nProof. \\[\n\\begin{align*}\n\\mathbb{E}(Y) &= \\int_{y = 0}^{y = \\infty} y f_Y \\left(y \\mid \\lambda \\right) \\mathrm{d}y \\\\\n&= \\int_{y = 0}^{y = \\infty} y \\lambda \\exp \\left( -\\lambda y \\right) \\mathrm{d}y \\\\\n&= \\lambda \\int_{y = 0}^{y = \\infty} y \\exp \\left( -\\lambda y \\right) \\mathrm{d}y. \\\\\n\\end{align*}\n\\tag{E.12}\\]\nEquation E.12 cannot be solved straightforwardly, we need to use integration by parts as follows:\n\\[\n\\begin{equation}\n  \\begin{split}\n    u &= y \\\\\n    \\mathrm{d}u &= \\mathrm{d}y\n  \\end{split}\n\\qquad \\qquad\n  \\begin{split}\n    \\mathrm{d}v &= \\exp \\left( -\\lambda y \\right) \\mathrm{d}y \\\\\n    v &= -\\frac{1}{\\lambda} \\exp \\left( -\\lambda y \\right),\n  \\end{split}\n\\end{equation}\n\\]\nwhich yields\n\\[\n\\begin{align*}\n\\mathbb{E}(Y) &= \\lambda \\left[ u v \\Bigg|_{y = 0}^{y = \\infty} - \\int_{y = 0}^{y = \\infty} v \\mathrm{d}u \\right] \\\\\n&= \\lambda \\left\\{ \\left[ -\\frac{1}{\\lambda} y \\exp(-\\lambda y) \\right] \\Bigg|_{y = 0}^{y = \\infty} + \\frac{1}{\\lambda} \\int_{y = 0}^{y = \\infty} \\exp{\\left( -\\lambda y \\right)} \\mathrm{d}y \\right\\} \\\\\n&= \\lambda \\Bigg\\{ -\\frac{1}{\\lambda} \\Bigg[ \\underbrace{\\infty \\times \\exp(-\\infty)}_{0} - \\underbrace{0 \\times \\exp(0)}_{0} \\Bigg] - \\\\\n& \\qquad \\frac{1}{\\lambda^2} \\exp{\\left( -\\lambda y \\right)} \\Bigg|_{y = 0}^{y = \\infty} \\Bigg\\} \\\\\n&= \\lambda \\left\\{ -\\frac{1}{\\lambda} (0) - \\frac{1}{\\lambda^2} \\left[ \\exp \\left( -\\infty \\right) - \\exp \\left( 0 \\right) \\right] \\right\\} \\\\\n&= \\lambda \\left[ 0 - \\frac{1}{\\lambda^2} (0 - 1) \\right] \\\\\n&= \\frac{\\lambda}{\\lambda^2} \\\\\n&= \\frac{1}{\\lambda}. \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\quad \\qquad \\qquad \\quad \\qquad \\qquad \\square\n\\end{align*}\n\\]\n\nScale Parametrization\nVia Equation C.4, the expected value or mean of an Exponential-distributed random variable \\(Y\\) can be found as follows:\n\nProof. \\[\n\\begin{align*}\n\\mathbb{E}(Y) &= \\int_{y = 0}^{y = \\infty} y f_Y \\left(y \\mid \\beta \\right) \\mathrm{d}y \\\\\n&= \\int_{y = 0}^{y = \\infty} \\frac{y}{\\beta} \\exp \\left( -\\frac{y}{\\beta} \\right) \\mathrm{d}y \\\\\n&= \\frac{1}{\\beta} \\int_{y = 0}^{y = \\infty} y \\exp \\left( -\\frac{y}{\\beta} \\right) \\mathrm{d}y. \\\\\n\\end{align*}\n\\tag{E.13}\\]\nEquation E.13 cannot be solved straightforwardly, we need to use integration by parts as follows:\n\\[\n\\begin{equation}\n  \\begin{split}\n    u &= y \\\\\n    \\mathrm{d}u &= \\mathrm{d}y\n  \\end{split}\n\\qquad \\qquad\n  \\begin{split}\n    \\mathrm{d}v &= \\exp \\left( -\\frac{y}{\\beta} \\right) \\mathrm{d}y \\\\\n    v &= -\\beta \\exp \\left( -\\frac{y}{\\beta} \\right),\n  \\end{split}\n\\end{equation}\n\\]\nwhich yields\n\\[\n\\begin{align*}\n\\mathbb{E}(Y) &= \\frac{1}{\\beta} \\left[ u v \\Bigg|_{y = 0}^{y = \\infty} - \\int_{y = 0}^{y = \\infty} v \\mathrm{d}u \\right] \\\\\n&= \\frac{1}{\\beta} \\left\\{ \\left[ -\\beta y \\exp \\left( -\\frac{y}{\\beta} \\right) \\right] \\Bigg|_{y = 0}^{y = \\infty} + \\beta \\int_{y = 0}^{y = \\infty} \\exp \\left( -\\frac{y}{\\beta} \\right) \\mathrm{d}y \\right\\} \\\\\n&= \\frac{1}{\\beta} \\Bigg\\{ -\\beta \\Bigg[ \\underbrace{\\infty \\times \\exp(-\\infty)}_{0} - \\underbrace{0 \\times \\exp(0)}_{0} \\Bigg] - \\\\\n& \\qquad \\beta^2 \\exp \\left( -\\frac{y}{\\beta} \\right) \\Bigg|_{y = 0}^{y = \\infty} \\Bigg\\} \\\\\n&= \\frac{1}{\\beta} \\left\\{ -\\beta (0) - \\beta^2 \\left[ \\exp \\left( -\\infty \\right) - \\exp \\left( 0 \\right) \\right] \\right\\} \\\\\n&= \\frac{1}{\\beta} \\left[ 0 - \\beta^2 (0 - 1) \\right] \\\\\n&= \\frac{\\beta^2}{\\beta} \\\\\n&= \\beta. \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\quad \\qquad \\qquad \\quad \\qquad \\qquad \\square\n\\end{align*}\n\\]\n\n\nE.3.3 Variance\nGiven the two above parametrizations of the Exponential distribution, there are two possible mathematical expressions for the variance as discussed below.\nRate Parametrization\nVia Equation C.5 and the Equation C.4 of a continuous expected value, the variance of an Exponential-distributed random variable \\(Y\\) can be found as follows:\n\nProof. \\[\n\\begin{align*}\n\\text{Var} (Y) &= \\mathbb{E} \\left( Y^2 \\right) - \\left[ \\mathbb{E}(Y)\\right]^2 \\\\\n&= \\mathbb{E} \\left( Y^2 \\right) - \\frac{1}{\\lambda^2} \\qquad \\text{since $\\mathbb{E}(Y) = \\frac{1}{\\lambda}$}.\n\\end{align*}\n\\tag{E.14}\\]\nNow, we need to find \\(\\mathbb{E} \\left( Y^2 \\right)\\) from Equation E.14. Hence, we make the following derivation via the LOTUS from Equation C.2 when \\(g(Y) = y^2\\):\n\\[\n\\begin{align*}\n\\mathbb{E} \\left( Y^2 \\right) &= \\int_{y = 0}^{y = \\infty} y^2 f_Y \\left(y \\mid \\lambda \\right) \\mathrm{d}y \\\\\n&= \\int_{y = 0}^{y = \\infty} y^2 \\lambda \\exp \\left( -\\lambda y \\right) \\mathrm{d}y \\\\\n&= \\lambda \\int_{y = 0}^{y = \\infty} y^2 \\exp \\left( -\\lambda y \\right) \\mathrm{d}y. \\\\\n\\end{align*}\n\\tag{E.15}\\]\nEquation E.15 cannot be solved straightforwardly, we need to use integration by parts as follows:\n\\[\n\\begin{equation}\n  \\begin{split}\n    u &= y^2 \\\\\n    \\mathrm{d}u &= 2y \\mathrm{d}y\n  \\end{split}\n\\qquad \\qquad\n  \\begin{split}\n    \\mathrm{d}v &= \\exp \\left( -\\lambda y \\right) \\mathrm{d}y \\\\\n    v &= -\\frac{1}{\\lambda} \\exp \\left( -\\lambda y \\right),\n  \\end{split}\n\\end{equation}\n\\]\nwhich yields\n\\[\n\\begin{align*}\n\\mathbb{E} \\left( Y^2 \\right) &= \\lambda \\left[ u v \\Bigg|_{y = 0}^{y = \\infty} - \\int_{y = 0}^{y = \\infty} v \\mathrm{d}u \\right] \\\\\n&= \\lambda \\bigg\\{ \\left[ -\\frac{1}{\\lambda} y^2 \\exp(-\\lambda y) \\right] \\Bigg|_{y = 0}^{y = \\infty} + \\\\\n& \\qquad \\frac{2}{\\lambda} \\int_{y = 0}^{y = \\infty} y \\exp{\\left( -\\lambda y \\right)} \\mathrm{d}y \\bigg\\} \\\\\n&= \\lambda \\Bigg\\{ -\\frac{1}{\\lambda} \\Bigg[ \\underbrace{\\infty \\times \\exp(-\\infty)}_{0} - \\underbrace{0 \\times \\exp(0)}_{0} \\Bigg] + \\\\\n& \\qquad \\frac{2}{\\lambda} \\int_{y = 0}^{y = \\infty} y \\exp{\\left( -\\lambda y \\right)} \\mathrm{d}y \\Bigg\\} \\\\\n&= \\lambda \\left\\{ -\\frac{1}{\\lambda} (0) + \\frac{2}{\\lambda} \\int_{y = 0}^{y = \\infty} y \\exp{\\left( -\\lambda y \\right)} \\mathrm{d}y \\right\\} \\\\\n&= \\lambda \\left\\{ 0 + \\frac{2}{\\lambda} \\int_{y = 0}^{y = \\infty} y \\exp{\\left( -\\lambda y \\right)} \\mathrm{d}y \\right\\} \\\\\n&= 2 \\int_{y = 0}^{y = \\infty} y \\exp{\\left( -\\lambda y \\right)} \\mathrm{d}y. \\\\\n\\end{align*}\n\\tag{E.16}\\]\nAgain, we need to apply integration by parts to solve Equation E.16:\n\\[\n\\begin{equation}\n  \\begin{split}\n    u &= y \\\\\n    \\mathrm{d}u &= \\mathrm{d}y\n  \\end{split}\n\\qquad \\qquad\n  \\begin{split}\n    \\mathrm{d}v &= \\exp \\left( -\\lambda y \\right) \\mathrm{d}y \\\\\n    v &= -\\frac{1}{\\lambda} \\exp \\left( -\\lambda y \\right),\n  \\end{split}\n\\end{equation}\n\\]\nwhich yields\n\\[\n\\begin{align*}\n\\mathbb{E} \\left( Y^2 \\right) &= 2 \\left[ u v \\Bigg|_{y = 0}^{y = \\infty} - \\int_{y = 0}^{y = \\infty} v \\mathrm{d}u \\right] \\\\\n&= 2 \\left\\{ \\left[ -\\frac{1}{\\lambda} y \\exp(-\\lambda y) \\right] \\Bigg|_{y = 0}^{y = \\infty} + \\frac{1}{\\lambda} \\int_{y = 0}^{y = \\infty} \\exp{\\left( -\\lambda y \\right)} \\mathrm{d}y \\right\\} \\\\\n&= 2 \\Bigg\\{ -\\frac{1}{\\lambda} \\Bigg[ \\underbrace{\\infty \\times \\exp(-\\infty)}_{0} - \\underbrace{0 \\times \\exp(0)}_{0} \\Bigg] - \\\\\n& \\qquad \\frac{1}{\\lambda^2} \\exp{\\left( -\\lambda y \\right)} \\Bigg|_{y = 0}^{y = \\infty} \\Bigg\\} \\\\\n&= 2 \\left\\{ -\\frac{1}{\\lambda} (0) - \\frac{1}{\\lambda^2} \\left[ \\exp \\left( -\\infty \\right) - \\exp \\left( 0 \\right) \\right] \\right\\} \\\\\n&= 2 \\left[ 0 - \\frac{1}{\\lambda^2} (0 - 1) \\right] \\\\\n&= \\frac{2}{\\lambda^2}.\n\\end{align*}\n\\tag{E.17}\\]\nFinally, we plug Equation E.17 into Equation E.14:\n\\[\n\\begin{align*}\n\\text{Var} (Y) &= \\mathbb{E} \\left( Y^2 \\right) - \\frac{1}{\\lambda^2} \\\\\n&= \\frac{2}{\\lambda^2} - \\frac{1}{\\lambda^2} \\\\\n&= \\frac{1}{\\lambda^2}. \\qquad \\qquad \\square\n\\end{align*}\n\\]\n\nScale Parametrization\nVia Equation C.5 and the Equation C.4 of a continuous expected value, the variance of an Exponential-distributed random variable \\(Y\\) can be found as follows:\n\nProof. \\[\n\\begin{align*}\n\\text{Var} (Y) &= \\mathbb{E} \\left( Y^2 \\right) - \\left[ \\mathbb{E}(Y)\\right]^2 \\\\\n&= \\mathbb{E} \\left( Y^2 \\right) - \\beta^2 \\qquad \\text{since $\\mathbb{E}(Y) = \\beta$}.\n\\end{align*}\n\\tag{E.18}\\]\nNow, we need to find \\(\\mathbb{E} \\left( Y^2 \\right)\\) from Equation E.18. Hence, we make the following derivation via the LOTUS from Equation C.2 when \\(g(Y) = y^2\\):\n\\[\n\\begin{align*}\n\\mathbb{E} \\left( Y^2 \\right) &= \\int_{y = 0}^{y = \\infty} y^2 f_Y \\left(y \\mid \\beta \\right) \\mathrm{d}y \\\\\n&= \\int_{y = 0}^{y = \\infty} y^2 \\frac{1}{\\beta} \\exp \\left( -\\frac{y}{\\beta} \\right) \\mathrm{d}y \\\\\n&= \\frac{1}{\\beta} \\int_{y = 0}^{y = \\infty} y^2 \\exp \\left( -\\frac{y}{\\beta} \\right) \\mathrm{d}y. \\\\\n\\end{align*}\n\\tag{E.19}\\]\nEquation E.19 cannot be solved straightforwardly, we need to use integration by parts as follows:\n\\[\n\\begin{equation}\n  \\begin{split}\n    u &= y^2 \\\\\n    \\mathrm{d}u &= 2y \\mathrm{d}y\n  \\end{split}\n\\qquad \\qquad\n  \\begin{split}\n    \\mathrm{d}v &= \\exp \\left( -\\frac{y}{\\beta} \\right) \\mathrm{d}y \\\\\n    v &= -\\beta \\exp \\left( -\\frac{y}{\\beta} \\right),\n  \\end{split}\n\\end{equation}\n\\]\nwhich yields\n\\[\n\\begin{align*}\n\\mathbb{E} \\left( Y^2 \\right) &= \\frac{1}{\\beta} \\left[ u v \\Bigg|_{y = 0}^{y = \\infty} - \\int_{y = 0}^{y = \\infty} v \\mathrm{d}u \\right] \\\\\n&= \\frac{1}{\\beta} \\Bigg\\{ \\left[ -\\beta y^2 \\exp \\left( -\\frac{y}{\\beta} \\right) \\right] \\Bigg|_{y = 0}^{y = \\infty} + \\\\\n& \\qquad 2 \\beta \\int_{y = 0}^{y = \\infty} y \\exp \\left( -\\frac{y}{\\beta} \\right) \\mathrm{d}y \\Bigg\\} \\\\\n&= \\frac{1}{\\beta} \\Bigg\\{ -\\beta \\Bigg[ \\underbrace{\\infty \\times \\exp(-\\infty)}_{0} - \\underbrace{0 \\times \\exp(0)}_{0} \\Bigg] + \\\\\n& \\qquad 2 \\beta \\int_{y = 0}^{y = \\infty} y \\exp \\left( -\\frac{y}{\\beta} \\right) \\mathrm{d}y \\Bigg\\} \\\\\n&= \\frac{1}{\\beta} \\left\\{ -\\beta (0) + 2 \\beta \\int_{y = 0}^{y = \\infty} y \\exp \\left( -\\frac{y}{\\beta} \\right) \\mathrm{d}y \\right\\} \\\\\n&= \\frac{1}{\\beta} \\left\\{ 0 + 2 \\beta \\int_{y = 0}^{y = \\infty} y \\exp \\left( -\\frac{y}{\\beta} \\right) \\mathrm{d}y \\right\\} \\\\\n&= 2 \\int_{y = 0}^{y = \\infty} y \\exp \\left( -\\frac{y}{\\beta} \\right) \\mathrm{d}y. \\\\\n\\end{align*}\n\\tag{E.20}\\]\nAgain, we need to apply integration by parts to solve Equation E.20:\n\\[\n\\begin{equation}\n  \\begin{split}\n    u &= y \\\\\n    \\mathrm{d}u &= \\mathrm{d}y\n  \\end{split}\n\\qquad \\qquad\n  \\begin{split}\n    \\mathrm{d}v &= \\exp \\left( -\\frac{y}{\\beta} \\right)\\mathrm{d}y \\\\\n    v &= -\\beta \\exp \\left( -\\frac{y}{\\beta} \\right),\n  \\end{split}\n\\end{equation}\n\\]\nwhich yields\n\\[\n\\begin{align*}\n\\mathbb{E} \\left( Y^2 \\right) &= 2 \\left[ u v \\Bigg|_{y = 0}^{y = \\infty} - \\int_{y = 0}^{y = \\infty} v \\mathrm{d}u \\right] \\\\\n&= 2 \\left\\{ \\left[ -\\beta y \\exp \\left( -\\frac{y}{\\beta} \\right) \\right] \\Bigg|_{y = 0}^{y = \\infty} + \\beta \\int_{y = 0}^{y = \\infty} \\exp \\left( -\\frac{y}{\\beta} \\right) \\mathrm{d}y \\right\\} \\\\\n&= 2 \\Bigg\\{ -\\beta \\Bigg[ \\underbrace{\\infty \\times \\exp(-\\infty)}_{0} - \\underbrace{0 \\times \\exp(0)}_{0} \\Bigg] - \\\\\n& \\qquad \\beta^2 \\exp \\left( -\\frac{y}{\\beta} \\right) \\Bigg|_{y = 0}^{y = \\infty} \\Bigg\\} \\\\\n&= 2 \\left\\{ -\\beta (0) - \\beta^2 \\left[ \\exp \\left( -\\infty \\right) - \\exp \\left( 0 \\right) \\right] \\right\\} \\\\\n&= 2 \\left[ 0 - \\beta^2 (0 - 1) \\right] \\\\\n&= 2 \\beta^2.\n\\end{align*}\n\\tag{E.21}\\]\nFinally, we plug Equation E.21 into Equation E.18:\n\\[\n\\begin{align*}\n\\text{Var} (Y) &= \\mathbb{E} \\left( Y^2 \\right) - \\beta^2 \\\\\n&= 2 \\beta^2 - \\beta^2 \\\\\n&= \\beta^2. \\qquad \\qquad \\square\n\\end{align*}\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#sec-gamma-distribution",
    "href": "book/C-distributional-mind-map.html#sec-gamma-distribution",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nE.4 Gamma",
    "text": "E.4 Gamma",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#sec-logistic-distribution",
    "href": "book/C-distributional-mind-map.html#sec-logistic-distribution",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nE.5 Logistic",
    "text": "E.5 Logistic",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#sec-normal-distribution",
    "href": "book/C-distributional-mind-map.html#sec-normal-distribution",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nE.6 Normal",
    "text": "E.6 Normal\nThis is possibly one the most famous probability distributions, and it is also known as Gaussian. It appears in many different statistical tools in the literature where certain regression models are included. Let random variable \\(Y\\) be considered continuous and unbounded. Then, \\(Y\\) is said to have a Normal distribution with the following location continuous parameter \\(\\mu\\) and scale continuous parameter \\(\\sigma^2\\):\n\\[\nY \\sim \\text{Normal}(\\mu, \\sigma^2).\n\\]\n\nE.6.1 Probability Density Function\nThe PDF of \\(Y\\) is the following:\n\\[\nf_Y \\left(y \\mid \\mu, \\sigma^2 \\right) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp{\\left[ - \\frac{(y - \\mu)^2}{2 \\sigma^2} \\right]} \\quad \\text{for $y \\in ( -\\infty, \\infty )$.}\n\\tag{E.22}\\]\n\n\nHeads-up on the use of \\(\\pi\\) in the Normal distribution!\n\n\nThe term \\(\\pi\\) in the Normal PDF depicted in Equation E.22 corresponds to the mathematical constant \\(3.141592...\\) Hence, this term does not correspond to another population parameter in this probability distribution.\n\n\nParameters \\(\\mu \\in (-\\infty, \\infty)\\) and \\(\\sigma \\in (0, \\infty)\\) refer to the random process’ location and scale, respectively. Figure E.4 shows nine members of the Normal parametric family, i.e., nine different PDFs with all possible pairwise combinations for three different scale parameters \\(\\mu = -3, 0, 3\\) and shape parameters \\(\\sigma^2 = 0.25, 1, 4\\). We can highlight the following:\n\nRegardless of the scale parameter \\(\\sigma^2\\), as we increase the location parameter \\(\\mu\\), note the center of the corresponding symmetric distribution moves more to the right.\nRegardless of the location parameter \\(\\mu\\), as we increase the scale parameter \\(\\sigma^2\\), note that there is more spread in the corresponding symmetric distribution.\n\n\n\n\n\n\n\n\nFigure E.4: Some members of the Normal or Gaussian parametric family.\n\n\n\n\n\nHow can we verify that Equation E.22 is a proper PDF (i.e., Equation E.22 integrates to one over the support of \\(Y\\))?",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/C-distributional-mind-map.html#sec-beta-distribution",
    "href": "book/C-distributional-mind-map.html#sec-beta-distribution",
    "title": "Appendix C — The Chocolified Distributional Mind Map",
    "section": "\nE.7 Beta",
    "text": "E.7 Beta\n\n\n\n\nConsul, P. C., and G. C. Jain. 1973. “A Generalization of the Poisson Distribution.” Technometrics 15 (4): 791–99. http://www.jstor.org/stable/1267389.\n\n\nEarlom, Richard. 1793. “Brook Taylor - National Portrait Gallery.” NPG D6930; Brook Taylor - Portrait - National Portrait Gallery. National Portrait Gallery. https://www.npg.org.uk/collections/search/portrait/mw40921/Brook-Taylor.\n\n\nGregory, James. 1668. Vera circuli et hyperbolae quadratura cui accedit geometria pars vniuersalis inseruiens quantitatum curuarum transmutationi & mensurae. Authore Iacobo Gregorio Abredonensi. Padua, Italy: Patavii: typis heredum Pauli Frambotti bibliop. https://archive.org/details/ita-bnc-mag-00001357-001/page/n10/mode/2up.\n\n\nHarding, Edward. 1798. Portrait of Colin MacLaurin. Courtesy of the Smithsonian Libraries and Archives. https://library.si.edu/image-gallery/72863.\n\n\nMaclaurin, Colin. 1742. A Treatise of Fluxions. Edinburgh, Scotland: Printed for the Author by T.W.; T. Ruddimans. https://archive.org/details/treatiseonfluxio02macl/page/n5/mode/2up.\n\n\nScotland, National Galleries of. n.d. Professor James Gregory, 1638 - 1675 (1). Mathematician. Professor James Gregory, 1638 - 1675 (1). Mathematician | National Galleries. https://www.nationalgalleries.org/art-and-artists/31132/professor-james-gregory-1638-1675-mathematician.\n\n\nTaylor, Brook. 1715. Methodus incrementorum directa & inversa. Auctore Brook Taylor, LL. D. & Regiae Societatis Secretario. London, England: Typis Pearsonianis Prostant apud Gul. Innys ad Insignia Principis in Coemeterio Paulino MDCCXV. https://archive.org/details/bim_eighteenth-century_methodus-incrementorum-d_taylor-brook_1717.\n\n\nWeisstein, Eric W. n.d.a. “Gamma Function.” From MathWorld–A Wolfram Web Resource. https://mathworld.wolfram.com/GammaFunction.html.\n\n\n———. n.d.b. “Taylor Series.” From MathWorld–A Wolfram Web Resource. https://mathworld.wolfram.com/TaylorSeries.html.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>The Chocolified Distributional Mind Map</span>"
    ]
  },
  {
    "objectID": "book/D-regression-mind-map.html",
    "href": "book/D-regression-mind-map.html",
    "title": "Appendix D — The Sugartastic Regression Mind Map",
    "section": "",
    "text": "Fun fact!\n\n\nSugartastic! So sweet, it could power a carnival’s worth of cotton candy machines.\n\n\n\n\n\nImage by Manfred Steger via Pixabay.\n\n\nThe regression mind map is a key component of the philosophy behind this book, besides the data science workflow from Section 1.2 and the ML-Stats dictionary found in Appendix A. Figure D.1 shows this regression mind map split in two zones by colour: discrete and continuous. This regression mind map is handy when executing the data modelling stage from the data science workflow, as explained in Section 1.2.4. Recall the first step in this stage is to choose a suitable regression model, and we made this decision in the function of the type of outcome \\(Y\\) we are dealing with. That said, the distributional mind map from Figure C.1 complements the regression mind map when identifying the correct type of outcome \\(Y\\).\n\n\n\n\n\n\n\nmindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}\n        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(\n          (Exponential &lt;br/&gt;Outcome Y)\n          (Weibull &lt;br/&gt;Outcome Y)\n          (Lognormal &lt;br/&gt;Outcome Y)\n        )Chapter 7: &lt;br/&gt;Semiparametric &lt;br/&gt;Survival &lt;br/&gt;Regression(\n          (Cox Proportional &lt;br/&gt;Hazards Model)\n            (Hazard Function &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n      {{Binary &lt;br/&gt;Outcome Y}}\n        {{Ungrouped &lt;br/&gt;Data}}\n          )Chapter 8: &lt;br/&gt;Binary Logistic &lt;br/&gt;Regression(\n            (Bernoulli &lt;br/&gt;Outcome Y)\n        {{Grouped &lt;br/&gt;Data}}\n          )Chapter 9: &lt;br/&gt;Binomial Logistic &lt;br/&gt;Regression(\n            (Binomial &lt;br/&gt;Outcome Y)\n      {{Count &lt;br/&gt;Outcome Y}}\n        {{Equidispersed &lt;br/&gt;Data}}\n          )Chapter 10: &lt;br/&gt;Classical Poisson &lt;br/&gt;Regression(\n            (Poisson &lt;br/&gt;Outcome Y)\n        {{Overdispersed &lt;br/&gt;Data}}\n          )Chapter 11: &lt;br/&gt;Negative Binomial &lt;br/&gt;Regression(\n            (Negative Binomial &lt;br/&gt;Outcome Y)\n        {{Overdispersed or &lt;br/&gt;Underdispersed &lt;br/&gt;Data}}\n          )Chapter 13: &lt;br/&gt;Generalized &lt;br/&gt;Poisson &lt;br/&gt;Regression(\n            (Generalized &lt;br/&gt;Poisson &lt;br/&gt;Outcome Y)\n        {{Zero Inflated &lt;br/&gt;Data}}\n          )Chapter 12: &lt;br/&gt;Zero Inflated &lt;br/&gt;Poisson &lt;br/&gt;Regression(\n            (Zero Inflated &lt;br/&gt;Poisson &lt;br/&gt;Outcome Y)\n      {{Categorical &lt;br/&gt;Outcome Y}}\n        {{Nominal &lt;br/&gt;Outcome Y}}\n          )Chapter 14: &lt;br/&gt;Multinomial &lt;br/&gt;Logistic &lt;br/&gt;Regression(\n            (Multinomial &lt;br/&gt;Outcome Y)\n        {{Ordinal &lt;br/&gt;Outcome Y}}\n          )Chapter 15: &lt;br/&gt;Ordinal &lt;br/&gt;Logistic &lt;br/&gt;Regression(\n            (Logistic &lt;br/&gt;Distributed &lt;br/&gt;Cumulative Outcome &lt;br/&gt;Probability)\n\n\n\n\n\n\n\n\nFigure D.1: Regression analysis mind map depicting all modelling techniques to be explored in this book. Depending on the type of outcome \\(Y\\), these techniques are split into two large zones: discrete and continuous.\n\n\nSuppose we start reading this regression map clockwise in the continuous zone. In that case, note this zone starts the cloud corresponding to Chapter 3 on the classical regression model called Ordinary Least-squares (OLS). Moreover, we can see that OLS is meant for an unbounded outcome \\(Y \\in (-\\infty, \\infty)\\). Then, we can proceed to the distributional assumption on \\(Y\\) in OLS, which would be Normal. Following up with the cloud corresponding to Chapter 4 on Gamma regression, we can see this model is meant for a nonnegative outcome \\(Y \\in [0, \\infty)\\) where we assume a Gamma distribution for \\(Y\\). This way of reading the continuous zone in the mind map will persist until the survival analysis models: Chapter 6 and Chapter 7.\nThen, we can proceed to the discrete zone with the cloud corresponding to Chapter 8 on the generalized linear model (GLM) called Binary Logistic regression which aims to model a binary outcome \\(Y \\in \\{0, 1 \\}\\). Note that the Binary Logistic regression model is meant for ungrouped data where each row in the training dataset contains unique feature values. Hence, in this modelling case, we assume the outcome \\(Y\\) as a Bernoulli trial where \\(1\\) indicates a success and \\(0\\) indicates a failure. Then, suppose we take another clockwise case such as Chapter 10 on the GLM Classical Poisson regression, this model is suitable for count-type outcomes where equidispersion is present (i.e., the mean of the counts is equal to its corresponding variance). Finally, this model assumes that the outcome is Poisson-distributed. This way of reading the discrete zone in the mind map will persist until Chapter 15 on Ordinal Logistic Regression.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>The Sugartastic Regression Mind Map</span>"
    ]
  },
  {
    "objectID": "book/continuous-zone.html",
    "href": "book/continuous-zone.html",
    "title": "Continuous Cuisine",
    "section": "",
    "text": "mindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n    Discrete &lt;br/&gt;Outcome Y\n\n\n\n\n\n\n\n\nFigure 1: Initial regression analysis mind map where, depending on the type of outcome \\(Y\\), we will split out modelling techniques into two large zones: discrete and continuous.",
    "crumbs": [
      "Continuous Cuisine"
    ]
  },
  {
    "objectID": "book/discrete-zone.html",
    "href": "book/discrete-zone.html",
    "title": "Discrete Cuisine",
    "section": "",
    "text": "mindmap\n  root((Regression \n  Analysis)\n    Continuous &lt;br/&gt;Outcome Y\n      {{Unbounded &lt;br/&gt;Outcome Y}}\n        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(\n          (Normal &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Outcome Y}}\n        )Chapter 4: &lt;br/&gt;Gamma Regression(\n          (Gamma &lt;br/&gt;Outcome Y)\n      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}\n        )Chapter 5: Beta &lt;br/&gt;Regression(\n          (Beta &lt;br/&gt;Outcome Y)\n      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}\n        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(\n          (Exponential &lt;br/&gt;Outcome Y)\n          (Weibull &lt;br/&gt;Outcome Y)\n          (Lognormal &lt;br/&gt;Outcome Y)\n        )Chapter 7: &lt;br/&gt;Semiparametric &lt;br/&gt;Survival &lt;br/&gt;Regression(\n          (Cox Proportional &lt;br/&gt;Hazards Model)\n            (Hazard Function &lt;br/&gt;Outcome Y)\n    Discrete &lt;br/&gt;Outcome Y\n\n\n\n\n\n\n\n\nFigure 1",
    "crumbs": [
      "Discrete Cuisine"
    ]
  }
]