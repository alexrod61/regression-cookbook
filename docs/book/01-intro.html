<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.53">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>1&nbsp; Getting Ready for Regression Cooking! – The Regression Cookbook (in development)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>

<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../book/02-stats-review.html" rel="next">
<link href="../book/audience-scope.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><style>html{ scroll-behavior: smooth; }</style>
<script src="../site_libs/quarto-diagram/mermaid.min.js"></script><script src="../site_libs/quarto-diagram/mermaid-init.js"></script><link href="../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">
<link href="../site_libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet">
<script src="../site_libs/htmlwidgets-1.6.4/htmlwidgets.js"></script><link href="../site_libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet">
<script src="../site_libs/datatables-binding-0.34.0/datatables.js"></script><script src="../site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><link href="../site_libs/dt-core-1.13.6/css/jquery.dataTables.min.css" rel="stylesheet">
<link href="../site_libs/dt-core-1.13.6/css/jquery.dataTables.extra.css" rel="stylesheet">
<script src="../site_libs/dt-core-1.13.6/js/jquery.dataTables.min.js"></script><link href="../site_libs/crosstalk-1.2.2/css/crosstalk.min.css" rel="stylesheet">
<script src="../site_libs/crosstalk-1.2.2/js/crosstalk.min.js"></script><script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script><link rel="stylesheet" href="../custom.css">
</head>
<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="navbar navbar-expand-lg " data-bs-theme="dark"><div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">The Regression Cookbook (in development)</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-end">
    <a href="https://github.com/alexrod61/regression-cookbook" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-0">
<li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://twitter.com/intent/tweet?url=%7Curl%7C">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://www.facebook.com/sharer/sharer.php?u=%7Curl%7C">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://www.linkedin.com/sharing/share-offsite/?url=%7Curl%7C">
              <i class="bi bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
      </ul>
</div>
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../book/01-intro.html"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Getting Ready for Regression Cooking!</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../index.html" class="sidebar-logo-link">
      <img src="../img/cookbook.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none"></a>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/meet-the-team.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Meet the Team</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/privacy-policy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Website Privacy Policy</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/audience-scope.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Audience and Scope</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/01-intro.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Getting Ready for Regression Cooking!</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/02-stats-review.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Basic Cuisine: A Review on Probability and Frequentist Statistical Inference</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../book/continuous-zone.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Continuous Cuisine</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/03-ols.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Ordinary Least-squares Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/04-gamma.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Gamma Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/05-beta.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Beta Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/06-parametric-survival.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Parametric Survival Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/07-semiparametric-survival.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Semiparametric Survival Regression</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../book/discrete-zone.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Discrete Cuisine</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/08-binary-logistic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Binary Logistic Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/09-binomial-logistic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Binomial Logistic Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/10-classical-poisson.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Classical Poisson Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/11-negative-binomial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Negative Binomial Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/12-zero-inflated-poisson.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Zero-Inflated Poisson Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/13-generalized-poisson.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Generalized Poisson Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/14-multinomial-logistic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Multinomial Logistic Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/15-ordinal-logistic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Ordinal Logistic Regression</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/A-dictionary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">ML-Stats Dictionary</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/B-greek-alphabet.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Greek Alphabet</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/C-distributional-mind-map.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Distributional Mind Map</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/D-regression-mind-map.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Regression Mind Map</span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">The recipe</h2>
   
  <ul>
<li><a href="#sec-ml-stats-dictionary" id="toc-sec-ml-stats-dictionary" class="nav-link active" data-scroll-target="#sec-ml-stats-dictionary"><span class="header-section-number">1.1</span> The ML-Stats Dictionary</a></li>
  <li>
<a href="#sec-ds-workflow" id="toc-sec-ds-workflow" class="nav-link" data-scroll-target="#sec-ds-workflow"><span class="header-section-number">1.2</span> The Data Science Workflow</a>
  <ul>
<li>
<a href="#sec-ds-workflow-study-design" id="toc-sec-ds-workflow-study-design" class="nav-link" data-scroll-target="#sec-ds-workflow-study-design"><span class="header-section-number">1.2.1</span> Study Design</a>
  <ul class="collapse">
<li><a href="#example-housing-sale-prices" id="toc-example-housing-sale-prices" class="nav-link" data-scroll-target="#example-housing-sale-prices">Example: Housing Sale Prices</a></li>
  </ul>
</li>
  <li>
<a href="#sec-ds-workflow-data-collection" id="toc-sec-ds-workflow-data-collection" class="nav-link" data-scroll-target="#sec-ds-workflow-data-collection"><span class="header-section-number">1.2.2</span> Data Collection and Wrangling</a>
  <ul class="collapse">
<li><a href="#example-collecting-data-for-housing-inference-and-predictions" id="toc-example-collecting-data-for-housing-inference-and-predictions" class="nav-link" data-scroll-target="#example-collecting-data-for-housing-inference-and-predictions">Example: Collecting Data for Housing Inference and Predictions</a></li>
  </ul>
</li>
  <li>
<a href="#sec-ds-workflow-eda" id="toc-sec-ds-workflow-eda" class="nav-link" data-scroll-target="#sec-ds-workflow-eda"><span class="header-section-number">1.2.3</span> Exploratory Data Analysis</a>
  <ul class="collapse">
<li><a href="#example-eda-for-housing-data" id="toc-example-eda-for-housing-data" class="nav-link" data-scroll-target="#example-eda-for-housing-data">Example: EDA for Housing Data</a></li>
  </ul>
</li>
  <li>
<a href="#sec-ds-workflow-modelling" id="toc-sec-ds-workflow-modelling" class="nav-link" data-scroll-target="#sec-ds-workflow-modelling"><span class="header-section-number">1.2.4</span> Data Modelling</a>
  <ul class="collapse">
<li><a href="#example-ols-regression-model-for-housing-data" id="toc-example-ols-regression-model-for-housing-data" class="nav-link" data-scroll-target="#example-ols-regression-model-for-housing-data">Example: OLS Regression Model for Housing Data</a></li>
  </ul>
</li>
  <li>
<a href="#sec-ds-workflow-estimation" id="toc-sec-ds-workflow-estimation" class="nav-link" data-scroll-target="#sec-ds-workflow-estimation"><span class="header-section-number">1.2.5</span> Estimation</a>
  <ul class="collapse">
<li><a href="#example-fitting-the-ols-regression-model-for-housing-data" id="toc-example-fitting-the-ols-regression-model-for-housing-data" class="nav-link" data-scroll-target="#example-fitting-the-ols-regression-model-for-housing-data">Example: Fitting the OLS Regression Model for Housing Data</a></li>
  </ul>
</li>
  <li><a href="#sec-ds-workflow-goodness-of-fit" id="toc-sec-ds-workflow-goodness-of-fit" class="nav-link" data-scroll-target="#sec-ds-workflow-goodness-of-fit"><span class="header-section-number">1.2.6</span> Goodness of Fit</a></li>
  <li><a href="#sec-ds-workflow-results" id="toc-sec-ds-workflow-results" class="nav-link" data-scroll-target="#sec-ds-workflow-results"><span class="header-section-number">1.2.7</span> Results</a></li>
  <li><a href="#sec-ds-workflow-storytelling" id="toc-sec-ds-workflow-storytelling" class="nav-link" data-scroll-target="#sec-ds-workflow-storytelling"><span class="header-section-number">1.2.8</span> Storytelling</a></li>
  </ul>
</li>
  <li><a href="#sec-regression-mindmap" id="toc-sec-regression-mindmap" class="nav-link" data-scroll-target="#sec-regression-mindmap"><span class="header-section-number">1.3</span> Mind Map of Regression Analysis</a></li>
  <li><a href="#sec-sup-learning-regression" id="toc-sec-sup-learning-regression" class="nav-link" data-scroll-target="#sec-sup-learning-regression"><span class="header-section-number">1.4</span> Supervised Learning and Regression Analysis</a></li>
  <li><a href="#sec-chapter-3-summary" id="toc-sec-chapter-3-summary" class="nav-link" data-scroll-target="#sec-chapter-3-summary"><span class="header-section-number">1.5</span> Chapter Summary</a></li>
  <li>
<a href="#sec-chapter-3-practice" id="toc-sec-chapter-3-practice" class="nav-link" data-scroll-target="#sec-chapter-3-practice"><span class="header-section-number">1.6</span> Practice Exercises</a>
  <ul>
<li><a href="#the-data-science-workflow" id="toc-the-data-science-workflow" class="nav-link" data-scroll-target="#the-data-science-workflow"><span class="header-section-number">1.6.1</span> The Data Science Workflow</a></li>
  <li><a href="#mind-map-of-regression-analysis" id="toc-mind-map-of-regression-analysis" class="nav-link" data-scroll-target="#mind-map-of-regression-analysis"><span class="header-section-number">1.6.2</span> Mind Map of Regression Analysis</a></li>
  <li><a href="#supervised-learning-and-regression-analysis" id="toc-supervised-learning-and-regression-analysis" class="nav-link" data-scroll-target="#supervised-learning-and-regression-analysis"><span class="header-section-number">1.6.3</span> Supervised Learning and Regression Analysis</a></li>
  </ul>
</li>
  </ul><div class="toc-actions"><ul><li><a href="https://github.com/alexrod61/regression-cookbook/edit/main/book/01-intro.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/alexrod61/regression-cookbook/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li><li><a href="https://github.com/alexrod61/regression-cookbook/blob/main/book/01-intro.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title"><span id="sec-intro" class="quarto-section-identifier"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Getting Ready for Regression Cooking!</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><!-- Google tag (gtag.js) --><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-7PRVEBE1EF"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-7PRVEBE1EF');
</script><p>First things first! Let us prepare for all the different regression techniques to be introduced in <a href="03-ols.html" class="quarto-xref"><span>Chapter 3</span></a>.</p>
<div class="LO">
<div class="LO-header">
<p>Learning Objectives</p>
</div>
<div class="LO-container">
<p>By the end of this chapter, you will be able to:</p>
<ul>
<li>Define <strong>the three core pillars</strong> to be applied in regression modelling throughout this book: a data science workflow, the right workflow flavour, and the most appropriate model.</li>
<li>Outline how the ML-Stats dictionary works <strong>to bridge the terminology</strong> used in machine learning (ML) and statistics.</li>
<li>Explain how <strong>the data science workflow</strong> can be applied in regression analysis.</li>
<li>Describe how the mind map of regression analysis acts as <strong>the primary chapter structure</strong> of this book and as a <strong>toolboox</strong>.</li>
<li>Contrast <strong>the differences and simmilarities</strong> between <strong>supervised learning</strong> and <strong>regression analysis</strong>.</li>
</ul>
</div>
</div>
<p>That said, we want to highlight one guiding principle for all of our work:</p>
<blockquote class="blockquote">
<p><strong>Different modelling estimation techniques in regression analysis become easier to understand once we develop a strong probabilistic and inferential grasp of populations or systems of interest.</strong></p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/flowchart.png" class="img-fluid figure-img" width="500"></p>
<figcaption>Image by <a href="https://pixabay.com/users/lucasjisrael-43158173/"><em>Lucas Israel</em></a> via <a href="https://pixabay.com/illustrations/flowchart-diagram-sketch-notepad-8860311/"><em>Pixabay</em></a>.</figcaption></figure>
</div>
<p>The above guiding principle rests on foundational statistical ideas on how data is generated and how it can be modelled through various regression methods. We will explore these underlying concepts in <a href="02-stats-review.html" class="quarto-xref"><span>Chapter 2</span></a>. Before doing so, however, this chapter will build on the following three core pillars:</p>
<ol type="1">
<li>Implementing a structured <strong>data science workflow</strong> as outlined in <a href="#sec-ds-workflow" class="quarto-xref"><span>Section 1.2</span></a>.</li>
<li>Selecting the appropriate workflow approach based on an <strong>inferential</strong> or <strong>predictive</strong> paradigm, as shown in <a href="#fig-ds-workflow" class="quarto-xref">Figure&nbsp;<span>1.1</span></a>.</li>
<li>Choosing the <strong>appropriate regression model</strong> based on the response variable or outcome of interest, using the mind map in <a href="#sec-regression-mindmap" class="quarto-xref"><span>Section 1.3</span></a> (analogous to a <strong>regression toolbox</strong>).</li>
</ol>
<div class="Warning">
<div class="Warning-header">
<p>The rationale behind the three pillars</p>
</div>
<div class="Warning-container">
<p>Each data science problem involving regression analysis has unique characteristics, depending on if the inquiry is inferential or predictive. Different types of outcomes (or response variables) require distinct modelling approaches. For example, we might analyze <strong>survival times</strong> (e.g., the time until one particular equipment of a given brand fails), <strong>categorical outcomes</strong> (e.g., a preferred musical genre in the Canadian young population), or <strong>count-based outcomes</strong> (e.g., how many customers we would expect on a regular Monday morning in the branches of a major national bank), etc. Moreover, under this regression context, our analysis extends beyond the outcome itself, but we also examine how it relates to other explanatory variables (the so-called features). For instance, if we are studying musical genre preferences among young Canadians, we could explore how age groups influence these preferences or compare genre popularity across provinces.</p>
<p>At first glance, it might seem that every regression problem should have a unique workflow tailored to its specific model. However, this is not entirely the case. In <a href="#fig-ds-workflow" class="quarto-xref">Figure&nbsp;<span>1.1</span></a>, we introduce a structured regression workflow designed as a proof of concept for thirteen different regression models. Each flow is covered in a separate chapter of this book alongside a review of probability and statistics (i.e, thirteen chapters in this book aside from the probability and statistics review). This workflow standardizes our approach, making analysis more transparent and efficient while allowing us to communicate insights effectively through data storytelling. Naturally, this workflow includes decision points that determine whether the approach follows an <strong>inferential</strong> or <strong>predictive</strong> path (the second pillar). As for our third pillar, this comes into play at the data modelling stage, where the regression toolbox <a href="#fig-regression-mindmap" class="quarto-xref">Figure&nbsp;<span>1.15</span></a> guides model selection based on the response variable type.</p>
</div>
</div>
<p>Let us establish a convention for using admonitions throughout this textbook. These admonitions will help distinguish between <strong>key concepts</strong>, <strong>important insights</strong>, and <strong>supplementary material</strong>, ensuring clarity as we explore different regression techniques. We will start using these admonitions in <a href="#sec-ml-stats-dictionary" class="quarto-xref"><span>Section 1.1</span></a>.</p>
<div id="Definition-sample" class="definition">
<div class="definition-header">
<p>Definition</p>
</div>
<div class="definition-container">
<p>A formal statistical and/or machine learning definition. This admonition aims to untangle the significant amount of jargon and concepts that both fields have. When applicable, alternative terminology will be included to highlight equivalent terms across statistics and machine learning.</p>
</div>
</div>
<div class="Heads-up">
<div class="Heads-up-header">
<p>Heads-up!</p>
</div>
<div class="Heads-up-container">
<p>An idea (or ideas) related to a modelling approach, a specific workflow stage, or an important data science concept. This admonition is used to flag crucial statistical or machine learning topics that warrant deeper exploration.</p>
</div>
</div>
<div class="Tip">
<div class="Tip-header">
<p>Tip</p>
</div>
<div class="Tip-container">
<p>An idea (or ideas) that may extend beyond the immediate discussion but provides additional context or helpful background. When applicable, references to further reading will be provided.</p>
</div>
</div>
<p>The core idea of the above admonition arrangement is to allow the reader to discern between ideas or concepts that are key to grasp from those whose understanding might not be highly essential (but still interesting to check out in further literature). With this structure in place, we can now introduce another foundational resource: a <strong>common ground</strong> between <strong>machine learning</strong> and <strong>statistics</strong> which will be elaborated on in the next section.</p>
<section id="sec-ml-stats-dictionary" class="level2" data-number="1.1"><h2 data-number="1.1" class="anchored" data-anchor-id="sec-ml-stats-dictionary">
<span class="header-section-number">1.1</span> The ML-Stats Dictionary</h2>
<p>Machine learning and statistics <strong>often overlap</strong>, especially in regression modelling. Topics covered in a regression-focused course, under a purely statistical framework, can also appear in machine learning-based courses on <strong>supervised learning</strong>, but the terminology can differ. Recognizing this overlap, the Master of Data Science (MDS) program at the University of British Columbia (UBC) provides the <a href="https://ubc-mds.github.io/resources_pages/terminology/">MDS Stat-ML dictionary</a> <span class="citation" data-cites="gelbart2017">(<a href="references.html#ref-gelbart2017" role="doc-biblioref">Gelbart 2017</a>)</span> under the following premises:</p>
<blockquote class="blockquote">
<p><em>This document is intended to help students navigate the large amount of jargon, terminology, and acronyms encountered in the MDS program and beyond.</em></p>
</blockquote>
<blockquote class="blockquote">
<p><em>This section covers terms that have different meanings in different contexts, specifically statistics vs.&nbsp;machine learning (ML).</em></p>
</blockquote>
<p>Both disciplines have a tremendous amount of jargon and terminology. As mentioned in the <a href="https://alexrod61.github.io/regression-cookbook/">Preface</a>, machine learning and statistics construct a <strong>substantial synergy</strong> reflected in data science. Despite this overlap, misunderstandings can still happen due to differences in terminology. To prevent this, we need clear bridges between these disciplines via a <strong>ML-Stats dictionary</strong> (<em>ML</em> stands for <em>Machine Learning</em>).</p>
<div class="Heads-up">
<div class="Heads-up-header">
<p>Heads-up on how the ML-Stats Dictionary is built and structured!</p>
</div>
<div class="Heads-up-container">
<p>The complete ML-Stats dictionary can be found in <a href="A-dictionary.html" class="quarto-xref"><span>Appendix A</span></a>. This resource builds upon the concepts introduced in the <a href="#Definition-sample">definition callout box</a> throughout the fifteen main chapters of this textbook. The dictionary aims to clarify terminology that varies between statistics and machine learning, specifically in the context of supervised learning and regression analysis.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/mopping.png" class="img-fluid figure-img" width="550"></p>
<figcaption>Image by <a href="https://pixabay.com/users/manfredsteger-1848497/"><em>manfredsteger</em></a> via <a href="https://pixabay.com/vectors/pixel-cells-hygiene-clean-up-6230154/"><em>Pixabay</em></a>.</figcaption></figure>
</div>
<p>Terms in this dictionary related to <span style="color: blue;">statistics</span> will be highlighted in <span style="color: blue;">blue</span>, while terms related to <span style="color: magenta;">machine learning</span> will be highlighted in <span style="color: magenta;">magenta</span>. This color scheme is designed to help readers easily navigate between the two disciplines. With practice, you will become proficient in applying concepts from both fields.</p>
</div>
</div>
<p>The above appendix will be the section in this book where the reader can find all those statistical and machine learning-related terms in alphabetical order. Notable terms (either statistical or machine learning-related) will include an admonition identifying which terms (again, either statistical or machine learning-related) are <strong>equivalent</strong> or <strong>somewhat equivalent</strong> (or <strong>even not equivalent if that is the case</strong>). For instance, consider the statistical term called <span style="color: blue;">dependent variable</span>:</p>
<blockquote class="blockquote">
<p>In supervised learning, it is the main variable of interest we are trying to <strong>learn</strong> or <strong>predict</strong>, or equivalently, in a statistical inference framework, the variable we are trying <strong>explain</strong>.</p>
</blockquote>
<p>Then, the above definition will be followed by this admonition:</p>
<div class="Equivalence">
<div class="Equivalence-header">
<p>Equivalent to:</p>
</div>
<div class="Equivalence-container">
<p><span style="color: blue;">Response variable</span>, <span style="color: magenta;">outcome</span>, <span style="color: magenta;">output</span> or <span style="color: magenta;">target</span>.</p>
</div>
</div>
<p>Note that we have identified four equivalent terms for the term <span style="color: blue;">dependent variable</span>. Furthermore, these terms can be <span style="color: blue;">statistical</span> or <span style="color: magenta;">machine learning-related</span>.</p>
<div class="Heads-up">
<div class="Heads-up-header">
<p>Heads-up on the use of terminology!</p>
</div>
<div class="Heads-up-container">
<p>Throughout this book, we will use specific concepts interchangeably while explaining different regression methods. If confusion arises, you must always check definitions and equivalences (or non-equivalences) in <a href="A-dictionary.html" class="quarto-xref"><span>Appendix A</span></a>.</p>
</div>
</div>
<p>Next, we will introduce the three main foundations of this textbook: a <strong>data science workflow</strong>, choosing the correct <strong>workflow flavour</strong> (<strong>inferential</strong> or <strong>predictive</strong>), and building your <strong>regression toolbox</strong>.</p>
</section><section id="sec-ds-workflow" class="level2" data-number="1.2"><h2 data-number="1.2" class="anchored" data-anchor-id="sec-ds-workflow">
<span class="header-section-number">1.2</span> The Data Science Workflow</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/idea.png" class="img-fluid figure-img" width="500"></p>
<figcaption>Image by <a href="https://pixabay.com/users/manfredsteger-1848497/"><em>manfredsteger</em></a> via <a href="https://pixabay.com/vectors/idea-visualization-line-art-3976295/"><em>Pixabay</em></a>.</figcaption></figure>
</div>
<p>Understanding the data science workflow is essential for mastering regression analysis. This workflow serves as a <strong>blueprint</strong> that guides us through each stage of our analysis, ensuring that we apply a systematic approach to solving our inquiries in a <strong>reproducible way</strong>. Each of the three pillars of this textbook—data science workflow, the right workflow flavour (inferential or predictive), and a regression toolbox—are deeply interconnected. Regardless of the regression model we explore, this general workflow provides a consistent framework that helps us navigate our data analysis with clarity and purpose.</p>
<p>As shown in <a href="#fig-ds-workflow" class="quarto-xref">Figure&nbsp;<span>1.1</span></a>, the data science workflow is composed of the following eight stages (each of which will be discussed in more detail in subsequent subsections):</p>
<ol type="1">
<li>
<strong>Study design:</strong> Define the research question, objectives, and variables of interest to ensure the analysis is purpose-driven and aligned with the problem at hand.</li>
<li>
<strong>Data collection and wrangling:</strong> Gather and clean data, addressing issues such as missing values, outliers, and inconsistencies to transform it into a usable format.</li>
<li>
<strong>Exploratory data analysis (EDA):</strong> Explore the data through statistical summaries and visualizations to identify patterns, trends, and potential anomalies.</li>
<li>
<strong>Data modelling:</strong> Apply statistical or machine learning models to uncover relationships between variables or make predictions based on the data.</li>
<li>
<strong>Estimation:</strong> Calculate model parameters to quantify relationships between variables and assess the accuracy and reliability of the model.</li>
<li>
<strong>Goodness of fit:</strong> Evaluate the model’s performance using metrics and model diagnostic checks to determine how well it explains the data.</li>
<li>
<strong>Results:</strong> Interpret the model’s outputs to derive meaningful insights and provide answers to the original research question.</li>
<li>
<strong>Storytelling</strong> Communicate the findings through a clear, engaging narrative that is accessible to a non-technical audience.</li>
</ol>
<p>By adhering to this workflow, we ensure that our regression analysis are not only systematic and thorough but also capable of producing results that are meaningful within the context of the problem we aim to solve.</p>
<div class="Heads-up">
<div class="Heads-up-header">
<p>Heads-up on the importance of a formal structure in regression analysis!</p>
</div>
<div class="Heads-up-container">
<p>From the earliest stages of learning data analysis, understanding the importance of a structured workflow is crucial. If we do not adhere to a predefined workflow, we risk misinterpreting the data, leading to incorrect conclusions that fail to address the core questions of our analysis. Such missteps can result in outcomes that are not only meaningless but potentially misleading when taken out of the problem’s context.</p>
<p>Therefore, it is essential for aspiring data scientists to internalize this workflow from the very beginning of their education. A systematic approach ensures that each stage of the analysis is conducted with precision, ultimately producing reliable and contextually relevant results.</p>
</div>
</div>
<div id="fig-ds-workflow" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-ds-workflow-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/data-science-workflow.png" class="img-fluid figure-img" width="1500">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ds-workflow-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.1: Data science workflow for <em>inferential</em> and <em>predictive</em> inquiries in regression analysis and supervised learning, respectively. The workflow is structured in eight stages: <em>study design</em>, <em>data collection and wrangling</em>, <em>exploratory data analysis</em>, <em>data modelling</em>, <em>estimation</em>, <em>goodness of fit</em>, <em>results</em>, and <em>storytelling</em>.
</figcaption></figure>
</div>
<section id="sec-ds-workflow-study-design" class="level3" data-number="1.2.1"><h3 data-number="1.2.1" class="anchored" data-anchor-id="sec-ds-workflow-study-design">
<span class="header-section-number">1.2.1</span> Study Design</h3>
<p>The first stage of this workflow is centred around defining the <strong>main statistical inquiries</strong> we aim to address throughout the data analysis process. As a data scientist, your primary task is to translate these inquiries from the stakeholders into one of two categories: <em>inferential</em> or <em>predictive</em>. This classification determines the direction of your analysis and the methods you will use:</p>
<ul>
<li>
<strong>Inferential:</strong> The objective here is to explore and quantify relationships of <strong>association</strong> or <strong>causation</strong> between explanatory variables (referred to as regressors in the models discussed in this textbook) and the response variable within the context of the specific problem at hand. For example, you might <strong>statistically seek</strong> to determine whether a particular marketing campaign (the regressor) significantly influences sales revenue (the response), and if it does, by how much.</li>
<li>
<strong>Predictive:</strong> In this case, the focus is on making <strong>accurate predictions</strong> about the response variable based on future observations of the regressors. Unlike inferential inquiries, where understanding the relationship between variables is key, the primary goal here is to <strong>maximize</strong> prediction accuracy. This approach is fundamental in machine learning. For instance, you might build a model to predict future sales revenue based on past marketing expenditures, without necessarily needing to understand the underlying relationship between the two.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/magnifying-glass-2.png" class="img-fluid figure-img" width="420"></p>
<figcaption>Image by <a href="https://pixabay.com/users/manfredsteger-1848497/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3699345"><em>Manfred Steger</em></a> via <a href="https://pixabay.com/vectors/pixel-cells-pixel-action-bound-3704046/"><em>Pixabay</em></a>.</figcaption></figure>
</div>
<div class="Heads-up">
<div class="Heads-up-header">
<p>Heads-up on the inquiry focus of this book!</p>
</div>
<div class="Heads-up-container">
<p>In the regression chapters of this book, we will emphasize both types of inquiries. As we follow the workflow from <a href="#fig-ds-workflow" class="quarto-xref">Figure&nbsp;<span>1.1</span></a>, we will explore the two pathways identified by the decision points concerning inference and prediction.</p>
</div>
</div>
<section id="example-housing-sale-prices" class="level4"><h4 class="anchored" data-anchor-id="example-housing-sale-prices">Example: Housing Sale Prices</h4>
<p>To illustrate the study design stage, let us consider a simple example involving housing sale prices in a specific city:</p>
<ul>
<li>If our goal is <strong>inferential</strong>, we might be interested in understanding the relationship between various factors—such as square footage, number of bedrooms, and proximity to schools—and housing sale prices. Specifically, we would ask questions like:</li>
</ul>
<blockquote class="blockquote">
<p><strong>How does the number of bedrooms affect the price of a house, once we account for other factors?</strong></p>
</blockquote>
<ul>
<li>If our goal is <strong>predictive</strong>, we would focus on estimating a model that can accurately predict the price of a house based on its features (i.e., the characteristics of a given house), regardless of whether we fully understand how each feature contributes to the price. Hence, we would be able to answer questions such as:</li>
</ul>
<blockquote class="blockquote">
<p><strong>What would be the predicted price of a house with 3,500 square feet and 3 bedrooms located on a block where the closest school is at 2.5 km?</strong></p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/house.png" class="img-fluid figure-img" width="350"></p>
<figcaption>Image by <a href="https://pixabay.com/users/tkaucic-1450822/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2827164"><em>Tomislav Kaučić</em></a> via <a href="https://pixabay.com/vectors/blueprint-house-architecture-2827164/"><em>Pixabay</em></a>.</figcaption></figure>
</div>
<p>In both cases, the study design stage involves <strong>clearly defining</strong> these objectives and determining the appropriate data modelling methods to address them. This stage sets the foundation for all subsequent steps in the data science workflow. After establishing the study design, the next step is <strong>data collection and wrangling</strong>, as shown in <a href="#fig-ds-workflow-study-design" class="quarto-xref">Figure&nbsp;<span>1.2</span></a>.</p>
<div id="fig-ds-workflow-study-design" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-ds-workflow-study-design-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/study-design.png" class="img-fluid figure-img" width="1000">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ds-workflow-study-design-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.2: <em>Study design</em> stage from the data science workflow in <a href="#fig-ds-workflow" class="quarto-xref">Figure&nbsp;<span>1.1</span></a>. This stage is directly followed by <em>data collection and wrangling</em>.
</figcaption></figure>
</div>
</section></section><section id="sec-ds-workflow-data-collection" class="level3" data-number="1.2.2"><h3 data-number="1.2.2" class="anchored" data-anchor-id="sec-ds-workflow-data-collection">
<span class="header-section-number">1.2.2</span> Data Collection and Wrangling</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/measurement.png" class="img-fluid figure-img" width="450"></p>
<figcaption>Image by <a href="https://pixabay.com/users/manfredsteger-1848497/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3699345"><em>Manfred Steger</em></a> via <a href="https://pixabay.com/vectors/pixel-cells-evaluation-measure-up-3976303/"><em>Pixabay</em></a>.</figcaption></figure>
</div>
<p>Once we have clearly defined our statistical questions, the next crucial step is to collect the data that will form the basis of our analysis. The way we collect this data is vital because it directly affects the accuracy and reliability of our results:</p>
<ul>
<li>For <strong>inferential inquiries</strong>, we focus on understanding <strong>populations</strong> or systems that we cannot fully observe. These populations are governed by characteristics (referred to as <strong>parameters</strong>) that we want to estimate. Because we cannot study every individual in the population or system, we collect a smaller, representative subset called a sample. The method we use to collect this sample—known as <strong>sampling</strong>—is crucial. A proper sampling method ensures that our sample reflects the larger population or system, allowing us to make accurate and precise generalizations (i.e., inferences) about the entire population or system. After collecting the sample, it is common practice to <strong>randomly split the data into training and test sets</strong>. This split allows us to build and assess our models, ensuring that the findings are robust and not overly tailored to the specific data at hand.</li>
<li>
<strong>For predictive inquiries</strong>, our goal is often to use existing data to make predictions about future events or outcomes. In these cases, we usually work with large datasets (databases) that have already been collected. Instead of focusing on whether the data represents a population (as in inferential inquiries), we focus on cleaning and preparing the data so that it can be used to train models that make accurate predictions. After wrangling the data, it is typically <strong>split into training, validation (if necessary, depending on our chosen modelling strategy), and test sets</strong>. The training set is used to build the model, the validation set is used to tune model parameters, and the test set evaluates the model’s final performance on unseen data.</li>
</ul>
<div class="Tip">
<div class="Tip-header">
<p>Tip on sampling techniques!</p>
</div>
<div class="Tip-container">
<p>Careful attention to sampling design is a crucial step in any research aimed at supporting valid regression-based inference. The selection of an <strong>appropriate sampling design</strong> should be guided by the structural characteristics of the population as well as the specific goals of the analysis. A well-designed sampling strategy enhances the accuracy, precision, and generalizability of parameter estimates derived from regression models, particularly when the intention is to extend model-based conclusions beyond the observed data to the whole population or system.</p>
<p>Below, we summarize some commonly used probability-based sampling designs, each of which has distinct implications for model validity and estimation efficiency:</p>
<ul>
<li>
<strong>Simple random sampling:</strong> Every unit in the population has an equal probability of selection. While this method is straightforward to implement and analyze, it may be inefficient or impractical for populations with heterogeneous subgroups.</li>
<li>
<strong>Systematic sampling:</strong> Sampling occurs at fixed intervals from an ordered list, starting from a randomly chosen point. This design can improve efficiency under certain ordering schemes, but caution is necessary to avoid biases related to periodicity.</li>
<li>
<strong>Stratified sampling:</strong> The population is divided into mutually exclusive strata based on key characteristics (e.g., age, income, region, etc.). Samples are drawn within each stratum, often in proportion to the strata sizes or based on optimal allocation. This approach increases precision for subgroup estimates and enhances overall model efficiency.</li>
<li>
<strong>Cluster sampling:</strong> The population is divided into naturally occurring clusters (e.g., households, schools, geographic units, etc.), and entire clusters are sampled randomly. This design is often preferred for cost efficiency, but it typically requires adjustments for intracluster correlation during analysis.</li>
</ul>
<p>In the context of our regression-based inferential framework, it is necessary to carefully plan data collection and preparation around the sampling strategy. The choice of sampling design can influence not only model estimation but also the interpretation and generalizability of the results. While this textbook does not provide an exhaustive treatment of sampling theory, we recommend <span class="citation" data-cites="lohr2021">Lohr (<a href="references.html#ref-lohr2021" role="doc-biblioref">2021</a>)</span> for an in-depth reference. Their work offers both theoretical insights and applied examples that are highly relevant for data scientists engaged in model-based inference.</p>
</div>
</div>
<section id="example-collecting-data-for-housing-inference-and-predictions" class="level4"><h4 class="anchored" data-anchor-id="example-collecting-data-for-housing-inference-and-predictions">Example: Collecting Data for Housing Inference and Predictions</h4>
<p>Let us continue with our housing example to illustrate the above concepts:</p>
<ul>
<li>
<strong>Inferential Approach:</strong> Suppose we want to understand how the number of bedrooms is associated with the housing sale prices in a city. To do this, we would collect a sample of house sales that accurately represents the city’s entire housing market. For instance, we might use stratified sampling to ensure that we include houses from different neighbourhoods in proportion to how common they are. After collecting the data, we would split it into training and test sets. The training set helps us build our model and estimate the relationship between variables, while the test set allows us to evaluate how well our findings generalize to new data.</li>
<li>
<strong>Predictive Approach:</strong> If our goal is to predict the selling price of a house based on its features (such as size, number of bedrooms, and location), we would gather a large dataset of recent house sales. This data might come from a real estate database that tracks the details of each sale. Before we can use this data to train a model, we would clean it by filling in any missing information, converting data to a consistent format, and making sure all variables are ready for analysis. After preprocessing, we would split the data into training, validation, and test sets. The training set would be used to fit the model, the validation set to fine-tune it, and the test set to assess how well the model can predict prices for houses it has not seen before.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/database.png" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption>Image by <a href="https://pixabay.com/users/io-images-1096650/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=4941338"><em>Stefan</em></a> via <a href="https://pixabay.com/vectors/database-manage-administer-4941338/"><em>Pixabay</em></a>.</figcaption></figure>
</div>
<p>As shown in <a href="#fig-ds-workflow-data-collection-wrangling" class="quarto-xref">Figure&nbsp;<span>1.3</span></a>, the data collection and wrangling stage is fundamental to the workflow. It directly follows the study design and sets the stage for exploratory data analysis.</p>
<div id="fig-ds-workflow-data-collection-wrangling" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-ds-workflow-data-collection-wrangling-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/data-collection-and-wrangling.png" class="img-fluid figure-img" width="1000">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ds-workflow-data-collection-wrangling-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.3: <em>Data collection and wrangling</em> stage from the data science workflow in <a href="#fig-ds-workflow" class="quarto-xref">Figure&nbsp;<span>1.1</span></a>. This stage is directly followed by <em>exploratory data analysis</em> and preceded by <em>study design</em>.
</figcaption></figure>
</div>
</section></section><section id="sec-ds-workflow-eda" class="level3" data-number="1.2.3"><h3 data-number="1.2.3" class="anchored" data-anchor-id="sec-ds-workflow-eda">
<span class="header-section-number">1.2.3</span> Exploratory Data Analysis</h3>
<p>Before diving into data modelling, it is crucial to develop a deep understanding of the relationships between the variables in our training data. This is where the third stage of the data science workflow comes into play: <strong>exploratory data analysis (EDA)</strong>. EDA serves as a vital process that allows us to visualize and summarize our data, uncover patterns, detect anomalies, and test key assumptions that will inform our modelling decisions.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/explore.png" class="img-fluid figure-img" width="400"></p>
<figcaption>Image by <a href="https://pixabay.com/users/manfredsteger-1848497/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3699345"><em>Manfred Steger</em></a> via <a href="https://pixabay.com/vectors/pixel-cells-pixel-outlook-success-3704053/"><em>Pixabay</em></a>.</figcaption></figure>
</div>
<p>The first step in EDA is to classify our variables according to their types. This classification is essential because it guides our choice of analysis techniques and models. Specifically, we need to determine whether each variable is <strong>discrete</strong> or <strong>continuous</strong>, and whether it has any specific characteristics such as being bounded or unbounded.</p>
<ul>
<li>
<strong>Response (i.e., the <span class="math inline">\(Y\)</span>):</strong>
<ul>
<li>Determine if the response variable is <strong>discrete</strong> (e.g., binary, count-based, categorical) or <strong>continuous</strong>.</li>
<li>If it is <strong>continuous</strong>, let us consider whether it is <strong>bounded</strong> (e.g., percentages that range between <span class="math inline">\(0\)</span> and <span class="math inline">\(100\)</span>) or <strong>unbounded</strong> (e.g., a variable like company profits/losses that can take on a wide range of values).</li>
</ul>
</li>
<li>
<strong>Regressors (i.e., the <span class="math inline">\(x\)</span>s):</strong>
<ul>
<li>For each regressor, we must identify whether it is <strong>discrete</strong> or <strong>continuous</strong>.</li>
<li>If a regressor is <strong>discrete</strong>, let us classify it further as binary, count-based, or categorical.</li>
<li>If a regressor is <strong>continuous</strong>, let us determine whether it is bounded or unbounded.</li>
</ul>
</li>
</ul>
<p>This classification scheme helps us select the appropriate visualization and statistical methods for our analysis, as different variable types often need different approaches. It ensures that we are well-equipped to make the right choices in our analyses.</p>
<p>After classifying your variables, the next step is to create <strong>visualizations</strong> and calculate <strong>descriptive statistics</strong> using our training data. This involves coding plots that can reveal the underlying distribution of each variable and the relationships between them. For instance, we might create histograms to visualize distributions, scatter plots to explore relationships between continuous variables, and box plots to compare discrete and categorical variables against a continuous variable.</p>
<p>Alongside these visualizations, it is important to calculate key descriptive statistics such as the mean, median, and standard deviation if our variables are numeric. These statistics provide a summary of our data, offering insights into <strong>central tendency</strong> and <strong>variability</strong>. We might also use a correlation matrix to assess the strength of relationships between continuous variables.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/mean.png" class="img-fluid figure-img" width="600"></p>
<figcaption>Image by <a href="https://pixabay.com/users/manfredsteger-1848497/"><em>Manfred Stege</em></a> via <a href="https://pixabay.com/vectors/pixel-cells-pixel-to-learn-goal-3674110/"><em>Pixabay</em></a>.</figcaption></figure>
</div>
<p>Once we have generated these plots and statistics, they should be displayed in a clear and logical manner. The goal here is to interpret the data and draw preliminary conclusions about the relationships between the observed variables. Presenting these findings effectively helps to uncover <strong>key descriptive insights</strong> and prepares you for the subsequent modelling stage. Finally, the insights gained from our EDA must be <strong>clearly articulated</strong>. This involves summarizing the key findings and considering their implications for the next stage of the workflow—data modelling. Observing patterns, correlations, and potential outliers in this stage will inform your modelling approach and ensure that it is grounded in a thorough and informed analysis.</p>
<div class="Heads-up">
<div class="Heads-up-header">
<p>Heads-up on the use of EDA to deliver inferential conclusions!</p>
</div>
<div class="Heads-up-container">
<p>EDA plays a critical role in uncovering patterns, detecting anomalies, and generating hypotheses. However, it is important to emphasize that the results of EDA <strong>should not be generalized beyond the specific sample data being analyzed</strong>. EDA is inherently descriptive and focused on the sample, and it is not intended to support inferential claims about larger populations. The insights gained from EDA are contingent on the specific sample and may not accurately reflect systematic relationships within the broader population. Nevertheless, EDA can provide valuable information to inform our modelling decisions.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/curious.png" class="img-fluid figure-img" width="250"></p>
<figcaption>Image by <a href="https://pixabay.com/users/manfredsteger-1848497/"><em>Manfred Stege</em></a> via <a href="https://pixabay.com/vectors/pixel-cells-emotion-fear-expression-6230192/"><em>Pixabay</em></a>.</figcaption></figure>
</div>
<p>Generalizing findings to a larger population requires formal statistical inference, which takes into account <strong>sampling variability</strong>, <strong>model uncertainty</strong>, and the <strong>precision of estimates</strong>. This is particularly important in regression analysis, where extending patterns observed in a sample to the wider population needs rigorous modelling assumptions, estimation procedures, and a quantification of uncertainty (e.g., through confidence intervals). Treating EDA findings as if they were inferential conclusions can lead to misleading interpretations throughout our data science workflow.</p>
</div>
</div>
<section id="example-eda-for-housing-data" class="level4"><h4 class="anchored" data-anchor-id="example-eda-for-housing-data">Example: EDA for Housing Data</h4>
<p>To illustrate the EDA process, we will follow it within the context of the housing example used in the previous two workflow stages, utilizing simulated data. Suppose we have a sample of <span class="math inline">\(n = 2,000\)</span> houses drawn from various Canadian cities through <strong>cluster sampling</strong>. As shown in <a href="#tbl-housing-variables" class="quarto-xref">Table&nbsp;<span>1.1</span></a>, our earlier <strong>inferential</strong> and <strong>predictive inquiries</strong> focus on <strong>housing sale price</strong> in <em>CAD</em> as our response variable in a regression context. Note that this numeric response cannot be negative, which classifies it as <strong>positively unbounded</strong>. Additionally, <a href="#tbl-housing-variables" class="quarto-xref">Table&nbsp;<span>1.1</span></a> provides the relevant details for the regressors in this case: the number of bedrooms, square footage, neighbourhood type, and proximity to schools. Note that we also indicate the <strong>coding names</strong> of all the variables involved.</p>
<div id="tbl-housing-variables" class="striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-housing-variables-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1.1: Classification table for variables in housing data.
</figcaption><div aria-describedby="tbl-housing-variables-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 26%">
<col style="width: 20%">
<col style="width: 14%">
<col style="width: 14%">
</colgroup>
<thead><tr class="header">
<th style="text-align: center;"><strong>Variable</strong></th>
<th style="text-align: center;"><strong>Type</strong></th>
<th style="text-align: center;"><strong>Scale</strong></th>
<th style="text-align: center;"><strong>Model Role</strong></th>
<th style="text-align: center;"><strong>Coding Name</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Housing Sale Price (<em>CAD</em>)</td>
<td style="text-align: center;">Continuous</td>
<td style="text-align: center;">Positively unbounded</td>
<td style="text-align: center;">Response</td>
<td style="text-align: center;"><code>sale_price</code></td>
</tr>
<tr class="even">
<td style="text-align: center;">Number of Bedrooms</td>
<td style="text-align: center;">Discrete</td>
<td style="text-align: center;">Count</td>
<td style="text-align: center;">Regressor</td>
<td style="text-align: center;"><code>bedrooms</code></td>
</tr>
<tr class="odd">
<td style="text-align: center;">Square Footage</td>
<td style="text-align: center;">Continuous</td>
<td style="text-align: center;">Positively unbounded</td>
<td style="text-align: center;">Regressor</td>
<td style="text-align: center;"><code>sqft</code></td>
</tr>
<tr class="even">
<td style="text-align: center;">Neighbourhood Type (<em>Rural</em>, <em>Suburban</em> or <em>Urban</em>)</td>
<td style="text-align: center;">Discrete</td>
<td style="text-align: center;">Categorical</td>
<td style="text-align: center;">Regressor</td>
<td style="text-align: center;"><code>neighbourhood</code></td>
</tr>
<tr class="odd">
<td style="text-align: center;">Proximity to Schools (<em>km</em>)</td>
<td style="text-align: center;">Continuous</td>
<td style="text-align: center;">Positively unbounded</td>
<td style="text-align: center;">Regressor</td>
<td style="text-align: center;"><code>school_distance</code></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Before continuing with this housing example, let us make a quick note on this textbook’s coding delivery.</p>
<div class="Heads-up">
<div class="Heads-up-header">
<p>Heads-up on coding tabs!</p>
</div>
<div class="Heads-up-container">
<p>You might be wondering:</p>
<blockquote class="blockquote">
<p><strong>Where do we begin with some <code>R</code> or <code>Python</code> code?</strong></p>
</blockquote>
<p>It is time to introduce our very first lines of code and provide some explanations about the coding approach in this book. Our goal is to make this book “<em>bilingual</em>,” meaning that all hands-on coding practices can be performed in either <code>R</code> or <code>Python</code>. Whenever we present a specific proof of concept or data modelling exercise, you will find two tabs: one for <code>R</code> and another for <code>Python</code>. We will first show the input code, followed by the output.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/juggling.png" class="img-fluid figure-img" width="300"></p>
<figcaption>Image by <a href="https://pixabay.com/users/manfredsteger-1848497/"><em>Manfred Stege</em></a> via <a href="https://pixabay.com/vectors/daycare-pixel-holding-hands-7464616/"><em>Pixabay</em></a>.</figcaption></figure>
</div>
<p>With this format, you can choose your coding journey based on your language preferences and interests as you progress throughout the book.</p>
</div>
</div>
<p>Having clarified the bilingual nature of this book with respect to coding, let us load this sample of <span class="math inline">\(n = 2,000\)</span> houses in both <code>R</code> and <code>Python</code>. For <code>Python</code>, we will need the <a href="https://pypi.org/project/pandas/">{pandas}</a> library. <a href="#tbl-housing-data-r" class="quarto-xref">Table&nbsp;<span>1.2</span></a> and <a href="#tbl-housing-data-py" class="quarto-xref">Table&nbsp;<span>1.3</span></a> show the first 100 rows of this full dataset and <code>R</code> and <code>Python</code>, respectively.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" aria-current="page"><strong><code>R</code> Code</strong></a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false"><strong><code>Python</code> Code</strong></a></li>
</ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Loading dataset</span></span>
<span><span class="va">housing_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.csv</a></span><span class="op">(</span><span class="st">"data/housing_data.csv"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Showing the first 100 houses of the full dataset</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">housing_data</span>, n <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Importing library</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Loading dataset</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>housing_data <span class="op">=</span> pd.read_csv(<span class="st">"data/housing_data.csv"</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Showing the first 100 houses of the full dataset</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(housing_data.head(<span class="dv">100</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true"><strong><code>R</code> Output</strong></a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false"><strong><code>Python</code> Output</strong></a></li>
</ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">
<div class="cell">
<div id="tbl-housing-data-r" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-housing-data-r-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1.2: First 100 rows of full housing data.
</figcaption><div aria-describedby="tbl-housing-data-r-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div class="datatables html-widget html-fill-item" id="htmlwidget-2d1a3c66385a3ed97913" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-2d1a3c66385a3ed97913">{"x":{"filter":"none","vertical":false,"data":[[261231.16,339775.55,278618.64,327928.51,305381.98,253581.65,295254.98,458867.71,300538.39,295686.19,443086.57,348312.78,279320,345914.98,301789.93,375825.49,280120.11,227685.65,251563.42,395131.52,361596.47,280411.44,309348.7,443241.78,203277.4,384670.03,365671.08,365862.61,357267.47,331353.98,317294.56,300798.76,336278.16,297931.7,332491.79,287536.6,328145.24,315680.41,292182.82,332170.6,243664.65,273883.81,338902.71,274403.44,307354.74,222506.71,252185.16,317702.04,350822.17,374639.53,257769.17,278628.35,265090.07,217741.74,307080.27,287785.59,212959.06,355388.77,436355.98,326937.23,368771.25,221188.43,399201.51,372806.64,274829.01,317658.43,231877.96,323238.8,307986.66,329744.95,352063.8,265486.43,258924.06,292913.13,359809.09,195704.34,316656.65,282517.9,267243.08,224624.54,318716.84,370066.76,323394.82,297283.09,261329.35,289111.33,214129.42,434086.48,384588.69,161707.78,326385.98,231450.44,280048.66,396307.16,317981.2,336089.25,281757.34,315713.23,325282.08,278132.41],[3,5,3,6,7,1,4,6,4,4,7,4,5,4,2,6,3,1,3,7,6,5,4,9,5,5,4,4,3,2,7,6,5,5,1,4,5,3,3,3,2,3,3,3,2,2,3,4,3,6,1,4,5,2,4,3,2,5,6,3,5,2,3,3,5,4,5,5,5,4,5,4,5,1,4,3,3,4,3,2,3,5,3,5,2,4,8,6,6,2,2,5,3,5,3,2,5,2,4,4],[1401.68,1384.02,1792.81,1747.13,780.26,2216.23,1899.89,2766.48,2074.08,1621.22,2918.96,2932.89,1312.52,1987.61,1715.5,1874.82,1891.02,1295.24,1914.24,2499.7,1734.36,1734.83,2359.43,2159.36,1140.6,1891.42,2461.42,2366.11,1967.98,2088.49,1321.23,1920.05,1418.22,1616.79,2174.24,1345.24,1906.77,1971.33,1821.96,2528.88,1391.06,2042.45,1764.43,1695.67,1985.64,1391.84,1274.62,1602.21,2500.7,1822.31,1932.57,1724.06,1988.2,1419.33,2263.16,2033.88,1477.42,1821.82,2086.53,2023.09,2392.77,1554.8,2246.45,2214.62,1735.01,1409.63,1364.34,1983.11,1771.55,2511.64,2014.06,1651.22,1389.78,1567.04,1937.16,1619.63,2005.69,1666.26,1757.78,1507.8,2562.02,1933.05,1892.25,1123.26,2063.92,1390.55,1443.39,2167.34,1618.92,1100.65,2507.96,849.04,2029.12,2206.9,1547.61,1977.71,1975.65,2216.25,1993.64,1702.05],["Urban","Urban","Urban","Suburban","Urban","Rural","Suburban","Suburban","Suburban","Urban","Rural","Rural","Urban","Suburban","Urban","Suburban","Suburban","Urban","Rural","Suburban","Rural","Rural","Rural","Urban","Suburban","Urban","Suburban","Urban","Urban","Urban","Urban","Rural","Suburban","Urban","Suburban","Urban","Urban","Urban","Suburban","Rural","Rural","Rural","Suburban","Suburban","Urban","Suburban","Suburban","Suburban","Suburban","Urban","Rural","Suburban","Rural","Rural","Suburban","Suburban","Suburban","Urban","Urban","Urban","Suburban","Suburban","Urban","Suburban","Suburban","Urban","Suburban","Suburban","Suburban","Suburban","Suburban","Suburban","Rural","Urban","Suburban","Suburban","Urban","Suburban","Rural","Suburban","Rural","Suburban","Urban","Suburban","Urban","Rural","Rural","Urban","Urban","Rural","Suburban","Suburban","Rural","Urban","Suburban","Urban","Urban","Suburban","Suburban","Rural"],[1.62,1.69,4.36,1.71,0.72,1.85,4.66,4.39,4.12,0.21,3.19,3.93,3.61,1.01,2.95,2.13,1.7,2.16,1.89,4.37,1.44,2.03,4.47,4.13,3.66,2.26,2.34,2.45,0.72,1.5,3.16,3.47,0.87,4.02,1.07,2.74,4.9,2.14,0.5,0.93,1.02,0.24,1.48,1.88,1.45,0.68,0.74,4.37,2.19,0.59,0.83,4.46,4.56,4.23,2.79,1.4,4.04,0.43,0.49,1.46,2.52,4.29,3.57,2.14,2.74,0.8,2.58,0.65,0.84,4.5,1.4,3.78,1.78,3.21,1.13,3.64,3.91,4.8,4.81,2.38,4.54,3.4,3.35,3.29,2.32,2.62,3.62,2.08,1.15,2.12,3.06,2.39,2.87,2.07,0.15,1.07,4.86,3.55,0.55,3.42]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>sale_price<\/th>\n      <th>bedrooms<\/th>\n      <th>sqft<\/th>\n      <th>neighbourhood<\/th>\n      <th>school_distance<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"ltipr","autoWidth":true,"columnDefs":[{"className":"dt-left","targets":"_all"},{"width":"200px","targets":"_all"},{"name":"sale_price","targets":0},{"name":"bedrooms","targets":1},{"name":"sqft","targets":2},{"name":"neighbourhood","targets":3},{"name":"school_distance","targets":4}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
</figure>
</div>
</div>
</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">
<div class="cell">
<div id="tbl-housing-data-py" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-housing-data-py-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1.3: First 100 rows of full housing data.
</figcaption><div aria-describedby="tbl-housing-data-py-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div class="datatables html-widget html-fill-item" id="htmlwidget-6098930864c3104a2d5c" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-6098930864c3104a2d5c">{"x":{"filter":"none","vertical":false,"data":[[261231.16,339775.55,278618.64,327928.51,305381.98,253581.65,295254.98,458867.71,300538.39,295686.19,443086.57,348312.78,279320,345914.98,301789.93,375825.49,280120.11,227685.65,251563.42,395131.52,361596.47,280411.44,309348.7,443241.78,203277.4,384670.03,365671.08,365862.61,357267.47,331353.98,317294.56,300798.76,336278.16,297931.7,332491.79,287536.6,328145.24,315680.41,292182.82,332170.6,243664.65,273883.81,338902.71,274403.44,307354.74,222506.71,252185.16,317702.04,350822.17,374639.53,257769.17,278628.35,265090.07,217741.74,307080.27,287785.59,212959.06,355388.77,436355.98,326937.23,368771.25,221188.43,399201.51,372806.64,274829.01,317658.43,231877.96,323238.8,307986.66,329744.95,352063.8,265486.43,258924.06,292913.13,359809.09,195704.34,316656.65,282517.9,267243.08,224624.54,318716.84,370066.76,323394.82,297283.09,261329.35,289111.33,214129.42,434086.48,384588.69,161707.78,326385.98,231450.44,280048.66,396307.16,317981.2,336089.25,281757.34,315713.23,325282.08,278132.41],[3,5,3,6,7,1,4,6,4,4,7,4,5,4,2,6,3,1,3,7,6,5,4,9,5,5,4,4,3,2,7,6,5,5,1,4,5,3,3,3,2,3,3,3,2,2,3,4,3,6,1,4,5,2,4,3,2,5,6,3,5,2,3,3,5,4,5,5,5,4,5,4,5,1,4,3,3,4,3,2,3,5,3,5,2,4,8,6,6,2,2,5,3,5,3,2,5,2,4,4],[1401.68,1384.02,1792.81,1747.13,780.26,2216.23,1899.89,2766.48,2074.08,1621.22,2918.96,2932.89,1312.52,1987.61,1715.5,1874.82,1891.02,1295.24,1914.24,2499.7,1734.36,1734.83,2359.43,2159.36,1140.6,1891.42,2461.42,2366.11,1967.98,2088.49,1321.23,1920.05,1418.22,1616.79,2174.24,1345.24,1906.77,1971.33,1821.96,2528.88,1391.06,2042.45,1764.43,1695.67,1985.64,1391.84,1274.62,1602.21,2500.7,1822.31,1932.57,1724.06,1988.2,1419.33,2263.16,2033.88,1477.42,1821.82,2086.53,2023.09,2392.77,1554.8,2246.45,2214.62,1735.01,1409.63,1364.34,1983.11,1771.55,2511.64,2014.06,1651.22,1389.78,1567.04,1937.16,1619.63,2005.69,1666.26,1757.78,1507.8,2562.02,1933.05,1892.25,1123.26,2063.92,1390.55,1443.39,2167.34,1618.92,1100.65,2507.96,849.04,2029.12,2206.9,1547.61,1977.71,1975.65,2216.25,1993.64,1702.05],["Urban","Urban","Urban","Suburban","Urban","Rural","Suburban","Suburban","Suburban","Urban","Rural","Rural","Urban","Suburban","Urban","Suburban","Suburban","Urban","Rural","Suburban","Rural","Rural","Rural","Urban","Suburban","Urban","Suburban","Urban","Urban","Urban","Urban","Rural","Suburban","Urban","Suburban","Urban","Urban","Urban","Suburban","Rural","Rural","Rural","Suburban","Suburban","Urban","Suburban","Suburban","Suburban","Suburban","Urban","Rural","Suburban","Rural","Rural","Suburban","Suburban","Suburban","Urban","Urban","Urban","Suburban","Suburban","Urban","Suburban","Suburban","Urban","Suburban","Suburban","Suburban","Suburban","Suburban","Suburban","Rural","Urban","Suburban","Suburban","Urban","Suburban","Rural","Suburban","Rural","Suburban","Urban","Suburban","Urban","Rural","Rural","Urban","Urban","Rural","Suburban","Suburban","Rural","Urban","Suburban","Urban","Urban","Suburban","Suburban","Rural"],[1.62,1.69,4.36,1.71,0.72,1.85,4.66,4.39,4.12,0.21,3.19,3.93,3.61,1.01,2.95,2.13,1.7,2.16,1.89,4.37,1.44,2.03,4.47,4.13,3.66,2.26,2.34,2.45,0.72,1.5,3.16,3.47,0.87,4.02,1.07,2.74,4.9,2.14,0.5,0.93,1.02,0.24,1.48,1.88,1.45,0.68,0.74,4.37,2.19,0.59,0.83,4.46,4.56,4.23,2.79,1.4,4.04,0.43,0.49,1.46,2.52,4.29,3.57,2.14,2.74,0.8,2.58,0.65,0.84,4.5,1.4,3.78,1.78,3.21,1.13,3.64,3.91,4.8,4.81,2.38,4.54,3.4,3.35,3.29,2.32,2.62,3.62,2.08,1.15,2.12,3.06,2.39,2.87,2.07,0.15,1.07,4.86,3.55,0.55,3.42]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>sale_price<\/th>\n      <th>bedrooms<\/th>\n      <th>sqft<\/th>\n      <th>neighbourhood<\/th>\n      <th>school_distance<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"ltipr","autoWidth":true,"columnDefs":[{"className":"dt-left","targets":"_all"},{"width":"200px","targets":"_all"},{"name":"sale_price","targets":0},{"name":"bedrooms","targets":1},{"name":"sqft","targets":2},{"name":"neighbourhood","targets":3},{"name":"school_distance","targets":4}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
</figure>
</div>
</div>
</div>
</div>
</div>
<div class="Tip">
<div class="Tip-header">
<p>Tip on this simulated housing data!</p>
</div>
<div class="Tip-container">
<p>The <code>housing_data</code> mentioned above is not an actual dataset; it is a simulated one designed to effectively illustrate our <strong>data science workflow</strong> in this chapter. This simulated dataset will somehow enable us to meet the assumptions of the chosen model during the <strong>data modelling stage</strong> outlined in <a href="#sec-ds-workflow-modelling" class="quarto-xref"><span>Section 1.2.4</span></a>. If you would like to learn more about this <strong>generative modelling process</strong>, you can refer to <a href="https://github.com/alexrod61/regression-cookbook/blob/main/book/code/housing-data.R">the provided <code>R</code> script</a>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/aha.png" class="img-fluid figure-img" width="300"></p>
<figcaption>Image by <a href="https://pixabay.com/users/manfredsteger-1848497/"><em>Manfred Stege</em></a> via <a href="https://pixabay.com/vectors/pixel-cells-emotion-confused-6230199/"><em>Pixabay</em></a>.</figcaption></figure>
</div>
</div>
</div>
<p>Now, we will randomly split the sampled data into training and testing sets for both <strong>inferential</strong> and <strong>predictive inquiries</strong>. Specifically, 20% of the data will be allocated to the training set, while the remaining 80% will serve as the testing set. For the predictive analysis, we will not create a validation set because our chosen modelling strategy (to be discussed in <a href="#sec-ds-workflow-modelling" class="quarto-xref"><span>Section 1.2.4</span></a>) does not require it. The below codes do the following:</p>
<ul>
<li>
<code>R</code>: This code executes an 80/20 random split of the <code>housing_data</code> dataset using the <a href="https://rsample.tidymodels.org/">{rsample}</a> package <span class="citation" data-cites="rsample">(<a href="references.html#ref-rsample" role="doc-biblioref">Frick et al. 2025</a>)</span>. The <code><a href="https://rdrr.io/r/base/Random.html">set.seed()</a></code> function ensures reproducibility, while <code><a href="https://rsample.tidymodels.org/reference/initial_split.html">initial_split()</a></code> partitions the data into training and testing subsets. The resulting split object is then passed to <code><a href="https://rsample.tidymodels.org/reference/initial_split.html">training()</a></code> and <code><a href="https://rsample.tidymodels.org/reference/initial_split.html">testing()</a></code> to extract the corresponding datasets. A sanity check follows, where <code><a href="https://rdrr.io/r/base/dim.html">dim()</a></code> and <code><a href="https://rdrr.io/r/base/nrow.html">nrow()</a></code> are used to inspect the shapes of each subset and to compute their observed proportions, confirming that the split aligns with the intended allocation.</li>
<li>
<code>Python</code>: This code performs an analogous 80/20 partition of <code>housing_data</code> using <code>train_test_split()</code> from <a href="https://scikit-learn.org/stable/">{scikit-learn}</a> <span class="citation" data-cites="scikit-learn">(<a href="references.html#ref-scikit-learn" role="doc-biblioref">Pedregosa et al. 2011</a>)</span>, with <code>random_state</code> ensuring reproducibility. The function returns the training and testing subsets directly. A subsequent sanity check uses <code>.shape</code> and <code>len()</code> to inspect the size of each subset and to verify the observed proportions of the split, ensuring that the partitioning matches the expected configuration before proceeding with further modelling steps. Note that we also use the <a href="https://pypi.org/project/numpy/">{numpy}</a> library <span class="citation" data-cites="numpy">(<a href="references.html#ref-numpy" role="doc-biblioref">Harris et al. 2020</a>)</span>.</li>
</ul>
<div class="Heads-up">
<div class="Heads-up-header">
<p>Heads-up on the different training and testing sets obtained via <code>R</code> and <code>Python</code>!</p>
</div>
<div class="Heads-up-container">
<p>It turns out that both the <a href="https://rsample.tidymodels.org">{rsample}</a> package in <code>R</code> and <a href="https://scikit-learn.org/stable/">{scikit-learn}</a> in <code>Python</code> utilize different pseudo-random number generators. As a result, they produce <strong>different training and testing data splits</strong>, even when using <strong>the same seed values</strong>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/pieces.png" class="img-fluid figure-img" width="250"></p>
<figcaption>Image by <a href="https://pixabay.com/users/manfredsteger-1848497/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3699345"><em>Manfred Steger</em></a> via <a href="https://pixabay.com/vectors/pixel-cells-pixel-to-learn-3674106/"><em>Pixabay</em></a>.</figcaption></figure>
</div>
</div>
</div>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true"><strong><code>R</code> Code</strong></a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false"><strong><code>Python</code> Code</strong></a></li>
</ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Loading library</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://rsample.tidymodels.org">rsample</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Seed for reproducibility</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Randomly splitting into training and testing sets</span></span>
<span><span class="va">housing_data_splitting</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rsample.tidymodels.org/reference/initial_split.html">initial_split</a></span><span class="op">(</span><span class="va">housing_data</span>,</span>
<span>  prop <span class="op">=</span> <span class="fl">0.2</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Assigning data points to training and testing sets</span></span>
<span><span class="va">training_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rsample.tidymodels.org/reference/initial_split.html">training</a></span><span class="op">(</span><span class="va">housing_data_splitting</span><span class="op">)</span></span>
<span><span class="va">testing_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rsample.tidymodels.org/reference/initial_split.html">testing</a></span><span class="op">(</span><span class="va">housing_data_splitting</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Dimension check</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Training shape:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">training_data</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Testing shape:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">testing_data</span><span class="op">)</span>, <span class="st">"\n\n"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Proportion check</span></span>
<span><span class="va">n_total</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">housing_data</span><span class="op">)</span></span>
<span><span class="va">n_train</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">training_data</span><span class="op">)</span></span>
<span><span class="va">n_test</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">testing_data</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Training proportion:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">n_train</span> <span class="op">/</span> <span class="va">n_total</span>, <span class="fl">3</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span><span class="op">(</span><span class="st">"Testing proportion:"</span>,  <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="va">n_test</span>  <span class="op">/</span> <span class="va">n_total</span>, <span class="fl">3</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Importing libraries</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Seed for reproducibility</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>random_state <span class="op">=</span> <span class="dv">123</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Randomly splitting into training and testing sets</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>training_data, testing_data <span class="op">=</span> train_test_split(</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    housing_data,</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    test_size<span class="op">=</span><span class="fl">0.8</span>,</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span>random_state</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Dimension check</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training shape:"</span>, training_data.shape)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Testing shape:"</span>, testing_data.shape, <span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Proportion check</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>n_total <span class="op">=</span> <span class="bu">len</span>(housing_data)</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>n_train <span class="op">=</span> <span class="bu">len</span>(training_data)</span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>n_test  <span class="op">=</span> <span class="bu">len</span>(testing_data)</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training proportion:"</span>, <span class="bu">round</span>(n_train<span class="op">/</span>n_total, <span class="dv">3</span>))</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Testing proportion:"</span>,  <span class="bu">round</span>(n_test<span class="op">/</span>n_total, <span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true"><strong><code>R</code> Output</strong></a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false"><strong><code>Python</code> Output</strong></a></li>
</ul>
<div class="tab-content">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Training shape: 400 5 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Testing shape: 1600 5 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Training proportion: 0.2 </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Testing proportion: 0.8 </code></pre>
</div>
</div>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>Training shape: (400, 5)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Testing shape: (1600, 5) </code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Training proportion: 0.2</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Testing proportion: 0.8</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>In addition, the code below displays the first 100 rows of our training data, which is a subset of size equal to 400 data points.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-5-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-1" role="tab" aria-controls="tabset-5-1" aria-selected="true"><strong><code>R</code> Code</strong></a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-2" role="tab" aria-controls="tabset-5-2" aria-selected="false"><strong><code>Python</code> Code</strong></a></li>
</ul>
<div class="tab-content">
<div id="tabset-5-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-5-1-tab">
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Showing the first 100 houses of the training set</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html">head</a></span><span class="op">(</span><span class="va">training_data</span>, n <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-5-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-2-tab">
<div class="sourceCode" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Showing the first 100 houses of the training set</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(training_data.head(<span class="dv">100</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-6-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-1" role="tab" aria-controls="tabset-6-1" aria-selected="true"><strong><code>R</code> Output</strong></a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-2" role="tab" aria-controls="tabset-6-2" aria-selected="false"><strong><code>Python</code> Output</strong></a></li>
</ul>
<div class="tab-content">
<div id="tabset-6-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-6-1-tab">
<div class="cell">
<div id="tbl-housing-training-data-r" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-housing-training-data-r-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1.4: First 100 rows of training data.
</figcaption><div aria-describedby="tbl-housing-training-data-r-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div class="datatables html-widget html-fill-item" id="htmlwidget-b6ee110078e168d963ab" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-b6ee110078e168d963ab">{"x":{"filter":"none","vertical":false,"data":[[328372.11,336402.49,224330.72,350962.46,311366.21,401851.84,277221.87,253336.31,371437.5,299061.01,329887.42,422864.64,379760.99,229707.02,326882.84,347689.35,303906.34,306621.76,222982.16,402621.52,325850.92,295566.46,257970.44,187540.03,271990.84,214519.8,384670.03,336840.52,354678.56,291491.89,372905.01,312379.62,273394.36,343748.25,314578.07,408561.44,375747.67,305850.21,264969.14,354596.42,291023.81,347102.68,366287.69,284080.43,279788.48,314066.76,343950.72,315714.24,177526.93,357635.84,283643.65,256114.1,404802.71,280339.4,244576.07,170663.34,233844.17,235022.09,362734.64,265486.43,301700.3,247753.45,358029.48,357346.65,354078.75,332578.33,247195.8,435515.88,430347.85,310116.83,243664.65,410561.39,161707.78,351406.82,247797.3,235602.02,218678.95,296802.37,370105.8,200522.61,359698.57,324144.04,248241.01,356527.34,332378.87,364836.18,356952.91,211181.38,223417.94,297931.7,285433.24,279320,307986.66,315930.57,207239.48,277392.71,303085.5,288726.39,314973.87,274902.91],[3,4,6,5,7,6,4,3,7,4,7,4,4,3,5,4,1,2,4,3,7,3,4,1,1,2,5,2,3,2,6,4,3,9,8,4,8,6,2,5,3,6,4,4,5,4,3,3,3,7,4,4,4,2,1,4,3,3,6,4,5,5,3,5,3,2,3,6,8,5,2,7,2,5,4,1,3,6,5,5,6,3,2,3,5,3,3,4,2,5,2,5,5,4,3,3,4,4,4,4],[1922.96,2000.11,1088.54,1883,1454.56,2284.37,1498.6,1134.66,2001.97,1234.87,1462.84,2278.08,2371.01,1533.34,2062.61,2219.14,1820.72,2199.32,1465.6,2342.73,1663.7,1963.18,1330.96,1409.56,2110.25,1342.67,1891.42,1753.08,1798.06,1644.56,1824.67,1880.73,2271.03,1445.08,1619.27,2165.66,1880.1,2318.17,2171.47,1845.13,2357.87,2187.77,2090.2,1868.52,1668.38,1560.68,1621.63,1776.03,1173.14,1664.45,1422.38,1672.41,1941.72,1989.96,1681.89,992.52,930.35,1308.1,1470.63,1651.22,1590.66,1223.73,1656.43,1883.85,2414.86,1881.47,2036.42,2397.27,1819.56,2399.2,1391.06,2113.78,1100.65,1975.49,1970.09,1256.8,1013.16,1622.02,1993.1,1302.03,2004.04,2589.08,1964.23,2379.15,1676.86,2152.89,2347.62,1231.91,1857.77,1616.79,2014.5,1312.52,1771.55,1984.48,1119.37,1932.24,1725.87,1428.11,1840.78,1553.89],["Rural","Urban","Rural","Suburban","Suburban","Urban","Urban","Suburban","Suburban","Urban","Suburban","Urban","Urban","Suburban","Rural","Urban","Urban","Urban","Rural","Urban","Rural","Urban","Urban","Urban","Suburban","Suburban","Urban","Urban","Suburban","Urban","Urban","Suburban","Rural","Suburban","Suburban","Urban","Suburban","Suburban","Suburban","Suburban","Rural","Suburban","Urban","Suburban","Suburban","Urban","Urban","Suburban","Rural","Urban","Urban","Rural","Urban","Rural","Rural","Suburban","Suburban","Suburban","Urban","Suburban","Suburban","Suburban","Urban","Urban","Suburban","Urban","Suburban","Urban","Urban","Suburban","Rural","Suburban","Rural","Urban","Rural","Suburban","Urban","Suburban","Suburban","Rural","Rural","Suburban","Rural","Suburban","Suburban","Urban","Rural","Suburban","Suburban","Urban","Suburban","Urban","Suburban","Rural","Suburban","Rural","Suburban","Suburban","Urban","Suburban"],[0.12,0.57,3.19,3.23,3.34,4.92,2.44,1.28,1.94,1.92,0.41,2.56,3.12,1.55,4.38,4.37,4.51,3.86,3.69,1.22,1.69,3.86,2.19,2.4,1.49,1.26,2.26,3.62,0.74,2.61,1.39,1.81,2.7,2.68,3.69,0.49,0.95,4.35,0.32,3.41,4.95,2.98,4.85,0.88,1.91,2.1,0.87,2.25,0.5600000000000001,3.01,2.36,0.96,3.38,2.44,3.48,2.13,1.83,4.82,1.88,3.78,3.01,3.75,3.11,1.45,4.1,2.43,3.74,4.53,1.66,3.11,1.02,2.29,2.12,0.77,4.22,2.27,3.42,4.81,2.2,2.75,0.63,4.49,4.21,1.02,0.92,0.42,1.36,2.81,2.32,4.02,1.9,3.61,0.84,1.7,0.82,1.95,4.67,0.37,0.79,2.01]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>sale_price<\/th>\n      <th>bedrooms<\/th>\n      <th>sqft<\/th>\n      <th>neighbourhood<\/th>\n      <th>school_distance<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"ltipr","autoWidth":true,"columnDefs":[{"className":"dt-left","targets":"_all"},{"width":"200px","targets":"_all"},{"name":"sale_price","targets":0},{"name":"bedrooms","targets":1},{"name":"sqft","targets":2},{"name":"neighbourhood","targets":3},{"name":"school_distance","targets":4}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
</figure>
</div>
</div>
</div>
<div id="tabset-6-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-2-tab">
<div class="cell">
<div id="tbl-housing-training-data" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-housing-training-data-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1.5: First 100 rows of training data.
</figcaption><div aria-describedby="tbl-housing-training-data-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div class="datatables html-widget html-fill-item" id="htmlwidget-a8b1e548d7f45115ed62" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-a8b1e548d7f45115ed62">{"x":{"filter":"none","vertical":false,"data":[[301789.93,170663.34,401626.72,274457.02,354078.75,252427.04,369299.14,385866.66,275412.76,310610.71,332378.87,299704.94,297982.18,341533.77,327840.51,293333.96,254474.05,325065.2,477519.67,264212.83,252081.78,330169.45,256145.86,384670.03,323740.16,222101.83,310396.19,244374.23,339775.55,435515.88,296723.86,359109.55,274745.01,283798.11,259794.67,323778.5,338240.64,326409.28,309960.16,331185.66,237860.31,336343.5,314864.66,217741.74,311355.3,340822.56,224354.99,236142.04,387725.27,451087.18,220612.12,339983.19,357204.18,344376.87,276420.4,381547.67,196661.03,236309.43,282710.6,301278.1,332735.25,312791.12,381230.16,289851.18,364836.18,311119.65,222217.95,269381.2,319475.89,362452.05,322667.69,343801.06,299360.74,341504.24,296163.2,314578.07,328970.94,308403.03,257872.05,415667.37,307199.37,394120.02,346491.63,202758.29,315385.33,257438.63,282643.6,246146.16,305503.63,216279.58,298288.3,300593.41,326882.84,306253.85,318209.38,305567.71,352272.56,288129.53,397461.16,210627.05],[2,4,8,4,3,1,5,4,1,2,5,2,2,3,2,4,2,6,9,4,1,4,3,5,4,4,2,5,5,6,4,4,3,3,1,3,3,2,7,7,1,9,4,2,4,7,2,4,7,4,5,3,6,2,4,1,1,3,4,5,5,4,7,4,3,1,5,2,3,4,2,6,5,2,2,8,3,5,1,9,3,8,4,4,5,5,2,4,8,2,8,4,5,4,3,5,6,4,5,3],[1715.5,992.52,2212.77,1662.18,2414.86,1567.93,1645.54,2449.15,1845.85,1782.84,1676.86,1456.39,1522.03,1821.68,1949.74,2317.98,1345.35,1699.6,1943.72,1598.5,1569.35,1467.39,1438.56,1891.42,2067.31,1341.77,1844,1407.05,1384.02,2397.27,1675.89,2411.95,1630.85,2313.58,1617.01,1939.64,1976.12,1741.43,1631.88,1176.87,1739.59,1885.79,1505.37,1419.33,2133.72,2046.9,1430.72,1762.34,1805.56,2685.79,1795.71,2578.65,1936.36,1974,1718.09,2650.42,1746.26,1284.27,1622.03,1865.81,1921.22,1689.64,2163.02,1882.25,2152.89,2262.53,1077.24,1362.68,1971.15,1969.46,1838.76,1999.17,1735.68,2072.73,1746.65,1619.27,2141.45,1723.86,1828.9,1927.16,1062.57,2019.51,2100.65,1552.15,1552.69,2022.9,1615.81,1222.6,1624.57,1115.85,974.51,1883.68,2062.61,2054.38,2149.47,2130.32,1651.86,1365.29,2587.85,1284.51],["Urban","Suburban","Urban","Urban","Suburban","Suburban","Urban","Urban","Suburban","Urban","Suburban","Urban","Urban","Suburban","Urban","Urban","Urban","Suburban","Urban","Urban","Suburban","Urban","Suburban","Urban","Suburban","Rural","Suburban","Urban","Urban","Urban","Suburban","Suburban","Suburban","Rural","Suburban","Urban","Suburban","Urban","Suburban","Urban","Suburban","Suburban","Urban","Rural","Rural","Suburban","Rural","Rural","Suburban","Urban","Suburban","Suburban","Urban","Urban","Urban","Urban","Suburban","Rural","Urban","Suburban","Urban","Suburban","Rural","Urban","Urban","Suburban","Suburban","Urban","Urban","Urban","Urban","Suburban","Urban","Suburban","Urban","Suburban","Urban","Suburban","Suburban","Urban","Urban","Suburban","Urban","Suburban","Urban","Urban","Urban","Urban","Rural","Urban","Urban","Rural","Rural","Urban","Rural","Suburban","Suburban","Urban","Suburban","Suburban"],[2.95,2.13,1.72,2.83,4.1,0.87,4.22,2.12,4.48,3.66,0.92,4.76,2.75,0.86,0.17,3.46,0.64,3.5,2.91,2.33,2.5,0.63,1.49,2.26,3.39,3.66,1.28,1.75,1.69,4.53,1.16,2.31,1.73,4.9,0.5600000000000001,1.69,0.78,3.09,1.92,4.94,4.17,4.65,1.65,4.23,2.34,1.93,3.36,3.83,4.21,1.39,3.29,2.19,0.93,4.01,4.38,1.13,4.03,4.41,3.51,4.14,1.1,1.44,2.43,3.65,0.42,4.26,4.04,0.59,4.25,3.43,0.11,2.05,4.45,2.41,4.96,3.69,4.88,0.51,1.37,1.58,3.39,4.36,4.36,3.98,1.59,4.88,2.28,2.74,1.8,3.9,4.14,4.32,4.38,3.2,2.43,4.15,2.79,1.59,4.58,3.69]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>sale_price<\/th>\n      <th>bedrooms<\/th>\n      <th>sqft<\/th>\n      <th>neighbourhood<\/th>\n      <th>school_distance<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"ltipr","autoWidth":true,"columnDefs":[{"className":"dt-left","targets":"_all"},{"width":"200px","targets":"_all"},{"name":"sale_price","targets":0},{"name":"bedrooms","targets":1},{"name":"sqft","targets":2},{"name":"neighbourhood","targets":3},{"name":"school_distance","targets":4}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
</figure>
</div>
</div>
</div>
</div>
</div>
<p>Due to the use of different pseudo-random number generators for data splitting in <code>R</code> and <code>Python</code>, the <code>training_data</code> in the tables above differs. Now, let us make a necessary clarification about why we need to split the data in inferential inquiries.</p>
<div class="Heads-up">
<div class="Heads-up-header">
<p>Heads-up on data splitting for inferential inquiries!</p>
</div>
<div class="Heads-up-container">
<p>In machine learning, data splitting is a foundational practice designed to prevent data leakage in <strong>predictive inquiries</strong>. However, you may wonder:</p>
<blockquote class="blockquote">
<p><strong>Why should we also split the data for inferential inquiries?</strong></p>
</blockquote>
<p>In the context of statistical inference, especially when making claims about population parameters, data splitting plays a different but important role: it helps prevent <strong>double dipping</strong>. Double dipping refers to the misuse of the same data for both exploring hypotheses (as in EDA) and formally testing those hypotheses. This practice undermines the validity of inferential claims <strong>by increasing the probability of Type I errors</strong>—incorrectly rejecting the null hypothesis <span class="math inline">\(H_0\)</span> when it is actually true for the population under study.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/paint.png" class="img-fluid figure-img" width="525"></p>
<figcaption>Image by <a href="https://pixabay.com/users/manfredsteger-1848497/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3699345"><em>Manfred Steger</em></a> via <a href="https://pixabay.com/vectors/pixel-cells-pixel-social-network-3704049/"><em>Pixabay</em></a>.</figcaption></figure>
</div>
<p>To illustrate this, consider conducting a one-sample <span class="math inline">\(t\)</span>-test in a double-dipping scenario for a population mean <span class="math inline">\(\mu\)</span>. Suppose we first observe a sample mean of <span class="math inline">\(\bar{x} = 9.5\)</span> (i.e., an EDA summary statistic), and then decide to test the null hypothesis</p>
<p><span class="math display">\[\text{$H_0$: } \mu \geq 10\]</span></p>
<p>against the alternative hypothesis</p>
<p><span class="math display">\[\text{$H_1$: } \mu &lt; 10,\]</span></p>
<p><strong>after performing EDA on the same data</strong>. If we proceed with the formal <span class="math inline">\(t\)</span>-test using that same data, we are essentially tailoring the hypothesis to fit our sample. Empirical simulations can show that such practices lead to <strong>inflated false positive rates</strong>, which threaten the reproducibility and integrity of statistical inference.</p>
<p>Unlike predictive modelling, <strong>data splitting is not a routine practice in statistical inference</strong>. However, it becomes relevant when the line between exploration and formal testing is blurred. For more information on double dipping in statistical inference, Chapter 6 of <span class="citation" data-cites="reinhart2015">Reinhart (<a href="references.html#ref-reinhart2015" role="doc-biblioref">2015</a>)</span> offers in-depth insights and some real-life examples.</p>
</div>
</div>
<p>After classifying the variables and splitting our data, we will move on to coding the plots and calculating the summary statistics.</p>
<div class="Heads-up">
<div class="Heads-up-header">
<p>Heads-up on the use of <code>R</code>-generated training and testing for the rest of the data science workflow!</p>
</div>
<div class="Heads-up-container">
<p>We have clarified that both <code>R</code> and <code>Python</code> produce different random data splits, even when using the same seeds. Therefore, in all the following <code>Python</code> code snippets related to this housing price case, we will be utilizing <strong>both the training and testing sets</strong> generated by the <code>R</code>-based data splitting. This approach ensures consistency in our coding outputs.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/idea.png" class="img-fluid figure-img" width="500"></p>
<figcaption>Image by <a href="https://pixabay.com/users/manfredsteger-1848497/"><em>manfredsteger</em></a> via <a href="https://pixabay.com/vectors/idea-visualization-line-art-3976295/"><em>Pixabay</em></a>.</figcaption></figure>
</div>
<p>If you want to reproduce all these outputs in <code>Python</code> using <code>Quarto</code> <span class="citation" data-cites="quarto">(<a href="references.html#ref-quarto" role="doc-biblioref">Allaire et al. 2025</a>)</span>, while utilizing the <code>R</code>-generated sets, you can import these datasets from the <code>R</code> environment using the <a href="https://rstudio.github.io/reticulate/">{reticulate}</a> package <span class="citation" data-cites="reticulate">(<a href="references.html#ref-reticulate" role="doc-biblioref">Ushey, Allaire, and Tang 2025</a>)</span>.</p>
</div>
</div>
<p>As we move forward, we provide a list of plots and summary statistics, along with their corresponding EDA outputs and interpretations. This is based on our training data, which has a size of 400. Note that we are not providing the code to generate all of the EDA output directly (though you can find the <code>R</code> source <a href="https://github.com/alexrod61/regression-cookbook/blob/main/book/01-intro.qmd">here</a>). However, subsequent chapters will include both <code>R</code> and <code>Python</code> code snippets to generate the corresponding EDA insights. Below is the list:</p>
<ul>
<li>A <strong>histogram</strong> of housing sale prices, as in <a href="#fig-histogram-sales-prices" class="quarto-xref">Figure&nbsp;<span>1.4</span></a>, shows the response’s distribution and helps identify any outliers. The training set reveals a <strong>fairly symmetric distribution</strong> of sale prices, with a noticeable concentration of sales between <span class="math inline">\(\$200,000\)</span> and <span class="math inline">\(\$400,000\)</span>. However, there are a few outliers. Even with just 20% of the total data, this plot provides valuable graphical insights into central tendency and variability.</li>
</ul>
<div class="cell">
<div class="cell-output-display">
<div id="fig-histogram-sales-prices" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-histogram-sales-prices-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="01-intro_files/figure-html/fig-histogram-sales-prices-1.png" class="img-fluid figure-img" width="1344">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-histogram-sales-prices-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.4: Histogram of housing sale prices via training set.
</figcaption></figure>
</div>
</div>
</div>
<ul>
<li>Side-by-side <strong>jitter plots</strong>, as in <a href="#fig-jitter-plot-sales-prices-bedrooms" class="quarto-xref">Figure&nbsp;<span>1.5</span></a>, visualize the distribution of sale prices across different bedroom counts, highlighting spread. Overall, these plots indicate a <strong>positive association</strong> between the number of bedrooms and housing sale price. Note that the average price (represented by red diamonds) tends to increase with the addition of more bedrooms. The training set predominantly has homes with 3 to 5 bedrooms, and there are some high-priced outliers present even among mid-sized homes.</li>
</ul>
<div class="cell">
<div class="cell-output-display">
<div id="fig-jitter-plot-sales-prices-bedrooms" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-jitter-plot-sales-prices-bedrooms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="01-intro_files/figure-html/fig-jitter-plot-sales-prices-bedrooms-1.png" class="img-fluid figure-img" width="1344">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-jitter-plot-sales-prices-bedrooms-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.5: Side-by-side jitter plots of housing sale prices by number of bedrooms via training set (red diamonds indicate sale price means by number of bedrooms).
</figcaption></figure>
</div>
</div>
</div>
<ul>
<li>A <strong>scatter plot</strong> displaying the relationship between square footage and housing sale price, as in <a href="#fig-scatter-plot-sqft-sales-prices" class="quarto-xref">Figure&nbsp;<span>1.6</span></a>, illustrates how these two continuous variables interact. There is a clear <strong>upward trend</strong> in the training data, indicated by the fitted solid red line of the simple linear regression (which is a preliminary regression fit used by different plotting tools in <code>R</code> or <code>Python</code>, via the model from <a href="03-ols.html" class="quarto-xref"><span>Chapter 3</span></a>). Although the variability increases with larger square footage, the overall <strong>positive linear pattern</strong> is still clear.</li>
</ul>
<div class="cell">
<div class="cell-output-display">
<div id="fig-scatter-plot-sqft-sales-prices" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-scatter-plot-sqft-sales-prices-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="01-intro_files/figure-html/fig-scatter-plot-sqft-sales-prices-1.png" class="img-fluid figure-img" width="1344">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-scatter-plot-sqft-sales-prices-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.6: Scatter plot of square footage versus housing sale prices via training set (solid red line indicates a simple linear regression fitting).
</figcaption></figure>
</div>
</div>
</div>
<ul>
<li>Side-by-side <strong>box plots</strong>, as in <a href="#fig-box-plot-neighbourhood-sale-prices" class="quarto-xref">Figure&nbsp;<span>1.7</span></a>, are used to compare housing sale prices across different types of neighbourhoods, highlighting variations in median prices. The training data reveals neighbourhood-specific price patterns: urban homes tend to have higher prices, while rural homes are generally less expensive. However, from a graphical perspective, we do not observe major differences in price spreads between these types of neighbourhoods.</li>
</ul>
<div class="cell">
<div class="cell-output-display">
<div id="fig-box-plot-neighbourhood-sale-prices" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-box-plot-neighbourhood-sale-prices-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="01-intro_files/figure-html/fig-box-plot-neighbourhood-sale-prices-1.png" class="img-fluid figure-img" width="1344">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-box-plot-neighbourhood-sale-prices-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.7: Side-by-side box plots of housing sale prices by neighbourhood type via training set.
</figcaption></figure>
</div>
</div>
</div>
<ul>
<li>The <strong>scatter plot</strong> showing the relationship between proximity to schools and housing sale price, as in <a href="#fig-scatter-plot-prox-schools-sales-prices" class="quarto-xref">Figure&nbsp;<span>1.8</span></a>, reveals an <strong>almost flat trend</strong> in the training data. This observation is supported by the fitted solid red line of the simple linear regression (same model from <a href="03-ols.html" class="quarto-xref"><span>Chapter 3</span></a>), indicating a <strong>weak graphical relationship</strong> between these two variables.</li>
</ul>
<div class="cell">
<div class="cell-output-display">
<div id="fig-scatter-plot-prox-schools-sales-prices" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-scatter-plot-prox-schools-sales-prices-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="01-intro_files/figure-html/fig-scatter-plot-prox-schools-sales-prices-1.png" class="img-fluid figure-img" width="1344">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-scatter-plot-prox-schools-sales-prices-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.8: Scatter plot of proximity to schools versus housing sale prices via training set.
</figcaption></figure>
</div>
</div>
</div>
<ul>
<li>
<strong>Descriptive statistics</strong> from <a href="#tbl-housing-data-summary-stats" class="quarto-xref">Table&nbsp;<span>1.6</span></a>, such as the mean and standard deviation, summarize continuous variables. In addition, a <strong>Pearson correlation matrix</strong> from <a href="#tbl-housing-data-correlation-matrix" class="quarto-xref">Table&nbsp;<span>1.7</span></a> numerically assesses the relationships between these variables. Note that square footage is positively correlated with housing sale price, while proximity to schools has a negative association.</li>
</ul>
<div class="cell">
<div id="tbl-housing-data-summary-stats" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-housing-data-summary-stats-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1.6: Descriptive statistics of housing data via training set.
</figcaption><div aria-describedby="tbl-housing-data-summary-stats-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div class="datatables html-widget html-fill-item" id="htmlwidget-6a3fc29c9c09fe032a24" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-6a3fc29c9c09fe032a24">{"x":{"filter":"none","vertical":false,"data":[["Housing Sale Price (CAD)","Number of Bedrooms","Square Footage","Proximity to Schools (km)"],["$306,068","     3.98","1,793.2","     2.52"],["$59,779.36","    1.65","420.15","    1.39"],["$69,991.10","    1.00","775.32","    0.12"],["$495,461","     9.00","3,008.8","     4.99"],["$304,789","     4.00","1,781.6","     2.46"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>Variable<\/th>\n      <th>Mean<\/th>\n      <th>Standard Deviation<\/th>\n      <th>Minimum<\/th>\n      <th>Maximum<\/th>\n      <th>Median<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"dom":"t","paging":false,"scrollX":true,"autoWidth":true,"columnDefs":[{"className":"dt-left","targets":"_all"},{"name":"Variable","targets":0},{"name":"Mean","targets":1},{"name":"Standard Deviation","targets":2},{"name":"Minimum","targets":3},{"name":"Maximum","targets":4},{"name":"Median","targets":5}],"order":[],"orderClasses":false}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
</figure>
</div>
</div>
<div class="cell">
<div id="tbl-housing-data-correlation-matrix" class="cell quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-housing-data-correlation-matrix-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1.7: Pearson correlation matrix of housing data, via training set, for numeric variables.
</figcaption><div aria-describedby="tbl-housing-data-correlation-matrix-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<div>
<figure class="figure"><p><img src="01-intro_files/figure-html/tbl-housing-data-correlation-matrix-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</figure>
</div>
</div>
<p>In <strong>displaying and interpreting results</strong>, the plots and statistics will guide us in understanding the data. In this specific example, these exploratory insights help identify key factors, such as square footage and neighbourhood type, that influence housing sale prices. They also highlight any outliers that may need further attention during modelling. By following this EDA process, we will establish a <strong>solid descriptive foundation</strong> for effective data modelling, ensuring that the key variables and their relationships are well understood.</p>
<p>Finally, this structured approach to EDA is visually summarized in <a href="#fig-ds-workflow-eda" class="quarto-xref">Figure&nbsp;<span>1.9</span></a>, which shows the sequential steps from variable classification to the delivery of exploratory insights.</p>
<div id="fig-ds-workflow-eda" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-ds-workflow-eda-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/eda.png" class="img-fluid figure-img" width="1000">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ds-workflow-eda-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.9: <em>Exploratory data analysis</em> stage from the data science workflow in <a href="#fig-ds-workflow" class="quarto-xref">Figure&nbsp;<span>1.1</span></a>. This stage is directly followed by <em>data modelling</em> and preceded by <em>data collection and wrangling</em>.
</figcaption></figure>
</div>
</section></section><section id="sec-ds-workflow-modelling" class="level3" data-number="1.2.4"><h3 data-number="1.2.4" class="anchored" data-anchor-id="sec-ds-workflow-modelling">
<span class="header-section-number">1.2.4</span> Data Modelling</h3>
<p>The previous EDA provides a solid descriptive foundation regarding the identified types of data for our response variable and regressors, as well as their graphical relationships. This information will guide us in selecting a suitable regression model based on the following factors:</p>
<ol type="a">
<li>The <strong>response type</strong> (e.g., whether it is continuous, bounded or unbounded, count, binary, categorical, etc.).</li>
<li>The <strong>flexibility</strong> of the chosen model (e.g., its ability to handle extreme values or outliers).</li>
<li>Its <strong>interpretability</strong> (i.e., can we effectively communicate our statistical findings to stakeholders?).</li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/blender.png" class="img-fluid figure-img" width="400"></p>
<figcaption>Image by <a href="https://pixabay.com/users/manfredsteger-1848497/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3699345"><em>Manfred Steger</em></a> via <a href="https://pixabay.com/vectors/pixel-cells-blended-learning-6230153/"><em>Pixabay</em></a>.</figcaption></figure>
</div>
<p>In statistical literature, we often encounter <strong>classical linear regression models</strong>, such as the Ordinary Least-squares (OLS) model discussed in <a href="03-ols.html" class="quarto-xref"><span>Chapter 3</span></a>. This model enables us to explain our continuous response variable of interest, denoted as a <strong>random variable <span class="math inline">\(Y\)</span></strong>, in the form of a <strong>linear combination</strong> of a specified set of regressors (the <strong>observed <span class="math inline">\(x\)</span> variables</strong>). A linear combination is essentially an additive relationship where <span class="math inline">\(Y\)</span> depends on the <span class="math inline">\(x\)</span> variables, which are multiplied by <strong>regression coefficients</strong>. Alternatively, for both continuous and discrete response variables, we can utilize more complex models that establish a <strong>non-linear relationship</strong> between <span class="math inline">\(Y\)</span> and the <span class="math inline">\(x\)</span> variables. Some of these models are referred to as generalized linear models (GLMs).</p>
<p>For this workflow stage, whether using a classical linear regression model like OLS or a more complex one such as a GLM (a type of model that is covered in this book along other models that explain <strong>survival time responses</strong>), we need to establish modelling equations that align with both theoretical and data-driven considerations. These modelling equations will need definitions for the parameters, link functions (if applicable as in the case of GLMs), and any relevant distributional assumptions based on the chosen model. Then, once we have defined our modelling equation(s), we can proceed to the estimation stage. Note that this data modelling stage is iterative, as illustrated in <a href="#fig-ds-workflow-data-modelling" class="quarto-xref">Figure&nbsp;<span>1.10</span></a>. The process will depend heavily on the results obtained during the goodness-of-fit stage.</p>
<div id="fig-ds-workflow-data-modelling" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-ds-workflow-data-modelling-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/data-modelling.png" class="img-fluid figure-img" width="1000">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ds-workflow-data-modelling-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.10: <em>Data modelling</em> stage from the data science workflow in <a href="#fig-ds-workflow" class="quarto-xref">Figure&nbsp;<span>1.1</span></a>. This stage is directly preceded by <em>exploratory data analysis</em>. On the other hand, it is directly followed by <em>estimation</em> but indirectly with <em>goodness of fit</em>. If necessary, the <em>goodness-of-fit</em> stage could retake the process to <em>data modelling</em>.
</figcaption></figure>
</div>
<section id="example-ols-regression-model-for-housing-data" class="level4"><h4 class="anchored" data-anchor-id="example-ols-regression-model-for-housing-data">Example: OLS Regression Model for Housing Data</h4>
<p>Let us continue with our housing example, where our response of interest is the <strong>sale price</strong> of a house in CAD, as shown in <a href="#tbl-housing-variables" class="quarto-xref">Table&nbsp;<span>1.1</span></a>. During the study design stage outlined in <a href="#sec-ds-workflow-study-design" class="quarto-xref"><span>Section 1.2.1</span></a>, we identified two key inquiries: <strong>inferential</strong> and <strong>predictive</strong>. The inferential inquiry focuses on understanding the statistical associations between the sale price and other variables, such as square footage, number of bedrooms, and proximity to schools. In contrast, the predictive inquiry involves fitting a suitable model to obtain estimates that will enable us to predict housing sale prices based on these same features.</p>
<p>Before selecting a model, we need to define our mathematical notation for all the variables involved. Let <span class="math inline">\(Y_i\)</span> represent the continuous sale price of the <span class="math inline">\(i\)</span>th house in CAD from a dataset of size <span class="math inline">\(n\)</span> used to estimate a chosen model <strong>in general</strong>, where <span class="math inline">\(i = 1, 2, \ldots, n\)</span>. For the observed explanatory variables, we define the following:</p>
<ul>
<li>
<span class="math inline">\(x_{i, 1}\)</span> is the number of bedrooms in the <span class="math inline">\(i\)</span>th house, which is a count-type variable.</li>
<li>
<span class="math inline">\(x_{i, 2}\)</span> is the continuous square footage of the <span class="math inline">\(i\)</span>th house.</li>
<li>
<span class="math inline">\(x_{i, 3}\)</span> is the continuous proximity to schools for the <span class="math inline">\(i\)</span>th house in km.</li>
</ul>
<p>To mathematically represent the categorical and nominal neighbourhood types to which the <span class="math inline">\(i\)</span>th house could belong, we need more than one variable <span class="math inline">\(x\)</span>. In regression analysis involving nominal explanatory variables, we typically use <strong>binary dummy variables</strong>. In this example, these dummy variables will help us identify the neighbourhood type of each house. Generally, for a nominal variable with <span class="math inline">\(u\)</span> categories, we need to define <span class="math inline">\(u - 1\)</span> dummy variables, as shown in <a href="#tbl-dummy-variables" class="quarto-xref">Table&nbsp;<span>1.8</span></a>.</p>
<div id="tbl-dummy-variables" class="striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-dummy-variables-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1.8: Dummy variable arrangement for a categorical and nominal <span class="math inline">\(x\)</span> with <span class="math inline">\(u\)</span> levels.
</figcaption><div aria-describedby="tbl-dummy-variables-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover caption-top table">
<thead><tr class="header">
<th style="text-align: center;"><strong>Level</strong></th>
<th style="text-align: center;"><span class="math inline">\(x_{i, 1}\)</span></th>
<th style="text-align: center;"><span class="math inline">\(x_{i, 2}\)</span></th>
<th style="text-align: center;"><span class="math inline">\(\cdots\)</span></th>
<th style="text-align: center;"><span class="math inline">\(x_{i, u - 1}\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(1\)</span></td>
<td style="text-align: center;"><span class="math inline">\(0\)</span></td>
<td style="text-align: center;"><span class="math inline">\(0\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\cdots\)</span></td>
<td style="text-align: center;"><span class="math inline">\(0\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(2\)</span></td>
<td style="text-align: center;"><span class="math inline">\(1\)</span></td>
<td style="text-align: center;"><span class="math inline">\(0\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\cdots\)</span></td>
<td style="text-align: center;"><span class="math inline">\(0\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\vdots\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\vdots\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\vdots\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\ddots\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\vdots\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(u\)</span></td>
<td style="text-align: center;"><span class="math inline">\(0\)</span></td>
<td style="text-align: center;"><span class="math inline">\(0\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\cdots\)</span></td>
<td style="text-align: center;"><span class="math inline">\(1\)</span></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<div class="Heads-up">
<div class="Heads-up-header">
<p>Heads-up on how to use dummy variables!</p>
</div>
<div class="Heads-up-container">
<p>In <a href="#tbl-dummy-variables" class="quarto-xref">Table&nbsp;<span>1.8</span></a>, note that level <span class="math inline">\(1\)</span> is considered the <strong>baseline (reference) level</strong>. If the <span class="math inline">\(i\)</span>th observation belongs to level <span class="math inline">\(1\)</span>, then all the dummy variables <span class="math inline">\(x_{i, 1}, \ldots, x_{i, u - 1}\)</span> will take the value of <span class="math inline">\(0\)</span>. The choice of baseline affects how we interpret the estimated regression coefficients later in our data science workflow.</p>
</div>
</div>
<p><a href="#tbl-dummy-variables-neighbourhood" class="quarto-xref">Table&nbsp;<span>1.9</span></a> shows the dummy variable arrangement for our housing example regarding the neighbourhood type <strong>where <em>rural</em> is the baseline level</strong>. Since we have three levels (<em>rural</em>, <em>suburban</em>, and <em>urban</em>), our chosen model will have two binary dummy variables for the <span class="math inline">\(i\)</span>th house:</p>
<p><span id="eq-dummy-housing-1"><span class="math display">\[
x_{i, 4} =
\begin{cases}
1 \quad \text{if the house belongs to a suburban neighbourhood},\\
0 \quad \text{otherwise};
\end{cases}
\tag{1.1}\]</span></span></p>
<p>and</p>
<p><span id="eq-dummy-housing-2"><span class="math display">\[
x_{i, 5} =
\begin{cases}
1 \quad \text{if the house belongs to an urban neighbourhood},\\
0 \quad \text{otherwise}.
\end{cases}
\tag{1.2}\]</span></span></p>
<div id="tbl-dummy-variables-neighbourhood" class="striped hover quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure"><figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-dummy-variables-neighbourhood-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1.9: Dummy variable arrangement for the categorical and nominal neighbourhood type with <span class="math inline">\(3\)</span> levels.
</figcaption><div aria-describedby="tbl-dummy-variables-neighbourhood-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="table-striped table-hover caption-top table">
<thead><tr class="header">
<th style="text-align: center;"><strong>Level</strong></th>
<th style="text-align: center;"><span class="math inline">\(x_{i,4}\)</span></th>
<th style="text-align: center;"><span class="math inline">\(x_{i,5}\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\text{Rural}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(0\)</span></td>
<td style="text-align: center;"><span class="math inline">\(0\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;"><span class="math inline">\(\text{Suburban}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(1\)</span></td>
<td style="text-align: center;"><span class="math inline">\(0\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\text{Urban}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(0\)</span></td>
<td style="text-align: center;"><span class="math inline">\(1\)</span></td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>With the mathematical notation for our data variables defined, it is time to choose a suitable regression model to address our inferential and predictive inquiries. Since the nature of <span class="math inline">\(Y_i\)</span> is continuous, we may consider using OLS regression, as outlined in <a href="03-ols.html" class="quarto-xref"><span>Chapter 3</span></a>, although there is an important <strong>distributional matter</strong> to be highlighted at the end of this section. OLS is typically the first regression model to explore because it is a widely used model that is easy to understand and communicate to stakeholders. We refer to OLS as a <strong>parametric model</strong>, a distinction that other models, such as the GLMs, also have. Let us define this type of model below.</p>
<div id="Definition-parametric-model" class="definition">
<div class="definition-header">
<p>Definition of parametric model</p>
</div>
<div class="definition-container">
<p>A parametric model is a type of model that assumes a specific functional relationship between the response variable of interest, <span class="math inline">\(Y\)</span>, which is considered a <strong>random variable</strong>, and one or more <strong>observed explanatory variables</strong>, <span class="math inline">\(x\)</span>. This relationship is characterized by a finite set of parameters and can often be expressed as a linear combination of the observed <span class="math inline">\(x\)</span> variables, which favours <strong>interpretability</strong>.</p>
<p>Moreover, since <span class="math inline">\(Y\)</span> is a random variable, there is room to make further assumptions on it in the form of a probability distribution, independence or even homoscedasticity (the condition where all responses in the population have the same variance). It is essential to test these assumptions after fitting this type of models, as any deviations may result in <strong>misleading or biased</strong> estimates, predictions, and inferential conclusions.</p>
</div>
</div>
<p>A parametric model, as previously mentioned, allows us to prioritize interpretability in our regression analysis, and OLS offers this advantageous characteristic. The classical setup of OLS describes the relationship between the response variable <span class="math inline">\(Y\)</span> and the observed variables <span class="math inline">\(x\)</span> as a linear combination, represented by the following equation for <span class="math inline">\(i = 1, 2, \ldots, n\)</span> in this housing price example:</p>
<p><span id="eq-housing-OLS"><span class="math display">\[
Y_i = \underbrace{\beta_0 + \beta_1 x_{i, 1} + \beta_2 x_{i, 2} + \beta_3 x_{i, 3} + \beta_4 x_{i, 4} + \beta_5 x_{i, 5}}_{\text{Systematic Component}} + \underbrace{\varepsilon_i.}_{\substack{\text{Random} \\ \text{Component}}}
\tag{1.3}\]</span></span></p>
<p><a href="#eq-housing-OLS" class="quarto-xref">Equation&nbsp;<span>1.3</span></a> indicates two important components in this regression model on its righ-hand side:</p>
<ol type="1">
<li>
<strong>Systematic Component:</strong> This component includes six <strong>fixed and unknown</strong> regression parameters (<span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, <span class="math inline">\(\beta_2\)</span>, <span class="math inline">\(\beta_3\)</span>, <span class="math inline">\(\beta_4\)</span>, and <span class="math inline">\(\beta_5\)</span>) that we will estimate in the next stage using our training data. Note that this component represents the expected value of the response variable <span class="math inline">\(Y\)</span>, <strong>conditioned on the observed values of the regressors</strong> and it is also the result of the assumptions on the random component below:</li>
</ol>
<p><span id="eq-expected-housing"><span class="math display">\[
\begin{align*}
\mathbb{E}(Y_i \mid x_{i, 1}, \ldots, x_{i, 5}) &amp;= \beta_0 + \beta_1 x_{i, 1} + \beta_2 x_{i, 2} + \\
&amp; \qquad \beta_3 x_{i, 3} + \beta_4 x_{i, 4} + \beta_5 x_{i, 5}.
\end{align*}
\tag{1.4}\]</span></span></p>
<ol start="2" type="1">
<li>
<strong>Random Component:</strong> For the <span class="math inline">\(i\)</span>th observation, this is denoted by the random variable <span class="math inline">\(\varepsilon_i\)</span>. This component measures how much the observed value of the response may deviate from its conditioned mean, and <strong>it is considered random noise</strong>. Since <span class="math inline">\(\varepsilon_i\)</span> is assumed to be a random variable and is added to a fixed systematic component on the right-hand side of <a href="#eq-housing-OLS" class="quarto-xref">Equation&nbsp;<span>1.3</span></a>, this aligns with the notion that <span class="math inline">\(Y_i\)</span> is treated as a random variable on the left-hand side.</li>
</ol>
<p>We also need to state the modelling assumptions for this OLS case:</p>
<ul>
<li>Each observed regressor on the right-hand side of the <a href="#eq-housing-OLS" class="quarto-xref">Equation&nbsp;<span>1.3</span></a> has an associated <strong>regression coefficient</strong> <span class="math inline">\(\beta_j\)</span> for <span class="math inline">\(j = 1, 2, \ldots, 5\)</span> (these were already indicated as part of the regression parameters). These coefficients represent the expected change in the response variable when a specific regressor <span class="math inline">\(x_{i,j}\)</span> changes by one unit. Additionally, the regression parameter <span class="math inline">\(\beta_0\)</span> serves as the <strong>intercept</strong> of this linear model, representing the mean of the response when all five regressors are equal to zero. This entire arrangement allows for a more interpretable model and aids in addressing our inferential inquiry.</li>
<li>To pave the way for the corresponding inferential test in OLS, the error term <span class="math inline">\(\varepsilon_i\)</span> is typically assumed to be <strong>normally distributed</strong> with a <strong>mean of zero</strong> (this mean is consistent with the conditioned expected value outlined in <a href="#eq-expected-housing" class="quarto-xref">Equation&nbsp;<span>1.4</span></a>). Additionally, it is assumed that the variance is constant across observations, referred to as the so-called <strong>homoscedasticity</strong>, and denoted as <span class="math inline">\(\sigma^2\)</span> (another regression parameter fixed and unknown to estimate via the training set). Furthermore, all error terms <span class="math inline">\(\varepsilon_i\)</span> are assumed to be <strong>statistically independent</strong>. These assumptions can be mathematically represented as follows:</li>
</ul>
<p><span class="math display">\[
\begin{gather*}
\mathbb{E}(\varepsilon_i) = 0 \\
\text{Var}(\varepsilon_i) = \sigma^2 \\
\varepsilon_i \sim \text{Normal}(0, \sigma^2) \\
\varepsilon_i \perp \!\!\! \perp \varepsilon_k \; \; \; \; \text{for} \; i \neq k  \; \; \; \; \text{(independence)}.
\end{gather*}
\]</span></p>
<div class="Heads-up">
<div class="Heads-up-header">
<p>Heads-up on the use of an alternative systematic component!</p>
</div>
<div class="Heads-up-container">
<p>The systematic component in <a href="#eq-housing-OLS" class="quarto-xref">Equation&nbsp;<span>1.3</span></a> is considered <strong>linear with respect to the regression parameters</strong> <span class="math inline">\(\beta_1\)</span>, <span class="math inline">\(\beta_2\)</span>, <span class="math inline">\(\beta_3\)</span>, <span class="math inline">\(\beta_4\)</span>, and <span class="math inline">\(\beta_5\)</span>. Therefore, we can model the regressors using mathematical transformations, such as the following polynomial:</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 x_{i, 1} + \beta_2 x_{i, 2}^2 + \beta_3 x_{i, 3}^3 + \beta_4 x_{i, 4} + \beta_5 x_{i, 5} + \varepsilon_i.
\]</span></p>
<p>This linearity condition on the parameters makes our OLS model flexible enough to improve accuracy in predictive inquiries. However, we would sacrifice some interpretability for inferential inquiries.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/surprise.png" class="img-fluid figure-img" width="475"></p>
<figcaption>Image by <a href="https://pixabay.com/users/manfredsteger-1848497/"><em>Manfred Stege</em></a> via <a href="https://pixabay.com/vectors/pixel-cells-emotion-pressure-6230208/"><em>Pixabay</em></a>.</figcaption></figure>
</div>
</div>
</div>
<p>Before we conclude this stage, note that <a href="02-stats-review.html" class="quarto-xref"><span>Chapter 2</span></a> will explore the fundamentals of probability and statistical inference in greater depth. This exploration will enhance our understanding of the modelling assumptions underlying the regression models discussed throughout this book. Additionally, we will broaden our perspective on regression to consider more appropriate models for <strong>nonnegative responses</strong>, instead of relying on OLS with the assumption of an <strong>unbounded, normally distributed response</strong> which might be unrealistic for nonnegative housing prices (and still a mild violation on our response assumptions, given that the housing prices appear to have a bell-shaped distribution as shown in <a href="#fig-histogram-sales-prices" class="quarto-xref">Figure&nbsp;<span>1.4</span></a>).</p>
</section></section><section id="sec-ds-workflow-estimation" class="level3" data-number="1.2.5"><h3 data-number="1.2.5" class="anchored" data-anchor-id="sec-ds-workflow-estimation">
<span class="header-section-number">1.2.5</span> Estimation</h3>
<p>Based on the data we have and our EDA, defining a suitable regression model (along with the equations that relate the response variable <span class="math inline">\(Y\)</span> to the regressors <span class="math inline">\(x\)</span> and the corresponding regression parameters) is an essential step in our data science workflow. This leads us to the next stage: <strong>estimation</strong>. In this stage, we aim to obtain what we refer to as <strong>modelling estimates</strong> using our <strong>training dataset</strong>. The method we choose for estimation largely depends on the specific regression model we adopt to address our inquiries.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/plug.png" class="img-fluid figure-img" width="500"></p>
<figcaption>Image by <a href="https://pixabay.com/users/manfredsteger-1848497/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3699345"><em>Manfred Steger</em></a> via <a href="https://pixabay.com/vectors/pixel-cells-pixel-college-3702064/"><em>Pixabay</em></a>.</figcaption></figure>
</div>
<p>In all core chapters of this book, except for <a href="03-ols.html" class="quarto-xref"><span>Chapter 3</span></a>, the default method we will use is <strong>maximum likelihood estimation (MLE)</strong> (the fundamental insights are provided in <a href="02-stats-review.html#sec-mle" class="quarto-xref"><span>Section 2.2</span></a>). Regardless of the chosen estimation method, these estimates (denoted with a hat notation) will allow us to quantify the association (or causation, if applicable) between the outcome variable <span class="math inline">\(Y\)</span> and the <span class="math inline">\(x\)</span> regressors. This is particularly relevant in inferential inquiries, provided that the results are statistically significant, as discussed in <a href="#sec-ds-workflow-results" class="quarto-xref"><span>Section 1.2.7</span></a>.</p>
<p>As illustrated in <a href="#fig-ds-workflow-estimation" class="quarto-xref">Figure&nbsp;<span>1.11</span></a>, the data modelling stage will yield the necessary components for this phase in the form of a suitable model, modelling equation, and regression parameters. We will then use the corresponding <code>R</code> or <code>Python</code> fitting function, where the inputs will include the coded modelling equation (which contains the variables of interest: the outcome and the regressors) along with the training set. These fitting functions serve the following purposes:</p>
<ul>
<li>In most regression models, obtaining analytical (i.e., exact) solutions for our <strong>parameter estimates</strong> is not feasible. Specifically, MLE can employ an optimization method such as <strong>Newton-Raphson</strong> or <strong>iteratively reweighted least squares (IRLS)</strong>, as we aim to <strong>maximize</strong> the log-likelihood function that involves our observed data and unknown parameters. This function is numerically optimized to estimate these parameters. More information regarding numerical optimization in MLE, including a brief discussion of the Newton-Raphson method, can be found in <a href="02-stats-review.html#sec-num-optimization" class="quarto-xref"><span>Section 2.2.3</span></a>. Throughout the core chapters of the book, we will delve deeper into the fundamentals of IRLS.</li>
<li>Once the estimation process has been completed using the appropriate log-likelihood function and numerical optimization method (i.e., when the method has converged to an optimal solution), we will obtain outputs that include <strong>parameter estimates</strong>. These parameter estimates will be used in the subsequent workflow stage, called goodness of fit, to statistically assess whether our <strong>fitted model</strong> satisfies the assumptions we made about our data in the previous modelling stage.</li>
</ul>
<div id="fig-ds-workflow-estimation" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-ds-workflow-estimation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/estimation.png" class="img-fluid figure-img" width="1000">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ds-workflow-estimation-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.11: <em>Estimation</em> stage from the data science workflow in <a href="#fig-ds-workflow" class="quarto-xref">Figure&nbsp;<span>1.1</span></a>. This stage is directly preceded by <em>data modelling</em> and followed by <em>goodness of fit</em>. If necessary, the <em>goodness-of-fit</em> stage could retake the process to <em>data modelling</em> and then to <em>estimation</em>.
</figcaption></figure>
</div>
<section id="example-fitting-the-ols-regression-model-for-housing-data" class="level4"><h4 class="anchored" data-anchor-id="example-fitting-the-ols-regression-model-for-housing-data">Example: Fitting the OLS Regression Model for Housing Data</h4>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/houses.png" class="img-fluid figure-img" width="400"></p>
<figcaption>Image by <a href="https://pixabay.com/users/gustavorezende-1488336/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=8500500"><em>Gustavo Rezende</em></a> via <a href="https://pixabay.com/vectors/town-city-village-isometric-houses-8500500/"><em>Pixabay</em></a>.</figcaption></figure>
</div>
<p>Let us examine the <code>training_data</code> for this housing case, which consists of 400 observations. As shown in <a href="#tbl-housing-variables" class="quarto-xref">Table&nbsp;<span>1.1</span></a>, for the <span class="math inline">\(i\)</span>th house, we have different regressors: the number of bedrooms (<code>bedrooms</code>, denoted as <span class="math inline">\(x_{i, 1}\)</span>), the continuous square footage (<code>sqft</code>, denoted as <span class="math inline">\(x_{i, 2}\)</span>), the continuous proximity to schools in km (<code>school_distance</code>, denoted as <span class="math inline">\(x_{i, 3}\)</span>), and neighborhood type (represented by dummy variables <span class="math inline">\(x_{i, 4}\)</span> as in <a href="#eq-dummy-housing-1" class="quarto-xref">Equation&nbsp;<span>1.1</span></a> and <span class="math inline">\(x_{i, 5}\)</span> as in <a href="#eq-dummy-housing-2" class="quarto-xref">Equation&nbsp;<span>1.2</span></a>, where <em>rural</em> is the baseline). The response variable we are interested in is the continuous housing sale price in CAD (<code>sale price</code>, denoted as <span class="math inline">\(Y_i\)</span>). Additionally, we will revisit our modelling approach as outlined in <a href="#eq-housing-OLS" class="quarto-xref">Equation&nbsp;<span>1.3</span></a>:</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 x_{i, 1} + \beta_2 x_{i, 2} + \beta_3 x_{i, 3} + \beta_4 x_{i, 4} + \beta_5 x_{i, 5} + \varepsilon_i,
\]</span></p>
<p>where <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span>, <span class="math inline">\(\beta_2\)</span>, <span class="math inline">\(\beta_3\)</span>, <span class="math inline">\(\beta_4\)</span>, and <span class="math inline">\(\beta_5\)</span> represent the unknown regression parameters to be estimated to address our inferential and predictive inquiries. Additionally, we have another parameter to estimate, that is the common variance between the random components of each observation (<span class="math inline">\(i = 1, 2, \ldots, n\)</span>):</p>
<p><span class="math display">\[
\text{Var}(\varepsilon_i) = \sigma^2.
\]</span></p>
<p>Having set up the coding starting point for this estimation, we need to use the corresponding fitting functions to find <span class="math inline">\(\hat{\beta}_0\)</span>, <span class="math inline">\(\hat{\beta}_1\)</span>, <span class="math inline">\(\hat{\beta}_2\)</span>, <span class="math inline">\(\hat{\beta}_3\)</span>, <span class="math inline">\(\hat{\beta}_4\)</span>, <span class="math inline">\(\hat{\beta}_5\)</span>, <span class="math inline">\(\hat{\sigma}^2\)</span> via OLS regression (as we already decided in the data modelling stage). Therefore, let us the following function and libraries:</p>
<ul>
<li>
<code>R</code>: We fit and summarize an OLS model using the <a href="https://www.tidyverse.org">{tidyverse}</a> and <a href="https://broom.tidymodels.org/reference/broom.html">{broom}</a> <span class="citation" data-cites="broom">(<a href="references.html#ref-broom" role="doc-biblioref">Robinson, Hayes, and Couch 2025</a>)</span> packages. It first loads the two libraries, which provide tools for data manipulation and for converting model outputs into tidy data frames, respectively. The <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> function then fits the OLS regression model for the response <code>sale_price</code> from four explanatory variables: <code>bedrooms</code>, <code>sqft</code>, <code>school_distance</code>, and <code>neighbourhood</code> via the <code>training_data</code>. The resulting model object, stored in <code>training_OLS_model</code>, contains the estimated parameters (column <code>estimate</code>) and related statistics (which will be explained in the <strong>results</strong> stage via the <strong>testing set</strong>). The <code><a href="https://generics.r-lib.org/reference/tidy.html">tidy()</a></code> function from <a href="https://broom.tidymodels.org/reference/broom.html">{broom}</a> transforms this model output into a neat, tabular format. Finally, <code><a href="https://dplyr.tidyverse.org/reference/mutate_all.html">mutate_if()</a></code> rounds all numeric columns in this tidy summary to two decimal places, producing a clean, readable table of regression results.</li>
<li>
<code>Python</code>: This code fits and summarizes the same OLS model using the <a href="https://www.statsmodels.org/stable/index.html">{statsmodels}</a> <span class="citation" data-cites="statsmodels">(<a href="references.html#ref-statsmodels" role="doc-biblioref">Seabold and Perktold 2010</a>)</span>, <a href="https://pypi.org/project/pandas/">{pandas}</a>, and <a href="https://pypi.org/project/numpy/">{numpy}</a> libraries. It begins by specifying and fitting this OLS model through <code>smf.ols()</code>, which regresses <code>sale_price</code> based on four explanatory variables: <code>bedrooms</code>, <code>sqft</code>, <code>school_distance</code>, and <code>neighbourhood</code> via the <code>training_data</code>. The <code>.fit()</code> method estimates the regression coefficients and computes related statistics. Next, a tidy summary table is created using <code>pd.DataFrame()</code>, which organizes the model output into a clear format. Each numeric value is rounded to two decimal places with <code>np.round()</code> for readability. Finally, the code prints this table, providing a concise, easy-to-read summary of the regression model.</li>
</ul>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-7-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-1" role="tab" aria-controls="tabset-7-1" aria-selected="true"><strong><code>R</code></strong></a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-7-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-2" role="tab" aria-controls="tabset-7-2" aria-selected="false"><strong><code>Python</code></strong></a></li>
</ul>
<div class="tab-content">
<div id="tabset-7-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-7-1-tab">
<div class="cell">
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Loading libraries</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://broom.tidymodels.org/">broom</a></span><span class="op">)</span></span>
<span><span class="co"># To import R-generated datasets to Python environment</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://rstudio.github.io/reticulate/">reticulate</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Fitting the OLS model</span></span>
<span><span class="va">training_OLS_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="va">sale_price</span> <span class="op">~</span> <span class="va">bedrooms</span> <span class="op">+</span> <span class="va">sqft</span> <span class="op">+</span></span>
<span>    <span class="va">school_distance</span> <span class="op">+</span> <span class="va">neighbourhood</span>,</span>
<span>  data <span class="op">=</span> <span class="va">training_data</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Displaying the tidy table</span></span>
<span><span class="fu"><a href="https://generics.r-lib.org/reference/tidy.html">tidy</a></span><span class="op">(</span><span class="va">training_OLS_model</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate_all.html">mutate_if</a></span><span class="op">(</span><span class="va">is.numeric</span>, <span class="va">round</span>, <span class="fl">2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 5
  term                  estimate std.error statistic p.value
  &lt;chr&gt;                    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
1 (Intercept)            53948.     8029.       6.72       0
2 bedrooms               14107.      860.      16.4        0
3 sqft                      99.0       3.4     29.1        0
4 school_distance        -6964.     1032.      -6.75       0
5 neighbourhoodSuburban  26908.     3999.       6.73       0
6 neighbourhoodUrban     60509.     3970.      15.2        0</code></pre>
</div>
</div>
</div>
<div id="tabset-7-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-7-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Importing libraries</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.formula.api <span class="im">as</span> smf</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Importing R-generated training set via R library reticulate</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>training_data <span class="op">=</span> r.training_data</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Fitting the OLS model</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>training_OLS_model <span class="op">=</span> smf.ols(</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    formula<span class="op">=</span><span class="st">"sale_price ~ bedrooms + sqft + school_distance + neighbourhood"</span>,</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    data<span class="op">=</span>training_data</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>).fit()</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating a tidy summary table</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>training_OLS_tidy <span class="op">=</span> pd.DataFrame({</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">"term"</span>: training_OLS_model.params.index,</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">"estimate"</span>: np.<span class="bu">round</span>(training_OLS_model.params.values, <span class="dv">2</span>),</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>    <span class="st">"std_error"</span>: np.<span class="bu">round</span>(training_OLS_model.bse.values, <span class="dv">2</span>),</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">"t_value"</span>: np.<span class="bu">round</span>(training_OLS_model.tvalues.values, <span class="dv">2</span>),</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">"p_value"</span>: np.<span class="bu">round</span>(training_OLS_model.pvalues.values, <span class="dv">2</span>)</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Displaying the tidy table</span></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(training_OLS_tidy)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                        term  estimate  std_error  t_value  p_value
0                  Intercept  53948.21    8029.29     6.72      0.0
1  neighbourhood[T.Suburban]  26908.04    3998.83     6.73      0.0
2     neighbourhood[T.Urban]  60509.46    3969.56    15.24      0.0
3                   bedrooms  14107.19     859.81    16.41      0.0
4                       sqft     99.01       3.40    29.12      0.0
5            school_distance  -6963.93    1031.76    -6.75      0.0</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="Heads-up">
<div class="Heads-up-header">
<p>Heads-up on the OLS analytical estimates!</p>
</div>
<div class="Heads-up-container">
<p>Unlike GLMs, which will be discussed beginning in <a href="04-gamma.html" class="quarto-xref"><span>Chapter 4</span></a>, OLS regression provides exact analytical estimates. Therefore, it is not necessary to rely on numerical optimization in this case. You can find further details about this matter in <a href="03-ols.html" class="quarto-xref"><span>Chapter 3</span></a>.</p>
</div>
</div>
<p>Since the <strong>inferential inquiry</strong> in this example aims to understand the <strong>statistical associations</strong> between housing sale prices and their explanatory variables, while the <strong>predictive inquiry</strong> seeks to fit a suitable model that allows us to <strong>predict housing sale prices</strong> based on these same features, we might be tempted to use <code>training_OLS_model</code> to address both inquiries right away. However, according to our data science workflow, these analyses should be conducted during the <strong>results stage</strong>, after we have completed model diagnostic checks. For now, we will use the <code>training_data</code> and <code>training_OLS_model</code> to perform this corresponding <strong>goodness of fit</strong> in the next stage.</p>
</section></section><section id="sec-ds-workflow-goodness-of-fit" class="level3" data-number="1.2.6"><h3 data-number="1.2.6" class="anchored" data-anchor-id="sec-ds-workflow-goodness-of-fit">
<span class="header-section-number">1.2.6</span> Goodness of Fit</h3>
<div id="fig-ds-workflow-goodness-of-fit" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-ds-workflow-goodness-of-fit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/goodness-of-fit.png" class="img-fluid figure-img" width="1000">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ds-workflow-goodness-of-fit-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.12: <em>Goodness-of-fit</em> stage from the data science workflow in <a href="#fig-ds-workflow" class="quarto-xref">Figure&nbsp;<span>1.1</span></a>. This stage is directly preceded by <em>estimation</em> and followed by <em>results</em>. If necessary, the <em>goodness-of-fit</em> stage could retake the process to <em>data modelling</em> and then to <em>estimation</em>.
</figcaption></figure>
</div>
</section><section id="sec-ds-workflow-results" class="level3" data-number="1.2.7"><h3 data-number="1.2.7" class="anchored" data-anchor-id="sec-ds-workflow-results">
<span class="header-section-number">1.2.7</span> Results</h3>
<!--
and **standard errors**. Note that standard errors are essential for inferential inquiries, as they are used in **hypothesis testing**. Additionally, these standard errors can be utilized in a later workflow stage to calculate **confidence intervals (CIs)** for our **statistically significant** estimated regression parameters. CIs provide a measure of uncertainty associated with the estimations derived from the sampled data. For a refresher on statistical inference, please refer to @sec-basics-inf.

-->
<div id="fig-ds-workflow-results" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-ds-workflow-results-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/results.png" class="img-fluid figure-img" width="1000">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ds-workflow-results-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.13: <em>Results</em> stage from the data science workflow in <a href="#fig-ds-workflow" class="quarto-xref">Figure&nbsp;<span>1.1</span></a>. This stage is directly followed by <em>storytelling</em> and preceded by <em>goodness of fit</em>.
</figcaption></figure>
</div>
</section><section id="sec-ds-workflow-storytelling" class="level3" data-number="1.2.8"><h3 data-number="1.2.8" class="anchored" data-anchor-id="sec-ds-workflow-storytelling">
<span class="header-section-number">1.2.8</span> Storytelling</h3>
<div id="fig-ds-workflow-storytelling" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-ds-workflow-storytelling-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/storytelling.png" class="img-fluid figure-img" width="1000">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ds-workflow-storytelling-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.14: <em>Storytelling</em> stage from the data science workflow in <a href="#fig-ds-workflow" class="quarto-xref">Figure&nbsp;<span>1.1</span></a>. This stage preceded by <em>results</em>.
</figcaption></figure>
</div>
</section></section><section id="sec-regression-mindmap" class="level2" data-number="1.3"><h2 data-number="1.3" class="anchored" data-anchor-id="sec-regression-mindmap">
<span class="header-section-number">1.3</span> Mind Map of Regression Analysis</h2>
<br><center>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/mind-map.png" class="img-fluid figure-img" width="350"></p>
<figcaption>Image by <a href="https://pixabay.com/users/manfredsteger-1848497/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3699345"><em>Manfred Steger</em></a> via <a href="https://pixabay.com/vectors/pixel-cells-pixel-mindmap-3704048/"><em>Pixabay</em></a>.</figcaption></figure>
</div>
</center>
<p>Having defined the necessary statistical aspects to execute a proper supervised learning analysis, either <em>inferential</em> or <em>predictive</em> across its seven sequential phases, we must dig into the different approaches we might encounter in practice as regression models. The nature of our outcome of interest will dictate any given modelling approach to apply, depicted as clouds in <a href="#fig-regression-mindmap" class="quarto-xref">Figure&nbsp;<span>1.15</span></a>. Note these regression models can be split into two sets depending on whether the outcome of interest is <em>continuous</em> or <em>discrete</em>. Therefore, under a probabilistic view, identifying the nature of a given random variable is crucial in regression analysis.</p>
<div id="fig-regression-mindmap" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-regression-mindmap-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"></figure><p></p>
<div>
<pre class="mermaid mermaid-js">mindmap
  root((Regression 
  Analysis)
    Continuous &lt;br/&gt;Outcome Y
      {{Unbounded &lt;br/&gt;Outcome Y}}
        )Chapter 3: &lt;br/&gt;Ordinary &lt;br/&gt;Least Squares &lt;br/&gt;Regression(
          (Normal &lt;br/&gt;Outcome Y)
      {{Nonnegative &lt;br/&gt;Outcome Y}}
        )Chapter 4: &lt;br/&gt;Gamma Regression(
          (Gamma &lt;br/&gt;Outcome Y)
      {{Bounded &lt;br/&gt;Outcome Y &lt;br/&gt; between 0 and 1}}
        )Chapter 5: Beta &lt;br/&gt;Regression(
          (Beta &lt;br/&gt;Outcome Y)
      {{Nonnegative &lt;br/&gt;Survival &lt;br/&gt;Time Y}}
        )Chapter 6: &lt;br/&gt;Parametric &lt;br/&gt; Survival &lt;br/&gt;Regression(
          (Exponential &lt;br/&gt;Outcome Y)
          (Weibull &lt;br/&gt;Outcome Y)
          (Lognormal &lt;br/&gt;Outcome Y)
        )Chapter 7: &lt;br/&gt;Semiparametric &lt;br/&gt;Survival &lt;br/&gt;Regression(
          (Cox Proportional &lt;br/&gt;Hazards Model)
            (Hazard Function &lt;br/&gt;Outcome Y)
    Discrete &lt;br/&gt;Outcome Y
      {{Binary &lt;br/&gt;Outcome Y}}
        {{Ungrouped &lt;br/&gt;Data}}
          )Chapter 8: &lt;br/&gt;Binary Logistic &lt;br/&gt;Regression(
            (Bernoulli &lt;br/&gt;Outcome Y)
        {{Grouped &lt;br/&gt;Data}}
          )Chapter 9: &lt;br/&gt;Binomial Logistic &lt;br/&gt;Regression(
            (Binomial &lt;br/&gt;Outcome Y)
      {{Count &lt;br/&gt;Outcome Y}}
        {{Equidispersed &lt;br/&gt;Data}}
          )Chapter 10: &lt;br/&gt;Classical Poisson &lt;br/&gt;Regression(
            (Poisson &lt;br/&gt;Outcome Y)
        {{Overdispersed &lt;br/&gt;Data}}
          )Chapter 11: &lt;br/&gt;Negative Binomial &lt;br/&gt;Regression(
            (Negative Binomial &lt;br/&gt;Outcome Y)
        {{Overdispersed or &lt;br/&gt;Underdispersed &lt;br/&gt;Data}}
          )Chapter 13: &lt;br/&gt;Generalized &lt;br/&gt;Poisson &lt;br/&gt;Regression(
            (Generalized &lt;br/&gt;Poisson &lt;br/&gt;Outcome Y)
        {{Zero Inflated &lt;br/&gt;Data}}
          )Chapter 12: &lt;br/&gt;Zero Inflated &lt;br/&gt;Poisson &lt;br/&gt;Regression(
            (Zero Inflated &lt;br/&gt;Poisson &lt;br/&gt;Outcome Y)
      {{Categorical &lt;br/&gt;Outcome Y}}
        {{Nominal &lt;br/&gt;Outcome Y}}
          )Chapter 14: &lt;br/&gt;Multinomial &lt;br/&gt;Logistic &lt;br/&gt;Regression(
            (Multinomial &lt;br/&gt;Outcome Y)
        {{Ordinal &lt;br/&gt;Outcome Y}}
          )Chapter 15: &lt;br/&gt;Ordinal &lt;br/&gt;Logistic &lt;br/&gt;Regression(
            (Logistic &lt;br/&gt;Distributed &lt;br/&gt;Cumulative Outcome &lt;br/&gt;Probability)
</pre>
</div>
<p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-regression-mindmap-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1.15: Regression analysis mind map depicting all modelling techniques to be explored in this book. Depending on the type of outcome <span class="math inline">\(Y\)</span>, these techniques are split into two large zones: <em>discrete</em> and <em>continuous</em>.
</figcaption></figure>
</div>
<p>That said, we will go beyond OLS regression and explore further regression techniques. In practice, these techniques have been developed in the statistical literature to address practical cases where the OLS modelling framework and assumptions are not suitable anymore. Thus, throughout this block, we will cover (at least) one new regression model per lecture.</p>
<p>As we can see in the clouds of <a href="#fig-regression-mindmap" class="quarto-xref">Figure&nbsp;<span>1.15</span></a>, there are 13 regression models: 8 belonging to discrete outcomes and 5 to continuous outcomes. Each of these models is contained in a chapter of this book, beginning with the most basic regression tool known as ordinary least-squares in <a href="03-ols.html" class="quarto-xref"><span>Chapter 3</span></a>. We must clarify that the current statistical literature is not restricted to these 13 regression models. The field of regression analysis is vast, and one might encounter more complex models to target certain specific inquiries. Nonetheless, I consider these models the fundamental regression approaches that any data scientist must be familiar with in everyday practice.</p>
<p>Even though this book comprises thirteen core chapters, each depicting a different regression model, we have split these chapters into two major subsets: those with <em>continuous</em> outcomes and those with <em>discrete</em> outcomes.</p>
</section><section id="sec-sup-learning-regression" class="level2" data-number="1.4"><h2 data-number="1.4" class="anchored" data-anchor-id="sec-sup-learning-regression">
<span class="header-section-number">1.4</span> Supervised Learning and Regression Analysis</h2>
</section><section id="sec-chapter-3-summary" class="level2" data-number="1.5"><h2 data-number="1.5" class="anchored" data-anchor-id="sec-chapter-3-summary">
<span class="header-section-number">1.5</span> Chapter Summary</h2>
</section><section id="sec-chapter-3-practice" class="level2" data-number="1.6"><h2 data-number="1.6" class="anchored" data-anchor-id="sec-chapter-3-practice">
<span class="header-section-number">1.6</span> Practice Exercises</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/exercises.png" class="img-fluid figure-img" width="550"></p>
<figcaption>Image by <a href="https://pixabay.com/users/manfredsteger-1848497/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3699345"><em>Manfred Steger</em></a> via <a href="https://pixabay.com/vectors/children-teacher-rectangular-figures-7464611/"><em>Pixabay</em></a>.</figcaption></figure>
</div>
<p>This is the first exercise set in the cookbook. Therefore, we must provide a full elaboration on why exercises have been designed the way they are. As a <strong>first design principle</strong>, we want you to <strong>build regression skills</strong> before you build speed. In the early stages of statistical learning, students often “<em>memorize formulas</em>” without going further into what they actually mean. To prevent that from happening in this cookbook, all the exercise sets across all chapters prioritize the following:</p>
<ol type="1">
<li>Translating between words, mathematical notation, and model statements.</li>
<li>Identifying what each regression model is assuming (i.e., the usual assumptions we must make on our observed data before fitting any given regression model).</li>
<li>Interpreting modelling outputs in plain words with correct claims, e.g., “<em>given the explanatory variables</em>,” “<em>holding other explanatory variables fixed</em>,” etc.</li>
</ol>
<p>Note that you will encounter <strong>multiple-choice</strong> and <strong>true/false</strong> questions not as “<em>gotchas</em>”, but as a way to show common conceptual slips early (e.g., confusing the role of the error term in the OLS modelling equation, mixing up conditional and marginal statements, etc.).</p>
<p>A <strong>second design principle</strong> is that every exercise comes with a <strong>full rationale</strong>, not just an short answer. For example, in our experience, an effective learning happens when students can check why a multiple-choice answer is correct and why the other alternatives are wrong. A similar situation happens with other styles of questions such as true/false or open-ended questions (especially, for those full data-based case studies in subsequent chapters where the data science workflow is applied for each regression model of this book). That “<em>full rationale</em>” style is deliberate: it turns each question into a mini-lesson you can revisit later when the regression models get more complex (i.e., when go beyond OLS). The goal is that by the time you hit complex chapters in this book, you already have a reliable habit of asking (for instance):</p>
<blockquote class="blockquote">
<p><strong>What is the likelihood?</strong></p>
<p><strong>What is the systematic part of this model?</strong></p>
<p><strong>What assumptions does this model imply?</strong></p>
<p><strong>What would I look at to check them?</strong></p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/plug-2.png" class="img-fluid figure-img" width="475"></p>
<figcaption>Image by <a href="https://pixabay.com/users/manfredsteger-1848497/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3699345"><em>Manfred Steger</em></a> via <a href="https://pixabay.com/vectors/pixel-cells-problem-technology-3974187/"><em>Pixabay</em></a>.</figcaption></figure>
</div>
<p>The general exercise mix in this whole textbook is designed to mirror <strong>real assessment</strong> and <strong>real practice</strong>: multiple-choice builds <strong>quick recognition</strong>, true/false trains <strong>precision in language</strong> (a major source of statistical confusion in our teaching experience!), and open-ended questions train <strong>explanation, interpretation, and professional communication</strong>. Regression is not just a mechanical procedure. It is a full analysis argument you make with data, and you have to be able to justify your modelling choices and interpret results responsibly. So the exercises are written to gradually move you from “<em>I can compute it</em>” to “<em>I can explain it”,</em> and from”<em>I know the tool</em>” to “<em>I can choose the tool</em>,” which is exactly the transition that separates basic comfort with regression from real data science competence.</p>
<p>Finally, the below introductory exercises are <strong>low-technical</strong> on purpose: no coding, minimal algebra, and a heavy emphasis on reading and reasoning. That is not because coding will not be essential across the whole cookbook, it is because this introductory chapter aims to teach the “<em>grammar</em>” of regression before we start writing complete analyses (as in subsequent chapters). Beginning <a href="03-ols.html" class="quarto-xref"><span>Chapter 3</span></a>, you will get <strong>full and coding-based case studies</strong> where you must do hands-on EDA, modelling equation setup, fitting, inference or prediction, diagnostics, and reporting, and you will see how the same conceptual moves show up repeatedly (e.g., choosing a probability distribution that matches the support of the outcome, interpreting coefficients on the correct scale, recognizing when the model is being asked to do something it cannot do, etc.). These early exercises are the <strong>scaffolding</strong> that makes those later case studies feel structured rather than overwhelming.</p>
<section id="the-data-science-workflow" class="level3" data-number="1.6.1"><h3 data-number="1.6.1" class="anchored" data-anchor-id="the-data-science-workflow">
<span class="header-section-number">1.6.1</span> The Data Science Workflow</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/idea.png" class="img-fluid figure-img" width="500"></p>
<figcaption>Image by <a href="https://pixabay.com/users/manfredsteger-1848497/"><em>manfredsteger</em></a> via <a href="https://pixabay.com/vectors/idea-visualization-line-art-3976295/"><em>Pixabay</em></a>.</figcaption></figure>
</div>
<div class="Question">
<div class="Question-header">
<p>Question 1.1</p>
</div>
<div class="Question-container">
<p><strong>Open-ended Question</strong></p>
<p>A streaming platform analyzes how long people watch a new series. The analyst reports <strong>summary statistics</strong> like the mean watch time, the median, and a plot comparing watch time across weekdays and weekends. <strong>In four to six sentences</strong>, explain the difference between a <strong>data description</strong> (e.g., summary statistics) and a <strong>regression model</strong>.</p>
</div>
</div>
<div class="Answer">
<div class="Answer-header">
<p>Answer 1.1</p>
</div>
<div class="Answer-container">
<details><summary><strong>Click here to reveal the answer!</strong>
</summary><p><strong>Answer:</strong></p>
<p>A data description <strong>summarizes what was observed</strong> in this particular dataset (e.g., means, medians, percentiles, plots, etc.) without committing to any explanation for why watch time varies or how new users might behave. It answers “<em>what did we see?</em>,” but <strong>it does not specify a generative story for the outcomes</strong>. On the other hand, with <span class="math inline">\(k\)</span> features, a regression model proposes a probabilistic mechanism for</p>
<p><span class="math display">\[Y \mid \mathbf{x} \quad \text{where} \quad \mathbf{x} = (x_1, \dots, x_k)^\top\]</span></p>
<p>(i.e., watch time as a response given features like day of week, device type, and whether the episode autoplays, etc.), using <strong>parameters</strong> to represent <strong>systematic structure</strong> (e.g., how the expected watch time changes with features) and randomness (e.g., variability around that expectation). Because it is a model, it can be used to <strong>predict</strong> watch time for new users, quantify the <strong>association</strong> between the response and features, and be checked via diagnostics for misfit. In short, descriptions are “<em>what happened</em>,’ while regression models are”<em>what process could have produced this, and what should we expect next under the model</em>.”</p>
</details>
</div>
</div>
<div class="Question">
<div class="Question-header">
<p>Question 1.2</p>
</div>
<div class="Question-container">
<p><strong>Multiple Choice</strong></p>
<p>For the <span class="math inline">\(i\)</span>th continuous response <span class="math inline">\(Y_i\)</span>, consider the model</p>
<p><span id="eq-exercise-model-random"><span class="math display">\[
Y_i = \beta_0 + \beta_1 x_i + \varepsilon_i.
\tag{1.5}\]</span></span></p>
<p>Which term is <strong>random</strong> in <a href="#eq-exercise-model-random" class="quarto-xref">Equation&nbsp;<span>1.5</span></a>? Select the correct option</p>
<p><strong>A.</strong> <span class="math inline">\(\beta_0\)</span> only.</p>
<p><strong>B.</strong> <span class="math inline">\(\beta_1\)</span> only.</p>
<p><strong>C.</strong> Both <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>.</p>
<p><strong>D.</strong> <span class="math inline">\(\varepsilon_i\)</span> only.</p>
<p><strong>E.</strong> <span class="math inline">\(x_i\)</span> only.</p>
</div>
</div>
<div class="Answer">
<div class="Answer-header">
<p>Answer 1.2</p>
</div>
<div class="Answer-container">
<details><summary><strong>Click here to reveal the answer!</strong>
</summary><p><strong>Correct answer:</strong> D.</p>
<p><strong>Rationale:</strong></p>
<p><a href="#eq-exercise-model-random" class="quarto-xref">Equation&nbsp;<span>1.5</span></a> can be considered the <strong>classical regression model OLS</strong> where <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> are fixed (and unknown) <strong>parameters</strong>; the <strong>randomness</strong> is captured by the error term <span class="math inline">\(\varepsilon_i\)</span> (and, thus, by <span class="math inline">\(Y_i\)</span>). The regressor <span class="math inline">\(x_i\)</span> is typically treated as <strong>fixed/observed</strong> in the conditional view <span class="math inline">\(Y \mid x\)</span>.</p>
</details>
</div>
</div>
<div class="Question">
<div class="Question-header">
<p>Question 1.3</p>
</div>
<div class="Question-container">
<p><strong>Open-ended Question</strong></p>
<p>A hospital analytics team fits an OLS regression to study the <strong>association</strong> between a discharge checklist indicator (<span class="math inline">\(x_{\text{checklist}}\)</span>) and patients’ length of stay <span class="math inline">\(Y\)</span>, while adjusting for age (<span class="math inline">\(x_{\text{age}}\)</span>), baseline severity (<span class="math inline">\(x_{\text{severity}}\)</span>), and admitting service (<span class="math inline">\(x_{\text{admitting}}\)</span>). They plan to report the <strong>estimated checklist coefficient</strong> <span class="math inline">\(\hat{\beta}_{\text{checklist}}\)</span> as an adjusted association, along with a <strong>standard error</strong> and a <strong>95% CI</strong>.</p>
<p>Why do we care about checking assumptions after fitting an OLS model and before making inferences? Give two reasons <strong>in three to five sentences</strong>.</p>
</div>
</div>
<div class="Answer">
<div class="Answer-header">
<p>Answer 1.3</p>
</div>
<div class="Answer-container">
<details><summary><strong>Click here to reveal the answer!</strong>
</summary><p><strong>Answer:</strong></p>
<strong>Even for association</strong>, OLS inference assumes the fitted model has captured the systematic part of <span class="math inline">\(Y\)</span>, conditioned an all the features, <strong>well enough</strong> that the remaining residuals do not show obvious structure (e.g., strong curvature, changing spread, or a few extreme points driving the fit up or down). First, if assumptions like constant variance or independence fail, the usual OLS standard errors (and, therefore, the 95% CI for <span class="math inline">\(\hat{\beta}_{\text{checklist}}\)</span>) can be <strong>misleading</strong>, so we might overstate or understate how precisely we have estimated the association. Second, model diagnostics help detect <strong>misspecification</strong>: residual patterns can indicate missing terms (interactions, nonlinearities) or influential observations, meaning the reported “<em>adjusted association</em>” may be an artifact of a poor model rather than a stable summary of the data. Assumption checking is how we keep the reported association and its uncertainty defensible.
</details>
</div>
</div>
</section><section id="mind-map-of-regression-analysis" class="level3" data-number="1.6.2"><h3 data-number="1.6.2" class="anchored" data-anchor-id="mind-map-of-regression-analysis">
<span class="header-section-number">1.6.2</span> Mind Map of Regression Analysis</h3>
</section><section id="supervised-learning-and-regression-analysis" class="level3" data-number="1.6.3"><h3 data-number="1.6.3" class="anchored" data-anchor-id="supervised-learning-and-regression-analysis">
<span class="header-section-number">1.6.3</span> Supervised Learning and Regression Analysis</h3>
<p><br></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure"><p><img src="img/argument.png" class="img-fluid figure-img" width="350"></p>
<figcaption>Image by <a href="https://pixabay.com/users/manfredsteger-1848497/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3699345"><em>Manfred Steger</em></a> via <a href="https://pixabay.com/vectors/pixel-pixel-cells-pedagogy-3699345/"><em>Pixabay</em></a>.</figcaption></figure>
</div>
<div class="Question">
<div class="Question-header">
<p>Question</p>
</div>
<div class="Question-container">
<p><strong>Multiple Choice</strong></p>
<p>Which statement best matches the definition of <strong>supervised learning</strong>? Select the correct option:</p>
<p><strong>A.</strong> Learning an estimate of <span class="math inline">\(P(\text{data})\)</span> without labels.</p>
<p><strong>B.</strong> Learning a mapping from <span class="math inline">\(k\)</span> features <span class="math inline">\(\mathbf{x} = (x_1, \dots, x_k)^\top\)</span> to a labelled target <span class="math inline">\(y\)</span>.</p>
<p><strong>C.</strong> Learning causal effects of interventions on an outcome.</p>
<p><strong>D.</strong> Learning the joint distribution of a set of features <span class="math inline">\(\mathbf{X}\)</span> only.</p>
</div>
</div>
<div class="Answer">
<div class="Answer-header">
<p>Answer</p>
</div>
<div class="Answer-container">
<details><summary><strong>Click here to reveal the answer!</strong>
</summary><p><strong>Correct answer:</strong> B.</p>
<p><strong>Rationale:</strong></p>
<p>Supervised learning assumes labelled pairs <span class="math inline">\({(\mathbf{x}_i, y_i)}\)</span> and aims to learn a rule that predicts <span class="math inline">\(y\)</span> from a function <span class="math inline">\(\mathbf{x}\)</span> on new observations (which will be contained in a <strong>test set</strong>). Options <strong>A</strong> and <strong>D</strong> describe unsupervised goals (no labelled outcomed <span class="math inline">\(y\)</span>). Option <strong>C</strong> is about causal inference, which is not required for supervised learning and is not the focus of this textbook on regression analysis.</p>
</details>
</div>
</div>
<div class="Question">
<div class="Question-header">
<p>Question</p>
</div>
<div class="Question-container">
<p><strong>True or False</strong></p>
<blockquote class="blockquote">
<p>Regression analysis is always about predicting or making inference on a continuous outcome.</p>
</blockquote>
</div>
</div>
<div class="Answer">
<div class="Answer-header">
<p>Answer</p>
</div>
<div class="Answer-container">
<details><summary><strong>Click here to reveal the answer!</strong>
</summary><p><strong>Correct answer:</strong> False.</p>
<p><strong>Rationale:</strong></p>
<p>In statistics, <strong>regression analysis</strong> refers to modelling a conditional response <span class="math inline">\(Y \mid \mathbf{X}\)</span> (where <span class="math inline">\(\mathbf{X}\)</span> is a set of regressors) with an appropriate probability distribution. The response <span class="math inline">\(Y\)</span> (note the uppercase notation since we assume the response as a random variable) can be continuous (e.g., Normal, Gamma, Lognormal, etc.), binary (Bernoulli), counts (Poisson, Negative Binomial, generalized Poisson, etc.), proportions (Beta), or categories (Multinomial), among others. Restricting regression to <strong>continuous prediction or inference</strong> is <strong>incorrect</strong>.</p>
</details>
</div>
</div>
<div class="Question">
<div class="Question-header">
<p>Question</p>
</div>
<div class="Question-container">
<p><strong>Multiple Choice</strong></p>
<p>In a <strong>frequentist regression model</strong>, which object is most directly responsible for linking explanatory variables to the distribution of the response <span class="math inline">\(Y\)</span>? Select the correct option:</p>
<p><strong>A.</strong> Only the loss function.</p>
<p><strong>B.</strong> The likelihood function for <span class="math inline">\(Y \mid \mathbf{x}\)</span>, with <span class="math inline">\(k\)</span> features in vector <span class="math inline">\(\mathbf{x} = (x_1, \dots, x_k)^\top\)</span> along its corresponding parametrization.</p>
<p><strong>C.</strong> The training and testing data splits.</p>
<p><strong>D.</strong> The random seed used for the optimization method of the likelihood function.</p>
</div>
</div>
<div class="Answer">
<div class="Answer-header">
<p>Answer</p>
</div>
<div class="Answer-container">
<details><summary><strong>Click here to reveal the answer!</strong>
</summary><p><strong>Correct answer:</strong> B.</p>
<p><strong>Rationale:</strong></p>
<p>Regression analysis assumes a probabilistic generative model for the <strong>random variable</strong> <span class="math inline">\(Y \mid \mathbf{x}\)</span>, which is represented by a likelihood function. This likelihood function (which might be <strong>continuous</strong> or <strong>discrete</strong>) it is conditioned on <span class="math inline">\(\mathbf{x}\)</span> with its corresponding regression parameters (i.e., the <strong>systematic component</strong>). These parameters are meant to be estimated through a given <strong>maximum likelihood method</strong>. On the other hand, a loss function might be derived from the likelihood function (e.g., it can be the negative log-likelihood to be minimized instead). Still, without a likelihood function, we cannot generally assign a <strong>probabilistic interpretation</strong> to our regression modelling. Then, the training and testing data splits are elements of the modelling process for estimation and evaluation, respectively. Finally, the random seed used for optimization is merely an element of model estimation.</p>
</details>
</div>
</div>
<div class="Question">
<div class="Question-header">
<p>Question</p>
</div>
<div class="Question-container">
<p><strong>True or False</strong></p>
<blockquote class="blockquote">
<p>Two different regression models can yield similar response predictions <span class="math inline">\(\hat{y}\)</span> but lead to different uncertainty metrics on their estimated parameters (e.g., different standard errors or confidence intervals).</p>
</blockquote>
</div>
</div>
<div class="Answer">
<div class="Answer-header">
<p>Answer</p>
</div>
<div class="Answer-container">
<details><summary><strong>Click here to reveal the answer!</strong>
</summary><p><strong>Correct answer:</strong> True.</p>
<p><strong>Rationale:</strong></p>
<p>Uncertainty metrics on estimated parameters between two regression models are not linked to how close their corresponding predicted responses are. Two regression models, under different parametrizations, can provide similar <strong>point estimates</strong> on their corresponding intercepts and coefficients which would yield similar response predictions <span class="math inline">\(\hat{y}\)</span>. That said, their uncertainty metrics may differ, as they depend on the assumed modelling variability, how each model is parametrized, and how uncertainty is propagated throughout the estimation process.</p>
</details>
</div>
</div>
<div class="Question">
<div class="Question-header">
<p>Question</p>
</div>
<div class="Question-container">
<p><strong>Open-ended Question</strong></p>
<p>A tutoring centre wants to <strong>predict</strong> the average time <span class="math inline">\(Y\)</span> (in minutes) a student will take to complete a practice exercise using <span class="math inline">\(k\)</span> <strong>features</strong> such as the exercise difficulty rating, the student’s prior quiz score, whether they used hints, and the topic area. Let <span class="math inline">\(\mathbf{x} = (x_1, \dots, x_k)^\top\)</span> denote these <strong>explanatory variables</strong>, and consider modelling the <strong>conditional response</strong></p>
<p><span class="math display">\[
Y \mid \mathbf{x}.
\]</span></p>
<p><strong>In three to five sentences</strong>, explain why specifying a probability model for <span class="math inline">\(Y \mid \mathbf{x}\)</span> is useful in regression analysis, even if the centre’s main goal is prediction.</p>
</div>
</div>
<div class="Answer">
<div class="Answer-header">
<p>Answer</p>
</div>
<div class="Answer-container">
<details><summary><strong>Click here to reveal the answer!</strong>
</summary><p><strong>Answer:</strong></p>
<p>Even if we want to predict the <strong>average time</strong> a student will take on an exercise using features like difficulty, prior performance, and hint usage, two students with the same set of features <span class="math inline">\(\mathbf{x}\)</span> can still take different amounts of time because focus, distractions, and pacing vary. A probability model for</p>
<p><span class="math display">\[Y \mid \mathbf{x}\]</span></p>
<p>makes that variability explicit, so we get not only a point prediction for the average time but also a sense of <strong>how uncertain that prediction is</strong>. That is useful for planning (e.g., the chance an exercise runs over the 20-minute block) and for setting realistic expectations for students. It also forces us to state <strong>assumptions</strong> about the shape of outcomes (e.g., skewed times, heavy tails, outliers), which often improves calibration and makes predictions more trustworthy in practice.</p>
</details>
</div>
</div>
<div class="Question">
<div class="Question-header">
<p>Question</p>
</div>
<div class="Question-container">
<p><strong>Multiple Choice</strong></p>
<p>Which statement best captures the relationship between <strong>supervised learning</strong> and <strong>regression analysis</strong> in this cookbook? Select the correct option:</p>
<p><strong>A.</strong> They are unrelated topics.</p>
<p><strong>B.</strong> Supervised learning is a subset of regression analysis.</p>
<p><strong>C.</strong> Regression models can be used for supervised learning, but regression analysis emphasizes probabilistic modelling and uncertainty.</p>
<p><strong>D.</strong> Regression analysis is only about hypothesis tests; supervised learning is only about prediction.</p>
</div>
</div>
<div class="Answer">
<div class="Answer-header">
<p>Answer</p>
</div>
<div class="Answer-container">
<details><summary><strong>Click here to reveal the answer!</strong>
</summary><p><strong>Correct answer:</strong> C.</p>
<p><strong>Rationale:</strong></p>
<p>Regression models <strong>map</strong> <span class="math inline">\(k\)</span> features (i.e., regressors) to a target <span class="math inline">\(Y\)</span> (i.e., response), so they can certainly be used for supervised prediction. The <strong>distinguishing characteristic</strong> of regression analysis (as used in this cookbook) is that it begins with an explicit <strong>probabilistic model</strong> for</p>
<p><span class="math display">\[Y \mid \mathbf{x} \quad \text{where} \quad \mathbf{x} = (x_1, \dots, x_k)^\top\]</span></p>
<p>and treats interpretation, uncertainty quantification, and model diagnostics as primary results. Hence, options A and B are incorrect. Option D is too extreme: both domains overlap substantially, and regression analysis can be predictive while supervised learning can be probabilistic.</p>
</details>
</div>
</div>
<div class="Question">
<div class="Question-header">
<p>Question</p>
</div>
<div class="Question-container">
<p><strong>True or False</strong></p>
<blockquote class="blockquote">
<p>Using train/test data splits or cross-validation is incompatible with regression analysis.</p>
</blockquote>
</div>
</div>
<div class="Answer">
<div class="Answer-header">
<p>Answer</p>
</div>
<div class="Answer-container">
<details><summary><strong>Click here to reveal the answer!</strong>
</summary><p><strong>Correct answer:</strong> False.</p>
<p><strong>Rationale:</strong></p>
<p>Train/test splits and cross-validation are <strong>evaluation tools</strong> that can be used with any predictive model, including regression models. Regression analysis often adds additional goals (<strong>interpretation</strong>, <strong>uncertainty</strong>, <strong>diagnostics</strong>, etc.), but it can still benefit from out-of-sample evaluation when prediction performance matters.</p>
</details>
</div>
</div>
<div class="Question">
<div class="Question-header">
<p>Question</p>
</div>
<div class="Question-container">
<p><strong>Multiple Choice</strong></p>
<p>Which statement best describes what <strong>regression analysis</strong> tries to model? Select the correct option:</p>
<p><strong>A.</strong> The unconditional distribution of the response <span class="math inline">\(Y\)</span>.</p>
<p><strong>B.</strong> The conditional distribution <span class="math inline">\(Y \mid \mathbf{x}\)</span> where <span class="math inline">\(\mathbf{x} = (x_1, \dots, x_k)^\top\)</span> is a vector of <span class="math inline">\(k\)</span> explanatory variables.</p>
<p><strong>C.</strong> The conditional distribution of the feature vector <span class="math inline">\(\mathbf{X} \mid y\)</span> where <span class="math inline">\(\mathbf{x} = (x_1, \dots, x_k)^\top\)</span>.</p>
<p><strong>D.</strong> The marginal distribution of each explanatory variable in vector <span class="math inline">\(\mathbf{x} = (x_1, \dots, x_k)^\top\)</span> separately.</p>
</div>
</div>
<div class="Answer">
<div class="Answer-header">
<p>Answer</p>
</div>
<div class="Answer-container">
<details><summary><strong>Click here to reveal the answer!</strong>
</summary><p><strong>Correct answer:</strong> B.</p>
<p><strong>Rationale:</strong></p>
<p>Regression analysis is fundamentally about <strong>how the response <span class="math inline">\(Y\)</span> behaves given a set of <span class="math inline">\(k\)</span> explanatory variables</strong>: the mean (or another statistic) of <span class="math inline">\(Y\)</span> changes as <span class="math inline">\(\mathbf{x}\)</span> changes, and we model that relationship through <span class="math inline">\(Y \mid \mathbf{X}\)</span>. Modelling <span class="math inline">\(Y\)</span> alone (as in option A) ignores explanatory variables; modelling <span class="math inline">\(\mathbf{X} \mid y\)</span> (as in option C) flips the analysis direction; and option D is merely univariate modelling of explanatory variables</p>
</details>
</div>
</div>
<div class="Question">
<div class="Question-header">
<p>Question</p>
</div>
<div class="Question-container">
<p><strong>Open-ended Question</strong></p>
<p>A hospital quality improvement team is trying to reduce the average recovery time (in days) after a routine procedure. A manager says:</p>
<blockquote class="blockquote">
<p>“<em>Regression analysis is only for prediction. If we want to understand what’s driving longer recoveries, regression won’t help.</em>”</p>
</blockquote>
<p><strong>In four to six sentences</strong>, how would you respond to the manager? Explain whether regression can be useful for <strong>interpretation</strong> in addition to prediction, and describe what a regression model can tell us about recovery time <span class="math inline">\(Y\)</span> as a function of <span class="math inline">\(k\)</span> patient and treatment features, i.e., <span class="math inline">\(\mathbf{x} = (x_1, \dots, x_k)^\top\)</span>. In your answer, state what <strong>regression coefficients</strong> mean under the model, and how you would <strong>communicate uncertainty</strong> about those relationships (e.g., standard errors, confidence intervals, etc.).</p>
</div>
</div>
<div class="Answer">
<div class="Answer-header">
<p>Answer</p>
</div>
<div class="Answer-container">
<details><summary><strong>Click here to reveal the answer!</strong>
</summary><p><strong>Answer:</strong></p>
<p>Regression is not only for prediction; it can also be a tool for <strong>interpretation</strong> when our goal is <strong>to understand how average recovery time</strong> relates to <strong>patient and treatment characteristics</strong>. For instance, in a model for</p>
<p><span class="math display">\[Y \mid \mathbf{x},\]</span></p>
<p>a given <strong>regression coefficient</strong> would explain how the expected (average) recovery time changes when one feature increases by one unit, holding the other variables fixed, under the assumptions of the model. That can help the hospital identify which factors (e.g., age, comorbidities, anesthesia type, post-op protocol, etc.) are associated with longer recoveries and where to focus quality-improvement efforts. That said, <strong>model estimation uncertainty matters too</strong>: standard errors and confidence intervals communicate how precise those estimated associations are and whether the data support a meaningful relationship. Prediction and interpretation are different goals, but <strong>regression often supports both in a single and coherent framework</strong>.</p>
</details>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-quarto" class="csl-entry" role="listitem">
Allaire, J. J., Charles Teague, Carlos Scheidegger, Yihui Xie, Christophe Dervieux, and Gordon Woodhull. 2025. <span>“<span>Quarto</span>.”</span> <a href="https://doi.org/10.5281/zenodo.5960048">https://doi.org/10.5281/zenodo.5960048</a>.
</div>
<div id="ref-rsample" class="csl-entry" role="listitem">
Frick, Hannah, Fanny Chow, Max Kuhn, Michael Mahoney, Julia Silge, and Hadley Wickham. 2025. <em>Rsample: General Resampling Infrastructure</em>. <a href="https://doi.org/10.32614/CRAN.package.rsample">https://doi.org/10.32614/CRAN.package.rsample</a>.
</div>
<div id="ref-gelbart2017" class="csl-entry" role="listitem">
Gelbart, Michael. 2017. <span>“Data Science Terminology.”</span> <em>UBC MDS</em>. Master of Data Science at the University of British Columbia. <a href="https://ubc-mds.github.io/resources_pages/terminology/">https://ubc-mds.github.io/resources_pages/terminology/</a>.
</div>
<div id="ref-numpy" class="csl-entry" role="listitem">
Harris, Charles R., K. Jarrod Millman, Stéfan J. van der Walt, Ralf Gommers, Pauli Virtanen, David Cournapeau, Eric Wieser, et al. 2020. <span>“Array Programming with <span>NumPy</span>.”</span> <em>Nature</em> 585 (7825): 357–62. <a href="https://doi.org/10.1038/s41586-020-2649-2">https://doi.org/10.1038/s41586-020-2649-2</a>.
</div>
<div id="ref-lohr2021" class="csl-entry" role="listitem">
Lohr, S. L. 2021. <em>Sampling: Design and Analysis</em>. Chapman; Hall/CRC. https://doi.org/<a href="https://doi.org/10.1201/9780429298899">https://doi.org/10.1201/9780429298899</a>.
</div>
<div id="ref-scikit-learn" class="csl-entry" role="listitem">
Pedregosa, F., G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, et al. 2011. <span>“Scikit-Learn: Machine Learning in <span>P</span>ython.”</span> <em>Journal of Machine Learning Research</em> 12: 2825–30.
</div>
<div id="ref-reinhart2015" class="csl-entry" role="listitem">
Reinhart, Alex. 2015. <em>Statistics Done Wrong: The Woefully Complete Guide</em>. 1st ed. San Francisco, CA: No Starch Press. <a href="https://www.statisticsdonewrong.com/index.html">https://www.statisticsdonewrong.com/index.html</a>.
</div>
<div id="ref-broom" class="csl-entry" role="listitem">
Robinson, David, Alex Hayes, and Simon Couch. 2025. <em>Broom: Convert Statistical Objects into Tidy Tibbles</em>. <a href="https://broom.tidymodels.org/">https://broom.tidymodels.org/</a>.
</div>
<div id="ref-statsmodels" class="csl-entry" role="listitem">
Seabold, Skipper, and Josef Perktold. 2010. <span>“Statsmodels: Econometric and Statistical Modeling with Python.”</span> In <em>9th Python in Science Conference</em>.
</div>
<div id="ref-reticulate" class="csl-entry" role="listitem">
Ushey, Kevin, JJ Allaire, and Yuan Tang. 2025. <em>Reticulate: Interface to ’Python’</em>. <a href="https://doi.org/10.32614/CRAN.package.reticulate">https://doi.org/10.32614/CRAN.package.reticulate</a>.
</div>
</div>
</section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/alexrod61\.github\.io\/regression-cookbook\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
          // default icon
          link.classList.add("external");
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><script src="https://giscus.app/client.js" data-repo="alexrod61/regression-cookbook" data-repo-id="R_kgDOMSJoUA" data-category="General" data-category-id="" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="en" crossorigin="anonymous" async="">
</script><input type="hidden" id="giscus-base-theme" value="light"><input type="hidden" id="giscus-alt-theme" value="dark"><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../book/audience-scope.html" class="pagination-link" aria-label="Audience and Scope">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Audience and Scope</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../book/02-stats-review.html" class="pagination-link" aria-label="Basic Cuisine: A Review on Probability and Frequentist Statistical Inference">
        <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Basic Cuisine: A Review on Probability and Frequentist Statistical Inference</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2025; G. Alexi Rodríguez-Arelis, Andy Tai, and Ben Chen</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/alexrod61/regression-cookbook/edit/main/book/01-intro.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/alexrod61/regression-cookbook/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li><li><a href="https://github.com/alexrod61/regression-cookbook/blob/main/book/01-intro.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li></ul></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>


<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>