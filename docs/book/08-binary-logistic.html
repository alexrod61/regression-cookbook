<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Binary Logistic Regression – The Regression Cookbook (in development)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>

<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../book/09-binomial-logistic.html" rel="next">
<link href="../book/discrete-zone.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-c102d61e9f42aa51f65b68241b633b47.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script><style>html{ scroll-behavior: smooth; }</style>
<script src="../site_libs/quarto-diagram/mermaid.min.js"></script><script src="../site_libs/quarto-diagram/mermaid-init.js"></script><link href="../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script><script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script><link rel="stylesheet" href="../custom.css">
</head>
<body class="nav-sidebar floating nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="navbar navbar-expand-lg " data-bs-theme="dark"><div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">The Regression Cookbook (in development)</span>
    </a>
  </div>
        <div class="quarto-navbar-tools tools-end">
    <a href="https://github.com/alexrod61/regression-cookbook" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Share" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" role="link" aria-label="Share"><i class="bi bi-share"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-0">
<li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://twitter.com/intent/tweet?url=|url|">
              <i class="bi bi-twitter pe-1"></i>
            Twitter
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
              <i class="bi bi-facebook pe-1"></i>
            Facebook
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
              <i class="bi bi-linkedin pe-1"></i>
            LinkedIn
            </a>
          </li>
      </ul>
</div>
</div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav><nav class="quarto-secondary-nav"><div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../book/discrete-zone.html">Discrete Cuisine</a></li><li class="breadcrumb-item"><a href="../book/08-binary-logistic.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Binary Logistic Regression</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../index.html" class="sidebar-logo-link">
      <img src="../img/cookbook.png" alt="" class="sidebar-logo py-0 d-lg-inline d-none"></a>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/privacy-policy.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Website Privacy Policy</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/audience-scope.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Audience and Scope</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/01-intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Getting Ready for Regression Cooking!</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/02-stats-review.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Basic Cuisine: A Review on Probability and Frequentist Statistical Inference</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../book/continuous-zone.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Continuous Cuisine</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/03-ols.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Zestylicious Ordinary Least-squares Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/04-gamma.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Smoketastic Gamma Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/05-beta.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Soup-erb Beta Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/06-parametric-survival.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Crunchified Parametric Survival Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/07-semiparametric-survival.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Butteryfied Semiparametric Survival Regression</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="../book/discrete-zone.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Discrete Cuisine</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/08-binary-logistic.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Binary Logistic Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/09-binomial-logistic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Cheesified Binomial Logistic Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/10-classical-poisson.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Bubblarious Classical Poisson Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/11-negative-binomial.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Umami-zing Negative Binomial Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/12-zero-inflated-poisson.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Spicetacular Zero-Inflated Poisson Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/13-generalized-poisson.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Herbalicious Generalized Poisson Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/14-multinomial-logistic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Picklified Multinomial Logistic Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/15-ordinal-logistic.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Tang-tastic Ordinal Logistic Regression</span></span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/A-dictionary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">The Fusionified ML-Stats Dictionary</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/B-greek-alphabet.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">The Snazzalicious Greek Alphabet</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/C-distributional-mind-map.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">The Chocolified Distributional Mind Map</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../book/D-regression-mind-map.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">The Sugartastic Regression Mind Map</span></span></a>
  </div>
</li>
      </ul>
</li>
    </ul>
</div>
</nav><div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active"><h2 id="toc-title">The recipe</h2>
   
  <ul>
<li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">8.1</span> Introduction</a></li>
  <li><a href="#why-ordinary-least-squares-fails-for-binary-outcomes" id="toc-why-ordinary-least-squares-fails-for-binary-outcomes" class="nav-link" data-scroll-target="#why-ordinary-least-squares-fails-for-binary-outcomes"><span class="header-section-number">8.2</span> Why Ordinary Least Squares Fails for Binary Outcomes</a></li>
  <li>
<a href="#the-logit-function" id="toc-the-logit-function" class="nav-link" data-scroll-target="#the-logit-function"><span class="header-section-number">8.3</span> The Logit Function</a>
  <ul>
<li><a href="#logit-a-link-between-probability-and-linear-predictors" id="toc-logit-a-link-between-probability-and-linear-predictors" class="nav-link" data-scroll-target="#logit-a-link-between-probability-and-linear-predictors"><span class="header-section-number">8.3.1</span> Logit: A Link Between Probability and Linear Predictors</a></li>
  <li><a href="#from-log-odds-back-to-probability" id="toc-from-log-odds-back-to-probability" class="nav-link" data-scroll-target="#from-log-odds-back-to-probability"><span class="header-section-number">8.3.2</span> From Log-Odds Back to Probability</a></li>
  <li><a href="#understanding-the-s-shape" id="toc-understanding-the-s-shape" class="nav-link" data-scroll-target="#understanding-the-s-shape"><span class="header-section-number">8.3.3</span> Understanding the “S” Shape</a></li>
  <li><a href="#the-logistic-function-and-its-shape-code" id="toc-the-logistic-function-and-its-shape-code" class="nav-link" data-scroll-target="#the-logistic-function-and-its-shape-code"><span class="header-section-number">8.3.4</span> The Logistic Function and Its Shape (Code)</a></li>
  </ul>
</li>
  <li>
<a href="#case-study-understanding-financial-behaviors" id="toc-case-study-understanding-financial-behaviors" class="nav-link" data-scroll-target="#case-study-understanding-financial-behaviors"><span class="header-section-number">8.4</span> Case Study: Understanding Financial Behaviors</a>
  <ul>
<li><a href="#the-dataset" id="toc-the-dataset" class="nav-link" data-scroll-target="#the-dataset"><span class="header-section-number">8.4.1</span> The Dataset</a></li>
  <li>
<a href="#the-problem-were-trying-to-solve" id="toc-the-problem-were-trying-to-solve" class="nav-link" data-scroll-target="#the-problem-were-trying-to-solve"><span class="header-section-number">8.4.2</span> The Problem We’re Trying to Solve</a>
  <ul class="collapse">
<li><a href="#the-balancing-act-of-lending" id="toc-the-balancing-act-of-lending" class="nav-link" data-scroll-target="#the-balancing-act-of-lending">1. The Balancing Act of Lending</a></li>
  <li><a href="#the-asymmetry-of-errors" id="toc-the-asymmetry-of-errors" class="nav-link" data-scroll-target="#the-asymmetry-of-errors">2. The Asymmetry of Errors</a></li>
  </ul>
</li>
  <li><a href="#study-design" id="toc-study-design" class="nav-link" data-scroll-target="#study-design"><span class="header-section-number">8.4.3</span> Study Design</a></li>
  <li>
<a href="#applying-study-design-to-our-case-study" id="toc-applying-study-design-to-our-case-study" class="nav-link" data-scroll-target="#applying-study-design-to-our-case-study"><span class="header-section-number">8.4.4</span> Applying Study Design to Our Case Study</a>
  <ul class="collapse">
<li><a href="#why-we-split-the-data-training-vs.-testing" id="toc-why-we-split-the-data-training-vs.-testing" class="nav-link" data-scroll-target="#why-we-split-the-data-training-vs.-testing">Why We Split the Data (Training vs.&nbsp;Testing)</a></li>
  <li><a href="#the-challenge-of-class-imbalance" id="toc-the-challenge-of-class-imbalance" class="nav-link" data-scroll-target="#the-challenge-of-class-imbalance">The Challenge of Class Imbalance</a></li>
  <li><a href="#influential-points-and-outliers" id="toc-influential-points-and-outliers" class="nav-link" data-scroll-target="#influential-points-and-outliers">Influential Points and Outliers</a></li>
  </ul>
</li>
  <li><a href="#data-preparation-in-action" id="toc-data-preparation-in-action" class="nav-link" data-scroll-target="#data-preparation-in-action"><span class="header-section-number">8.4.5</span> Data Preparation in Action</a></li>
  </ul>
</li>
  <li>
<a href="#fitting-the-binary-logistic-regression-model" id="toc-fitting-the-binary-logistic-regression-model" class="nav-link" data-scroll-target="#fitting-the-binary-logistic-regression-model"><span class="header-section-number">8.5</span> Fitting the Binary Logistic Regression Model</a>
  <ul>
<li><a href="#model-specification" id="toc-model-specification" class="nav-link" data-scroll-target="#model-specification"><span class="header-section-number">8.5.1</span> Model Specification</a></li>
  <li><a href="#fitting-the-model" id="toc-fitting-the-model" class="nav-link" data-scroll-target="#fitting-the-model"><span class="header-section-number">8.5.2</span> Fitting the Model</a></li>
  <li><a href="#model-output-interpretation" id="toc-model-output-interpretation" class="nav-link" data-scroll-target="#model-output-interpretation"><span class="header-section-number">8.5.3</span> Model Output Interpretation</a></li>
  </ul>
</li>
  <li>
<a href="#interpreting-model-results-log-odds-and-odds-ratios" id="toc-interpreting-model-results-log-odds-and-odds-ratios" class="nav-link" data-scroll-target="#interpreting-model-results-log-odds-and-odds-ratios"><span class="header-section-number">8.6</span> Interpreting Model Results: Log-Odds and Odds Ratios</a>
  <ul>
<li><a href="#the-log-odds-output" id="toc-the-log-odds-output" class="nav-link" data-scroll-target="#the-log-odds-output"><span class="header-section-number">8.6.1</span> The “Log-Odds” Output</a></li>
  <li><a href="#the-odds-ratio-or" id="toc-the-odds-ratio-or" class="nav-link" data-scroll-target="#the-odds-ratio-or"><span class="header-section-number">8.6.2</span> The “Odds Ratio” (OR)</a></li>
  </ul>
</li>
  <li><a href="#from-log-odds-to-probabilities-simple-model" id="toc-from-log-odds-to-probabilities-simple-model" class="nav-link" data-scroll-target="#from-log-odds-to-probabilities-simple-model"><span class="header-section-number">8.7</span> From Log-Odds to Probabilities (Simple Model)</a></li>
  <li>
<a href="#data-preparation-and-wrangling" id="toc-data-preparation-and-wrangling" class="nav-link" data-scroll-target="#data-preparation-and-wrangling"><span class="header-section-number">8.8</span> Data Preparation and Wrangling</a>
  <ul>
<li><a href="#handling-missing-data" id="toc-handling-missing-data" class="nav-link" data-scroll-target="#handling-missing-data"><span class="header-section-number">8.8.1</span> Handling Missing Data</a></li>
  <li><a href="#encoding-categorical-variables" id="toc-encoding-categorical-variables" class="nav-link" data-scroll-target="#encoding-categorical-variables"><span class="header-section-number">8.8.2</span> Encoding Categorical Variables</a></li>
  <li><a href="#splitting-the-data" id="toc-splitting-the-data" class="nav-link" data-scroll-target="#splitting-the-data"><span class="header-section-number">8.8.3</span> Splitting the Data</a></li>
  </ul>
</li>
  <li>
<a href="#exploratory-data-analysis-eda" id="toc-exploratory-data-analysis-eda" class="nav-link" data-scroll-target="#exploratory-data-analysis-eda"><span class="header-section-number">8.9</span> Exploratory Data Analysis (EDA)</a>
  <ul>
<li><a href="#classifying-variables" id="toc-classifying-variables" class="nav-link" data-scroll-target="#classifying-variables"><span class="header-section-number">8.9.1</span> Classifying Variables</a></li>
  <li><a href="#visualizing-distributions" id="toc-visualizing-distributions" class="nav-link" data-scroll-target="#visualizing-distributions"><span class="header-section-number">8.9.2</span> Visualizing Distributions</a></li>
  <li><a href="#exploring-relationships-with-binary-outcome" id="toc-exploring-relationships-with-binary-outcome" class="nav-link" data-scroll-target="#exploring-relationships-with-binary-outcome"><span class="header-section-number">8.9.3</span> Exploring Relationships with Binary Outcome</a></li>
  </ul>
</li>
  <li>
<a href="#data-modelling" id="toc-data-modelling" class="nav-link" data-scroll-target="#data-modelling"><span class="header-section-number">8.10</span> Data Modelling</a>
  <ul>
<li><a href="#choosing-a-logistic-regression-model" id="toc-choosing-a-logistic-regression-model" class="nav-link" data-scroll-target="#choosing-a-logistic-regression-model"><span class="header-section-number">8.10.1</span> Choosing a Logistic Regression Model</a></li>
  <li><a href="#defining-the-probability-distribution" id="toc-defining-the-probability-distribution" class="nav-link" data-scroll-target="#defining-the-probability-distribution"><span class="header-section-number">8.10.2</span> Defining the Probability Distribution</a></li>
  <li><a href="#setting-up-the-logistic-regression-equation" id="toc-setting-up-the-logistic-regression-equation" class="nav-link" data-scroll-target="#setting-up-the-logistic-regression-equation"><span class="header-section-number">8.10.3</span> Setting Up the Logistic Regression Equation</a></li>
  <li><a href="#the-missing-error-term-epsilon" id="toc-the-missing-error-term-epsilon" class="nav-link" data-scroll-target="#the-missing-error-term-epsilon"><span class="header-section-number">8.10.4</span> The Missing Error Term (<span class="math inline">\(\epsilon\)</span>)</a></li>
  <li><a href="#counting-the-parameters" id="toc-counting-the-parameters" class="nav-link" data-scroll-target="#counting-the-parameters"><span class="header-section-number">8.10.5</span> Counting the Parameters</a></li>
  </ul>
</li>
  <li>
<a href="#estimation" id="toc-estimation" class="nav-link" data-scroll-target="#estimation"><span class="header-section-number">8.11</span> Estimation</a>
  <ul>
<li><a href="#maximum-likelihood-estimation-mle" id="toc-maximum-likelihood-estimation-mle" class="nav-link" data-scroll-target="#maximum-likelihood-estimation-mle"><span class="header-section-number">8.11.1</span> Maximum Likelihood Estimation (MLE)</a></li>
  </ul>
</li>
  <li>
<a href="#estimation-1" id="toc-estimation-1" class="nav-link" data-scroll-target="#estimation-1"><span class="header-section-number">8.12</span> Estimation</a>
  <ul>
<li><a href="#maximum-likelihood-estimation-mle-1" id="toc-maximum-likelihood-estimation-mle-1" class="nav-link" data-scroll-target="#maximum-likelihood-estimation-mle-1"><span class="header-section-number">8.12.1</span> Maximum Likelihood Estimation (MLE)</a></li>
  </ul>
</li>
  <li>
<a href="#inference" id="toc-inference" class="nav-link" data-scroll-target="#inference"><span class="header-section-number">8.13</span> Inference</a>
  <ul>
<li><a href="#wald-tests" id="toc-wald-tests" class="nav-link" data-scroll-target="#wald-tests"><span class="header-section-number">8.13.1</span> Wald Tests</a></li>
  <li><a href="#likelihood-ratio-tests" id="toc-likelihood-ratio-tests" class="nav-link" data-scroll-target="#likelihood-ratio-tests"><span class="header-section-number">8.13.2</span> Likelihood Ratio Tests</a></li>
  <li><a href="#confidence-intervals" id="toc-confidence-intervals" class="nav-link" data-scroll-target="#confidence-intervals"><span class="header-section-number">8.13.3</span> Confidence Intervals</a></li>
  </ul>
</li>
  <li>
<a href="#coefficient-interpretation" id="toc-coefficient-interpretation" class="nav-link" data-scroll-target="#coefficient-interpretation"><span class="header-section-number">8.14</span> Coefficient Interpretation</a>
  <ul>
<li><a href="#odds-ratios-and-their-meaning" id="toc-odds-ratios-and-their-meaning" class="nav-link" data-scroll-target="#odds-ratios-and-their-meaning"><span class="header-section-number">8.14.1</span> Odds Ratios and Their Meaning</a></li>
  <li><a href="#pitfalls-in-interpretation" id="toc-pitfalls-in-interpretation" class="nav-link" data-scroll-target="#pitfalls-in-interpretation"><span class="header-section-number">8.14.2</span> Pitfalls in Interpretation</a></li>
  <li><a href="#example-from-loan-default-dataset" id="toc-example-from-loan-default-dataset" class="nav-link" data-scroll-target="#example-from-loan-default-dataset"><span class="header-section-number">8.14.3</span> Example from Loan Default Dataset</a></li>
  </ul>
</li>
  <li>
<a href="#predictions" id="toc-predictions" class="nav-link" data-scroll-target="#predictions"><span class="header-section-number">8.15</span> Predictions</a>
  <ul>
<li><a href="#predicted-probabilities-vs.-predicted-classes" id="toc-predicted-probabilities-vs.-predicted-classes" class="nav-link" data-scroll-target="#predicted-probabilities-vs.-predicted-classes"><span class="header-section-number">8.15.1</span> Predicted Probabilities vs.&nbsp;Predicted Classes</a></li>
  <li><a href="#evaluating-performance" id="toc-evaluating-performance" class="nav-link" data-scroll-target="#evaluating-performance"><span class="header-section-number">8.15.2</span> Evaluating Performance</a></li>
  </ul>
</li>
  <li>
<a href="#goodness-of-fit-model-selection" id="toc-goodness-of-fit-model-selection" class="nav-link" data-scroll-target="#goodness-of-fit-model-selection"><span class="header-section-number">8.16</span> Goodness of Fit &amp; Model Selection</a>
  <ul>
<li><a href="#pseudo-r-squared-measures" id="toc-pseudo-r-squared-measures" class="nav-link" data-scroll-target="#pseudo-r-squared-measures"><span class="header-section-number">8.16.1</span> Pseudo R-Squared Measures</a></li>
  <li><a href="#analysis-of-deviance" id="toc-analysis-of-deviance" class="nav-link" data-scroll-target="#analysis-of-deviance"><span class="header-section-number">8.16.2</span> Analysis of Deviance</a></li>
  <li><a href="#information-criteria" id="toc-information-criteria" class="nav-link" data-scroll-target="#information-criteria"><span class="header-section-number">8.16.3</span> Information Criteria</a></li>
  </ul>
</li>
  <li>
<a href="#model-diagnostics" id="toc-model-diagnostics" class="nav-link" data-scroll-target="#model-diagnostics"><span class="header-section-number">8.17</span> Model Diagnostics</a>
  <ul>
<li><a href="#deviance-residuals" id="toc-deviance-residuals" class="nav-link" data-scroll-target="#deviance-residuals"><span class="header-section-number">8.17.1</span> Deviance Residuals</a></li>
  <li><a href="#binned-residual-plots" id="toc-binned-residual-plots" class="nav-link" data-scroll-target="#binned-residual-plots"><span class="header-section-number">8.17.2</span> Binned Residual Plots</a></li>
  <li><a href="#detecting-influential-points" id="toc-detecting-influential-points" class="nav-link" data-scroll-target="#detecting-influential-points"><span class="header-section-number">8.17.3</span> Detecting Influential Points</a></li>
  </ul>
</li>
  <li>
<a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results"><span class="header-section-number">8.18</span> Results</a>
  <ul>
<li><a href="#predictive-analysis" id="toc-predictive-analysis" class="nav-link" data-scroll-target="#predictive-analysis"><span class="header-section-number">8.18.1</span> Predictive Analysis</a></li>
  <li><a href="#inferential-analysis" id="toc-inferential-analysis" class="nav-link" data-scroll-target="#inferential-analysis"><span class="header-section-number">8.18.2</span> Inferential Analysis</a></li>
  </ul>
</li>
  <li><a href="#storytelling" id="toc-storytelling" class="nav-link" data-scroll-target="#storytelling"><span class="header-section-number">8.19</span> Storytelling</a></li>
  </ul><div class="toc-actions"><ul><li><a href="https://github.com/alexrod61/regression-cookbook/edit/main/book/08-binary-logistic.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/alexrod61/regression-cookbook/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li><li><a href="https://github.com/alexrod61/regression-cookbook/blob/main/book/08-binary-logistic.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../book/discrete-zone.html">Discrete Cuisine</a></li><li class="breadcrumb-item"><a href="../book/08-binary-logistic.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Binary Logistic Regression</span></a></li></ol></nav><div class="quarto-title">
<h1 class="title">Binary Logistic Regression</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header><!--#
# Quarto Document Setup
# ======================================================
# This section defines metadata and execution rules for the chapter.
# - "title" sets the chapter title displayed in the rendered book.
# - "execute: eval: false" prevents R/Python code from being run 
#   during rendering (useful if code is illustrative, or if setup 
#   is handled separately).
# ====================================================== --><!-- ======================================================
Google Analytics Tracking Snippet
------------------------------------------------------
- This loads the Google Analytics "gtag.js" script asynchronously 
  so it does not block page rendering.
- The `id` value ("G-7PRVEBE1EF") is your unique measurement ID.
- `window.dataLayer` is initialized if it doesn’t exist already.
- The `gtag` function pushes tracking events into the dataLayer.
- `gtag('js', new Date());` records the time the analytics script 
  was loaded.
- `gtag('config', 'G-7PRVEBE1EF');` activates tracking for this ID.
------------------------------------------------------
You can safely move this block into the YAML `include-in-header` 
if you want it injected site-wide, rather than repeating it per 
chapter.
====================================================== --><!-- Google tag (gtag.js) --><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-7PRVEBE1EF"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-7PRVEBE1EF');
</script><!-- 
This block creates a **Mermaid mindmap diagram** that shows how different 
chapters in the book fit into the broader context of regression analysis.  

- It organizes regression models by the type of outcome variable (Continuous vs. Discrete).  
- Each branch links to a chapter in the book (e.g., OLS, Gamma Regression, Beta Regression).  
- This diagram provides readers with a "map" of where Binary Logistic Regression fits in.  
--><div id="fig-binary-logistic-regression" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-binary-logistic-regression-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"></figure><p></p>
<div>

</div>
<p></p>
</div>
</div>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-binary-logistic-regression-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.1
</figcaption></figure>
</div>
<div class="LO">
<div class="LO-header">
<p><strong>Learning Objectives</strong></p>
</div>
<div class="LO-container">
<p>By the end of this chapter, you will be able to:</p>
<ul>
<li>Explain how <strong>Binary Logistic Regression</strong> models the probability of a binary outcome using <strong>log-odds</strong>.<br>
</li>
<li>Describe why <strong>Ordinary Least Squares</strong> is not appropriate for binary outcomes, and how the <strong>logistic function</strong> addresses this.<br>
</li>
<li>Fit a binary logistic regression model in both <code>R</code> and <code>Python</code>.<br>
</li>
<li>Interpret <strong>log-odds</strong>, <strong>odds ratios</strong>, and <strong>predicted probabilities</strong> in real-world contexts.<br>
</li>
<li>Evaluate model fit using metrics such as <strong>accuracy</strong>, <strong>confusion matrices</strong>, and <strong>ROC curves</strong>.<br>
</li>
<li>Identify when binary logistic regression is the <strong>appropriate tool</strong>, and understand its <strong>limitations</strong>.<br>
</li>
</ul>
</div>
</div>
<section id="introduction" class="level2" data-number="8.1"><h2 data-number="8.1" class="anchored" data-anchor-id="introduction">
<span class="header-section-number">8.1</span> Introduction</h2>
<p>In many real-world problems, the outcome we’re trying to predict is <strong>not a number</strong> — it’s a <strong>yes or no</strong>, <strong>success or failure</strong>, <strong>clicked or didn’t click</strong>. For example:</p>
<ul>
<li>Will a student <strong>default on a loan</strong> given their credit score and income?</li>
<li>Will a student <strong>pass a course</strong> based on whether they have a part-time job and how many hours they studied?</li>
<li>Will a student <strong>likely graduate within 4 years</strong>, based on their academic record and declared major?</li>
</ul>
<p>These outcomes are <strong>binary</strong>: they can take on only two possible values, typically coded as <code>1</code> (event occurs) and <code>0</code> (event does not occur).</p>
<p>To model such outcomes, we need a regression approach that produces <strong>predicted probabilities</strong> between 0 and 1 — not arbitrary numbers on the real line. This is where <strong>Binary Logistic Regression</strong> comes in.</p>
<p>In this chapter, we’ll see how logistic regression: - Links input variables to the <strong>log-odds</strong> of the outcome, - Produces interpretable coefficients (like <strong>odds ratios</strong>), and - Helps us make informed predictions in binary classification problems.</p>
</section><section id="why-ordinary-least-squares-fails-for-binary-outcomes" class="level2" data-number="8.2"><h2 data-number="8.2" class="anchored" data-anchor-id="why-ordinary-least-squares-fails-for-binary-outcomes">
<span class="header-section-number">8.2</span> Why Ordinary Least Squares Fails for Binary Outcomes</h2>
<p>To understand the need for logistic regression, consider applying Ordinary Least Squares (OLS) to a <strong>binary outcome</strong>.</p>
<p>Suppose we are trying to predict whether a student <strong>defaulted</strong> on a loan (<code>1</code>) or <strong>did not default</strong> (<code>0</code>) using a continuous predictor like <code>credit_score</code>.</p>
<p>Before diving into the technical reasons why OLS is inappropriate for binary outcomes, let’s look at a simplified version of the dataset we’ll use throughout this chapter:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Prepare data: numeric default variable and select predictor</span></span>
<span><span class="va">blr_data</span> <span class="op">&lt;-</span> <span class="va">BLR</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">select</span><span class="op">(</span><span class="va">credit_score</span>, <span class="va">defaulted</span><span class="op">)</span> <span class="op">%&gt;%</span></span>
<span>  <span class="fu">mutate</span><span class="op">(</span>defaulted <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">defaulted</span><span class="op">)</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Below is a sample of this dataset:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 6%">
<col style="width: 8%">
<col style="width: 17%">
<col style="width: 9%">
<col style="width: 12%">
<col style="width: 14%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 8%">
</colgroup>
<thead><tr class="header">
<th style="text-align: right;"><strong>credit_score</strong></th>
<th style="text-align: right;"><strong>income</strong></th>
<th style="text-align: right;"><strong>education_years</strong></th>
<th style="text-align: right;"><strong>married</strong></th>
<th style="text-align: right;"><strong>owns_home</strong></th>
<th style="text-align: right;"><strong>age</strong></th>
<th style="text-align: right;"><strong>defaulted</strong></th>
<th style="text-align: right;"><strong>successes</strong></th>
<th style="text-align: right;"><strong>trials</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">787</td>
<td style="text-align: right;">118911</td>
<td style="text-align: right;">17</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">47</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">9</td>
<td style="text-align: right;">10</td>
</tr>
<tr class="even">
<td style="text-align: right;">441</td>
<td style="text-align: right;">53122</td>
<td style="text-align: right;">13</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">50</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">10</td>
</tr>
<tr class="odd">
<td style="text-align: right;">407</td>
<td style="text-align: right;">39174</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">50</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">5</td>
<td style="text-align: right;">10</td>
</tr>
<tr class="even">
<td style="text-align: right;">812</td>
<td style="text-align: right;">148982</td>
<td style="text-align: right;">12</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">32</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">10</td>
</tr>
<tr class="odd">
<td style="text-align: right;">825</td>
<td style="text-align: right;">154293</td>
<td style="text-align: right;">16</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">41</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">7</td>
<td style="text-align: right;">10</td>
</tr>
<tr class="even">
<td style="text-align: right;">729</td>
<td style="text-align: right;">111562</td>
<td style="text-align: right;">15</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">64</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">7</td>
<td style="text-align: right;">10</td>
</tr>
<tr class="odd">
<td style="text-align: right;">700</td>
<td style="text-align: right;">70000</td>
<td style="text-align: right;">15</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">46</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">8</td>
<td style="text-align: right;">10</td>
</tr>
<tr class="even">
<td style="text-align: right;">451</td>
<td style="text-align: right;">40311</td>
<td style="text-align: right;">12</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">59</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">10</td>
</tr>
<tr class="odd">
<td style="text-align: right;">404</td>
<td style="text-align: right;">45944</td>
<td style="text-align: right;">13</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">53</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">10</td>
</tr>
<tr class="even">
<td style="text-align: right;">374</td>
<td style="text-align: right;">43167</td>
<td style="text-align: right;">11</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">34</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">4</td>
<td style="text-align: right;">10</td>
</tr>
</tbody>
</table>
<p>Now, let’s narrow in on the key variables of interest for this section.</p>
<table class="caption-top table">
<thead><tr class="header">
<th><strong>credit_score</strong></th>
<th><strong>defaulted</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td>787</td>
<td>0</td>
</tr>
<tr class="even">
<td>441</td>
<td>1</td>
</tr>
<tr class="odd">
<td>407</td>
<td>1</td>
</tr>
<tr class="even">
<td>812</td>
<td>0</td>
</tr>
<tr class="odd">
<td>825</td>
<td>0</td>
</tr>
<tr class="even">
<td>729</td>
<td>0</td>
</tr>
<tr class="odd">
<td>700</td>
<td>0</td>
</tr>
<tr class="even">
<td>451</td>
<td>1</td>
</tr>
<tr class="odd">
<td>404</td>
<td>1</td>
</tr>
<tr class="even">
<td>374</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>This dataset allows us to examine whether a student defaulted on a loan (<code>defaulted = 1</code>) based on their <code>credit_score</code>. It’s a classic binary outcome: a “yes” or “no” event.</p>
<p>If we use OLS, we estimate:</p>
<p><span class="math display">\[
\mathbb{E}(Y_i \mid X_i) = \pi_i = \beta_0 + \beta_1 X_i
\]</span></p>
<p>This means we’re treating the <strong>probability of default</strong> (<span class="math inline">\(\pi_i\)</span>) as a linear function of credit score.</p>
<p>However, there are <strong>two fundamental issues</strong> with using OLS here:</p>
<ol type="1">
<li>The linear model can produce predicted values <strong>less than 0</strong> or <strong>greater than 1</strong> — which doesn’t make sense when modeling a <strong>probability</strong>.</li>
<li>OLS assumes <strong>constant variance</strong> of the residuals, but binary outcomes inherently violate this assumption, because their variance depends on the mean:</li>
</ol>
<p><span class="math display">\[
\text{Var}(Y_i) = \pi_i(1 - \pi_i)
\]</span></p>
<p>To see this issue in action, let’s try fitting an OLS regression model using our binary outcome and a continuous predictor. While OLS is designed to minimize squared error, it doesn’t account for the discrete nature of the response — which means it can return predicted probabilities below 0 or above 1. In the example below, we use a customer’s credit score to predict the probability of default, and you’ll see how the linear model fails to respect the fundamental constraints of probability.</p>
<div id="fig-ols-failure-binary" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-ols-failure-binary-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/ols-failure-credit-score2.png" class="img-fluid figure-img" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-ols-failure-binary-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.2: OLS fails to constrain predictions between 0 and 1, despite binary outcomes.
</figcaption></figure>
</div>
<p>These limitations make OLS unsuitable for binary classification tasks.<br>
To properly model binary outcomes, we need a method that:</p>
<ul>
<li>Produces predictions strictly between 0 and 1,</li>
<li>Accounts for the fact that the variance depends on the mean, and</li>
<li>Connects our predictors to the probability of the event in a way that is easy to interpret.</li>
</ul>
<p>The key idea is to <strong>transform the probability</strong> so that it can be modeled as a linear function without breaking these rules.<br>
In the next section, we’ll see how the <strong>logit transformation</strong> does exactly that.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true" aria-current="page">R Code</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Python Code</a></li>
</ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># ⚠️ This OLS fit is not appropriate for binary outcomes.</span></span>
<span><span class="co"># We include it here only to illustrate why logistic regression is needed.</span></span>
<span></span>
<span><span class="co"># Load necessary libraries</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Prepare data: numeric default variable and select predictor</span></span>
<span><span class="va">blr_data</span> <span class="op">&lt;-</span> <span class="va">BLR</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="va">credit_score</span>, <span class="va">defaulted</span><span class="op">)</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>defaulted <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">defaulted</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Fit an OLS model (not ideal for binary outcome)</span></span>
<span><span class="va">ols_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">defaulted</span> <span class="op">~</span> <span class="va">credit_score</span>, data <span class="op">=</span> <span class="va">blr_data</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Add predicted values</span></span>
<span><span class="va">blr_data</span><span class="op">$</span><span class="va">predicted</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">ols_model</span>, newdata <span class="op">=</span> <span class="va">blr_data</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot actual data and OLS-fitted line</span></span>
<span><span class="va">plot</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">blr_data</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">credit_score</span>, y <span class="op">=</span> <span class="va">defaulted</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_jitter.html">geom_jitter</a></span><span class="op">(</span>height <span class="op">=</span> <span class="fl">0.05</span>, width <span class="op">=</span> <span class="fl">0</span>, alpha <span class="op">=</span> <span class="fl">0.4</span>, color <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">predicted</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"blue"</span>, linewidth <span class="op">=</span> <span class="fl">1.2</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span></span>
<span>    title <span class="op">=</span> <span class="st">"OLS Fitted Line on Binary Data"</span>,</span>
<span>    x <span class="op">=</span> <span class="st">"Credit Score"</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Predicted Probability of Default"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/coord_cartesian.html">coord_cartesian</a></span><span class="op">(</span>ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.2</span>, <span class="fl">1.2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span><span class="op">(</span>plot.title <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_text</a></span><span class="op">(</span>hjust <span class="op">=</span> <span class="fl">0.5</span>, face <span class="op">=</span> <span class="st">"bold"</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">plot</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ⚠️ This OLS fit is not appropriate for binary outcomes.</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># We include it here only to illustrate why logistic regression is needed.</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract relevant columns from the BLR dataset</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>blr <span class="op">=</span> r.data[<span class="st">'BLR'</span>]</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> blr[[<span class="st">'credit_score'</span>, <span class="st">'defaulted'</span>]].copy()</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'defaulted'</span>] <span class="op">=</span> df[<span class="st">'defaulted'</span>].astype(<span class="bu">int</span>)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit an OLS model</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(df[<span class="st">'credit_score'</span>])</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.OLS(df[<span class="st">'defaulted'</span>], X).fit()</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'predicted'</span>] <span class="op">=</span> model.predict(X)</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the actual binary outcomes and OLS predictions</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">4</span>))</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>ax.scatter(df[<span class="st">'credit_score'</span>], df[<span class="st">'defaulted'</span>], alpha<span class="op">=</span><span class="fl">0.4</span>, color<span class="op">=</span><span class="st">'black'</span>, label<span class="op">=</span><span class="st">'Actual Data'</span>, s<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>ax.plot(df[<span class="st">'credit_score'</span>], df[<span class="st">'predicted'</span>], color<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="st">'OLS Fit'</span>, linewidth<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"OLS Fitted Line on Binary Data"</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"Credit Score"</span>)</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"Predicted Probability of Default"</span>)</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>ax.set_ylim(<span class="op">-</span><span class="fl">0.2</span>, <span class="fl">1.2</span>)</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>ax.legend()</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>)</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-2-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-1" role="tab" aria-controls="tabset-2-1" aria-selected="true">R Output TODO</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-2-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-2-2" role="tab" aria-controls="tabset-2-2" aria-selected="false">Python Output TODO</a></li>
</ul>
<div class="tab-content">
<div id="tabset-2-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-2-1-tab">

</div>
<div id="tabset-2-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-2-2-tab">

</div>
</div>
</div>
</section><section id="the-logit-function" class="level2" data-number="8.3"><h2 data-number="8.3" class="anchored" data-anchor-id="the-logit-function">
<span class="header-section-number">8.3</span> The Logit Function</h2>
<p>In Section 8.2, we saw that modeling probability directly with a linear equation can produce impossible values (less than 0 or greater than 1) and ignores the way variance changes with the mean.</p>
<p>The fix is to apply a transformation that:</p>
<ul>
<li>Expands the (0, 1) probability range to the entire real line,</li>
<li>Is reversible, so we can convert back to probabilities, and</li>
<li>Preserves the ordering of probabilities.</li>
</ul>
<p>One transformation that checks all these boxes is the <strong>logit function</strong>.</p>
<section id="logit-a-link-between-probability-and-linear-predictors" class="level3" data-number="8.3.1"><h3 data-number="8.3.1" class="anchored" data-anchor-id="logit-a-link-between-probability-and-linear-predictors">
<span class="header-section-number">8.3.1</span> Logit: A Link Between Probability and Linear Predictors</h3>
<p>The <strong>logit function</strong> transforms the probability <span class="math inline">\(\pi_i\)</span> into a value on the entire real line: <span class="math display">\[
\text{logit}(\pi_i) = \log\!\left(\frac{\pi_i}{1 - \pi_i}\right) = \beta_0 + \beta_1 X_i
\]</span></p>
<p>This transformation:</p>
<ul>
<li>Is <strong>monotonic</strong> (it preserves order),</li>
<li>Maps probabilities <span class="math inline">\(\pi_i \in (0, 1)\)</span> to <span class="math inline">\((-\infty, \infty)\)</span>, and</li>
<li>Solves the range issue of OLS by letting us fit a linear model in the transformed space.</li>
</ul>
<p>By modeling the <strong>log-odds</strong> as a linear function of predictors and then inverting the transformation, we obtain valid predicted <strong>probabilities</strong> that remain within <span class="math inline">\([0,1]\)</span>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <strong>logit function</strong> is defined as: <span class="math display">\[
\text{logit}(\pi_i) = \log\!\left(\frac{\pi_i}{1 - \pi_i}\right)
\]</span> It models the <strong>log-odds</strong> of the outcome as a linear function of predictors.</p>
</div>
</div>
</section><section id="from-log-odds-back-to-probability" class="level3" data-number="8.3.2"><h3 data-number="8.3.2" class="anchored" data-anchor-id="from-log-odds-back-to-probability">
<span class="header-section-number">8.3.2</span> From Log-Odds Back to Probability</h3>
<p>While the model calculates linearly on the log-odds scale, we ultimately want to understand the probability of the outcome (<span class="math inline">\(\pi_i\)</span>). To do this, we invert the logit function.</p>
<p>The inverse of the logit is the <strong>Sigmoid function</strong> (also called the logistic function):</p>
<p><span class="math display">\[
\pi_i = \frac{1}{1 + e^{-(\beta_0 + \beta_1 X_i)}}
\]</span></p>
<p>This function takes our linear prediction (<span class="math inline">\(\beta_0 + \beta_1 X_i\)</span>), which can range from <span class="math inline">\(-\infty\)</span> to <span class="math inline">\(+\infty\)</span>, and “squashes” it into the range <span class="math inline">\((0, 1)\)</span>. This mathematical trick ensures that no matter how extreme our predictor values get, our predicted probability never exceeds 1 or drops below 0.</p>
<div id="fig-logistic-curve" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-logistic-curve-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/logistic-curve.png" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-logistic-curve-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.3: The Logistic Function showing the S-shape curve
</figcaption></figure>
</div>
</section><section id="understanding-the-s-shape" class="level3" data-number="8.3.3"><h3 data-number="8.3.3" class="anchored" data-anchor-id="understanding-the-s-shape">
<span class="header-section-number">8.3.3</span> Understanding the “S” Shape</h3>
<p>The sigmoid function is not just a boundary enforcer; it fundamentally changes how we interpret the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. Unlike a straight line, the sigmoid curve is <strong>non-linear</strong>.</p>
<p><strong>1. The Steep Middle (High Sensitivity)</strong> When the probability is near 0.5 (the “tipping point”), the curve is steepest. This means that small changes in the predictor <span class="math inline">\(X\)</span> result in <strong>large changes</strong> in the probability <span class="math inline">\(\pi_i\)</span>. * <em>Context:</em> If a borrower is borderline (e.g., 50/50 chance of default), a small improvement in their credit score can drastically reduce their default risk.</p>
<p><strong>2. The Flat Tails (Diminishing Returns)</strong> As the probability approaches 0 or 1, the curve flattens out (asymptotes). In these regions, even large changes in <span class="math inline">\(X\)</span> result in <strong>tiny changes</strong> in <span class="math inline">\(\pi_i\)</span>. * <em>Context:</em> If a borrower has a near-perfect credit score (risk <span class="math inline">\(\approx 0.01\%\)</span>), increasing their score further makes almost no difference to their probability of default. The model recognizes that they are already “maxed out” on safety.</p>
<p>This captures a realistic property of many binary outcomes: <strong>interventions are most effective when the outcome is uncertain.</strong></p>
<p>This transformation lets us use a linear predictor on the <strong>log-odds</strong> scale and then recover valid probabilities.<br>
This idea forms the basis of <strong>binary logistic regression</strong>, introduced next.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Visualizing the Difference
</div>
</div>
<div class="callout-body-container callout-body">
<p>In <strong>OLS (Linear Regression)</strong>, the slope is constant (<span class="math inline">\(\beta_1\)</span>). In <strong>Logistic Regression</strong>, the “slope” (rate of change in probability) changes constantly—it is steepest at <span class="math inline">\(\pi = 0.5\)</span> and approaches zero at the extremes.</p>
</div>
</div>
<hr></section><section id="the-logistic-function-and-its-shape-code" class="level3" data-number="8.3.4"><h3 data-number="8.3.4" class="anchored" data-anchor-id="the-logistic-function-and-its-shape-code">
<span class="header-section-number">8.3.4</span> The Logistic Function and Its Shape (Code)</h3>
<p>The following plot illustrates this behavior. Notice how the linear model (red dashed line) marches blindly past 0 and 1, while the logistic model (blue solid line) respects the boundaries and shows the characteristic “S” shape.</p>
<div id="fig-logistic-sigmoid" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure"><div aria-describedby="fig-logistic-sigmoid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="img/logistic-sigmoid.png" class="img-fluid figure-img" style="width:90.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-logistic-sigmoid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8.4: The Sigmoid ‘S-Curve’ vs.&nbsp;Linear Fit. The logistic model (blue solid line) respects the [0,1] probability bounds and captures the non-linear “diminishing returns” at the extremes, whereas the linear model (red dashed line) extends indefinitely.
</figcaption></figure>
</div>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-3-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-1" role="tab" aria-controls="tabset-3-1" aria-selected="true">R Code</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-3-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-3-2" role="tab" aria-controls="tabset-3-2" aria-selected="false">Python Code</a></li>
</ul>
<div class="tab-content">
<div id="tabset-3-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-3-1-tab">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Logistic vs Linear fit demo</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">4</span>, <span class="fl">4</span>, length.out <span class="op">=</span> <span class="fl">200</span><span class="op">)</span></span>
<span><span class="va">eta</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">1</span> <span class="op">+</span> <span class="fl">1.2</span> <span class="op">*</span> <span class="va">x</span>                  <span class="co"># linear predictor (log-odds)</span></span>
<span><span class="va">pi</span>  <span class="op">&lt;-</span> <span class="fl">1</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">eta</span><span class="op">)</span><span class="op">)</span>           <span class="co"># sigmoid (probability)</span></span>
<span></span>
<span><span class="co"># A naive linear "probability" for comparison</span></span>
<span><span class="co"># Rescaled to make the visual comparison clear</span></span>
<span><span class="va">p_lin</span> <span class="op">&lt;-</span> <span class="fu">scales</span><span class="fu">::</span><span class="fu"><a href="https://scales.r-lib.org/reference/rescale.html">rescale</a></span><span class="op">(</span><span class="va">eta</span>, to <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.4</span>, <span class="fl">1.4</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span>, sigmoid <span class="op">=</span> <span class="va">pi</span>, linear <span class="op">=</span> <span class="va">p_lin</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">df</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">x</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="co"># The Sigmoid Curve</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">sigmoid</span><span class="op">)</span>, linewidth <span class="op">=</span> <span class="fl">1.2</span>, color <span class="op">=</span> <span class="st">"#2C3E50"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="co"># The Naive Linear Line</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="va">linear</span><span class="op">)</span>, linetype <span class="op">=</span> <span class="st">"dashed"</span>, color <span class="op">=</span> <span class="st">"#E74C3C"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="co"># Visual guide for the "Steep Middle"</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_segment.html">geom_segment</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fl">0.8</span>, y <span class="op">=</span> <span class="fl">0.2</span>, xend <span class="op">=</span> <span class="fl">0.8</span>, yend <span class="op">=</span> <span class="fl">0.8</span><span class="op">)</span>, </span>
<span>               arrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/grid/arrow.html">arrow</a></span><span class="op">(</span>length <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/grid/unit.html">unit</a></span><span class="op">(</span><span class="fl">0.2</span>, <span class="st">"cm"</span><span class="op">)</span><span class="op">)</span>, color <span class="op">=</span> <span class="st">"gray50"</span>, size <span class="op">=</span> <span class="fl">0.1</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/annotate.html">annotate</a></span><span class="op">(</span><span class="st">"text"</span>, x <span class="op">=</span> <span class="fl">1.5</span>, y <span class="op">=</span> <span class="fl">0.5</span>, label <span class="op">=</span> <span class="st">"Steepest change\nat p ~ 0.5"</span>, </span>
<span>           size <span class="op">=</span> <span class="fl">3.5</span>, hjust <span class="op">=</span> <span class="fl">0</span>, color <span class="op">=</span> <span class="st">"gray30"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/coord_cartesian.html">coord_cartesian</a></span><span class="op">(</span>ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">0.1</span>, <span class="fl">1.1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Linear predictor (η = β0 + β1 X)"</span>,</span>
<span>       y <span class="op">=</span> <span class="st">"Probability (π)"</span>,</span>
<span>       title <span class="op">=</span> <span class="st">"The Sigmoid 'S-Curve' vs. Linear Fit"</span>,</span>
<span>       subtitle <span class="op">=</span> <span class="st">"Logistic regression captures diminishing returns at the extremes"</span>,</span>
<span>       caption <span class="op">=</span> <span class="st">"Blue: Logistic Sigmoid (Valid Probabilities). Red: Naive Linear (Violates Bounds)."</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span>base_size <span class="op">=</span> <span class="fl">12</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-3-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-3-2-tab">
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">1</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">200</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>eta <span class="op">=</span> <span class="op">-</span><span class="dv">1</span> <span class="op">+</span> <span class="fl">1.2</span> <span class="op">*</span> x</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>pi <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>eta))  <span class="co"># logistic sigmoid</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Linear "probability" rescaled for comparison</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>p_lin <span class="op">=</span> (eta <span class="op">-</span> eta.<span class="bu">min</span>()) <span class="op">/</span> (eta.<span class="bu">max</span>() <span class="op">-</span> eta.<span class="bu">min</span>()) <span class="op">*</span> (<span class="fl">1.8</span>) <span class="op">-</span> <span class="fl">0.4</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Sigmoid</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>plt.plot(x, pi, label<span class="op">=</span><span class="st">"Logistic Sigmoid (Valid $</span><span class="er">\</span><span class="st">pi$)"</span>, linewidth<span class="op">=</span><span class="fl">2.5</span>, color<span class="op">=</span><span class="st">"#2C3E50"</span>)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot Naive Linear</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>plt.plot(x, p_lin, <span class="st">"--"</span>, label<span class="op">=</span><span class="st">"Naive Linear (Violates Bounds)"</span>, color<span class="op">=</span><span class="st">"#E74C3C"</span>)</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Annotate the "Steep Middle"</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>plt.annotate(<span class="st">'Steepest change</span><span class="ch">\n</span><span class="st">at $</span><span class="er">\</span><span class="st">pi </span><span class="ch">\\</span><span class="st">approx 0.5$'</span>, xy<span class="op">=</span>(<span class="fl">0.83</span>, <span class="fl">0.5</span>), xytext<span class="op">=</span>(<span class="dv">2</span>, <span class="fl">0.45</span>),</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>             arrowprops<span class="op">=</span><span class="bu">dict</span>(facecolor<span class="op">=</span><span class="st">'black'</span>, arrowstyle<span class="op">=</span><span class="st">'-&gt;'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>),</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>             fontsize<span class="op">=</span><span class="dv">10</span>, color<span class="op">=</span><span class="st">"#555555"</span>)</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="op">-</span><span class="fl">0.1</span>, <span class="fl">1.1</span>)</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>plt.axhline(<span class="dv">0</span>, color<span class="op">=</span><span class="st">'grey'</span>, lw<span class="op">=</span><span class="fl">0.5</span>, ls<span class="op">=</span><span class="st">':'</span>)</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>plt.axhline(<span class="dv">1</span>, color<span class="op">=</span><span class="st">'grey'</span>, lw<span class="op">=</span><span class="fl">0.5</span>, ls<span class="op">=</span><span class="st">':'</span>)</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Linear predictor ($</span><span class="er">\</span><span class="st">eta = </span><span class="ch">\\</span><span class="st">beta_0 + </span><span class="ch">\\</span><span class="st">beta_1 X$)"</span>)</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Probability ($</span><span class="er">\</span><span class="st">pi$)"</span>)</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"The Sigmoid 'S-Curve' vs. Linear Fit"</span>)</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">'upper left'</span>)</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, alpha<span class="op">=</span><span class="fl">0.3</span>)</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<hr></section></section><section id="case-study-understanding-financial-behaviors" class="level2" data-number="8.4"><h2 data-number="8.4" class="anchored" data-anchor-id="case-study-understanding-financial-behaviors">
<span class="header-section-number">8.4</span> Case Study: Understanding Financial Behaviors</h2>
<p>Statistical models are most useful when they connect to a real-world problem. Here, we’ll use binary logistic regression to study <strong>financial behavior</strong> — specifically, the likelihood that a student <strong>defaults</strong> on a loan.</p>
<hr>
<section id="the-dataset" class="level3" data-number="8.4.1"><h3 data-number="8.4.1" class="anchored" data-anchor-id="the-dataset">
<span class="header-section-number">8.4.1</span> The Dataset</h3>
<p>We’ll use the <code>Logistic_Regression</code> dataset (packaged in <code>cookbook</code>).</p>
<ul>
<li>
<p><strong>Predictors</strong>:</p>
<ul>
<li>
<code>credit_score</code> (numeric, higher = lower risk)</li>
<li>
<code>income</code> (numeric, annual income in dollars)</li>
<li>
<code>age</code> (numeric)</li>
<li>
<code>loan_amount</code> (numeric, loan size)</li>
<li>
<code>student</code> (categorical: yes/no)</li>
</ul>
</li>
<li>
<p><strong>Outcome</strong>:</p>
<ul>
<li>
<code>defaulted</code> (binary: <code>1 = default</code>, <code>0 = no default</code>)</li>
</ul>
</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>This is a <strong>binary classification problem</strong>: given a mix of continuous and categorical predictors, we want to predict whether a student defaults.</p>
</div>
</div>
<hr></section><section id="the-problem-were-trying-to-solve" class="level3" data-number="8.4.2"><h3 data-number="8.4.2" class="anchored" data-anchor-id="the-problem-were-trying-to-solve">
<span class="header-section-number">8.4.2</span> The Problem We’re Trying to Solve</h3>
<p>Banks and lenders routinely face a critical decision:</p>
<blockquote class="blockquote">
<p><em>Given a customer’s financial history, should we approve their loan application?</em></p>
</blockquote>
<p>While this sounds like a simple “Yes” or “No” question, the reality is a complex game of <strong>probability and risk management</strong>.</p>
<section id="the-balancing-act-of-lending" class="level4"><h4 class="anchored" data-anchor-id="the-balancing-act-of-lending">1. The Balancing Act of Lending</h4>
<p>Lending is a trade-off between two competing goals:</p>
<ul>
<li><p><strong>Maximizing Profit:</strong> The bank wants to lend to as many people as possible to earn interest.</p></li>
<li><p><strong>Minimizing Loss:</strong> The bank wants to avoid lending to people who will not pay the money back (default).</p></li>
</ul>
<p>If a bank is too strict, they reject good customers and lose profit. If they are too lenient, they lose their principal investment. The goal of <strong>Binary Logistic Regression</strong> here is not just to guess who defaults, but to <strong>quantify the risk</strong> (<span class="math inline">\(\hat{\pi}_i\)</span>) so the bank can find the profitable “sweet spot.”</p>
</section><section id="the-asymmetry-of-errors" class="level4"><h4 class="anchored" data-anchor-id="the-asymmetry-of-errors">2. The Asymmetry of Errors</h4>
<p>In this context, being wrong in one direction is much more expensive than being wrong in the other.</p>
<ul>
<li>
<strong>False Positive (Type I Error):</strong> The model predicts a customer will default, but they would have paid.
<ul>
<li>
<em>Cost:</em> The bank loses the potential interest (opportunity cost).</li>
</ul>
</li>
<li>
<strong>False Negative (Type II Error):</strong> The model predicts a customer is safe, but they default.
<ul>
<li>
<em>Cost:</em> The bank loses the entire loan amount.</li>
</ul>
</li>
</ul>
<p>Because a False Negative is usually much costlier than a False Positive, lenders need a model that outputs a precise <strong>probability</strong> (e.g., “There is an 18% chance this person defaults”). This allows them to set a custom <strong>decision threshold</strong>—perhaps they only approve loans if the risk of default is below 10%, rather than the standard 50%.</p>
<hr></section></section><section id="study-design" class="level3" data-number="8.4.3"><h3 data-number="8.4.3" class="anchored" data-anchor-id="study-design">
<span class="header-section-number">8.4.3</span> Study Design</h3>
<ul>
<li><p><strong>Predictor types</strong>: both <strong>continuous</strong> (income, age, credit_score, loan_amount) and <strong>categorical</strong> (student status).</p></li>
<li><p><strong>Outcome</strong>: binary (defaulted).</p></li>
<li><p><strong>Sample size</strong>: dataset includes a few hundred observations (enough to illustrate the method).</p></li>
<li>
<p><strong>Assumptions</strong>:</p>
<ul>
<li>Observations are independent.</li>
<li>Predictors have a linear relationship with the <strong>log-odds</strong> of default.</li>
<li>No perfect collinearity among predictors.</li>
</ul>
</li>
</ul>
<hr></section><section id="applying-study-design-to-our-case-study" class="level3" data-number="8.4.4"><h3 data-number="8.4.4" class="anchored" data-anchor-id="applying-study-design-to-our-case-study">
<span class="header-section-number">8.4.4</span> Applying Study Design to Our Case Study</h3>
<p>Before we fit the model, we must prepare the data. In predictive modeling, this involves three critical steps: <strong>splitting</strong>, <strong>checking for imbalance</strong>, and <strong>handling outliers</strong>.</p>
<section id="why-we-split-the-data-training-vs.-testing" class="level4"><h4 class="anchored" data-anchor-id="why-we-split-the-data-training-vs.-testing">Why We Split the Data (Training vs.&nbsp;Testing)</h4>
<p>A common mistake is to fit a model on all available data and then evaluate its performance on that same data. This leads to <strong>overfitting</strong>: the model memorizes the specific noise in the dataset rather than learning the underlying patterns.</p>
<p>To ensure our model generalizes to new, unseen borrowers, we split the data into two sets:</p>
<ul>
<li>
<strong>Training Set (e.g., 70%):</strong> Used to estimate the coefficients (<span class="math inline">\(\hat{\beta}\)</span>). The model “sees” this data.</li>
<li>
<strong>Testing Set (e.g., 30%):</strong> Used <em>only</em> to evaluate performance. The model never sees this data during fitting.</li>
</ul></section><section id="the-challenge-of-class-imbalance" class="level4"><h4 class="anchored" data-anchor-id="the-challenge-of-class-imbalance">The Challenge of Class Imbalance</h4>
<p>In loan default data, “success” (paying back the loan) is much more common than “failure” (defaulting). This is known as <strong>class imbalance</strong>.</p>
<p>If 95% of borrowers pay back their loans, a naive model could simply predict “No Default” for everyone and achieve <strong>95% accuracy</strong>. However, this model is useless to the bank because it identifies <strong>zero</strong> risks.</p>
<p>To handle this during the split, we use <strong>stratified sampling</strong>. This ensures that the proportion of defaulters is exactly the same in both the training and testing sets, preventing the “rare” event from disappearing entirely in the test set.</p>
</section><section id="influential-points-and-outliers" class="level4"><h4 class="anchored" data-anchor-id="influential-points-and-outliers">Influential Points and Outliers</h4>
<p>Logistic regression is sensitive to <strong>outliers</strong> (extreme values). A single borrower with an income of $10,000,000 or an age of 110 can pull the logistic curve disproportionately, biasing the results.</p>
<p>Before modeling, we should check for:</p>
<ul>
<li>
<strong>Data Entry Errors:</strong> (e.g., a credit score of 9000, which is impossible).</li>
<li>
<strong>Extreme Leverage Points:</strong> Legitimate but extreme values that might need to be capped or investigated.</li>
</ul>
<hr></section></section><section id="data-preparation-in-action" class="level3" data-number="8.4.5"><h3 data-number="8.4.5" class="anchored" data-anchor-id="data-preparation-in-action">
<span class="header-section-number">8.4.5</span> Data Preparation in Action</h3>
<p>Below, we split the data while preserving the class balance (stratification) and encode the categorical variables.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-4-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-1" role="tab" aria-controls="tabset-4-1" aria-selected="true">R Code</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-4-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-4-2" role="tab" aria-controls="tabset-4-2" aria-selected="false">Python Code</a></li>
</ul>
<div class="tab-content">
<div id="tabset-4-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-4-1-tab">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://rsample.tidymodels.org">rsample</a></span><span class="op">)</span> <span class="co"># Part of tidymodels for splitting</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 1. Check Class Imbalance</span></span>
<span><span class="co"># Notice if defaults are rare (e.g., &lt; 10%)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/proportions.html">prop.table</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">BLR</span><span class="op">$</span><span class="va">defaulted</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 2. Stratified Split</span></span>
<span><span class="co"># We use 'strata = defaulted' to ensure both sets have the same % of defaults</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">split</span> <span class="op">&lt;-</span> <span class="fu">initial_split</span><span class="op">(</span><span class="va">BLR</span>, prop <span class="op">=</span> <span class="fl">0.70</span>, strata <span class="op">=</span> <span class="va">defaulted</span><span class="op">)</span></span>
<span></span>
<span><span class="va">train_data</span> <span class="op">&lt;-</span> <span class="fu">training</span><span class="op">(</span><span class="va">split</span><span class="op">)</span></span>
<span><span class="va">test_data</span>  <span class="op">&lt;-</span> <span class="fu">testing</span><span class="op">(</span><span class="va">split</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 3. Verify the split</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">train_data</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span><span class="op">(</span><span class="va">test_data</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-4-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-4-2-tab">
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Check Class Imbalance</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df[<span class="st">'defaulted'</span>].value_counts(normalize<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Stratified Split</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co"># We use 'stratify=y' to ensure both sets have the same % of defaults</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df.drop(columns<span class="op">=</span>[<span class="st">'defaulted'</span>])</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'defaulted'</span>]</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    X, y, </span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    test_size<span class="op">=</span><span class="fl">0.3</span>, </span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    random_state<span class="op">=</span><span class="dv">123</span>, </span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    stratify<span class="op">=</span>y  <span class="co"># Crucial for imbalanced data</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Verify the split</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training set shape: </span><span class="sc">{</span>X_train<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Testing set shape: </span><span class="sc">{</span>X_test<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<hr></section></section><section id="fitting-the-binary-logistic-regression-model" class="level2" data-number="8.5"><h2 data-number="8.5" class="anchored" data-anchor-id="fitting-the-binary-logistic-regression-model">
<span class="header-section-number">8.5</span> Fitting the Binary Logistic Regression Model</h2>
<p>Now that we’ve prepared the data, we fit the model. Our goal is to estimate the unknown parameters (<span class="math inline">\(\beta\)</span>) that link our predictors (like <code>credit_score</code>) to the probability of default.</p>
<hr>
<section id="model-specification" class="level3" data-number="8.5.1"><h3 data-number="8.5.1" class="anchored" data-anchor-id="model-specification">
<span class="header-section-number">8.5.1</span> Model Specification</h3>
<p>We define the relationship between the predictors and the probability of default <span class="math inline">\(\pi_i\)</span> as:</p>
<p><span class="math display">\[
\log\!\left(\frac{\pi_i}{1 - \pi_i}\right) = \beta_0 + \beta_1\,\text{credit\_score}_i + \beta_2\,\text{income}_i + \dots + \beta_k X_{ki}
\]</span></p>
<p>Here is what the parameters entail:</p>
<ul>
<li>
<span class="math inline">\(\pi_i\)</span>: The probability that the <span class="math inline">\(i\)</span>-th student defaults.</li>
<li>
<span class="math inline">\(\beta_0\)</span> (<strong>The Intercept</strong>): The expected log-odds of default when all predictors are zero. (Often theoretical, as no one has 0 credit score).</li>
<li>
<span class="math inline">\(\beta_1, \dots, \beta_k\)</span> (<strong>The Slopes</strong>): The change in the <strong>log-odds</strong> of default for a one-unit increase in the predictor, holding all other variables constant.</li>
</ul></section><section id="fitting-the-model" class="level3" data-number="8.5.2"><h3 data-number="8.5.2" class="anchored" data-anchor-id="fitting-the-model">
<span class="header-section-number">8.5.2</span> Fitting the Model</h3>
<p>To estimate these <span class="math inline">\(\beta\)</span> parameters, we use <strong>Maximum Likelihood Estimation (MLE)</strong>.</p>
<p>In R, we use the <code><a href="https://rdrr.io/r/stats/glm.html">glm()</a></code> function (Generalized Linear Model). Crucially, we must specify <code>family = binomial</code>.</p>
<ul>
<li><p><strong>Why <code>family = binomial</code>?</strong> Standard regression (OLS) assumes the target variable follows a <strong>Normal (Gaussian)</strong> distribution. However, our target is binary (0/1), which follows a <strong>Bernoulli/Binomial</strong> distribution. This argument tells the software to switch from “Least Squares” to “Maximum Likelihood” using the binomial distribution.</p></li>
<li><p><strong>Why Logit?</strong> By default, <code>family = binomial</code> uses the <strong>logit</strong> link function. While other links exist (like <em>probit</em>), the logit is preferred for its interpretability (odds ratios) and mathematical properties.</p></li>
</ul>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-5-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-1" role="tab" aria-controls="tabset-5-1" aria-selected="true">R Code</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-5-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-5-2" role="tab" aria-controls="tabset-5-2" aria-selected="false">Python Code</a></li>
</ul>
<div class="tab-content">
<div id="tabset-5-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-5-1-tab">
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Fit the model using Generalized Linear Model (glm)</span></span>
<span><span class="co"># family = binomial automatically defaults to link = "logit"</span></span>
<span><span class="va">fit_glm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">defaulted</span> <span class="op">~</span> <span class="va">credit_score</span> <span class="op">+</span> <span class="va">income</span> <span class="op">+</span> <span class="va">age</span> <span class="op">+</span> <span class="va">loan_amount</span> <span class="op">+</span> <span class="va">student</span>,</span>
<span>               data <span class="op">=</span> <span class="va">BLR</span>,</span>
<span>               family <span class="op">=</span> <span class="va">binomial</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">fit_glm</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-5-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-5-2-tab">
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Define Predictors (X) and Target (y)</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Note: We access the R dataframe 'BLR' using 'r.BLR'</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> r.BLR</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df[[<span class="st">'credit_score'</span>, <span class="st">'income'</span>, <span class="st">'age'</span>, <span class="st">'loan_amount'</span>, <span class="st">'student'</span>]]</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'defaulted'</span>]</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Add Intercept manually (Statsmodels does not add it by default)</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(X)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Fit the Logit model</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> sm.Logit(y, X).fit()</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section><section id="model-output-interpretation" class="level3" data-number="8.5.3"><h3 data-number="8.5.3" class="anchored" data-anchor-id="model-output-interpretation">
<span class="header-section-number">8.5.3</span> Model Output Interpretation</h3>
<p>The output table provides the <strong>Estimate</strong> (the <span class="math inline">\(\beta\)</span> coefficients) for each predictor.</p>
<ul>
<li>
<strong>Positive Coefficient (+):</strong> As this variable increases, the log-odds of default <em>increase</em> (Higher Risk).</li>
<li>
<strong>Negative Coefficient (-):</strong> As this variable increases, the log-odds of default <em>decrease</em> (Lower Risk).</li>
</ul>
<p>In the next section, we will convert these raw log-odds into <strong>Odds Ratios</strong>, which are much easier to interpret for business decisions.</p>
<hr></section></section><section id="interpreting-model-results-log-odds-and-odds-ratios" class="level2" data-number="8.6"><h2 data-number="8.6" class="anchored" data-anchor-id="interpreting-model-results-log-odds-and-odds-ratios">
<span class="header-section-number">8.6</span> Interpreting Model Results: Log-Odds and Odds Ratios</h2>
<p>In the previous section, we fit a model with several predictors. To clearly demonstrate how to interpret the coefficients, let’s focus on a simplified model using just two key variables: <code>credit_score</code> and <code>income</code>.</p>
<section id="the-log-odds-output" class="level3" data-number="8.6.1"><h3 data-number="8.6.1" class="anchored" data-anchor-id="the-log-odds-output">
<span class="header-section-number">8.6.1</span> The “Log-Odds” Output</h3>
<p>By default, logistic regression software outputs coefficients (<span class="math inline">\(\hat{\beta}\)</span>) in <strong>log-odds</strong>.</p>
<ul>
<li>
<strong>R:</strong> The <code>estimate</code> column.</li>
<li>
<strong>Python:</strong> The <code>coef</code> column.</li>
</ul>
<p>While mathematically necessary, log-odds are difficult for humans to visualize. (e.g., <em>“What does a -0.004 change in log-odds mean?”</em>).</p>
</section><section id="the-odds-ratio-or" class="level3" data-number="8.6.2"><h3 data-number="8.6.2" class="anchored" data-anchor-id="the-odds-ratio-or">
<span class="header-section-number">8.6.2</span> The “Odds Ratio” (OR)</h3>
<p>To make these numbers interpretable, we exponentiate the coefficients: <span class="math display">\[\text{OR} = e^{\hat{\beta}}\]</span></p>
<ul>
<li>
<strong>If <span class="math inline">\(\text{OR} &gt; 1\)</span>:</strong> The predictor is associated with <strong>higher</strong> odds of default.</li>
<li>
<strong>If <span class="math inline">\(\text{OR} &lt; 1\)</span>:</strong> The predictor is associated with <strong>lower</strong> odds of default.</li>
<li>
<strong>If <span class="math inline">\(\text{OR} = 1\)</span>:</strong> No association.</li>
</ul>
<p>Below, we fit the simplified model and calculate the Odds Ratios with 95% Confidence Intervals.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-6-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-1" role="tab" aria-controls="tabset-6-1" aria-selected="true">R Code</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-6-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-6-2" role="tab" aria-controls="tabset-6-2" aria-selected="false">Python Code</a></li>
</ul>
<div class="tab-content">
<div id="tabset-6-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-6-1-tab">
<div class="cell">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Fit a simplified model for clear interpretation</span></span>
<span><span class="va">fit_simple</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span></span>
<span>  <span class="va">defaulted</span> <span class="op">~</span> <span class="va">credit_score</span> <span class="op">+</span> <span class="va">income</span>,</span>
<span>  data <span class="op">=</span> <span class="va">BLR</span>,</span>
<span>  family <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/family.html">binomial</a></span><span class="op">(</span>link <span class="op">=</span> <span class="st">"logit"</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># We use broom::tidy to easily extract coefficients and convert them</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://broom.tidymodels.org/">broom</a></span><span class="op">)</span></span>
<span><span class="va">coef_table</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://generics.r-lib.org/reference/tidy.html">tidy</a></span><span class="op">(</span><span class="va">fit_simple</span>, conf.int <span class="op">=</span> <span class="cn">TRUE</span>, conf.level <span class="op">=</span> <span class="fl">0.95</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Calculate Odds Ratios (OR) by exponentiating estimates and CIs</span></span>
<span><span class="va">coef_table</span><span class="op">$</span><span class="va">odds_ratio</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">coef_table</span><span class="op">$</span><span class="va">estimate</span><span class="op">)</span></span>
<span><span class="va">coef_table</span><span class="op">$</span><span class="va">or_low</span>     <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">coef_table</span><span class="op">$</span><span class="va">conf.low</span><span class="op">)</span></span>
<span><span class="va">coef_table</span><span class="op">$</span><span class="va">or_high</span>    <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">coef_table</span><span class="op">$</span><span class="va">conf.high</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Display the table</span></span>
<span><span class="fu">knitr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html">kable</a></span><span class="op">(</span></span>
<span>  <span class="va">coef_table</span><span class="op">[</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"term"</span>,<span class="st">"estimate"</span>,<span class="st">"std.error"</span>,<span class="st">"p.value"</span>,<span class="st">"odds_ratio"</span>,<span class="st">"or_low"</span>,<span class="st">"or_high"</span><span class="op">)</span><span class="op">]</span>,</span>
<span>  digits <span class="op">=</span> <span class="fl">4</span>,</span>
<span>  col.names <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Term"</span>,<span class="st">"Log-Odds (β)"</span>,<span class="st">"SE"</span>,<span class="st">"p"</span>,<span class="st">"Odds Ratio"</span>,<span class="st">"OR 2.5%"</span>,<span class="st">"OR 97.5%"</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-6-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-6-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Access the data from R</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> r.BLR</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(df[[<span class="st">'credit_score'</span>, <span class="st">'income'</span>]])</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'defaulted'</span>]</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the simplified model</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>logit_model <span class="op">=</span> sm.Logit(y, X).fit(disp<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Extract Parameters (Log-Odds)</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> logit_model.params</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>conf   <span class="op">=</span> logit_model.conf_int()</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Calculate Odds Ratios (OR)</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a><span class="co"># We exponentiate the log-odds to get the OR</span></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>odds_ratios <span class="op">=</span> np.exp(params)</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>conf_or     <span class="op">=</span> np.exp(conf)</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Create a clean summary table</span></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>results_table <span class="op">=</span> pd.DataFrame({</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Log-Odds (β)"</span>: params,</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">"p-value"</span>: logit_model.pvalues,</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Odds Ratio"</span>: odds_ratios,</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>    <span class="st">"OR 2.5%"</span>: conf_or[<span class="dv">0</span>],</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>    <span class="st">"OR 97.5%"</span>: conf_or[<span class="dv">1</span>]</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(results_table.<span class="bu">round</span>(<span class="dv">4</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p><strong>Interpretation of the Output</strong></p>
<ul>
<li>
<strong>Intercept:</strong> usually ignored in interpretation.</li>
<li>
<strong>credit_score:</strong> If the coefficient is <span class="math inline">\(\beta \approx -0.01\)</span>, then <span class="math inline">\(\text{OR} \approx 0.99\)</span>.
<ul>
<li>
<em>Meaning:</em> For every 1-point increase in credit score, the odds of default are multiplied by 0.99 (a ~1% decrease), holding income constant.</li>
</ul>
</li>
<li>
<strong>income:</strong> If the <span class="math inline">\(\text{OR} \approx 1.00\)</span>, the effect per dollar is tiny. In such cases, it is often useful to rescale the variable (e.g., income in $10k units) to see a meaningful effect size.</li>
</ul>
<hr></section></section><section id="from-log-odds-to-probabilities-simple-model" class="level2" data-number="8.7"><h2 data-number="8.7" class="anchored" data-anchor-id="from-log-odds-to-probabilities-simple-model">
<span class="header-section-number">8.7</span> From Log-Odds to Probabilities (Simple Model)</h2>
<p>To fully understand how the model converts abstract “log-odds” into a tangible “probability,” it is best to start with the simplest case: <strong>one predictor</strong>.</p>
<p>In a simple binary logistic regression, the relationship is:</p>
<p><span class="math display">\[
\hat{\pi} = \frac{1}{1 + e^{-(\hat{\beta}_0 + \hat{\beta}_1 X)}}
\]</span></p>
<p>Below, we fit a model using <strong>only</strong> <code>credit_score</code> to predict default. We will then calculate the predicted probability (<span class="math inline">\(\hat{\pi}\)</span>) for a student with a Low, Median, and High credit score.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-7-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-1" role="tab" aria-controls="tabset-7-1" aria-selected="true">R Code</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-7-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-7-2" role="tab" aria-controls="tabset-7-2" aria-selected="false">Python Code</a></li>
</ul>
<div class="tab-content">
<div id="tabset-7-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-7-1-tab">
<div class="cell">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># 1. Fit a Simple Model (1 Predictor)</span></span>
<span><span class="va">fit_simple</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">defaulted</span> <span class="op">~</span> <span class="va">credit_score</span>, data <span class="op">=</span> <span class="va">BLR</span>, family <span class="op">=</span> <span class="va">binomial</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 2. Define Scenarios: Low, Median, and High Credit Score</span></span>
<span><span class="co"># We pick the 25th, 50th, and 75th percentiles</span></span>
<span><span class="va">qs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/quantile.html">quantile</a></span><span class="op">(</span><span class="va">BLR</span><span class="op">$</span><span class="va">credit_score</span>, probs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span><span class="op">)</span>, na.rm <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span></span>
<span><span class="va">scenarios</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  scenario <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Low (25th %)"</span>, <span class="st">"Median (50th %)"</span>, <span class="st">"High (75th %)"</span><span class="op">)</span>,</span>
<span>  credit_score <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">qs</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 3. Calculate Linear Predictor (Log-Odds) and Probability</span></span>
<span><span class="co"># type = "link" gives log-odds (eta)</span></span>
<span><span class="co"># type = "response" gives probability (pi)</span></span>
<span><span class="va">scenarios</span><span class="op">$</span><span class="va">log_odds</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">fit_simple</span>, newdata <span class="op">=</span> <span class="va">scenarios</span>, type <span class="op">=</span> <span class="st">"link"</span><span class="op">)</span></span>
<span><span class="va">scenarios</span><span class="op">$</span><span class="va">prob_pi</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">fit_simple</span>, newdata <span class="op">=</span> <span class="va">scenarios</span>, type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Display Results</span></span>
<span><span class="fu">knitr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/knitr/man/kable.html">kable</a></span><span class="op">(</span></span>
<span>  <span class="va">scenarios</span>,</span>
<span>  digits <span class="op">=</span> <span class="fl">3</span>,</span>
<span>  col.names <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Scenario"</span>, <span class="st">"Credit Score"</span>, <span class="st">"Log-Odds (η)"</span>, <span class="st">"Probability (π)"</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="tabset-7-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-7-2-tab">
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Fit a Simple Model (1 Predictor)</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co"># We define X with only credit_score</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>X_simple <span class="op">=</span> sm.add_constant(df[[<span class="st">'credit_score'</span>]])</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'defaulted'</span>]</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>model_simple <span class="op">=</span> sm.Logit(y, X_simple).fit(disp<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Define Scenarios</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>qs <span class="op">=</span> df[<span class="st">'credit_score'</span>].quantile([<span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>]).values</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>scenarios <span class="op">=</span> pd.DataFrame({</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'const'</span>: <span class="fl">1.0</span>, </span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">'credit_score'</span>: qs</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>}, index<span class="op">=</span>[<span class="st">"Low (25th %)"</span>, <span class="st">"Median (50th %)"</span>, <span class="st">"High (75th %)"</span>])</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Calculate Linear Predictor and Probability manually</span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a><span class="co"># eta = beta0 + beta1 * score</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>eta <span class="op">=</span> np.dot(scenarios, model_simple.params)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a><span class="co"># pi = 1 / (1 + e^-eta)</span></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>pi  <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> np.exp(<span class="op">-</span>eta))</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Display Results</span></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>results <span class="op">=</span> pd.DataFrame({</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Credit Score"</span>: scenarios[<span class="st">'credit_score'</span>],</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Log-Odds (η)"</span>: eta,</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Probability (π)"</span>: pi</span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(results.<span class="bu">round</span>(<span class="dv">3</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</div>
<p><strong>Interpretation</strong></p>
<ul>
<li>
<strong>At Low Credit Score:</strong> The log-odds are likely positive (or less negative), resulting in a higher probability (<span class="math inline">\(\pi\)</span>) of default.</li>
<li>
<strong>At High Credit Score:</strong> The log-odds become strongly negative. Because of the exponent in the denominator (<span class="math inline">\(e^{-\text{negative}}\)</span> is large), the probability <span class="math inline">\(\pi\)</span> shrinks toward 0.</li>
</ul>
<p>This demonstrates the <strong>inverse relationship</strong>: as credit score goes <em>up</em>, the probability of default goes <em>down</em>, following the S-curve shape we saw earlier.</p>
<p><strong>Next Steps:</strong> Now that we understand the mechanics of the simple model, we can expand our view. Real-world problems are rarely caused by a single factor. In the following sections, we will add more variables (like <code>income</code> and <code>student</code> status) to build a <strong>multiple</strong> logistic regression model.</p>
<hr></section><section id="data-preparation-and-wrangling" class="level2" data-number="8.8"><h2 data-number="8.8" class="anchored" data-anchor-id="data-preparation-and-wrangling">
<span class="header-section-number">8.8</span> Data Preparation and Wrangling</h2>
<p>Before we can train a model, we must bridge the gap between how data is <em>collected</em> and how a regression model <em>consumes</em> it. Raw data is often messy, incomplete, or stored in text formats that mathematical algorithms cannot process.</p>
<p>Data wrangling ensures our inputs are <strong>reliable</strong> (free of errors), <strong>complete</strong> (no missing values), and <strong>structured</strong> (numerical matrices). Without this step, even the most sophisticated algorithm will fail—a principle known as “Garbage In, Garbage Out.”</p>
<section id="handling-missing-data" class="level3" data-number="8.8.1"><h3 data-number="8.8.1" class="anchored" data-anchor-id="handling-missing-data">
<span class="header-section-number">8.8.1</span> Handling Missing Data</h3>
<p>Real-world datasets frequently have gaps—a borrower might leave the “Income” field blank. Logistic regression requires a complete set of observations; it cannot calculate a coefficient for a “blank” space.</p>
<p>We must first check the extent of the problem. If only a few rows have missing data, we typically remove them.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Strategies for Missing Values
</div>
</div>
<div class="callout-body-container callout-body">
<p>When data is missing, you have three main options:</p>
<ol type="1">
<li>
<strong>Deletion (Complete Case Analysis):</strong> If missingness is rare (&lt;5% of data) and random, simply remove those rows. This is the most common approach in introductory texts.</li>
<li>
<strong>Imputation:</strong> Replace missing values with the mean, median, or a value predicted by other variables. This preserves sample size but adds complexity.</li>
<li>
<strong>Flagging:</strong> Create a new binary variable (e.g., <code>income_missing = 1</code>) to model the missingness explicitly.</li>
</ol>
</div>
</div>
</section><section id="encoding-categorical-variables" class="level3" data-number="8.8.2"><h3 data-number="8.8.2" class="anchored" data-anchor-id="encoding-categorical-variables">
<span class="header-section-number">8.8.2</span> Encoding Categorical Variables</h3>
<p>Logistic regression works with <strong>matrices of numbers</strong>. It cannot mathematically multiply a coefficient <span class="math inline">\(\beta\)</span> by the text string “Married.”</p>
<p>To fix this, we perform <strong>One-Hot Encoding</strong> (or Dummy Encoding). This converts a categorical variable into a binary 0/1 flag.</p>
<ul>
<li>
<strong>Original:</strong> <code>student = "Yes"</code>
</li>
<li>
<strong>Encoded:</strong> <code>student_yes = 1</code>
</li>
</ul>
<p><strong>Note on Multicollinearity:</strong> If a variable has two categories (Student: Yes/No), we only need <strong>one</strong> column (<code>is_student</code>). If we included both <code>student_yes</code> and <code>student_no</code>, they would be perfectly correlated, causing the math to break (the “Dummy Variable Trap”).</p>
</section><section id="splitting-the-data" class="level3" data-number="8.8.3"><h3 data-number="8.8.3" class="anchored" data-anchor-id="splitting-the-data">
<span class="header-section-number">8.8.3</span> Splitting the Data</h3>
<p>Finally, as discussed in the study design, we split our clean, encoded dataset into training and testing sets to evaluate performance fairly.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-8-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-1" role="tab" aria-controls="tabset-8-1" aria-selected="true">R Code</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-8-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-8-2" role="tab" aria-controls="tabset-8-2" aria-selected="false">Python Code</a></li>
</ul>
<div class="tab-content">
<div id="tabset-8-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-8-1-tab">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://dplyr.tidyverse.org">dplyr</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/topepo/caret/">caret</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 1. Handling Missing Data</span></span>
<span><span class="co"># We check for NAs and, for this chapter, remove incomplete rows</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/NA.html">is.na</a></span><span class="op">(</span><span class="va">BLR</span><span class="op">)</span><span class="op">)</span> </span>
<span><span class="va">BLR_clean</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/na.fail.html">na.omit</a></span><span class="op">(</span><span class="va">BLR</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 2. Encoding</span></span>
<span><span class="co"># R handles factor encoding automatically in glm(), </span></span>
<span><span class="co"># but it is good practice to ensure variables are factors.</span></span>
<span><span class="va">BLR_clean</span> <span class="op">&lt;-</span> <span class="va">BLR_clean</span> <span class="op"><a href="https://magrittr.tidyverse.org/reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span></span>
<span>    student <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">student</span><span class="op">)</span>,</span>
<span>    married <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">married</span><span class="op">)</span>,</span>
<span>    owns_home <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">owns_home</span><span class="op">)</span></span>
<span>  <span class="op">)</span></span>
<span></span>
<span><span class="co"># 3. Splitting (Stratified to handle class imbalance)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">trainIndex</span> <span class="op">&lt;-</span> <span class="fu">createDataPartition</span><span class="op">(</span><span class="va">BLR_clean</span><span class="op">$</span><span class="va">defaulted</span>, p <span class="op">=</span> <span class="fl">0.7</span>, list <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">train_data</span> <span class="op">&lt;-</span> <span class="va">BLR_clean</span><span class="op">[</span><span class="va">trainIndex</span>, <span class="op">]</span></span>
<span><span class="va">test_data</span>  <span class="op">&lt;-</span> <span class="va">BLR_clean</span><span class="op">[</span><span class="op">-</span><span class="va">trainIndex</span>, <span class="op">]</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-8-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-8-2-tab">
<div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Handling Missing Data</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Drop rows with any missing values</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>df_clean <span class="op">=</span> df.dropna().copy()</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Encoding Categorical Variables</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co"># We use pd.get_dummies to convert text categories to 0s and 1s.</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="co"># drop_first=True prevents the "Dummy Variable Trap" (e.g., keeps 'student_Yes', drops 'student_No')</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>df_clean <span class="op">=</span> pd.get_dummies(df_clean, columns<span class="op">=</span>[<span class="st">'student'</span>, <span class="st">'married'</span>, <span class="st">'owns_home'</span>], drop_first<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the new columns to verify</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_clean.head())</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Splitting (Stratified)</span></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df_clean.drop(columns<span class="op">=</span>[<span class="st">'defaulted'</span>])</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df_clean[<span class="st">'defaulted'</span>]</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">123</span>, stratify<span class="op">=</span>y</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<hr></section></section><section id="exploratory-data-analysis-eda" class="level2" data-number="8.9"><h2 data-number="8.9" class="anchored" data-anchor-id="exploratory-data-analysis-eda">
<span class="header-section-number">8.9</span> Exploratory Data Analysis (EDA)</h2>
<p>Before fitting a logistic regression, we need to understand the structure of our data. Exploratory analysis helps us spot patterns, distributions, and potential issues.</p>
<section id="classifying-variables" class="level3" data-number="8.9.1"><h3 data-number="8.9.1" class="anchored" data-anchor-id="classifying-variables">
<span class="header-section-number">8.9.1</span> Classifying Variables</h3>
<p>To select the appropriate modeling technique, we must first classify our variables. In this analysis, <code>defaulted</code> is our binary outcome, and the remaining variables serve as <strong>regressors</strong> (explanatory variables).</p>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 25%">
</colgroup>
<thead><tr class="header">
<th style="text-align: left;">Variable</th>
<th style="text-align: left;">Type</th>
<th style="text-align: left;">Role</th>
<th style="text-align: left;">Description</th>
</tr></thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><code>defaulted</code></td>
<td style="text-align: left;">Categorical (Binary)</td>
<td style="text-align: left;">Outcome (<span class="math inline">\(Y\)</span>)</td>
<td style="text-align: left;">
<span class="math inline">\(1=\)</span> Default, <span class="math inline">\(0=\)</span> No Default</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>credit_score</code></td>
<td style="text-align: left;">Continuous (Integer)</td>
<td style="text-align: left;">Regressor (<span class="math inline">\(X\)</span>)</td>
<td style="text-align: left;">Credit rating (300-850)</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>income</code></td>
<td style="text-align: left;">Continuous</td>
<td style="text-align: left;">Regressor (<span class="math inline">\(X\)</span>)</td>
<td style="text-align: left;">Annual income in CAD</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>age</code></td>
<td style="text-align: left;">Continuous (Integer)</td>
<td style="text-align: left;">Regressor (<span class="math inline">\(X\)</span>)</td>
<td style="text-align: left;">Borrower age in years</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>loan_amount</code></td>
<td style="text-align: left;">Continuous</td>
<td style="text-align: left;">Regressor (<span class="math inline">\(X\)</span>)</td>
<td style="text-align: left;">Size of loan in CAD</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>education_years</code></td>
<td style="text-align: left;">Count / Discrete</td>
<td style="text-align: left;">Regressor (<span class="math inline">\(X\)</span>)</td>
<td style="text-align: left;">Years of schooling</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><code>married</code></td>
<td style="text-align: left;">Categorical (Nominal)</td>
<td style="text-align: left;">Regressor (<span class="math inline">\(X\)</span>)</td>
<td style="text-align: left;">Marital status</td>
</tr>
<tr class="even">
<td style="text-align: left;"><code>owns_home</code></td>
<td style="text-align: left;">Categorical (Nominal)</td>
<td style="text-align: left;">Regressor (<span class="math inline">\(X\)</span>)</td>
<td style="text-align: left;">Home ownership status</td>
</tr>
</tbody>
</table></section><section id="visualizing-distributions" class="level3" data-number="8.9.2"><h3 data-number="8.9.2" class="anchored" data-anchor-id="visualizing-distributions">
<span class="header-section-number">8.9.2</span> Visualizing Distributions</h3>
<ul>
<li>
<strong>Continuous regressors</strong> (e.g., <code>credit_score</code>, <code>income</code>) can be visualized with histograms or density plots, split by default status.</li>
<li>
<strong>Categorical regressors</strong> (e.g., <code>married</code>, <code>owns_home</code>) can be compared with barplots of default rates.</li>
</ul></section><section id="exploring-relationships-with-binary-outcome" class="level3" data-number="8.9.3"><h3 data-number="8.9.3" class="anchored" data-anchor-id="exploring-relationships-with-binary-outcome">
<span class="header-section-number">8.9.3</span> Exploring Relationships with Binary Outcome</h3>
<p>Boxplots or violin plots of <code>credit_score</code> by default status, or barplots of default rates by home ownership, help reveal potential relationships. We also check correlations among continuous regressors to watch for multicollinearity.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-9-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-9-1" role="tab" aria-controls="tabset-9-1" aria-selected="true">R Code</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-9-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-9-2" role="tab" aria-controls="tabset-9-2" aria-selected="false">Python Code</a></li>
</ul>
<div class="tab-content">
<div id="tabset-9-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-9-1-tab">
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.sthda.com/english/wiki/ggcorrplot-visualization-of-a-correlation-matrix-using-ggplot2">ggcorrplot</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Boxplot of credit score by default</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">BLR</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">defaulted</span><span class="op">)</span>, y <span class="op">=</span> <span class="va">credit_score</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_boxplot.html">geom_boxplot</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Defaulted"</span>, y <span class="op">=</span> <span class="st">"Credit Score"</span>, </span>
<span>       title <span class="op">=</span> <span class="st">"Credit Score Distribution by Default Status"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Barplot of default by home ownership</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">BLR</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">owns_home</span><span class="op">)</span>, fill <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">defaulted</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_bar.html">geom_bar</a></span><span class="op">(</span>position <span class="op">=</span> <span class="st">"fill"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Owns Home"</span>, y <span class="op">=</span> <span class="st">"Proportion"</span>, </span>
<span>       fill <span class="op">=</span> <span class="st">"Defaulted"</span>,</span>
<span>       title <span class="op">=</span> <span class="st">"Default Rates by Home Ownership"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Correlation heatmap (Numeric regressors only)</span></span>
<span><span class="va">corr</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/cor.html">cor</a></span><span class="op">(</span><span class="va">BLR</span><span class="op">[</span>,<span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"credit_score"</span>,<span class="st">"income"</span>,<span class="st">"education_years"</span>,<span class="st">"age"</span><span class="op">)</span><span class="op">]</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/ggcorrplot/man/ggcorrplot.html">ggcorrplot</a></span><span class="op">(</span><span class="va">corr</span>, lab <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-9-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-9-2-tab">
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Boxplot credit score by default</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>sns.boxplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">"defaulted"</span>, y<span class="op">=</span><span class="st">"credit_score"</span>)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Credit Score Distribution by Default Status"</span>)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Barplot default by home ownership</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>sns.barplot(data<span class="op">=</span>df, x<span class="op">=</span><span class="st">"owns_home"</span>, y<span class="op">=</span><span class="st">"defaulted"</span>, errorbar<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Default Rates by Home Ownership"</span>)</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Correlation heatmap</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>corr <span class="op">=</span> df[[<span class="st">'credit_score'</span>,<span class="st">'income'</span>,<span class="st">'education_years'</span>,<span class="st">'age'</span>]].corr()</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>sns.heatmap(corr, annot<span class="op">=</span><span class="va">True</span>, cmap<span class="op">=</span><span class="st">"coolwarm"</span>)</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Correlation Heatmap of Continuous Regressors"</span>)</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<hr></section></section><section id="data-modelling" class="level2" data-number="8.10"><h2 data-number="8.10" class="anchored" data-anchor-id="data-modelling">
<span class="header-section-number">8.10</span> Data Modelling</h2>
<p>With EDA complete, we’re ready to formally specify our logistic regression model.</p>
<section id="choosing-a-logistic-regression-model" class="level3" data-number="8.10.1"><h3 data-number="8.10.1" class="anchored" data-anchor-id="choosing-a-logistic-regression-model">
<span class="header-section-number">8.10.1</span> Choosing a Logistic Regression Model</h3>
<p>The response variable is binary: <code>defaulted</code> <span class="math inline">\(\in \{0,1\}\)</span>. Logistic regression is appropriate because it models the probability of the event occurring (<span class="math inline">\(\pi_i\)</span>) rather than the raw outcome.</p>
</section><section id="defining-the-probability-distribution" class="level3" data-number="8.10.2"><h3 data-number="8.10.2" class="anchored" data-anchor-id="defining-the-probability-distribution">
<span class="header-section-number">8.10.2</span> Defining the Probability Distribution</h3>
<p>Unlike linear regression, we do not model <span class="math inline">\(Y_i\)</span> directly. Instead, we assume that the outcome follows a <strong>Bernoulli distribution</strong>:</p>
<p><span class="math display">\[
Y_i \sim \text{Bernoulli}(\pi_i)
\]</span> where <span class="math inline">\(\pi_i\)</span> is the probability that the <span class="math inline">\(i\)</span>-th customer defaults.</p>
</section><section id="setting-up-the-logistic-regression-equation" class="level3" data-number="8.10.3"><h3 data-number="8.10.3" class="anchored" data-anchor-id="setting-up-the-logistic-regression-equation">
<span class="header-section-number">8.10.3</span> Setting Up the Logistic Regression Equation</h3>
<p>We link the regressors to the probability <span class="math inline">\(\pi_i\)</span> using the logit function:</p>
<p><span class="math display">\[\log\left(\frac{\pi_i}{1 - \pi_i}\right) = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \dots + \beta_k X_{ki}
\]</span></p>
</section><section id="the-missing-error-term-epsilon" class="level3" data-number="8.10.4"><h3 data-number="8.10.4" class="anchored" data-anchor-id="the-missing-error-term-epsilon">
<span class="header-section-number">8.10.4</span> The Missing Error Term (<span class="math inline">\(\epsilon\)</span>)</h3>
<p>You may notice a key difference here compared to OLS equations (<span class="math inline">\(Y = \beta X + \epsilon\)</span>): <strong>there is no error term</strong> <span class="math inline">\(\epsilon\)</span> at the end of the equation.</p>
<ul>
<li>In OLS, <span class="math inline">\(\epsilon\)</span> captures random noise around the mean.</li>
<li>In Logistic Regression, the randomness is inherent in the <strong>Bernoulli distribution</strong> of <span class="math inline">\(Y\)</span> itself. Once we know <span class="math inline">\(\pi_i\)</span> (the probability), the randomness comes from the “coin flip” of whether the event actually happens or not. We do not add an extra error term to the log-odds equation.</li>
</ul></section><section id="counting-the-parameters" class="level3" data-number="8.10.5"><h3 data-number="8.10.5" class="anchored" data-anchor-id="counting-the-parameters">
<span class="header-section-number">8.10.5</span> Counting the Parameters</h3>
<p>If we fit a model using <code>credit_score</code> and <code>income</code> to predict default, we are estimating <strong>3 parameters</strong>:</p>
<ol type="1">
<li>
<span class="math inline">\(\beta_0\)</span>: The intercept.</li>
<li>
<span class="math inline">\(\beta_1\)</span>: The coefficient for <code>credit_score</code>.</li>
<li>
<span class="math inline">\(\beta_2\)</span>: The coefficient for <code>income</code>.</li>
</ol>
<p>Generally, if we have <span class="math inline">\(k\)</span> regressors, we estimate <span class="math inline">\(k+1\)</span> parameters.</p>
<hr>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-10-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-10-1" role="tab" aria-controls="tabset-10-1" aria-selected="true">R Code</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-10-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-10-2" role="tab" aria-controls="tabset-10-2" aria-selected="false">Python Code</a></li>
</ul>
<div class="tab-content">
<div id="tabset-10-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-10-1-tab">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Fit the full model</span></span>
<span><span class="co"># We use family = binomial to indicate Y ~ Bernoulli(pi)</span></span>
<span><span class="va">logit_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">defaulted</span> <span class="op">~</span> <span class="va">credit_score</span> <span class="op">+</span> <span class="va">income</span> <span class="op">+</span> <span class="va">married</span> <span class="op">+</span> <span class="va">owns_home</span>,</span>
<span>                   data <span class="op">=</span> <span class="va">BLR</span>, family <span class="op">=</span> <span class="va">binomial</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">logit_model</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-10-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-10-2-tab">
<div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Define Regressors (X) and Outcome (y)</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure categorical variables are encoded (if not done in wrangling step)</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> df[[<span class="st">'credit_score'</span>,<span class="st">'income'</span>,<span class="st">'married_Yes'</span>,<span class="st">'owns_home_Yes'</span>]] </span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(X)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'defaulted'</span>]</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>logit_model <span class="op">=</span> sm.Logit(y, X).fit()</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(logit_model.summary())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<hr></section></section><section id="estimation" class="level2" data-number="8.11"><h2 data-number="8.11" class="anchored" data-anchor-id="estimation">
<span class="header-section-number">8.11</span> Estimation</h2>
<p>Under a model with <span class="math inline">\(k\)</span> regressors, the coefficients <span class="math inline">\(\beta_0,\beta_1,\ldots,\beta_k\)</span> are unknown and must be estimated from the data.</p>
<section id="maximum-likelihood-estimation-mle" class="level3" data-number="8.11.1"><h3 data-number="8.11.1" class="anchored" data-anchor-id="maximum-likelihood-estimation-mle">
<span class="header-section-number">8.11.1</span> Maximum Likelihood Estimation (MLE)</h3>
<p>Because our outcome <span class="math inline">\(Y_i\)</span> follows a Bernoulli distribution with probability <span class="math inline">\(\pi_i\)</span>, we cannot use “Least Squares.” Instead, we use <strong>Maximum Likelihood Estimation</strong>.</p>
<p>We seek the values of <span class="math inline">\(\beta\)</span> that maximize the likelihood of observing the data we actually collected. The likelihood function is:</p>
<p><span class="math display">\[
L(\boldsymbol\beta)=\prod_{i=1}^n \pi_i^{y_i}(1-\pi_i)^{1-y_i}
\]</span> Where <span class="math inline">\(\pi_i\)</span> is connected to our regressors via the inverse-logit:</p>
<p><span class="math display">\[\pi_i=\frac{e^{\beta_0 + \dots + \beta_k X_{ki}}}{1+e^{\beta_0 + \dots + \beta_k X_{ki}}}
\]</span> The computer solves this using an iterative algorithm (Newton-Raphson) to find the <span class="math inline">\(\hat{\beta}\)</span> values that make the observed defaults most probable.</p>
<hr></section></section><section id="estimation-1" class="level2" data-number="8.12"><h2 data-number="8.12" class="anchored" data-anchor-id="estimation-1">
<span class="header-section-number">8.12</span> Estimation</h2>
<p>Under a model with <span class="math inline">\(k\)</span> regressors, the coefficients <span class="math inline">\(\beta_0,\beta_1,\ldots,\beta_k\)</span> are unknown and must be estimated from the data.</p>
<section id="maximum-likelihood-estimation-mle-1" class="level3" data-number="8.12.1"><h3 data-number="8.12.1" class="anchored" data-anchor-id="maximum-likelihood-estimation-mle-1">
<span class="header-section-number">8.12.1</span> Maximum Likelihood Estimation (MLE)</h3>
<p>Because our outcome <span class="math inline">\(Y_i\)</span> follows a Bernoulli distribution with probability <span class="math inline">\(\pi_i\)</span>, we cannot use “Least Squares.” Instead, we use <strong>Maximum Likelihood Estimation</strong>.</p>
<p>We seek the values of <span class="math inline">\(\beta\)</span> that maximize the likelihood of observing the data we actually collected. The likelihood function is:</p>
<p><span class="math display">\[
L(\boldsymbol\beta)=\prod_{i=1}^n \pi_i^{y_i}(1-\pi_i)^{1-y_i}
\]</span>Where <span class="math inline">\(\pi_i\)</span> is connected to our regressors via the inverse-logit:</p>
<p><span class="math display">\[\\pi\_i=\\frac{e^{\\beta\_0 + \\dots + \\beta\_k X\_{ki}}}{1+e^{\\beta\_0 + \\dots + \\beta\_k X\_{ki}}}
\]</span>The computer solves this using an iterative algorithm (Newton-Raphson) to find the <span class="math inline">\(\hat{\beta}\)</span> values that make the observed defaults most probable.</p>
<hr></section></section><section id="inference" class="level2" data-number="8.13"><h2 data-number="8.13" class="anchored" data-anchor-id="inference">
<span class="header-section-number">8.13</span> Inference</h2>
<p>After estimating a logistic regression model, we often want to know whether predictors are <strong>statistically significant</strong> — i.e., whether they have a meaningful relationship with the probability of default. In logistic regression, inference is based on the <strong>likelihood framework</strong>.</p>
<section id="wald-tests" class="level3" data-number="8.13.1"><h3 data-number="8.13.1" class="anchored" data-anchor-id="wald-tests">
<span class="header-section-number">8.13.1</span> Wald Tests</h3>
<p>The <strong>Wald test</strong> checks whether an individual coefficient is significantly different from zero. For example, we can test whether <code>credit_score</code> has a nonzero effect on the odds of default. The test statistic is the ratio of the estimated coefficient to its standard error.</p>
</section><section id="likelihood-ratio-tests" class="level3" data-number="8.13.2"><h3 data-number="8.13.2" class="anchored" data-anchor-id="likelihood-ratio-tests">
<span class="header-section-number">8.13.2</span> Likelihood Ratio Tests</h3>
<p>We can also compare <strong>nested models</strong> (e.g., model with <code>credit_score</code> only vs.&nbsp;model with <code>credit_score + income</code>) using the <strong>likelihood ratio (LR) test</strong>. This evaluates whether adding predictors significantly improves model fit.</p>
</section><section id="confidence-intervals" class="level3" data-number="8.13.3"><h3 data-number="8.13.3" class="anchored" data-anchor-id="confidence-intervals">
<span class="header-section-number">8.13.3</span> Confidence Intervals</h3>
<p>Finally, we often report <strong>confidence intervals for odds ratios</strong>. For example, if the odds ratio for credit score is 0.99 with a 95% CI [0.98, 0.995], we can say with confidence that higher credit scores reduce the odds of default.</p>
<p><strong>TODOs for this section:</strong></p>
<ul>
<li>Wald test output for credit score and income.</li>
<li>Likelihood ratio test comparing one- vs.&nbsp;two-predictor models.</li>
<li>Confidence intervals for odds ratios, reported in plain language.</li>
</ul>
<hr>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-11-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-11-1" role="tab" aria-controls="tabset-11-1" aria-selected="true">R Code</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-11-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-11-2" role="tab" aria-controls="tabset-11-2" aria-selected="false">Python Code</a></li>
</ul>
<div class="tab-content">
<div id="tabset-11-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-11-1-tab">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Logistic regression</span></span>
<span><span class="va">logit_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">defaulted</span> <span class="op">~</span> <span class="va">credit_score</span> <span class="op">+</span> <span class="va">income</span>,</span>
<span>                   data <span class="op">=</span> <span class="va">BLR</span>, family <span class="op">=</span> <span class="va">binomial</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Wald test results are included in summary</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">logit_model</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Confidence intervals for odds ratios</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span>OR <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">logit_model</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/confint.html">confint</a></span><span class="op">(</span><span class="va">logit_model</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Likelihood ratio test for nested models</span></span>
<span><span class="va">model1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">defaulted</span> <span class="op">~</span> <span class="va">credit_score</span>, data <span class="op">=</span> <span class="va">BLR</span>, family <span class="op">=</span> <span class="va">binomial</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">model1</span>, <span class="va">logit_model</span>, test <span class="op">=</span> <span class="st">"Chisq"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-11-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-11-2-tab">
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> chi2</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> r.data[<span class="st">'BLR'</span>].copy()</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'defaulted'</span>] <span class="op">=</span> df[<span class="st">'defaulted'</span>].astype(<span class="bu">int</span>)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Full model</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>X_full <span class="op">=</span> sm.add_constant(df[[<span class="st">'credit_score'</span>,<span class="st">'income'</span>]])</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'defaulted'</span>]</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>model_full <span class="op">=</span> sm.Logit(y, X_full).fit()</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Wald test (coeff / SE)</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>wald_stats <span class="op">=</span> (model_full.params <span class="op">/</span> model_full.bse)<span class="op">**</span><span class="dv">2</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Wald test chi2 values:</span><span class="ch">\n</span><span class="st">"</span>, wald_stats)</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Confidence intervals for odds ratios</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>conf <span class="op">=</span> model_full.conf_int()</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>odds_ratios <span class="op">=</span> np.exp(model_full.params)</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>conf_exp <span class="op">=</span> np.exp(conf)</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Odds Ratios:</span><span class="ch">\n</span><span class="st">"</span>, pd.DataFrame({<span class="st">"OR"</span>: odds_ratios,</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>                                      <span class="st">"2.5%"</span>: conf_exp[<span class="dv">0</span>],</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>                                      <span class="st">"97.5%"</span>: conf_exp[<span class="dv">1</span>]}))</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Likelihood ratio test vs simpler model</span></span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>X_simple <span class="op">=</span> sm.add_constant(df[[<span class="st">'credit_score'</span>]])</span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>model_simple <span class="op">=</span> sm.Logit(y, X_simple).fit()</span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>LR_stat <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> (model_full.llf <span class="op">-</span> model_simple.llf)</span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>df_diff <span class="op">=</span> model_full.df_model <span class="op">-</span> model_simple.df_model</span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>p_value <span class="op">=</span> chi2.sf(LR_stat, df_diff)</span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"LR Test: chi2=</span><span class="sc">{</span>LR_stat<span class="sc">:.2f}</span><span class="ss">, df=</span><span class="sc">{</span>df_diff<span class="sc">}</span><span class="ss">, p=</span><span class="sc">{</span>p_value<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<hr></section></section><section id="coefficient-interpretation" class="level2" data-number="8.14"><h2 data-number="8.14" class="anchored" data-anchor-id="coefficient-interpretation">
<span class="header-section-number">8.14</span> Coefficient Interpretation</h2>
<p>Once we’ve established that predictors matter, the next step is to <strong>interpret the coefficients</strong> in a meaningful way.</p>
<section id="odds-ratios-and-their-meaning" class="level3" data-number="8.14.1"><h3 data-number="8.14.1" class="anchored" data-anchor-id="odds-ratios-and-their-meaning">
<span class="header-section-number">8.14.1</span> Odds Ratios and Their Meaning</h3>
<p>Logistic regression coefficients are expressed in <strong>log-odds units</strong>. To make them interpretable, we exponentiate them to obtain <strong>odds ratios</strong>.</p>
<ul>
<li>Example: If the coefficient for credit score is -0.01, the odds ratio is about 0.99.</li>
<li>Interpretation: each 1-point increase in credit score reduces the odds of default by about 1%.</li>
</ul>
<p>Scaling makes interpretation clearer:</p>
<ul>
<li>A <strong>50-point increase</strong> in credit score reduces the odds of default by roughly 40%.</li>
<li>For income, if the odds ratio is 1.00001, it means that each additional dollar increases odds only slightly — so we might instead interpret per <strong>$10,000 increase</strong>.</li>
</ul></section><section id="pitfalls-in-interpretation" class="level3" data-number="8.14.2"><h3 data-number="8.14.2" class="anchored" data-anchor-id="pitfalls-in-interpretation">
<span class="header-section-number">8.14.2</span> Pitfalls in Interpretation</h3>
<p>It’s important to remember that odds ratios are <strong>multiplicative</strong>, not additive. This means the effect on probability depends on the baseline. For example:</p>
<ul>
<li>Going from a 40% chance of default to 30% is a big shift,</li>
<li>But the same odds ratio may translate into a much smaller change if the baseline probability is already low (e.g., from 5% to 4%).</li>
</ul>
<p>Clear communication requires translating odds ratios back into <strong>probability changes</strong> for meaningful scenarios.</p>
</section><section id="example-from-loan-default-dataset" class="level3" data-number="8.14.3"><h3 data-number="8.14.3" class="anchored" data-anchor-id="example-from-loan-default-dataset">
<span class="header-section-number">8.14.3</span> Example from Loan Default Dataset</h3>
<p>Suppose our model finds:</p>
<ul>
<li>OR for credit score = 0.99 → each point decrease in odds of default by 1%.</li>
<li>OR for income = 0.95 per $10,000 → higher income slightly reduces default risk.</li>
</ul>
<p>We can then present this in plain English:</p>
<blockquote class="blockquote">
<p>“A borrower with a credit score of 700 has about a 10% chance of default, but with a score of 600, their probability rises to nearly 30%, holding income constant.”</p>
</blockquote>
<p><strong>TODOs for this section:</strong></p>
<ul>
<li>Report odds ratios with 95% CI for credit score and income.</li>
<li>Translate coefficients into real-world terms (per 50-point change in credit score, per $10k change in income).</li>
<li>Add figure showing predicted probability curve vs.&nbsp;credit score.</li>
</ul>
<hr>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-12-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-12-1" role="tab" aria-controls="tabset-12-1" aria-selected="true">R Code</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-12-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-12-2" role="tab" aria-controls="tabset-12-2" aria-selected="false">Python Code</a></li>
</ul>
<div class="tab-content">
<div id="tabset-12-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-12-1-tab">
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Logistic regression</span></span>
<span><span class="va">logit_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">defaulted</span> <span class="op">~</span> <span class="va">credit_score</span> <span class="op">+</span> <span class="va">income</span>,</span>
<span>                   data <span class="op">=</span> <span class="va">BLR</span>, family <span class="op">=</span> <span class="va">binomial</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Odds ratios and CI</span></span>
<span><span class="va">odds_ratios</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span>OR <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">logit_model</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/confint.html">confint</a></span><span class="op">(</span><span class="va">logit_model</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">odds_ratios</span></span>
<span></span>
<span><span class="co"># Example: probability at credit_score = 600 vs 700</span></span>
<span><span class="va">new_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>credit_score <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">600</span>, <span class="fl">700</span><span class="op">)</span>,</span>
<span>                       income <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">BLR</span><span class="op">$</span><span class="va">income</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">logit_model</span>, newdata <span class="op">=</span> <span class="va">new_data</span>, type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-12-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-12-2-tab">
<div class="sourceCode" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Odds ratios</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> model_full.params</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>conf <span class="op">=</span> model_full.conf_int()</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>odds_ratios <span class="op">=</span> np.exp(params)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>conf_exp <span class="op">=</span> np.exp(conf)</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pd.DataFrame({<span class="st">"OR"</span>: odds_ratios,</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"2.5%"</span>: conf_exp[<span class="dv">0</span>],</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>                    <span class="st">"97.5%"</span>: conf_exp[<span class="dv">1</span>]}))</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: probability at 600 vs 700 credit score</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>test_data <span class="op">=</span> pd.DataFrame({</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">"const"</span>: <span class="dv">1</span>,</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">"credit_score"</span>: [<span class="dv">600</span>, <span class="dv">700</span>],</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">"income"</span>: [df[<span class="st">'income'</span>].mean(), df[<span class="st">'income'</span>].mean()]</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(model_full.predict(test_data))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<hr></section></section><section id="predictions" class="level2" data-number="8.15"><h2 data-number="8.15" class="anchored" data-anchor-id="predictions">
<span class="header-section-number">8.15</span> Predictions</h2>
<p>Once we’ve fit a logistic regression model, we can use it to generate <strong>predicted probabilities</strong> of default for each customer. These probabilities fall between 0 and 1 and tell us how likely the model thinks it is that a customer will default given their predictors.</p>
<section id="predicted-probabilities-vs.-predicted-classes" class="level3" data-number="8.15.1"><h3 data-number="8.15.1" class="anchored" data-anchor-id="predicted-probabilities-vs.-predicted-classes">
<span class="header-section-number">8.15.1</span> Predicted Probabilities vs.&nbsp;Predicted Classes</h3>
<p>Predicted probabilities can be turned into <strong>class predictions</strong> (default vs.&nbsp;no default) by applying a threshold, usually 0.5. Customers with probability ≥ 0.5 are classified as “default,” and those below as “no default.”</p>
<p>But in practice, the choice of threshold matters. If we lower the threshold to 0.3, we’ll catch more actual defaulters (higher <strong>sensitivity</strong>) but at the cost of more false alarms (lower <strong>specificity</strong>).</p>
</section><section id="evaluating-performance" class="level3" data-number="8.15.2"><h3 data-number="8.15.2" class="anchored" data-anchor-id="evaluating-performance">
<span class="header-section-number">8.15.2</span> Evaluating Performance</h3>
<p>To judge prediction quality, we use metrics such as:</p>
<ul>
<li>
<strong>Accuracy:</strong> proportion of correct predictions.</li>
<li>
<strong>Sensitivity (recall):</strong> proportion of true defaults correctly identified.</li>
<li>
<strong>Specificity:</strong> proportion of true non-defaults correctly identified.</li>
<li>
<strong>ROC curve &amp; AUC:</strong> performance across all thresholds, not just one.</li>
</ul>
<p>For our loan dataset, we might find that the model predicts non-defaults very well (high specificity) but misses some defaults (lower sensitivity). This trade-off is a central theme in logistic regression applications.</p>
<p><strong>TODOs for this section:</strong></p>
<ul>
<li>Insert confusion matrix for the loan dataset at threshold 0.5.</li>
<li>Add ROC curve and report AUC.</li>
<li>Discuss trade-offs between sensitivity and specificity with an example.</li>
</ul>
<hr>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-13-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-13-1" role="tab" aria-controls="tabset-13-1" aria-selected="true">R Code</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-13-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-13-2" role="tab" aria-controls="tabset-13-2" aria-selected="false">Python Code</a></li>
</ul>
<div class="tab-content">
<div id="tabset-13-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-13-1-tab">
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Logistic regression model</span></span>
<span><span class="va">logit_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">defaulted</span> <span class="op">~</span> <span class="va">credit_score</span> <span class="op">+</span> <span class="va">income</span>,</span>
<span>                   data <span class="op">=</span> <span class="va">BLR</span>, family <span class="op">=</span> <span class="va">binomial</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Predictions</span></span>
<span><span class="va">BLR</span><span class="op">$</span><span class="va">pred_prob</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">logit_model</span>, type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span></span>
<span><span class="va">BLR</span><span class="op">$</span><span class="va">pred_class</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">BLR</span><span class="op">$</span><span class="va">pred_prob</span> <span class="op">&gt;</span> <span class="fl">0.5</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Confusion matrix</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/topepo/caret/">caret</a></span><span class="op">)</span></span>
<span><span class="fu">confusionMatrix</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">BLR</span><span class="op">$</span><span class="va">pred_class</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">BLR</span><span class="op">$</span><span class="va">defaulted</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># ROC curve</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://xrobin.github.io/pROC/">pROC</a></span><span class="op">)</span></span>
<span><span class="va">roc_curve</span> <span class="op">&lt;-</span> <span class="fu">roc</span><span class="op">(</span><span class="va">BLR</span><span class="op">$</span><span class="va">defaulted</span>, <span class="va">BLR</span><span class="op">$</span><span class="va">pred_prob</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">roc_curve</span>, main<span class="op">=</span><span class="st">"ROC Curve for Loan Default Model"</span><span class="op">)</span></span>
<span><span class="fu">auc</span><span class="op">(</span><span class="va">roc_curve</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-13-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-13-2-tab">
<div class="sourceCode" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, classification_report, roc_curve, auc</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> r.data[<span class="st">'BLR'</span>].copy()</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'defaulted'</span>] <span class="op">=</span> df[<span class="st">'defaulted'</span>].astype(<span class="bu">int</span>)</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(df[[<span class="st">'credit_score'</span>,<span class="st">'income'</span>]])</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'defaulted'</span>]</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>logit_model <span class="op">=</span> sm.Logit(y, X).fit()</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'pred_prob'</span>] <span class="op">=</span> logit_model.predict(X)</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'pred_class'</span>] <span class="op">=</span> (df[<span class="st">'pred_prob'</span>] <span class="op">&gt;</span> <span class="fl">0.5</span>).astype(<span class="bu">int</span>)</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion matrix &amp; metrics</span></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(y, df[<span class="st">'pred_class'</span>]))</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y, df[<span class="st">'pred_class'</span>]))</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a><span class="co"># ROC curve</span></span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>fpr, tpr, thresholds <span class="op">=</span> roc_curve(y, df[<span class="st">'pred_prob'</span>])</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>roc_auc <span class="op">=</span> auc(fpr, tpr)</span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr, tpr, label<span class="op">=</span><span class="ss">f"AUC = </span><span class="sc">{</span>roc_auc<span class="sc">:.2f}</span><span class="ss">"</span>)</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>,<span class="dv">1</span>], [<span class="dv">0</span>,<span class="dv">1</span>], linestyle<span class="op">=</span><span class="st">"--"</span>, color<span class="op">=</span><span class="st">"grey"</span>)</span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"False Positive Rate"</span>)</span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"True Positive Rate"</span>)</span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"ROC Curve for Loan Default Model"</span>)</span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<hr></section></section><section id="goodness-of-fit-model-selection" class="level2" data-number="8.16"><h2 data-number="8.16" class="anchored" data-anchor-id="goodness-of-fit-model-selection">
<span class="header-section-number">8.16</span> Goodness of Fit &amp; Model Selection</h2>
<p>Evaluating whether our model is a “good” fit is just as important as making predictions. For logistic regression, the diagnostics differ from OLS.</p>
<section id="pseudo-r-squared-measures" class="level3" data-number="8.16.1"><h3 data-number="8.16.1" class="anchored" data-anchor-id="pseudo-r-squared-measures">
<span class="header-section-number">8.16.1</span> Pseudo R-Squared Measures</h3>
<p>Because we don’t have the same notion of variance explained as in OLS, we use <strong>pseudo R² measures</strong> (e.g., McFadden’s R²). These are useful for comparison, but don’t carry the same interpretation as R² in linear regression.</p>
</section><section id="analysis-of-deviance" class="level3" data-number="8.16.2"><h3 data-number="8.16.2" class="anchored" data-anchor-id="analysis-of-deviance">
<span class="header-section-number">8.16.2</span> Analysis of Deviance</h3>
<p>We can compare models using the <strong>deviance</strong> statistic, which measures how well the model fits relative to a saturated model. Lower deviance indicates better fit. Nested models (e.g., one with <code>credit_score</code> only vs.&nbsp;one with <code>credit_score + income</code>) can be compared using a likelihood ratio test.</p>
</section><section id="information-criteria" class="level3" data-number="8.16.3"><h3 data-number="8.16.3" class="anchored" data-anchor-id="information-criteria">
<span class="header-section-number">8.16.3</span> Information Criteria</h3>
<p>Another approach is to use <strong>information criteria</strong> such as:</p>
<ul>
<li><strong>AIC (Akaike Information Criterion)</strong></li>
<li><strong>BIC (Bayesian Information Criterion)</strong></li>
</ul>
<p>Both balance fit and complexity: lower AIC or BIC means a better trade-off. AIC tends to favor more complex models; BIC penalizes complexity more heavily.</p>
<p>For the loan default dataset, we might find that adding <code>income</code> improves fit according to AIC but not BIC, suggesting we need to decide between <strong>predictive accuracy</strong> and <strong>parsimony</strong>.</p>
<p><strong>TODOs for this section:</strong></p>
<ul>
<li>Report pseudo R² for the loan model.</li>
<li>Compare single-predictor vs.&nbsp;two-predictor models with deviance test.</li>
<li>Report AIC and BIC values.</li>
<li>Provide plain-language interpretation (e.g., “Adding income slightly improves model fit”).</li>
</ul>
<hr>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-14-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-14-1" role="tab" aria-controls="tabset-14-1" aria-selected="true">R Code</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-14-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-14-2" role="tab" aria-controls="tabset-14-2" aria-selected="false">Python Code</a></li>
</ul>
<div class="tab-content">
<div id="tabset-14-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-14-1-tab">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Fit models</span></span>
<span><span class="va">model1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">defaulted</span> <span class="op">~</span> <span class="va">credit_score</span>, data <span class="op">=</span> <span class="va">BLR</span>, family <span class="op">=</span> <span class="va">binomial</span><span class="op">)</span></span>
<span><span class="va">model2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">defaulted</span> <span class="op">~</span> <span class="va">credit_score</span> <span class="op">+</span> <span class="va">income</span>, data <span class="op">=</span> <span class="va">BLR</span>, family <span class="op">=</span> <span class="va">binomial</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Compare deviance (likelihood ratio test)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">model1</span>, <span class="va">model2</span>, test <span class="op">=</span> <span class="st">"Chisq"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Pseudo R-squared</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/atahk/pscl">pscl</a></span><span class="op">)</span></span>
<span><span class="fu">pR2</span><span class="op">(</span><span class="va">model2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># AIC and BIC</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/AIC.html">AIC</a></span><span class="op">(</span><span class="va">model1</span>, <span class="va">model2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/AIC.html">BIC</a></span><span class="op">(</span><span class="va">model1</span>, <span class="va">model2</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-14-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-14-2-tab">
<div class="sourceCode" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> r.data[<span class="st">'BLR'</span>].copy()</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'defaulted'</span>] <span class="op">=</span> df[<span class="st">'defaulted'</span>].astype(<span class="bu">int</span>)</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Model 1: credit score only</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>X1 <span class="op">=</span> sm.add_constant(df[[<span class="st">'credit_score'</span>]])</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>model1 <span class="op">=</span> sm.Logit(df[<span class="st">'defaulted'</span>], X1).fit()</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Model 2: credit score + income</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>X2 <span class="op">=</span> sm.add_constant(df[[<span class="st">'credit_score'</span>,<span class="st">'income'</span>]])</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>model2 <span class="op">=</span> sm.Logit(df[<span class="st">'defaulted'</span>], X2).fit()</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Likelihood ratio test</span></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>LR_stat <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> (model2.llf <span class="op">-</span> model1.llf)</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>df_diff <span class="op">=</span> model2.df_model <span class="op">-</span> model1.df_model</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> chi2</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>p_value <span class="op">=</span> chi2.sf(LR_stat, df_diff)</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Likelihood Ratio Test:"</span>, LR_stat, <span class="st">"df:"</span>, df_diff, <span class="st">"p:"</span>, p_value)</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a><span class="co"># AIC &amp; BIC</span></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Model 1 AIC/BIC:"</span>, model1.aic, model1.bic)</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Model 2 AIC/BIC:"</span>, model2.aic, model2.bic)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<hr></section></section><section id="model-diagnostics" class="level2" data-number="8.17"><h2 data-number="8.17" class="anchored" data-anchor-id="model-diagnostics">
<span class="header-section-number">8.17</span> Model Diagnostics</h2>
<p>Once we’ve estimated our logistic regression model, it’s important to check whether the model is <strong>well-specified</strong> and whether there are any <strong>problematic observations</strong> influencing the results. Diagnostics help us assess whether our predictions are trustworthy and whether model assumptions are being violated.</p>
<section id="deviance-residuals" class="level3" data-number="8.17.1"><h3 data-number="8.17.1" class="anchored" data-anchor-id="deviance-residuals">
<span class="header-section-number">8.17.1</span> Deviance Residuals</h3>
<p>In logistic regression, we don’t have “raw residuals” like in OLS. Instead, we use <strong>deviance residuals</strong>, which measure how far off each predicted probability is from the actual outcome. Large residuals may indicate observations the model struggles to predict — for instance, a borrower with a very high credit score who still defaulted.</p>
<p>Plotting deviance residuals can help detect such outliers.</p>
</section><section id="binned-residual-plots" class="level3" data-number="8.17.2"><h3 data-number="8.17.2" class="anchored" data-anchor-id="binned-residual-plots">
<span class="header-section-number">8.17.2</span> Binned Residual Plots</h3>
<p>Another way to check fit is with <strong>binned residual plots</strong>. Here, predicted probabilities are grouped (binned), and we compare average predicted probabilities with observed default rates in each bin. A well-calibrated model should show points lying close to the diagonal line (predicted = observed).</p>
<p>For our loan dataset, if the model predicts a 20% default rate for customers in a bin, then about 20% of those customers should actually have defaulted.</p>
</section><section id="detecting-influential-points" class="level3" data-number="8.17.3"><h3 data-number="8.17.3" class="anchored" data-anchor-id="detecting-influential-points">
<span class="header-section-number">8.17.3</span> Detecting Influential Points</h3>
<p>Finally, some individual cases may <strong>exert outsized influence</strong> on the model — often measured using statistics like <strong>Cook’s distance</strong> or <strong>leverage</strong>. For example, a single customer with an unusually low credit score but very high income may skew the coefficient estimates. Identifying such cases ensures that no single observation is disproportionately driving conclusions.</p>
<hr>
<p><strong>TODOs for this section:</strong></p>
<ul>
<li>Add plot of deviance residuals vs.&nbsp;predicted probabilities.</li>
<li>Add binned residual plot for calibration.</li>
<li>Add influence plot (highlighting high-leverage or influential cases).</li>
<li>Provide a short interpretation using the loan default dataset.</li>
</ul>
<hr>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-15-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-15-1" role="tab" aria-controls="tabset-15-1" aria-selected="true">R Code</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-15-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-15-2" role="tab" aria-controls="tabset-15-2" aria-selected="false">Python Code</a></li>
</ul>
<div class="tab-content">
<div id="tabset-15-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-15-1-tab">
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Logistic regression model</span></span>
<span><span class="va">logit_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">defaulted</span> <span class="op">~</span> <span class="va">credit_score</span> <span class="op">+</span> <span class="va">income</span>,</span>
<span>                   data <span class="op">=</span> <span class="va">BLR</span>, family <span class="op">=</span> <span class="va">binomial</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Deviance residuals</span></span>
<span><span class="va">residuals_dev</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/residuals.html">residuals</a></span><span class="op">(</span><span class="va">logit_model</span>, type <span class="op">=</span> <span class="st">"deviance"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Plot deviance residuals vs. predicted probabilities</span></span>
<span><span class="va">BLR</span><span class="op">$</span><span class="va">pred_prob</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">logit_model</span>, type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">BLR</span><span class="op">$</span><span class="va">pred_prob</span>, <span class="va">residuals_dev</span>,</span>
<span>     xlab <span class="op">=</span> <span class="st">"Predicted Probability"</span>,</span>
<span>     ylab <span class="op">=</span> <span class="st">"Deviance Residuals"</span>,</span>
<span>     main <span class="op">=</span> <span class="st">"Deviance Residuals vs Predicted Probability"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/abline.html">abline</a></span><span class="op">(</span>h <span class="op">=</span> <span class="fl">0</span>, col <span class="op">=</span> <span class="st">"red"</span>, lty <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Binned residual plot (using arm package)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://CRAN.R-project.org/package=arm">arm</a></span><span class="op">)</span></span>
<span><span class="fu">binnedplot</span><span class="op">(</span><span class="va">BLR</span><span class="op">$</span><span class="va">pred_prob</span>, <span class="va">residuals_dev</span>,</span>
<span>           xlab <span class="op">=</span> <span class="st">"Predicted Probability"</span>,</span>
<span>           ylab <span class="op">=</span> <span class="st">"Average Residual"</span>,</span>
<span>           main <span class="op">=</span> <span class="st">"Binned Residual Plot"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Influence measures</span></span>
<span><span class="va">influence_measures</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/influence.measures.html">influence.measures</a></span><span class="op">(</span><span class="va">logit_model</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">influence_measures</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-15-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-15-2-tab">
<div class="sourceCode" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Logistic regression</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> r.data[<span class="st">'BLR'</span>].copy()</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'defaulted'</span>] <span class="op">=</span> df[<span class="st">'defaulted'</span>].astype(<span class="bu">int</span>)</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(df[[<span class="st">'credit_score'</span>,<span class="st">'income'</span>]])</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'defaulted'</span>]</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>logit_model <span class="op">=</span> sm.Logit(y, X).fit()</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'pred_prob'</span>] <span class="op">=</span> logit_model.predict(X)</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Deviance residuals (via statsmodels residuals)</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>resid_dev <span class="op">=</span> logit_model.resid_dev</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot deviance residuals vs predicted probabilities</span></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>plt.scatter(df[<span class="st">'pred_prob'</span>], resid_dev, alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>plt.axhline(<span class="dv">0</span>, color<span class="op">=</span><span class="st">'red'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Predicted Probability"</span>)</span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Deviance Residuals"</span>)</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Deviance Residuals vs Predicted Probability"</span>)</span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Influence plot</span></span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a>sm.graphics.influence_plot(logit_model, criterion<span class="op">=</span><span class="st">"cooks"</span>)</span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<hr></section></section><section id="results" class="level2" data-number="8.18"><h2 data-number="8.18" class="anchored" data-anchor-id="results">
<span class="header-section-number">8.18</span> Results</h2>
<p>Once we’ve fit our logistic regression model, the next step is to <strong>present the results</strong>. Results can be organized into two complementary perspectives:</p>
<ol type="1">
<li>
<strong>Predictive Analysis</strong> — How well does our model classify customers into “default” vs.&nbsp;“non-default”?</li>
<li>
<strong>Inferential Analysis</strong> — What do the model’s coefficients tell us about the relationship between predictors (e.g., credit score, income) and the probability of default?</li>
</ol>
<section id="predictive-analysis" class="level3" data-number="8.18.1"><h3 data-number="8.18.1" class="anchored" data-anchor-id="predictive-analysis">
<span class="header-section-number">8.18.1</span> Predictive Analysis</h3>
<p>From a predictive standpoint, the model provides <strong>predicted probabilities</strong> for each customer. By applying a threshold (commonly 0.5), we can classify customers as predicted to default or not.</p>
<p>We then evaluate performance using:</p>
<ul>
<li>
<strong>Accuracy:</strong> The proportion of correct predictions.</li>
<li>
<strong>Sensitivity (Recall):</strong> How well the model detects actual defaults.</li>
<li>
<strong>Specificity:</strong> How well the model detects non-defaults.</li>
<li>
<strong>ROC Curve / AUC:</strong> Performance across all possible thresholds.</li>
</ul>
<p>For example, in our loan dataset, the model correctly classifies a high proportion of non-defaulters, but sensitivity may be lower if defaults are relatively rare.</p>
</section><section id="inferential-analysis" class="level3" data-number="8.18.2"><h3 data-number="8.18.2" class="anchored" data-anchor-id="inferential-analysis">
<span class="header-section-number">8.18.2</span> Inferential Analysis</h3>
<p>From an inferential perspective, the coefficients give us <strong>odds ratios</strong> that describe how predictors affect default risk.</p>
<p>For instance, a coefficient of <code>-0.01</code> for credit score corresponds to an <strong>odds ratio of 0.99</strong> — meaning that for every 1-point increase in credit score, the odds of defaulting decrease by about 1%. Scaled up, a <strong>50-point increase</strong> lowers the odds by roughly 40%.</p>
<p>By converting odds ratios into <strong>changes in probability</strong> at meaningful ranges of credit score, we provide a more intuitive interpretation for readers.</p>
<hr>
<p><strong>TODOs for this section:</strong></p>
<ul>
<li>Insert table summarizing model coefficients with odds ratios and confidence intervals.</li>
<li>Add classification table (confusion matrix) showing accuracy, sensitivity, specificity.</li>
<li>Include ROC curve for predictive storytelling.</li>
<li>Provide plain-language interpretation of at least one coefficient (credit score).</li>
</ul>
<hr>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-16-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-16-1" role="tab" aria-controls="tabset-16-1" aria-selected="true">R Code</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-16-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-16-2" role="tab" aria-controls="tabset-16-2" aria-selected="false">Python Code</a></li>
</ul>
<div class="tab-content">
<div id="tabset-16-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-16-1-tab">
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Fit logistic regression model</span></span>
<span><span class="va">logit_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">defaulted</span> <span class="op">~</span> <span class="va">credit_score</span> <span class="op">+</span> <span class="va">income</span>,</span>
<span>                   data <span class="op">=</span> <span class="va">BLR</span>, family <span class="op">=</span> <span class="va">binomial</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Summary for inference</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">logit_model</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Odds ratios with confidence intervals</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span>OR <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">logit_model</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/stats/confint.html">confint</a></span><span class="op">(</span><span class="va">logit_model</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Predictive evaluation</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/topepo/caret/">caret</a></span><span class="op">)</span></span>
<span><span class="va">pred_prob</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">logit_model</span>, type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span></span>
<span><span class="va">pred_class</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/ifelse.html">ifelse</a></span><span class="op">(</span><span class="va">pred_prob</span> <span class="op">&gt;</span> <span class="fl">0.5</span>, <span class="fl">1</span>, <span class="fl">0</span><span class="op">)</span></span>
<span><span class="fu">confusionMatrix</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">pred_class</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">BLR</span><span class="op">$</span><span class="va">defaulted</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># ROC curve</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://xrobin.github.io/pROC/">pROC</a></span><span class="op">)</span></span>
<span><span class="va">roc_curve</span> <span class="op">&lt;-</span> <span class="fu">roc</span><span class="op">(</span><span class="va">BLR</span><span class="op">$</span><span class="va">defaulted</span>, <span class="va">pred_prob</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">roc_curve</span>, main<span class="op">=</span><span class="st">"ROC Curve for Loan Default Model"</span><span class="op">)</span></span>
<span><span class="fu">auc</span><span class="op">(</span><span class="va">roc_curve</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-16-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-16-2-tab">
<div class="sourceCode" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> confusion_matrix, classification_report, roc_curve, auc</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Logistic regression</span></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> r.data[<span class="st">'BLR'</span>].copy()</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'defaulted'</span>] <span class="op">=</span> df[<span class="st">'defaulted'</span>].astype(<span class="bu">int</span>)</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(df[[<span class="st">'credit_score'</span>,<span class="st">'income'</span>]])</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'defaulted'</span>]</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>logit_model <span class="op">=</span> sm.Logit(y, X).fit()</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Inference: odds ratios</span></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> logit_model.params</span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>conf <span class="op">=</span> logit_model.conf_int()</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>odds_ratios <span class="op">=</span> pd.DataFrame({</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>    <span class="st">"OR"</span>: params.<span class="bu">apply</span>(<span class="kw">lambda</span> x: np.exp(x)),</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">"2.5%"</span>: conf[<span class="dv">0</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: np.exp(x)),</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>    <span class="st">"97.5%"</span>: conf[<span class="dv">1</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> x: np.exp(x))</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(odds_ratios)</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Predictions</span></span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'pred_prob'</span>] <span class="op">=</span> logit_model.predict(X)</span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'pred_class'</span>] <span class="op">=</span> (df[<span class="st">'pred_prob'</span>] <span class="op">&gt;</span> <span class="fl">0.5</span>).astype(<span class="bu">int</span>)</span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Confusion matrix &amp; report</span></span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(confusion_matrix(y, df[<span class="st">'pred_class'</span>]))</span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y, df[<span class="st">'pred_class'</span>]))</span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a><span class="co"># ROC Curve</span></span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a>fpr, tpr, thresholds <span class="op">=</span> roc_curve(y, df[<span class="st">'pred_prob'</span>])</span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a>roc_auc <span class="op">=</span> auc(fpr, tpr)</span>
<span id="cb31-35"><a href="#cb31-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-36"><a href="#cb31-36" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">4</span>))</span>
<span id="cb31-37"><a href="#cb31-37" aria-hidden="true" tabindex="-1"></a>plt.plot(fpr, tpr, color<span class="op">=</span><span class="st">'blue'</span>, label<span class="op">=</span><span class="ss">f'ROC curve (AUC = </span><span class="sc">{</span>roc_auc<span class="sc">:.2f}</span><span class="ss">)'</span>)</span>
<span id="cb31-38"><a href="#cb31-38" aria-hidden="true" tabindex="-1"></a>plt.plot([<span class="dv">0</span>,<span class="dv">1</span>], [<span class="dv">0</span>,<span class="dv">1</span>], color<span class="op">=</span><span class="st">'grey'</span>, linestyle<span class="op">=</span><span class="st">'--'</span>)</span>
<span id="cb31-39"><a href="#cb31-39" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"ROC Curve for Loan Default Model"</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb31-40"><a href="#cb31-40" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"False Positive Rate"</span>)</span>
<span id="cb31-41"><a href="#cb31-41" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"True Positive Rate"</span>)</span>
<span id="cb31-42"><a href="#cb31-42" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">"lower right"</span>)</span>
<span id="cb31-43"><a href="#cb31-43" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<hr></section></section><section id="storytelling" class="level2" data-number="8.19"><h2 data-number="8.19" class="anchored" data-anchor-id="storytelling">
<span class="header-section-number">8.19</span> Storytelling</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Effective storytelling connects statistical results to real-world meaning. Translate log-odds into “lenders are X times more likely to…” language.</p>
</div>
</div>
<p>The final step of our analysis is not just running the model, but <strong>communicating the findings</strong> clearly. Logistic regression results are often presented to stakeholders like lenders, policy makers, or managers, who may not be trained in statistics. For them, <strong>the story matters more than the math.</strong></p>
<p>Let’s revisit our loan default dataset. Suppose our logistic regression showed that <strong>credit score</strong> is strongly predictive of default:</p>
<ul>
<li>A 50-point increase in credit score reduces the odds of defaulting by about 40%.</li>
<li>In probability terms, this means that increasing credit score from 400 to 450 lowers the chance of default from roughly 70% to about 50%.</li>
</ul>
<p>Notice how we moved from the technical language of <strong>odds ratios</strong> to a <strong>plain-language probability story</strong>. This makes the model’s results accessible to a wider audience.</p>
<p>Visuals amplify the story:</p>
<ul>
<li>A plot of predicted probabilities vs.&nbsp;credit score shows the <strong>smooth S-shaped curve</strong> replacing the jagged OLS line.</li>
<li>A confusion matrix or ROC curve shows how well our model actually classifies defaulters.</li>
<li>Calibration plots show whether predicted probabilities line up with observed rates of default.</li>
</ul>
<p>Finally, good storytelling means acknowledging limitations. For example, our dataset may suffer from <strong>class imbalance</strong> (fewer defaults than non-defaults), which could bias results. We should be clear about what the model can and cannot do.</p>
<p><strong>TODOs for this section:</strong></p>
<ul>
<li>Add figure of predicted probabilities vs.&nbsp;actual defaults (using <code>credit_score</code>).</li>
<li>Show a ROC curve for the loan default model.</li>
<li>Add plain-language interpretations of coefficients (esp.&nbsp;odds ratio for <code>credit_score</code>).</li>
<li>Add a note about limitations (e.g., income and education may be correlated with credit score).</li>
</ul>
<hr>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist">
<li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-17-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-17-1" role="tab" aria-controls="tabset-17-1" aria-selected="true">R Code</a></li>
<li class="nav-item" role="presentation"><a class="nav-link" id="tabset-17-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-17-2" role="tab" aria-controls="tabset-17-2" aria-selected="false">Python Code</a></li>
</ul>
<div class="tab-content">
<div id="tabset-17-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-17-1-tab">
<div class="sourceCode" id="cb32"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span><span class="co"># Logistic regression on loan default data</span></span>
<span><span class="va">logit_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">defaulted</span> <span class="op">~</span> <span class="va">credit_score</span> <span class="op">+</span> <span class="va">income</span>,</span>
<span>                   data <span class="op">=</span> <span class="va">BLR</span>, family <span class="op">=</span> <span class="va">binomial</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Predicted probabilities</span></span>
<span><span class="va">BLR</span><span class="op">$</span><span class="va">pred_prob</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">logit_model</span>, type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Storytelling visualization</span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">BLR</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">credit_score</span>, y <span class="op">=</span> <span class="va">pred_prob</span>, color <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">as.factor</a></span><span class="op">(</span><span class="va">defaulted</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_smooth.html">geom_smooth</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"loess"</span>, se <span class="op">=</span> <span class="cn">FALSE</span>, color <span class="op">=</span> <span class="st">"black"</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span></span>
<span>    title <span class="op">=</span> <span class="st">"Predicted Probability of Default vs. Credit Score"</span>,</span>
<span>    x <span class="op">=</span> <span class="st">"Credit Score"</span>,</span>
<span>    y <span class="op">=</span> <span class="st">"Predicted Probability"</span>,</span>
<span>    color <span class="op">=</span> <span class="st">"Actual Default"</span></span>
<span>  <span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_minimal</a></span><span class="op">(</span><span class="op">)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tabset-17-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-17-2-tab">
<div class="sourceCode" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> statsmodels.api <span class="im">as</span> sm</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract loan default data</span></span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> r.data[<span class="st">'BLR'</span>].copy()</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'defaulted'</span>] <span class="op">=</span> df[<span class="st">'defaulted'</span>].astype(<span class="bu">int</span>)</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit logistic regression</span></span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> sm.add_constant(df[[<span class="st">'credit_score'</span>,<span class="st">'income'</span>]])</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> df[<span class="st">'defaulted'</span>]</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>logit_model <span class="op">=</span> sm.Logit(y, X).fit()</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'pred_prob'</span>] <span class="op">=</span> logit_model.predict(X)</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Storytelling visualization</span></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">4</span>))</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>scatter <span class="op">=</span> ax.scatter(df[<span class="st">'credit_score'</span>], df[<span class="st">'pred_prob'</span>],</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>                     c<span class="op">=</span>df[<span class="st">'defaulted'</span>], cmap<span class="op">=</span><span class="st">'coolwarm'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span class="st">"Predicted Probability of Default vs. Credit Score"</span>, fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="st">"Credit Score"</span>)</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="st">"Predicted Probability"</span>)</span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>legend1 <span class="op">=</span> ax.legend(<span class="op">*</span>scatter.legend_elements(), title<span class="op">=</span><span class="st">"Actual Default"</span>)</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>ax.add_artist(legend1)</span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>


</section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/alexrod61\.github\.io\/regression-cookbook\/");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
            // default icon
            link.classList.add("external");
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script><input type="hidden" id="giscus-base-theme" value="light"><input type="hidden" id="giscus-alt-theme" value="dark"><script>
  function loadGiscus() {
    // Function to get the theme based on body class
    const getTheme = () => {
      let baseTheme = document.getElementById('giscus-base-theme').value;
      let altTheme = document.getElementById('giscus-alt-theme').value;
      return document.body.classList.contains('quarto-dark') ? altTheme : baseTheme;
    };
    const script = document.createElement("script");
    script.src = "https://giscus.app/client.js";
    script.async = true;
    script.dataset.repo = "alexrod61/regression-cookbook";
    script.dataset.repoId = "R_kgDOMSJoUA";
    script.dataset.category = "General";
    script.dataset.categoryId = "";
    script.dataset.mapping = "title";
    script.dataset.reactionsEnabled = "1";
    script.dataset.emitMetadata = "0";
    script.dataset.inputPosition = "top";
    script.dataset.theme = getTheme();
    script.dataset.lang = "en";
    script.crossOrigin = "anonymous";
    // Append the script to the desired div instead of at the end of the body
    document.getElementById("quarto-content").appendChild(script);
  }
  loadGiscus();
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="../book/discrete-zone.html" class="pagination-link" aria-label="Discrete Cuisine">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Discrete Cuisine</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../book/09-binomial-logistic.html" class="pagination-link" aria-label="Cheesified Binomial Logistic Regression">
        <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Cheesified Binomial Logistic Regression</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">
<p>Copyright 2025; G. Alexi Rodríguez-Arelis, Andy Tai, and Ben Chen</p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    <div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/alexrod61/regression-cookbook/edit/main/book/08-binary-logistic.qmd" class="toc-action"><i class="bi bi-github"></i>Edit this page</a></li><li><a href="https://github.com/alexrod61/regression-cookbook/issues/new" class="toc-action"><i class="bi empty"></i>Report an issue</a></li><li><a href="https://github.com/alexrod61/regression-cookbook/blob/main/book/08-binary-logistic.qmd" class="toc-action"><i class="bi empty"></i>View source</a></li></ul></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>


<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>